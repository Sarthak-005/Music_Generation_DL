{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K7aKe_dRMqEM"
   },
   "outputs": [],
   "source": [
    "!unzip /content/drive/MyDrive/_ML_PROJECTS/Music_generation/music_generation.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ocYSLQwwM4Pv",
    "outputId": "c983c071-8db3-4258-a0b2-92931ad8b0eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
      "2022-07-23 07:01:25.686033: W tensorflow/core/data/root_dataset.cc:200] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "Batch 344: loss = 0.37838882207870483, acc = 0.8759765625\n",
      "Batch 345: loss = 0.37827005982398987, acc = 0.8779296875\n",
      "2022-07-23 07:01:25.742723: W tensorflow/core/data/root_dataset.cc:200] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "Batch 346: loss = 0.3646203875541687, acc = 0.8740234375\n",
      "Batch 347: loss = 0.4222048819065094, acc = 0.8603515625\n",
      "Batch 348: loss = 0.3801335096359253, acc = 0.8740234375\n",
      "Batch 349: loss = 0.35315051674842834, acc = 0.875\n",
      "Batch 350: loss = 0.3197069764137268, acc = 0.8857421875\n",
      "Batch 351: loss = 0.3671998977661133, acc = 0.876953125\n",
      "2022-07-23 07:01:25.918599: W tensorflow/core/data/root_dataset.cc:200] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "Batch 352: loss = 0.43076226115226746, acc = 0.849609375\n",
      "Batch 353: loss = 0.368716835975647, acc = 0.873046875\n",
      "Batch 354: loss = 0.3417763113975525, acc = 0.8818359375\n",
      "Batch 355: loss = 0.31662875413894653, acc = 0.8935546875\n",
      "Batch 356: loss = 0.32996100187301636, acc = 0.890625\n",
      "Batch 357: loss = 0.3616483807563782, acc = 0.873046875\n",
      "Batch 358: loss = 0.38059407472610474, acc = 0.8779296875\n",
      "Batch 359: loss = 0.40201830863952637, acc = 0.865234375\n",
      "Batch 360: loss = 0.3882879614830017, acc = 0.87890625\n",
      "Batch 361: loss = 0.3888098895549774, acc = 0.8671875\n",
      "Batch 362: loss = 0.3459789752960205, acc = 0.8798828125\n",
      "Batch 363: loss = 0.3933820426464081, acc = 0.86328125\n",
      "Batch 364: loss = 0.4172017276287079, acc = 0.84765625\n",
      "Batch 365: loss = 0.37749457359313965, acc = 0.8837890625\n",
      "Batch 366: loss = 0.3986814618110657, acc = 0.8671875\n",
      "Batch 367: loss = 0.3890359401702881, acc = 0.8720703125\n",
      "Batch 368: loss = 0.444089412689209, acc = 0.8544921875\n",
      "Batch 369: loss = 0.4677087068557739, acc = 0.8447265625\n",
      "Batch 370: loss = 0.3815371096134186, acc = 0.8662109375\n",
      "Batch 371: loss = 0.48543012142181396, acc = 0.8330078125\n",
      "Batch 372: loss = 0.3820188641548157, acc = 0.869140625\n",
      "Batch 373: loss = 0.42171764373779297, acc = 0.857421875\n",
      "Batch 374: loss = 0.45117321610450745, acc = 0.8525390625\n",
      "Batch 375: loss = 0.4637536406517029, acc = 0.8427734375\n",
      "Batch 376: loss = 0.4154765009880066, acc = 0.869140625\n",
      "Batch 377: loss = 0.4289133548736572, acc = 0.8447265625\n",
      "Batch 378: loss = 0.4413304030895233, acc = 0.8544921875\n",
      "Batch 379: loss = 0.4575364589691162, acc = 0.8515625\n",
      "Batch 380: loss = 0.3889845013618469, acc = 0.8701171875\n",
      "Batch 381: loss = 0.36184626817703247, acc = 0.873046875\n",
      "Batch 382: loss = 0.40608733892440796, acc = 0.86328125\n",
      "Batch 383: loss = 0.39268356561660767, acc = 0.8759765625\n",
      "2022-07-23 07:01:26.915109: W tensorflow/core/data/root_dataset.cc:200] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "Batch 384: loss = 0.4185321033000946, acc = 0.8466796875\n",
      "Batch 385: loss = 0.4486624300479889, acc = 0.84375\n",
      "Batch 386: loss = 0.38305503129959106, acc = 0.869140625\n",
      "Batch 387: loss = 0.4016787111759186, acc = 0.8642578125\n",
      "Batch 388: loss = 0.4183706045150757, acc = 0.857421875\n",
      "Batch 389: loss = 0.41847357153892517, acc = 0.8544921875\n",
      "Batch 390: loss = 0.46182477474212646, acc = 0.84765625\n",
      "Batch 391: loss = 0.41868355870246887, acc = 0.8583984375\n",
      "Batch 392: loss = 0.4393020272254944, acc = 0.8486328125\n",
      "Batch 393: loss = 0.48233479261398315, acc = 0.828125\n",
      "Batch 394: loss = 0.3969363570213318, acc = 0.869140625\n",
      "Batch 395: loss = 0.40233010053634644, acc = 0.8681640625\n",
      "Batch 396: loss = 0.4084716737270355, acc = 0.86328125\n",
      "Batch 397: loss = 0.31724417209625244, acc = 0.880859375\n",
      "Batch 398: loss = 0.3478514552116394, acc = 0.8759765625\n",
      "Batch 399: loss = 0.39430224895477295, acc = 0.8720703125\n",
      "2022-07-23 07:01:27.402859: W tensorflow/core/data/root_dataset.cc:200] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "Batch 400: loss = 0.3974316418170929, acc = 0.869140625\n",
      "2022-07-23 07:01:27.429647: W tensorflow/core/data/root_dataset.cc:200] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "Batch 401: loss = 0.42023518681526184, acc = 0.8681640625\n",
      "2022-07-23 07:01:27.456542: W tensorflow/core/data/root_dataset.cc:200] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "Batch 402: loss = 0.4010922610759735, acc = 0.87109375\n",
      "Batch 403: loss = 0.3818485736846924, acc = 0.8671875\n",
      "2022-07-23 07:01:27.522782: W tensorflow/core/data/root_dataset.cc:200] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "Batch 404: loss = 0.4493812918663025, acc = 0.8564453125\n",
      "Batch 405: loss = 0.4331550598144531, acc = 0.8583984375\n",
      "Batch 406: loss = 0.5106934309005737, acc = 0.83203125\n",
      "Batch 407: loss = 0.4369048476219177, acc = 0.8603515625\n",
      "2022-07-23 07:01:27.634849: W tensorflow/core/data/root_dataset.cc:200] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "Batch 408: loss = 0.5060358047485352, acc = 0.8330078125\n",
      "2022-07-23 07:01:27.661268: W tensorflow/core/data/root_dataset.cc:200] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "Batch 409: loss = 0.3997863531112671, acc = 0.86328125\n",
      "Batch 410: loss = 0.4716959595680237, acc = 0.8466796875\n",
      "2022-07-23 07:01:27.720592: W tensorflow/core/data/root_dataset.cc:200] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "Batch 411: loss = 0.4027412533760071, acc = 0.8818359375\n",
      "Batch 412: loss = 0.4203771650791168, acc = 0.853515625\n",
      "2022-07-23 07:01:27.788443: W tensorflow/core/data/root_dataset.cc:200] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "Batch 413: loss = 0.40974414348602295, acc = 0.8662109375\n",
      "2022-07-23 07:01:27.821151: W tensorflow/core/data/root_dataset.cc:200] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "Batch 414: loss = 0.39583754539489746, acc = 0.8671875\n",
      "Batch 415: loss = 0.4147959053516388, acc = 0.859375\n",
      "Batch 416: loss = 0.44739481806755066, acc = 0.8583984375\n",
      "Batch 417: loss = 0.44357314705848694, acc = 0.8583984375\n",
      "Batch 418: loss = 0.45492416620254517, acc = 0.8359375\n",
      "Batch 419: loss = 0.5523669719696045, acc = 0.8212890625\n",
      "Batch 420: loss = 0.4767252504825592, acc = 0.84375\n",
      "Batch 421: loss = 0.4695664942264557, acc = 0.8486328125\n",
      "Batch 422: loss = 0.49669015407562256, acc = 0.828125\n",
      "Batch 423: loss = 0.39577367901802063, acc = 0.8642578125\n",
      "Batch 424: loss = 0.48594313859939575, acc = 0.828125\n",
      "Batch 425: loss = 0.4228244125843048, acc = 0.8662109375\n",
      "2022-07-23 07:01:28.188026: W tensorflow/core/data/root_dataset.cc:200] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "Batch 426: loss = 0.4631955325603485, acc = 0.8330078125\n",
      "Batch 427: loss = 0.46095168590545654, acc = 0.85546875\n",
      "Batch 428: loss = 0.4130207300186157, acc = 0.859375\n",
      "Batch 429: loss = 0.3908705413341522, acc = 0.8623046875\n",
      "Batch 430: loss = 0.3576536476612091, acc = 0.8798828125\n",
      "Batch 431: loss = 0.40235865116119385, acc = 0.8623046875\n",
      "Batch 432: loss = 0.4351775348186493, acc = 0.83984375\n",
      "Batch 433: loss = 0.3522072732448578, acc = 0.880859375\n",
      "Batch 434: loss = 0.41691529750823975, acc = 0.859375\n",
      "Batch 435: loss = 0.4746429920196533, acc = 0.8388671875\n",
      "Batch 436: loss = 0.34263598918914795, acc = 0.8828125\n",
      "Batch 437: loss = 0.4445088505744934, acc = 0.8603515625\n",
      "Batch 438: loss = 0.43703407049179077, acc = 0.8505859375\n",
      "Batch 439: loss = 0.42263418436050415, acc = 0.8583984375\n",
      "Batch 440: loss = 0.4149664044380188, acc = 0.8564453125\n",
      "Batch 441: loss = 0.40086066722869873, acc = 0.8583984375\n",
      "\n",
      "Epoch 90/100\n",
      "Batch 1: loss = 0.523990273475647, acc = 0.84765625\n",
      "Batch 2: loss = 0.3978452980518341, acc = 0.8505859375\n",
      "Batch 3: loss = 0.4444778859615326, acc = 0.859375\n",
      "Batch 4: loss = 0.44887876510620117, acc = 0.8447265625\n",
      "Batch 5: loss = 0.4327796697616577, acc = 0.861328125\n",
      "Batch 6: loss = 0.370909184217453, acc = 0.87890625\n",
      "Batch 7: loss = 0.3797963857650757, acc = 0.873046875\n",
      "Batch 8: loss = 0.38525986671447754, acc = 0.8701171875\n",
      "Batch 9: loss = 0.4272676110267639, acc = 0.8486328125\n",
      "Batch 10: loss = 0.4153349995613098, acc = 0.8544921875\n",
      "Batch 11: loss = 0.4394634962081909, acc = 0.8408203125\n",
      "Batch 12: loss = 0.40489453077316284, acc = 0.8642578125\n",
      "Batch 13: loss = 0.4471784830093384, acc = 0.84765625\n",
      "Batch 14: loss = 0.38785409927368164, acc = 0.888671875\n",
      "Batch 15: loss = 0.3756405711174011, acc = 0.87109375\n",
      "Batch 16: loss = 0.4143098294734955, acc = 0.8720703125\n",
      "Batch 17: loss = 0.34919583797454834, acc = 0.888671875\n",
      "Batch 18: loss = 0.4401935935020447, acc = 0.85546875\n",
      "Batch 19: loss = 0.4416634738445282, acc = 0.8505859375\n",
      "Batch 20: loss = 0.4366592764854431, acc = 0.8486328125\n",
      "Batch 21: loss = 0.4463890790939331, acc = 0.8359375\n",
      "Batch 22: loss = 0.44841909408569336, acc = 0.8447265625\n",
      "Batch 23: loss = 0.453060120344162, acc = 0.8369140625\n",
      "Batch 24: loss = 0.421352356672287, acc = 0.8671875\n",
      "Batch 25: loss = 0.4600028991699219, acc = 0.8505859375\n",
      "Batch 26: loss = 0.42116987705230713, acc = 0.8505859375\n",
      "Batch 27: loss = 0.46233993768692017, acc = 0.8408203125\n",
      "Batch 28: loss = 0.3913862705230713, acc = 0.8681640625\n",
      "Batch 29: loss = 0.49880993366241455, acc = 0.828125\n",
      "Batch 30: loss = 0.42090874910354614, acc = 0.8515625\n",
      "Batch 31: loss = 0.4185560345649719, acc = 0.861328125\n",
      "Batch 32: loss = 0.37023138999938965, acc = 0.8779296875\n",
      "Batch 33: loss = 0.36006590723991394, acc = 0.8779296875\n",
      "Batch 34: loss = 0.33049190044403076, acc = 0.88671875\n",
      "Batch 35: loss = 0.3590462803840637, acc = 0.8896484375\n",
      "Batch 36: loss = 0.4264821708202362, acc = 0.8623046875\n",
      "Batch 37: loss = 0.3938312232494354, acc = 0.8681640625\n",
      "Batch 38: loss = 0.3807031214237213, acc = 0.869140625\n",
      "Batch 39: loss = 0.33792248368263245, acc = 0.8974609375\n",
      "Batch 40: loss = 0.3754189908504486, acc = 0.8828125\n",
      "Batch 41: loss = 0.37418273091316223, acc = 0.8818359375\n",
      "Batch 42: loss = 0.4560719132423401, acc = 0.841796875\n",
      "Batch 43: loss = 0.4311075210571289, acc = 0.8505859375\n",
      "Batch 44: loss = 0.48371291160583496, acc = 0.8291015625\n",
      "Batch 45: loss = 0.40088191628456116, acc = 0.8837890625\n",
      "Batch 46: loss = 0.3997897803783417, acc = 0.8564453125\n",
      "Batch 47: loss = 0.41918548941612244, acc = 0.857421875\n",
      "Batch 48: loss = 0.4012738764286041, acc = 0.8544921875\n",
      "Batch 49: loss = 0.40632736682891846, acc = 0.85546875\n",
      "Batch 50: loss = 0.46365615725517273, acc = 0.8359375\n",
      "Batch 51: loss = 0.4749455451965332, acc = 0.8349609375\n",
      "Batch 52: loss = 0.34790942072868347, acc = 0.873046875\n",
      "Batch 53: loss = 0.4404163956642151, acc = 0.8603515625\n",
      "Batch 54: loss = 0.4025864899158478, acc = 0.8603515625\n",
      "Batch 55: loss = 0.41864556074142456, acc = 0.8515625\n",
      "Batch 56: loss = 0.44906947016716003, acc = 0.8544921875\n",
      "Batch 57: loss = 0.4082374572753906, acc = 0.865234375\n",
      "Batch 58: loss = 0.4289487600326538, acc = 0.8515625\n",
      "Batch 59: loss = 0.4283806085586548, acc = 0.865234375\n",
      "Batch 60: loss = 0.3890572786331177, acc = 0.865234375\n",
      "Batch 61: loss = 0.4516109228134155, acc = 0.8359375\n",
      "Batch 62: loss = 0.45972123742103577, acc = 0.8515625\n",
      "Batch 63: loss = 0.43257126212120056, acc = 0.8427734375\n",
      "Batch 64: loss = 0.40664952993392944, acc = 0.875\n",
      "Batch 65: loss = 0.335794061422348, acc = 0.8828125\n",
      "Batch 66: loss = 0.41282904148101807, acc = 0.865234375\n",
      "Batch 67: loss = 0.4423701763153076, acc = 0.8544921875\n",
      "Batch 68: loss = 0.46984395384788513, acc = 0.8505859375\n",
      "Batch 69: loss = 0.4271811842918396, acc = 0.853515625\n",
      "Batch 70: loss = 0.43192949891090393, acc = 0.841796875\n",
      "Batch 71: loss = 0.43483349680900574, acc = 0.8515625\n",
      "Batch 72: loss = 0.4198330342769623, acc = 0.85546875\n",
      "Batch 73: loss = 0.42613667249679565, acc = 0.861328125\n",
      "Batch 74: loss = 0.42423200607299805, acc = 0.8623046875\n",
      "Batch 75: loss = 0.3648550808429718, acc = 0.876953125\n",
      "Batch 76: loss = 0.4221482276916504, acc = 0.8515625\n",
      "Batch 77: loss = 0.4650513231754303, acc = 0.828125\n",
      "Batch 78: loss = 0.45140576362609863, acc = 0.84375\n",
      "Batch 79: loss = 0.39663583040237427, acc = 0.859375\n",
      "Batch 80: loss = 0.4756600856781006, acc = 0.837890625\n",
      "Batch 81: loss = 0.37398454546928406, acc = 0.875\n",
      "Batch 82: loss = 0.4124060869216919, acc = 0.8447265625\n",
      "Batch 83: loss = 0.44739654660224915, acc = 0.857421875\n",
      "Batch 84: loss = 0.4166176915168762, acc = 0.8603515625\n",
      "Batch 85: loss = 0.4292393922805786, acc = 0.857421875\n",
      "Batch 86: loss = 0.434937447309494, acc = 0.857421875\n",
      "Batch 87: loss = 0.39962002635002136, acc = 0.8623046875\n",
      "Batch 88: loss = 0.4309099316596985, acc = 0.8466796875\n",
      "Batch 89: loss = 0.486747682094574, acc = 0.841796875\n",
      "Batch 90: loss = 0.44870156049728394, acc = 0.8447265625\n",
      "Batch 91: loss = 0.4213000237941742, acc = 0.8505859375\n",
      "Batch 92: loss = 0.433035671710968, acc = 0.841796875\n",
      "Batch 93: loss = 0.4500373303890228, acc = 0.83984375\n",
      "Batch 94: loss = 0.423470675945282, acc = 0.85546875\n",
      "Batch 95: loss = 0.42681100964546204, acc = 0.8525390625\n",
      "Batch 96: loss = 0.4044124484062195, acc = 0.861328125\n",
      "Batch 97: loss = 0.4197298288345337, acc = 0.859375\n",
      "Batch 98: loss = 0.47465959191322327, acc = 0.8310546875\n",
      "Batch 99: loss = 0.46222925186157227, acc = 0.83984375\n",
      "Batch 100: loss = 0.45207613706588745, acc = 0.837890625\n",
      "Batch 101: loss = 0.4012044668197632, acc = 0.8720703125\n",
      "Batch 102: loss = 0.39644259214401245, acc = 0.8603515625\n",
      "Batch 103: loss = 0.375848650932312, acc = 0.869140625\n",
      "Batch 104: loss = 0.3973884582519531, acc = 0.865234375\n",
      "Batch 105: loss = 0.39611390233039856, acc = 0.8720703125\n",
      "Batch 106: loss = 0.45889973640441895, acc = 0.8505859375\n",
      "Batch 107: loss = 0.4277779459953308, acc = 0.853515625\n",
      "Batch 108: loss = 0.42975544929504395, acc = 0.8623046875\n",
      "Batch 109: loss = 0.3552851676940918, acc = 0.888671875\n",
      "Batch 110: loss = 0.4013294279575348, acc = 0.8642578125\n",
      "Batch 111: loss = 0.5021505951881409, acc = 0.830078125\n",
      "Batch 112: loss = 0.41516557335853577, acc = 0.8642578125\n",
      "Batch 113: loss = 0.4090973436832428, acc = 0.87109375\n",
      "Batch 114: loss = 0.3565480709075928, acc = 0.8759765625\n",
      "Batch 115: loss = 0.45770183205604553, acc = 0.833984375\n",
      "Batch 116: loss = 0.415775865316391, acc = 0.8583984375\n",
      "Batch 117: loss = 0.4226836860179901, acc = 0.8701171875\n",
      "Batch 118: loss = 0.3891884386539459, acc = 0.880859375\n",
      "Batch 119: loss = 0.39838099479675293, acc = 0.8515625\n",
      "Batch 120: loss = 0.43386009335517883, acc = 0.8564453125\n",
      "Batch 121: loss = 0.3868512809276581, acc = 0.87109375\n",
      "Batch 122: loss = 0.36427512764930725, acc = 0.8759765625\n",
      "Batch 123: loss = 0.3912143111228943, acc = 0.869140625\n",
      "Batch 124: loss = 0.4416477084159851, acc = 0.8408203125\n",
      "Batch 125: loss = 0.37244942784309387, acc = 0.8759765625\n",
      "Batch 126: loss = 0.36622315645217896, acc = 0.890625\n",
      "Batch 127: loss = 0.4477010667324066, acc = 0.85546875\n",
      "Batch 128: loss = 0.3838889002799988, acc = 0.8642578125\n",
      "Batch 129: loss = 0.3613370358943939, acc = 0.875\n",
      "Batch 130: loss = 0.40733203291893005, acc = 0.853515625\n",
      "Batch 131: loss = 0.30847907066345215, acc = 0.8935546875\n",
      "Batch 132: loss = 0.3296646773815155, acc = 0.8916015625\n",
      "Batch 133: loss = 0.3340069055557251, acc = 0.8916015625\n",
      "Batch 134: loss = 0.38146746158599854, acc = 0.857421875\n",
      "Batch 135: loss = 0.42049357295036316, acc = 0.857421875\n",
      "Batch 136: loss = 0.3695303201675415, acc = 0.8837890625\n",
      "Batch 137: loss = 0.3447580635547638, acc = 0.8828125\n",
      "Batch 138: loss = 0.39720451831817627, acc = 0.8623046875\n",
      "Batch 139: loss = 0.3643564283847809, acc = 0.873046875\n",
      "Batch 140: loss = 0.39250823855400085, acc = 0.8681640625\n",
      "Batch 141: loss = 0.4421139359474182, acc = 0.8623046875\n",
      "Batch 142: loss = 0.39846354722976685, acc = 0.8662109375\n",
      "Batch 143: loss = 0.45503053069114685, acc = 0.845703125\n",
      "Batch 144: loss = 0.4501911997795105, acc = 0.841796875\n",
      "Batch 145: loss = 0.3667506277561188, acc = 0.869140625\n",
      "Batch 146: loss = 0.4379127025604248, acc = 0.8642578125\n",
      "Batch 147: loss = 0.4306775629520416, acc = 0.8544921875\n",
      "Batch 148: loss = 0.3755061626434326, acc = 0.8662109375\n",
      "Batch 149: loss = 0.37937667965888977, acc = 0.8671875\n",
      "Batch 150: loss = 0.42399609088897705, acc = 0.8603515625\n",
      "Batch 151: loss = 0.44679495692253113, acc = 0.83984375\n",
      "Batch 152: loss = 0.4008913040161133, acc = 0.86328125\n",
      "Batch 153: loss = 0.463894248008728, acc = 0.8349609375\n",
      "Batch 154: loss = 0.40036171674728394, acc = 0.8623046875\n",
      "Batch 155: loss = 0.3964275121688843, acc = 0.8681640625\n",
      "Batch 156: loss = 0.43767857551574707, acc = 0.8525390625\n",
      "Batch 157: loss = 0.4385160207748413, acc = 0.8583984375\n",
      "Batch 158: loss = 0.40806815028190613, acc = 0.861328125\n",
      "Batch 159: loss = 0.4425763189792633, acc = 0.8427734375\n",
      "Batch 160: loss = 0.40754222869873047, acc = 0.8671875\n",
      "Batch 161: loss = 0.4434542655944824, acc = 0.849609375\n",
      "Batch 162: loss = 0.4344845414161682, acc = 0.8466796875\n",
      "Batch 163: loss = 0.4181051254272461, acc = 0.8701171875\n",
      "Batch 164: loss = 0.41464880108833313, acc = 0.869140625\n",
      "Batch 165: loss = 0.4224090874195099, acc = 0.8447265625\n",
      "Batch 166: loss = 0.35145634412765503, acc = 0.876953125\n",
      "Batch 167: loss = 0.41001462936401367, acc = 0.85546875\n",
      "Batch 168: loss = 0.40800145268440247, acc = 0.87109375\n",
      "Batch 169: loss = 0.37784677743911743, acc = 0.8798828125\n",
      "Batch 170: loss = 0.3652266561985016, acc = 0.8720703125\n",
      "Batch 171: loss = 0.4236106872558594, acc = 0.85546875\n",
      "Batch 172: loss = 0.39190673828125, acc = 0.8642578125\n",
      "Batch 173: loss = 0.3669317364692688, acc = 0.8837890625\n",
      "Batch 174: loss = 0.37832456827163696, acc = 0.8759765625\n",
      "Batch 175: loss = 0.41084665060043335, acc = 0.8564453125\n",
      "Batch 176: loss = 0.42486390471458435, acc = 0.8662109375\n",
      "Batch 177: loss = 0.3701615333557129, acc = 0.8701171875\n",
      "Batch 178: loss = 0.40146327018737793, acc = 0.8662109375\n",
      "Batch 179: loss = 0.4341365098953247, acc = 0.8388671875\n",
      "Batch 180: loss = 0.3870990574359894, acc = 0.8740234375\n",
      "Batch 181: loss = 0.4354414939880371, acc = 0.8486328125\n",
      "Batch 182: loss = 0.4505549967288971, acc = 0.845703125\n",
      "Batch 183: loss = 0.38814684748649597, acc = 0.8671875\n",
      "Batch 184: loss = 0.4331913888454437, acc = 0.853515625\n",
      "Batch 185: loss = 0.4319167733192444, acc = 0.853515625\n",
      "Batch 186: loss = 0.4163523316383362, acc = 0.8623046875\n",
      "Batch 187: loss = 0.37640297412872314, acc = 0.8759765625\n",
      "Batch 188: loss = 0.39867329597473145, acc = 0.8603515625\n",
      "Batch 189: loss = 0.3499186635017395, acc = 0.8798828125\n",
      "Batch 190: loss = 0.407620906829834, acc = 0.8544921875\n",
      "Batch 191: loss = 0.4152863025665283, acc = 0.857421875\n",
      "Batch 192: loss = 0.38948142528533936, acc = 0.87890625\n",
      "Batch 193: loss = 0.45163631439208984, acc = 0.8408203125\n",
      "Batch 194: loss = 0.4248255789279938, acc = 0.861328125\n",
      "Batch 195: loss = 0.4632610082626343, acc = 0.841796875\n",
      "Batch 196: loss = 0.46373850107192993, acc = 0.8447265625\n",
      "Batch 197: loss = 0.48836398124694824, acc = 0.8447265625\n",
      "Batch 198: loss = 0.3744254410266876, acc = 0.875\n",
      "Batch 199: loss = 0.4756435453891754, acc = 0.8408203125\n",
      "Batch 200: loss = 0.45740988850593567, acc = 0.84375\n",
      "Batch 201: loss = 0.4504672884941101, acc = 0.8447265625\n",
      "Batch 202: loss = 0.4963914155960083, acc = 0.828125\n",
      "Batch 203: loss = 0.38897180557250977, acc = 0.8828125\n",
      "Batch 204: loss = 0.4383242726325989, acc = 0.841796875\n",
      "Batch 205: loss = 0.454036682844162, acc = 0.8525390625\n",
      "Batch 206: loss = 0.4026610851287842, acc = 0.857421875\n",
      "Batch 207: loss = 0.4575454294681549, acc = 0.84765625\n",
      "Batch 208: loss = 0.4235195219516754, acc = 0.861328125\n",
      "Batch 209: loss = 0.4478573799133301, acc = 0.8408203125\n",
      "Batch 210: loss = 0.37931951880455017, acc = 0.8798828125\n",
      "Batch 211: loss = 0.43784594535827637, acc = 0.84375\n",
      "Batch 212: loss = 0.45520418882369995, acc = 0.8544921875\n",
      "Batch 213: loss = 0.4376595616340637, acc = 0.857421875\n",
      "Batch 214: loss = 0.4331851899623871, acc = 0.857421875\n",
      "Batch 215: loss = 0.38274216651916504, acc = 0.876953125\n",
      "Batch 216: loss = 0.379634290933609, acc = 0.87109375\n",
      "Batch 217: loss = 0.36855190992355347, acc = 0.8798828125\n",
      "Batch 218: loss = 0.4158128499984741, acc = 0.8583984375\n",
      "Batch 219: loss = 0.4626982510089874, acc = 0.8515625\n",
      "Batch 220: loss = 0.401425302028656, acc = 0.865234375\n",
      "Batch 221: loss = 0.4657348394393921, acc = 0.841796875\n",
      "Batch 222: loss = 0.3784430921077728, acc = 0.8779296875\n",
      "Batch 223: loss = 0.37633126974105835, acc = 0.8759765625\n",
      "Batch 224: loss = 0.3661201000213623, acc = 0.880859375\n",
      "Batch 225: loss = 0.3569488525390625, acc = 0.8759765625\n",
      "Batch 226: loss = 0.40837231278419495, acc = 0.8583984375\n",
      "Batch 227: loss = 0.3722953200340271, acc = 0.875\n",
      "Batch 228: loss = 0.39653831720352173, acc = 0.869140625\n",
      "Batch 229: loss = 0.33970725536346436, acc = 0.888671875\n",
      "Batch 230: loss = 0.3980897068977356, acc = 0.8701171875\n",
      "Batch 231: loss = 0.4686982333660126, acc = 0.83203125\n",
      "Batch 232: loss = 0.41785702109336853, acc = 0.8623046875\n",
      "Batch 233: loss = 0.5374961495399475, acc = 0.828125\n",
      "Batch 234: loss = 0.3743187189102173, acc = 0.8759765625\n",
      "Batch 235: loss = 0.4330477714538574, acc = 0.8515625\n",
      "Batch 236: loss = 0.4457901418209076, acc = 0.857421875\n",
      "Batch 237: loss = 0.3706133961677551, acc = 0.888671875\n",
      "Batch 238: loss = 0.45456600189208984, acc = 0.8291015625\n",
      "Batch 239: loss = 0.3887780010700226, acc = 0.8662109375\n",
      "Batch 240: loss = 0.4533100128173828, acc = 0.853515625\n",
      "Batch 241: loss = 0.41688767075538635, acc = 0.86328125\n",
      "Batch 242: loss = 0.42106008529663086, acc = 0.865234375\n",
      "Batch 243: loss = 0.43315935134887695, acc = 0.841796875\n",
      "Batch 244: loss = 0.5102723836898804, acc = 0.8330078125\n",
      "Batch 245: loss = 0.42669081687927246, acc = 0.8701171875\n",
      "Batch 246: loss = 0.4316834509372711, acc = 0.8603515625\n",
      "Batch 247: loss = 0.4290580153465271, acc = 0.85546875\n",
      "Batch 248: loss = 0.38918939232826233, acc = 0.869140625\n",
      "Batch 249: loss = 0.39394718408584595, acc = 0.8681640625\n",
      "Batch 250: loss = 0.43459397554397583, acc = 0.85546875\n",
      "Batch 251: loss = 0.3855457603931427, acc = 0.873046875\n",
      "Batch 252: loss = 0.377393513917923, acc = 0.8818359375\n",
      "Batch 253: loss = 0.46380093693733215, acc = 0.8251953125\n",
      "Batch 254: loss = 0.43945762515068054, acc = 0.8369140625\n",
      "Batch 255: loss = 0.48500022292137146, acc = 0.84375\n",
      "Batch 256: loss = 0.45102429389953613, acc = 0.8583984375\n",
      "Batch 257: loss = 0.5200519561767578, acc = 0.833984375\n",
      "Batch 258: loss = 0.4531550705432892, acc = 0.8330078125\n",
      "Batch 259: loss = 0.5385891795158386, acc = 0.8232421875\n",
      "Batch 260: loss = 0.533240020275116, acc = 0.80859375\n",
      "Batch 261: loss = 0.4413067400455475, acc = 0.8515625\n",
      "Batch 262: loss = 0.44620805978775024, acc = 0.833984375\n",
      "Batch 263: loss = 0.4384132921695709, acc = 0.841796875\n",
      "Batch 264: loss = 0.38255196809768677, acc = 0.869140625\n",
      "Batch 265: loss = 0.4010521471500397, acc = 0.8740234375\n",
      "Batch 266: loss = 0.3907073140144348, acc = 0.8818359375\n",
      "Batch 267: loss = 0.36041170358657837, acc = 0.876953125\n",
      "Batch 268: loss = 0.41218340396881104, acc = 0.859375\n",
      "Batch 269: loss = 0.4601238965988159, acc = 0.841796875\n",
      "Batch 270: loss = 0.43932849168777466, acc = 0.8388671875\n",
      "Batch 271: loss = 0.37605932354927063, acc = 0.8623046875\n",
      "Batch 272: loss = 0.41531601548194885, acc = 0.8583984375\n",
      "Batch 273: loss = 0.43146759271621704, acc = 0.8544921875\n",
      "Batch 274: loss = 0.41774603724479675, acc = 0.861328125\n",
      "Batch 275: loss = 0.38109374046325684, acc = 0.8662109375\n",
      "Batch 276: loss = 0.4328222870826721, acc = 0.85546875\n",
      "Batch 277: loss = 0.4632144272327423, acc = 0.849609375\n",
      "Batch 278: loss = 0.39034780859947205, acc = 0.8623046875\n",
      "Batch 279: loss = 0.47756871581077576, acc = 0.8408203125\n",
      "Batch 280: loss = 0.48360493779182434, acc = 0.8408203125\n",
      "Batch 281: loss = 0.43608033657073975, acc = 0.8583984375\n",
      "Batch 282: loss = 0.4277796745300293, acc = 0.869140625\n",
      "Batch 283: loss = 0.4950605034828186, acc = 0.8408203125\n",
      "Batch 284: loss = 0.4650576412677765, acc = 0.8544921875\n",
      "Batch 285: loss = 0.4332675337791443, acc = 0.8505859375\n",
      "Batch 286: loss = 0.5052391886711121, acc = 0.8251953125\n",
      "Batch 287: loss = 0.4585421085357666, acc = 0.833984375\n",
      "Batch 288: loss = 0.4646240770816803, acc = 0.8515625\n",
      "Batch 289: loss = 0.3926793336868286, acc = 0.8720703125\n",
      "Batch 290: loss = 0.3991754353046417, acc = 0.8603515625\n",
      "Batch 291: loss = 0.4643518030643463, acc = 0.83984375\n",
      "Batch 292: loss = 0.42790424823760986, acc = 0.845703125\n",
      "Batch 293: loss = 0.4193556010723114, acc = 0.8583984375\n",
      "Batch 294: loss = 0.40970689058303833, acc = 0.8544921875\n",
      "Batch 295: loss = 0.4254348576068878, acc = 0.857421875\n",
      "Batch 296: loss = 0.3912387192249298, acc = 0.876953125\n",
      "Batch 297: loss = 0.3698478043079376, acc = 0.8857421875\n",
      "Batch 298: loss = 0.40640586614608765, acc = 0.869140625\n",
      "Batch 299: loss = 0.3785855174064636, acc = 0.8740234375\n",
      "Batch 300: loss = 0.4308827221393585, acc = 0.853515625\n",
      "Batch 301: loss = 0.3783152401447296, acc = 0.87109375\n",
      "Batch 302: loss = 0.44102537631988525, acc = 0.8388671875\n",
      "Batch 303: loss = 0.4806445240974426, acc = 0.83984375\n",
      "Batch 304: loss = 0.4097747206687927, acc = 0.8671875\n",
      "Batch 305: loss = 0.37109771370887756, acc = 0.8671875\n",
      "Batch 306: loss = 0.4586224853992462, acc = 0.8486328125\n",
      "Batch 307: loss = 0.3562548756599426, acc = 0.87890625\n",
      "Batch 308: loss = 0.4303795397281647, acc = 0.8642578125\n",
      "Batch 309: loss = 0.4275774359703064, acc = 0.8525390625\n",
      "Batch 310: loss = 0.4117763638496399, acc = 0.8623046875\n",
      "Batch 311: loss = 0.4510294198989868, acc = 0.849609375\n",
      "Batch 312: loss = 0.374872624874115, acc = 0.8720703125\n",
      "Batch 313: loss = 0.4835176467895508, acc = 0.833984375\n",
      "Batch 314: loss = 0.4414108991622925, acc = 0.83984375\n",
      "Batch 315: loss = 0.4213216006755829, acc = 0.857421875\n",
      "Batch 316: loss = 0.39055171608924866, acc = 0.865234375\n",
      "Batch 317: loss = 0.43230414390563965, acc = 0.8564453125\n",
      "Batch 318: loss = 0.4419698417186737, acc = 0.84375\n",
      "Batch 319: loss = 0.4783884584903717, acc = 0.841796875\n",
      "Batch 320: loss = 0.48312124609947205, acc = 0.8408203125\n",
      "Batch 321: loss = 0.47014227509498596, acc = 0.845703125\n",
      "Batch 322: loss = 0.37894320487976074, acc = 0.873046875\n",
      "Batch 323: loss = 0.4559969902038574, acc = 0.8330078125\n",
      "Batch 324: loss = 0.4156131148338318, acc = 0.859375\n",
      "Batch 325: loss = 0.4261755347251892, acc = 0.8515625\n",
      "Batch 326: loss = 0.3704536557197571, acc = 0.8720703125\n",
      "Batch 327: loss = 0.4137166440486908, acc = 0.8603515625\n",
      "Batch 328: loss = 0.4432181119918823, acc = 0.841796875\n",
      "Batch 329: loss = 0.45778459310531616, acc = 0.8505859375\n",
      "Batch 330: loss = 0.4183999001979828, acc = 0.85546875\n",
      "Batch 331: loss = 0.42185479402542114, acc = 0.849609375\n",
      "Batch 332: loss = 0.41961947083473206, acc = 0.8623046875\n",
      "Batch 333: loss = 0.4284231960773468, acc = 0.861328125\n",
      "Batch 334: loss = 0.3231198489665985, acc = 0.8974609375\n",
      "Batch 335: loss = 0.421358197927475, acc = 0.861328125\n",
      "Batch 336: loss = 0.4304327070713043, acc = 0.8515625\n",
      "Batch 337: loss = 0.4777328073978424, acc = 0.8466796875\n",
      "Batch 338: loss = 0.3754020035266876, acc = 0.875\n",
      "Batch 339: loss = 0.40214669704437256, acc = 0.8642578125\n",
      "Batch 340: loss = 0.38666847348213196, acc = 0.8681640625\n",
      "Batch 341: loss = 0.4089145064353943, acc = 0.857421875\n",
      "Batch 342: loss = 0.44791215658187866, acc = 0.8427734375\n",
      "Batch 343: loss = 0.37045204639434814, acc = 0.8740234375\n",
      "Batch 344: loss = 0.36848780512809753, acc = 0.865234375\n",
      "Batch 345: loss = 0.3738229274749756, acc = 0.8740234375\n",
      "Batch 346: loss = 0.37808963656425476, acc = 0.8642578125\n",
      "Batch 347: loss = 0.4541780948638916, acc = 0.8359375\n",
      "Batch 348: loss = 0.4122195541858673, acc = 0.8603515625\n",
      "Batch 349: loss = 0.3660100996494293, acc = 0.8798828125\n",
      "Batch 350: loss = 0.37772029638290405, acc = 0.880859375\n",
      "Batch 351: loss = 0.3661847710609436, acc = 0.869140625\n",
      "Batch 352: loss = 0.4054161310195923, acc = 0.853515625\n",
      "Batch 353: loss = 0.4056447148323059, acc = 0.8623046875\n",
      "Batch 354: loss = 0.34927040338516235, acc = 0.8798828125\n",
      "Batch 355: loss = 0.3059418201446533, acc = 0.8984375\n",
      "Batch 356: loss = 0.3389641344547272, acc = 0.8857421875\n",
      "Batch 357: loss = 0.40334752202033997, acc = 0.8623046875\n",
      "Batch 358: loss = 0.4114784598350525, acc = 0.8642578125\n",
      "Batch 359: loss = 0.396412193775177, acc = 0.8603515625\n",
      "Batch 360: loss = 0.3416968584060669, acc = 0.884765625\n",
      "Batch 361: loss = 0.39899778366088867, acc = 0.87109375\n",
      "Batch 362: loss = 0.4086568355560303, acc = 0.8603515625\n",
      "Batch 363: loss = 0.38862407207489014, acc = 0.8681640625\n",
      "Batch 364: loss = 0.4127538204193115, acc = 0.85546875\n",
      "Batch 365: loss = 0.3591153919696808, acc = 0.884765625\n",
      "Batch 366: loss = 0.39068707823753357, acc = 0.8681640625\n",
      "Batch 367: loss = 0.40334969758987427, acc = 0.873046875\n",
      "Batch 368: loss = 0.4401141107082367, acc = 0.8486328125\n",
      "Batch 369: loss = 0.46143800020217896, acc = 0.85546875\n",
      "Batch 370: loss = 0.3786124289035797, acc = 0.873046875\n",
      "Batch 371: loss = 0.47381162643432617, acc = 0.82421875\n",
      "Batch 372: loss = 0.39414122700691223, acc = 0.8671875\n",
      "Batch 373: loss = 0.40771546959877014, acc = 0.849609375\n",
      "Batch 374: loss = 0.44268709421157837, acc = 0.8662109375\n",
      "Batch 375: loss = 0.47100093960762024, acc = 0.8427734375\n",
      "Batch 376: loss = 0.4377080798149109, acc = 0.8583984375\n",
      "Batch 377: loss = 0.4026593863964081, acc = 0.85546875\n",
      "Batch 378: loss = 0.43186256289482117, acc = 0.8505859375\n",
      "Batch 379: loss = 0.5084161162376404, acc = 0.8349609375\n",
      "Batch 380: loss = 0.40510642528533936, acc = 0.859375\n",
      "Batch 381: loss = 0.3653106391429901, acc = 0.8740234375\n",
      "Batch 382: loss = 0.4054662585258484, acc = 0.8720703125\n",
      "Batch 383: loss = 0.36788004636764526, acc = 0.875\n",
      "Batch 384: loss = 0.4383554458618164, acc = 0.8515625\n",
      "Batch 385: loss = 0.42203792929649353, acc = 0.8447265625\n",
      "Batch 386: loss = 0.3848929703235626, acc = 0.857421875\n",
      "Batch 387: loss = 0.3837731182575226, acc = 0.8720703125\n",
      "Batch 388: loss = 0.4186970591545105, acc = 0.857421875\n",
      "Batch 389: loss = 0.42186158895492554, acc = 0.8583984375\n",
      "Batch 390: loss = 0.4546845853328705, acc = 0.841796875\n",
      "Batch 391: loss = 0.4330398440361023, acc = 0.845703125\n",
      "Batch 392: loss = 0.46056368947029114, acc = 0.8427734375\n",
      "Batch 393: loss = 0.450592964887619, acc = 0.84375\n",
      "Batch 394: loss = 0.37381482124328613, acc = 0.8701171875\n",
      "Batch 395: loss = 0.429325670003891, acc = 0.84765625\n",
      "Batch 396: loss = 0.43987834453582764, acc = 0.865234375\n",
      "Batch 397: loss = 0.36455580592155457, acc = 0.8818359375\n",
      "Batch 398: loss = 0.35638388991355896, acc = 0.8759765625\n",
      "Batch 399: loss = 0.3887231945991516, acc = 0.869140625\n",
      "Batch 400: loss = 0.43132340908050537, acc = 0.865234375\n",
      "Batch 401: loss = 0.3842322826385498, acc = 0.880859375\n",
      "Batch 402: loss = 0.4585120975971222, acc = 0.8486328125\n",
      "Batch 403: loss = 0.4038819372653961, acc = 0.859375\n",
      "Batch 404: loss = 0.4368473291397095, acc = 0.857421875\n",
      "Batch 405: loss = 0.42145752906799316, acc = 0.8583984375\n",
      "Batch 406: loss = 0.528583288192749, acc = 0.8251953125\n",
      "Batch 407: loss = 0.4136936068534851, acc = 0.859375\n",
      "Batch 408: loss = 0.5074748992919922, acc = 0.8193359375\n",
      "Batch 409: loss = 0.38219940662384033, acc = 0.865234375\n",
      "Batch 410: loss = 0.4625874161720276, acc = 0.84765625\n",
      "Batch 411: loss = 0.42144790291786194, acc = 0.8525390625\n",
      "Batch 412: loss = 0.4507502317428589, acc = 0.8486328125\n",
      "Batch 413: loss = 0.38385480642318726, acc = 0.8720703125\n",
      "Batch 414: loss = 0.40088748931884766, acc = 0.86328125\n",
      "Batch 415: loss = 0.4148915112018585, acc = 0.8623046875\n",
      "Batch 416: loss = 0.4794275164604187, acc = 0.8486328125\n",
      "Batch 417: loss = 0.4168531894683838, acc = 0.859375\n",
      "Batch 418: loss = 0.4703094959259033, acc = 0.83203125\n",
      "Batch 419: loss = 0.5496102571487427, acc = 0.8076171875\n",
      "Batch 420: loss = 0.4665747284889221, acc = 0.845703125\n",
      "Batch 421: loss = 0.47385191917419434, acc = 0.8310546875\n",
      "Batch 422: loss = 0.4816230833530426, acc = 0.83984375\n",
      "Batch 423: loss = 0.45772674679756165, acc = 0.8359375\n",
      "Batch 424: loss = 0.4442732334136963, acc = 0.853515625\n",
      "Batch 425: loss = 0.4295242726802826, acc = 0.857421875\n",
      "Batch 426: loss = 0.45780837535858154, acc = 0.8447265625\n",
      "Batch 427: loss = 0.4159027338027954, acc = 0.8544921875\n",
      "Batch 428: loss = 0.465241014957428, acc = 0.83984375\n",
      "Batch 429: loss = 0.43232694268226624, acc = 0.8544921875\n",
      "Batch 430: loss = 0.4093300700187683, acc = 0.873046875\n",
      "Batch 431: loss = 0.45926761627197266, acc = 0.849609375\n",
      "Batch 432: loss = 0.4530295133590698, acc = 0.853515625\n",
      "Batch 433: loss = 0.3730909824371338, acc = 0.87890625\n",
      "Batch 434: loss = 0.39542731642723083, acc = 0.8642578125\n",
      "Batch 435: loss = 0.44404831528663635, acc = 0.84765625\n",
      "Batch 436: loss = 0.3717947006225586, acc = 0.8759765625\n",
      "Batch 437: loss = 0.4613998234272003, acc = 0.83984375\n",
      "Batch 438: loss = 0.4265459179878235, acc = 0.8564453125\n",
      "Batch 439: loss = 0.3392607569694519, acc = 0.87890625\n",
      "Batch 440: loss = 0.44613078236579895, acc = 0.8427734375\n",
      "Batch 441: loss = 0.4082239866256714, acc = 0.865234375\n",
      "Saved checkpoint to weights.90.h5\n",
      "\n",
      "Epoch 91/100\n",
      "Batch 1: loss = 0.5488950610160828, acc = 0.8232421875\n",
      "Batch 2: loss = 0.3939039707183838, acc = 0.853515625\n",
      "Batch 3: loss = 0.4150306284427643, acc = 0.87109375\n",
      "Batch 4: loss = 0.42349594831466675, acc = 0.8623046875\n",
      "Batch 5: loss = 0.4071069657802582, acc = 0.853515625\n",
      "Batch 6: loss = 0.37534430623054504, acc = 0.87890625\n",
      "Batch 7: loss = 0.39721307158470154, acc = 0.865234375\n",
      "Batch 8: loss = 0.3832749128341675, acc = 0.869140625\n",
      "Batch 9: loss = 0.38901856541633606, acc = 0.853515625\n",
      "Batch 10: loss = 0.46546798944473267, acc = 0.83203125\n",
      "Batch 11: loss = 0.426708847284317, acc = 0.84765625\n",
      "Batch 12: loss = 0.4241577684879303, acc = 0.86328125\n",
      "Batch 13: loss = 0.430512398481369, acc = 0.8544921875\n",
      "Batch 14: loss = 0.3811768889427185, acc = 0.865234375\n",
      "Batch 15: loss = 0.38154369592666626, acc = 0.880859375\n",
      "Batch 16: loss = 0.43343839049339294, acc = 0.865234375\n",
      "Batch 17: loss = 0.3513529598712921, acc = 0.880859375\n",
      "Batch 18: loss = 0.4288981556892395, acc = 0.85546875\n",
      "Batch 19: loss = 0.44013676047325134, acc = 0.853515625\n",
      "Batch 20: loss = 0.4215598702430725, acc = 0.859375\n",
      "Batch 21: loss = 0.46560707688331604, acc = 0.841796875\n",
      "Batch 22: loss = 0.43327099084854126, acc = 0.8525390625\n",
      "Batch 23: loss = 0.440735399723053, acc = 0.8466796875\n",
      "Batch 24: loss = 0.40195363759994507, acc = 0.8837890625\n",
      "Batch 25: loss = 0.45285937190055847, acc = 0.8544921875\n",
      "Batch 26: loss = 0.40956687927246094, acc = 0.865234375\n",
      "Batch 27: loss = 0.5070745944976807, acc = 0.8232421875\n",
      "Batch 28: loss = 0.394888699054718, acc = 0.8759765625\n",
      "Batch 29: loss = 0.47457483410835266, acc = 0.8515625\n",
      "Batch 30: loss = 0.4447353780269623, acc = 0.8486328125\n",
      "Batch 31: loss = 0.4439181983470917, acc = 0.84765625\n",
      "Batch 32: loss = 0.35373103618621826, acc = 0.884765625\n",
      "Batch 33: loss = 0.33989015221595764, acc = 0.89453125\n",
      "Batch 34: loss = 0.341060996055603, acc = 0.890625\n",
      "Batch 35: loss = 0.35535717010498047, acc = 0.8818359375\n",
      "Batch 36: loss = 0.45056861639022827, acc = 0.8515625\n",
      "Batch 37: loss = 0.42307916283607483, acc = 0.8505859375\n",
      "Batch 38: loss = 0.38928040862083435, acc = 0.876953125\n",
      "Batch 39: loss = 0.3470427989959717, acc = 0.888671875\n",
      "Batch 40: loss = 0.3819495439529419, acc = 0.8740234375\n",
      "Batch 41: loss = 0.3262677490711212, acc = 0.8916015625\n",
      "Batch 42: loss = 0.4710720181465149, acc = 0.8291015625\n",
      "Batch 43: loss = 0.44312775135040283, acc = 0.8427734375\n",
      "Batch 44: loss = 0.42911404371261597, acc = 0.853515625\n",
      "Batch 45: loss = 0.34922224283218384, acc = 0.884765625\n",
      "Batch 46: loss = 0.4124607741832733, acc = 0.849609375\n",
      "Batch 47: loss = 0.40781086683273315, acc = 0.8662109375\n",
      "Batch 48: loss = 0.37420597672462463, acc = 0.87109375\n",
      "Batch 49: loss = 0.4181567430496216, acc = 0.859375\n",
      "Batch 50: loss = 0.4104175865650177, acc = 0.865234375\n",
      "Batch 51: loss = 0.46657583117485046, acc = 0.8310546875\n",
      "Batch 52: loss = 0.3297598361968994, acc = 0.8876953125\n",
      "Batch 53: loss = 0.424978107213974, acc = 0.859375\n",
      "Batch 54: loss = 0.43238821625709534, acc = 0.853515625\n",
      "Batch 55: loss = 0.4406866431236267, acc = 0.8583984375\n",
      "Batch 56: loss = 0.43393218517303467, acc = 0.8525390625\n",
      "Batch 57: loss = 0.4188835620880127, acc = 0.865234375\n",
      "Batch 58: loss = 0.37859317660331726, acc = 0.8759765625\n",
      "Batch 59: loss = 0.436528742313385, acc = 0.853515625\n",
      "Batch 60: loss = 0.38456645607948303, acc = 0.875\n",
      "Batch 61: loss = 0.44780269265174866, acc = 0.8525390625\n",
      "Batch 62: loss = 0.41402363777160645, acc = 0.859375\n",
      "Batch 63: loss = 0.43200236558914185, acc = 0.845703125\n",
      "Batch 64: loss = 0.36859408020973206, acc = 0.8837890625\n",
      "Batch 65: loss = 0.35842686891555786, acc = 0.8876953125\n",
      "Batch 66: loss = 0.3856154978275299, acc = 0.8681640625\n",
      "Batch 67: loss = 0.40549445152282715, acc = 0.8623046875\n",
      "Batch 68: loss = 0.4643588960170746, acc = 0.849609375\n",
      "Batch 69: loss = 0.4068191349506378, acc = 0.8662109375\n",
      "Batch 70: loss = 0.42877843976020813, acc = 0.849609375\n",
      "Batch 71: loss = 0.4306700527667999, acc = 0.8642578125\n",
      "Batch 72: loss = 0.45040950179100037, acc = 0.8544921875\n",
      "Batch 73: loss = 0.40028634667396545, acc = 0.859375\n",
      "Batch 74: loss = 0.4487394094467163, acc = 0.8505859375\n",
      "Batch 75: loss = 0.3412807881832123, acc = 0.880859375\n",
      "Batch 76: loss = 0.4298076629638672, acc = 0.8544921875\n",
      "Batch 77: loss = 0.47887545824050903, acc = 0.8310546875\n",
      "Batch 78: loss = 0.44930320978164673, acc = 0.857421875\n",
      "Batch 79: loss = 0.397352933883667, acc = 0.865234375\n",
      "Batch 80: loss = 0.5107151865959167, acc = 0.8349609375\n",
      "Batch 81: loss = 0.40588030219078064, acc = 0.87109375\n",
      "Batch 82: loss = 0.40939223766326904, acc = 0.8515625\n",
      "Batch 83: loss = 0.44968611001968384, acc = 0.84765625\n",
      "Batch 84: loss = 0.4041703939437866, acc = 0.8583984375\n",
      "Batch 85: loss = 0.439794659614563, acc = 0.8427734375\n",
      "Batch 86: loss = 0.4291682243347168, acc = 0.853515625\n",
      "Batch 87: loss = 0.3799567222595215, acc = 0.865234375\n",
      "Batch 88: loss = 0.42277318239212036, acc = 0.8623046875\n",
      "Batch 89: loss = 0.5087374448776245, acc = 0.8251953125\n",
      "Batch 90: loss = 0.43011271953582764, acc = 0.8515625\n",
      "Batch 91: loss = 0.4076487123966217, acc = 0.859375\n",
      "Batch 92: loss = 0.42364028096199036, acc = 0.84765625\n",
      "Batch 93: loss = 0.4425545334815979, acc = 0.8486328125\n",
      "Batch 94: loss = 0.46397334337234497, acc = 0.8515625\n",
      "Batch 95: loss = 0.4496096670627594, acc = 0.857421875\n",
      "Batch 96: loss = 0.37679675221443176, acc = 0.875\n",
      "Batch 97: loss = 0.45725569128990173, acc = 0.8515625\n",
      "Batch 98: loss = 0.46769168972969055, acc = 0.857421875\n",
      "Batch 99: loss = 0.4130935072898865, acc = 0.8662109375\n",
      "Batch 100: loss = 0.49192798137664795, acc = 0.830078125\n",
      "Batch 101: loss = 0.38812255859375, acc = 0.86328125\n",
      "Batch 102: loss = 0.3602340519428253, acc = 0.8671875\n",
      "Batch 103: loss = 0.38596606254577637, acc = 0.8642578125\n",
      "Batch 104: loss = 0.3688642978668213, acc = 0.8798828125\n",
      "Batch 105: loss = 0.43424034118652344, acc = 0.8525390625\n",
      "Batch 106: loss = 0.4482966661453247, acc = 0.85546875\n",
      "Batch 107: loss = 0.4436939060688019, acc = 0.8408203125\n",
      "Batch 108: loss = 0.47155386209487915, acc = 0.841796875\n",
      "Batch 109: loss = 0.3685900866985321, acc = 0.87109375\n",
      "Batch 110: loss = 0.46766364574432373, acc = 0.841796875\n",
      "Batch 111: loss = 0.44516685605049133, acc = 0.8505859375\n",
      "Batch 112: loss = 0.424906849861145, acc = 0.85546875\n",
      "Batch 113: loss = 0.3979406952857971, acc = 0.8671875\n",
      "Batch 114: loss = 0.339432954788208, acc = 0.8818359375\n",
      "Batch 115: loss = 0.5002146363258362, acc = 0.84375\n",
      "Batch 116: loss = 0.41633105278015137, acc = 0.8642578125\n",
      "Batch 117: loss = 0.4240499436855316, acc = 0.859375\n",
      "Batch 118: loss = 0.4131346046924591, acc = 0.8642578125\n",
      "Batch 119: loss = 0.4098910987377167, acc = 0.86328125\n",
      "Batch 120: loss = 0.437163770198822, acc = 0.857421875\n",
      "Batch 121: loss = 0.46057987213134766, acc = 0.849609375\n",
      "Batch 122: loss = 0.37970900535583496, acc = 0.8740234375\n",
      "Batch 123: loss = 0.41922158002853394, acc = 0.857421875\n",
      "Batch 124: loss = 0.4333597719669342, acc = 0.841796875\n",
      "Batch 125: loss = 0.41943493485450745, acc = 0.8642578125\n",
      "Batch 126: loss = 0.3741087317466736, acc = 0.87109375\n",
      "Batch 127: loss = 0.4454089105129242, acc = 0.8486328125\n",
      "Batch 128: loss = 0.39018234610557556, acc = 0.8681640625\n",
      "Batch 129: loss = 0.3680988550186157, acc = 0.8759765625\n",
      "Batch 130: loss = 0.39995861053466797, acc = 0.8662109375\n",
      "Batch 131: loss = 0.3521626889705658, acc = 0.873046875\n",
      "Batch 132: loss = 0.2862175703048706, acc = 0.8984375\n",
      "Batch 133: loss = 0.3280457556247711, acc = 0.89453125\n",
      "Batch 134: loss = 0.3906121850013733, acc = 0.8603515625\n",
      "Batch 135: loss = 0.42446842789649963, acc = 0.86328125\n",
      "Batch 136: loss = 0.3802759647369385, acc = 0.8740234375\n",
      "Batch 137: loss = 0.3739168047904968, acc = 0.8740234375\n",
      "Batch 138: loss = 0.3917251229286194, acc = 0.8720703125\n",
      "Batch 139: loss = 0.3773471713066101, acc = 0.8740234375\n",
      "Batch 140: loss = 0.4023001492023468, acc = 0.859375\n",
      "Batch 141: loss = 0.39916273951530457, acc = 0.8720703125\n",
      "Batch 142: loss = 0.44673800468444824, acc = 0.8369140625\n",
      "Batch 143: loss = 0.4511002004146576, acc = 0.84375\n",
      "Batch 144: loss = 0.44749361276626587, acc = 0.8515625\n",
      "Batch 145: loss = 0.3757026195526123, acc = 0.8701171875\n",
      "Batch 146: loss = 0.4335973858833313, acc = 0.857421875\n",
      "Batch 147: loss = 0.43501073122024536, acc = 0.849609375\n",
      "Batch 148: loss = 0.3976535201072693, acc = 0.869140625\n",
      "Batch 149: loss = 0.4017314910888672, acc = 0.87109375\n",
      "Batch 150: loss = 0.41308850049972534, acc = 0.8603515625\n",
      "Batch 151: loss = 0.4305672347545624, acc = 0.857421875\n",
      "Batch 152: loss = 0.3929930329322815, acc = 0.8671875\n",
      "Batch 153: loss = 0.3901059031486511, acc = 0.8720703125\n",
      "Batch 154: loss = 0.41747575998306274, acc = 0.861328125\n",
      "Batch 155: loss = 0.3537102937698364, acc = 0.87109375\n",
      "Batch 156: loss = 0.4704529345035553, acc = 0.83984375\n",
      "Batch 157: loss = 0.39312559366226196, acc = 0.875\n",
      "Batch 158: loss = 0.4337750971317291, acc = 0.8505859375\n",
      "Batch 159: loss = 0.45051681995391846, acc = 0.84765625\n",
      "Batch 160: loss = 0.4107149839401245, acc = 0.8662109375\n",
      "Batch 161: loss = 0.4793020784854889, acc = 0.8310546875\n",
      "Batch 162: loss = 0.44943732023239136, acc = 0.8515625\n",
      "Batch 163: loss = 0.44009968638420105, acc = 0.853515625\n",
      "Batch 164: loss = 0.415646493434906, acc = 0.8505859375\n",
      "Batch 165: loss = 0.43706995248794556, acc = 0.853515625\n",
      "Batch 166: loss = 0.35405927896499634, acc = 0.8779296875\n",
      "Batch 167: loss = 0.41624578833580017, acc = 0.8525390625\n",
      "Batch 168: loss = 0.41334080696105957, acc = 0.859375\n",
      "Batch 169: loss = 0.35586997866630554, acc = 0.875\n",
      "Batch 170: loss = 0.3929843008518219, acc = 0.8740234375\n",
      "Batch 171: loss = 0.4215446710586548, acc = 0.8671875\n",
      "Batch 172: loss = 0.38918501138687134, acc = 0.876953125\n",
      "Batch 173: loss = 0.384344220161438, acc = 0.8720703125\n",
      "Batch 174: loss = 0.3926798701286316, acc = 0.8671875\n",
      "Batch 175: loss = 0.4267628788948059, acc = 0.8427734375\n",
      "Batch 176: loss = 0.40204712748527527, acc = 0.8681640625\n",
      "Batch 177: loss = 0.36219632625579834, acc = 0.876953125\n",
      "Batch 178: loss = 0.4163248538970947, acc = 0.85546875\n",
      "Batch 179: loss = 0.45679008960723877, acc = 0.8369140625\n",
      "Batch 180: loss = 0.3854609429836273, acc = 0.869140625\n",
      "Batch 181: loss = 0.361028254032135, acc = 0.876953125\n",
      "Batch 182: loss = 0.41729092597961426, acc = 0.859375\n",
      "Batch 183: loss = 0.36623749136924744, acc = 0.8701171875\n",
      "Batch 184: loss = 0.4386450946331024, acc = 0.8427734375\n",
      "Batch 185: loss = 0.43075108528137207, acc = 0.8525390625\n",
      "Batch 186: loss = 0.3776290714740753, acc = 0.8779296875\n",
      "Batch 187: loss = 0.399585485458374, acc = 0.8759765625\n",
      "Batch 188: loss = 0.3759158253669739, acc = 0.8828125\n",
      "Batch 189: loss = 0.39128613471984863, acc = 0.853515625\n",
      "Batch 190: loss = 0.40761369466781616, acc = 0.857421875\n",
      "Batch 191: loss = 0.41503390669822693, acc = 0.8681640625\n",
      "Batch 192: loss = 0.3770887851715088, acc = 0.869140625\n",
      "Batch 193: loss = 0.44185981154441833, acc = 0.853515625\n",
      "Batch 194: loss = 0.43031102418899536, acc = 0.853515625\n",
      "Batch 195: loss = 0.4620451033115387, acc = 0.837890625\n",
      "Batch 196: loss = 0.4764155447483063, acc = 0.8505859375\n",
      "Batch 197: loss = 0.4726570248603821, acc = 0.84765625\n",
      "Batch 198: loss = 0.40637198090553284, acc = 0.86328125\n",
      "Batch 199: loss = 0.41398805379867554, acc = 0.857421875\n",
      "Batch 200: loss = 0.457211434841156, acc = 0.841796875\n",
      "Batch 201: loss = 0.4555741548538208, acc = 0.8466796875\n",
      "Batch 202: loss = 0.4866725206375122, acc = 0.83203125\n",
      "Batch 203: loss = 0.3980642259120941, acc = 0.869140625\n",
      "Batch 204: loss = 0.4333916902542114, acc = 0.8427734375\n",
      "Batch 205: loss = 0.4291497468948364, acc = 0.865234375\n",
      "Batch 206: loss = 0.4395022988319397, acc = 0.859375\n",
      "Batch 207: loss = 0.5136861205101013, acc = 0.83984375\n",
      "Batch 208: loss = 0.4461801052093506, acc = 0.853515625\n",
      "Batch 209: loss = 0.41087502241134644, acc = 0.869140625\n",
      "Batch 210: loss = 0.4067184031009674, acc = 0.87109375\n",
      "Batch 211: loss = 0.4530614912509918, acc = 0.8525390625\n",
      "Batch 212: loss = 0.45423585176467896, acc = 0.83984375\n",
      "Batch 213: loss = 0.4424785077571869, acc = 0.841796875\n",
      "Batch 214: loss = 0.4455898702144623, acc = 0.845703125\n",
      "Batch 215: loss = 0.4006345868110657, acc = 0.8671875\n",
      "Batch 216: loss = 0.35490089654922485, acc = 0.876953125\n",
      "Batch 217: loss = 0.3802236020565033, acc = 0.87890625\n",
      "Batch 218: loss = 0.40837082266807556, acc = 0.859375\n",
      "Batch 219: loss = 0.4155904948711395, acc = 0.865234375\n",
      "Batch 220: loss = 0.4136766195297241, acc = 0.8486328125\n",
      "Batch 221: loss = 0.46742093563079834, acc = 0.8544921875\n",
      "Batch 222: loss = 0.39630457758903503, acc = 0.87109375\n",
      "Batch 223: loss = 0.3655466139316559, acc = 0.8740234375\n",
      "Batch 224: loss = 0.32596880197525024, acc = 0.8828125\n",
      "Batch 225: loss = 0.369016170501709, acc = 0.8662109375\n",
      "Batch 226: loss = 0.4308668375015259, acc = 0.8623046875\n",
      "Batch 227: loss = 0.3826928436756134, acc = 0.8720703125\n",
      "Batch 228: loss = 0.394056499004364, acc = 0.8662109375\n",
      "Batch 229: loss = 0.39459890127182007, acc = 0.8759765625\n",
      "Batch 230: loss = 0.345786988735199, acc = 0.884765625\n",
      "Batch 231: loss = 0.4663645923137665, acc = 0.841796875\n",
      "Batch 232: loss = 0.4097689390182495, acc = 0.869140625\n",
      "Batch 233: loss = 0.5027713775634766, acc = 0.8310546875\n",
      "Batch 234: loss = 0.3887161612510681, acc = 0.8681640625\n",
      "Batch 235: loss = 0.43235987424850464, acc = 0.8583984375\n",
      "Batch 236: loss = 0.4069001078605652, acc = 0.873046875\n",
      "Batch 237: loss = 0.3504338562488556, acc = 0.8837890625\n",
      "Batch 238: loss = 0.394080251455307, acc = 0.853515625\n",
      "Batch 239: loss = 0.3716484606266022, acc = 0.8740234375\n",
      "Batch 240: loss = 0.5039664506912231, acc = 0.8359375\n",
      "Batch 241: loss = 0.40929678082466125, acc = 0.86328125\n",
      "Batch 242: loss = 0.4227678179740906, acc = 0.8505859375\n",
      "Batch 243: loss = 0.41506320238113403, acc = 0.8564453125\n",
      "Batch 244: loss = 0.48468491435050964, acc = 0.8310546875\n",
      "Batch 245: loss = 0.4143067002296448, acc = 0.8603515625\n",
      "Batch 246: loss = 0.4294419288635254, acc = 0.85546875\n",
      "Batch 247: loss = 0.42739081382751465, acc = 0.859375\n",
      "Batch 248: loss = 0.3976457417011261, acc = 0.8681640625\n",
      "Batch 249: loss = 0.3728660047054291, acc = 0.873046875\n",
      "Batch 250: loss = 0.4591619372367859, acc = 0.853515625\n",
      "Batch 251: loss = 0.3521086275577545, acc = 0.8759765625\n",
      "Batch 252: loss = 0.3736231327056885, acc = 0.8837890625\n",
      "Batch 253: loss = 0.4592411518096924, acc = 0.8505859375\n",
      "Batch 254: loss = 0.4433993101119995, acc = 0.8525390625\n",
      "Batch 255: loss = 0.4741959571838379, acc = 0.8349609375\n",
      "Batch 256: loss = 0.4307691752910614, acc = 0.8603515625\n",
      "Batch 257: loss = 0.48830899596214294, acc = 0.837890625\n",
      "Batch 258: loss = 0.4752062261104584, acc = 0.83984375\n",
      "Batch 259: loss = 0.5484951734542847, acc = 0.8251953125\n",
      "Batch 260: loss = 0.5286181569099426, acc = 0.8193359375\n",
      "Batch 261: loss = 0.44210243225097656, acc = 0.84375\n",
      "Batch 262: loss = 0.47830772399902344, acc = 0.8310546875\n",
      "Batch 263: loss = 0.44484949111938477, acc = 0.845703125\n",
      "Batch 264: loss = 0.437087744474411, acc = 0.8486328125\n",
      "Batch 265: loss = 0.43624818325042725, acc = 0.8525390625\n",
      "Batch 266: loss = 0.3855358064174652, acc = 0.865234375\n",
      "Batch 267: loss = 0.3416528105735779, acc = 0.88671875\n",
      "Batch 268: loss = 0.4423522651195526, acc = 0.8583984375\n",
      "Batch 269: loss = 0.44350868463516235, acc = 0.8662109375\n",
      "Batch 270: loss = 0.4458504915237427, acc = 0.861328125\n",
      "Batch 271: loss = 0.3869791626930237, acc = 0.869140625\n",
      "Batch 272: loss = 0.4186905026435852, acc = 0.853515625\n",
      "Batch 273: loss = 0.42480704188346863, acc = 0.8486328125\n",
      "Batch 274: loss = 0.4247778058052063, acc = 0.8564453125\n",
      "Batch 275: loss = 0.34027299284935, acc = 0.880859375\n",
      "Batch 276: loss = 0.41999489068984985, acc = 0.8544921875\n",
      "Batch 277: loss = 0.4128367304801941, acc = 0.8544921875\n",
      "Batch 278: loss = 0.3906329274177551, acc = 0.873046875\n",
      "Batch 279: loss = 0.4355599880218506, acc = 0.8564453125\n",
      "Batch 280: loss = 0.4911871552467346, acc = 0.8369140625\n",
      "Batch 281: loss = 0.43632230162620544, acc = 0.861328125\n",
      "Batch 282: loss = 0.4625765085220337, acc = 0.841796875\n",
      "Batch 283: loss = 0.464641273021698, acc = 0.8466796875\n",
      "Batch 284: loss = 0.440477192401886, acc = 0.84765625\n",
      "Batch 285: loss = 0.4464249908924103, acc = 0.86328125\n",
      "Batch 286: loss = 0.49637892842292786, acc = 0.8388671875\n",
      "Batch 287: loss = 0.4605383574962616, acc = 0.8310546875\n",
      "Batch 288: loss = 0.44634315371513367, acc = 0.841796875\n",
      "Batch 289: loss = 0.39275816082954407, acc = 0.869140625\n",
      "Batch 290: loss = 0.44428902864456177, acc = 0.8486328125\n",
      "Batch 291: loss = 0.48352035880088806, acc = 0.84375\n",
      "Batch 292: loss = 0.4399929344654083, acc = 0.83984375\n",
      "Batch 293: loss = 0.4282332956790924, acc = 0.865234375\n",
      "Batch 294: loss = 0.3911200761795044, acc = 0.8681640625\n",
      "Batch 295: loss = 0.4020330607891083, acc = 0.865234375\n",
      "Batch 296: loss = 0.43503695726394653, acc = 0.8505859375\n",
      "Batch 297: loss = 0.3712042570114136, acc = 0.8779296875\n",
      "Batch 298: loss = 0.3744564652442932, acc = 0.8740234375\n",
      "Batch 299: loss = 0.34563976526260376, acc = 0.8818359375\n",
      "Batch 300: loss = 0.4498061239719391, acc = 0.841796875\n",
      "Batch 301: loss = 0.3829755187034607, acc = 0.859375\n",
      "Batch 302: loss = 0.41413870453834534, acc = 0.85546875\n",
      "Batch 303: loss = 0.46350786089897156, acc = 0.84375\n",
      "Batch 304: loss = 0.3948817849159241, acc = 0.8740234375\n",
      "Batch 305: loss = 0.42378997802734375, acc = 0.8515625\n",
      "Batch 306: loss = 0.44935885071754456, acc = 0.8603515625\n",
      "Batch 307: loss = 0.3426334857940674, acc = 0.8828125\n",
      "Batch 308: loss = 0.4298242926597595, acc = 0.84765625\n",
      "Batch 309: loss = 0.4215255379676819, acc = 0.85546875\n",
      "Batch 310: loss = 0.43656831979751587, acc = 0.849609375\n",
      "Batch 311: loss = 0.4238816201686859, acc = 0.857421875\n",
      "Batch 312: loss = 0.3588871955871582, acc = 0.880859375\n",
      "Batch 313: loss = 0.4782010018825531, acc = 0.849609375\n",
      "Batch 314: loss = 0.47993409633636475, acc = 0.8310546875\n",
      "Batch 315: loss = 0.42672303318977356, acc = 0.8642578125\n",
      "Batch 316: loss = 0.40938109159469604, acc = 0.85546875\n",
      "Batch 317: loss = 0.4207276403903961, acc = 0.8603515625\n",
      "Batch 318: loss = 0.4098920524120331, acc = 0.857421875\n",
      "Batch 319: loss = 0.4488021433353424, acc = 0.8505859375\n",
      "Batch 320: loss = 0.4252288341522217, acc = 0.84765625\n",
      "Batch 321: loss = 0.47116732597351074, acc = 0.8388671875\n",
      "Batch 322: loss = 0.40748071670532227, acc = 0.8681640625\n",
      "Batch 323: loss = 0.4538564383983612, acc = 0.8447265625\n",
      "Batch 324: loss = 0.41600286960601807, acc = 0.8505859375\n",
      "Batch 325: loss = 0.4518769383430481, acc = 0.845703125\n",
      "Batch 326: loss = 0.3735124170780182, acc = 0.8857421875\n",
      "Batch 327: loss = 0.4046171009540558, acc = 0.85546875\n",
      "Batch 328: loss = 0.42928433418273926, acc = 0.8544921875\n",
      "Batch 329: loss = 0.49337074160575867, acc = 0.8388671875\n",
      "Batch 330: loss = 0.3940016031265259, acc = 0.8623046875\n",
      "Batch 331: loss = 0.40063056349754333, acc = 0.87109375\n",
      "Batch 332: loss = 0.42038536071777344, acc = 0.861328125\n",
      "Batch 333: loss = 0.44792670011520386, acc = 0.845703125\n",
      "Batch 334: loss = 0.36829936504364014, acc = 0.8798828125\n",
      "Batch 335: loss = 0.43238312005996704, acc = 0.853515625\n",
      "Batch 336: loss = 0.441866934299469, acc = 0.8623046875\n",
      "Batch 337: loss = 0.4883544445037842, acc = 0.8466796875\n",
      "Batch 338: loss = 0.4168224632740021, acc = 0.859375\n",
      "Batch 339: loss = 0.41341832280158997, acc = 0.8701171875\n",
      "Batch 340: loss = 0.40373924374580383, acc = 0.857421875\n",
      "Batch 341: loss = 0.47383174300193787, acc = 0.830078125\n",
      "Batch 342: loss = 0.4717925190925598, acc = 0.8271484375\n",
      "Batch 343: loss = 0.35633671283721924, acc = 0.873046875\n",
      "Batch 344: loss = 0.365832656621933, acc = 0.8818359375\n",
      "Batch 345: loss = 0.3796975016593933, acc = 0.86328125\n",
      "Batch 346: loss = 0.34238919615745544, acc = 0.8828125\n",
      "Batch 347: loss = 0.4316038191318512, acc = 0.8583984375\n",
      "Batch 348: loss = 0.3955947160720825, acc = 0.8681640625\n",
      "Batch 349: loss = 0.34439554810523987, acc = 0.8818359375\n",
      "Batch 350: loss = 0.3430458903312683, acc = 0.8818359375\n",
      "Batch 351: loss = 0.3585951328277588, acc = 0.8662109375\n",
      "Batch 352: loss = 0.4343026280403137, acc = 0.8291015625\n",
      "Batch 353: loss = 0.38473615050315857, acc = 0.8642578125\n",
      "Batch 354: loss = 0.3305702209472656, acc = 0.884765625\n",
      "Batch 355: loss = 0.28186148405075073, acc = 0.9091796875\n",
      "Batch 356: loss = 0.34205636382102966, acc = 0.880859375\n",
      "Batch 357: loss = 0.37952953577041626, acc = 0.8701171875\n",
      "Batch 358: loss = 0.3864075839519501, acc = 0.8671875\n",
      "Batch 359: loss = 0.3995474576950073, acc = 0.873046875\n",
      "Batch 360: loss = 0.37567827105522156, acc = 0.8798828125\n",
      "Batch 361: loss = 0.36997830867767334, acc = 0.880859375\n",
      "Batch 362: loss = 0.34479546546936035, acc = 0.8798828125\n",
      "Batch 363: loss = 0.4232921004295349, acc = 0.85546875\n",
      "Batch 364: loss = 0.44892242550849915, acc = 0.8515625\n",
      "Batch 365: loss = 0.34858059883117676, acc = 0.8857421875\n",
      "Batch 366: loss = 0.3979083299636841, acc = 0.86328125\n",
      "Batch 367: loss = 0.4163760542869568, acc = 0.8623046875\n",
      "Batch 368: loss = 0.47746092081069946, acc = 0.8544921875\n",
      "Batch 369: loss = 0.4887969493865967, acc = 0.830078125\n",
      "Batch 370: loss = 0.3751460909843445, acc = 0.8623046875\n",
      "Batch 371: loss = 0.44412851333618164, acc = 0.84765625\n",
      "Batch 372: loss = 0.3957318961620331, acc = 0.8583984375\n",
      "Batch 373: loss = 0.4492686688899994, acc = 0.8271484375\n",
      "Batch 374: loss = 0.457738995552063, acc = 0.8505859375\n",
      "Batch 375: loss = 0.47988247871398926, acc = 0.83203125\n",
      "Batch 376: loss = 0.4642798900604248, acc = 0.8505859375\n",
      "Batch 377: loss = 0.4438634514808655, acc = 0.8564453125\n",
      "Batch 378: loss = 0.44015711545944214, acc = 0.8544921875\n",
      "Batch 379: loss = 0.4749237895011902, acc = 0.8486328125\n",
      "Batch 380: loss = 0.40734314918518066, acc = 0.8671875\n",
      "Batch 381: loss = 0.35921987891197205, acc = 0.8798828125\n",
      "Batch 382: loss = 0.38417959213256836, acc = 0.87109375\n",
      "Batch 383: loss = 0.3684149980545044, acc = 0.8701171875\n",
      "Batch 384: loss = 0.4281193017959595, acc = 0.8486328125\n",
      "Batch 385: loss = 0.37220239639282227, acc = 0.8759765625\n",
      "Batch 386: loss = 0.3933301568031311, acc = 0.8671875\n",
      "Batch 387: loss = 0.3577636778354645, acc = 0.8837890625\n",
      "Batch 388: loss = 0.44659334421157837, acc = 0.8515625\n",
      "Batch 389: loss = 0.41116589307785034, acc = 0.8603515625\n",
      "Batch 390: loss = 0.47300413250923157, acc = 0.830078125\n",
      "Batch 391: loss = 0.4010750353336334, acc = 0.8603515625\n",
      "Batch 392: loss = 0.41518375277519226, acc = 0.8525390625\n",
      "Batch 393: loss = 0.43661144375801086, acc = 0.8466796875\n",
      "Batch 394: loss = 0.37849611043930054, acc = 0.876953125\n",
      "Batch 395: loss = 0.40229350328445435, acc = 0.8388671875\n",
      "Batch 396: loss = 0.44351649284362793, acc = 0.8486328125\n",
      "Batch 397: loss = 0.3237082362174988, acc = 0.8857421875\n",
      "Batch 398: loss = 0.34862270951271057, acc = 0.8701171875\n",
      "Batch 399: loss = 0.3983455300331116, acc = 0.8603515625\n",
      "Batch 400: loss = 0.41071003675460815, acc = 0.85546875\n",
      "Batch 401: loss = 0.4282580018043518, acc = 0.8525390625\n",
      "Batch 402: loss = 0.43256646394729614, acc = 0.8701171875\n",
      "Batch 403: loss = 0.3787890076637268, acc = 0.8828125\n",
      "Batch 404: loss = 0.45064234733581543, acc = 0.8583984375\n",
      "Batch 405: loss = 0.44806885719299316, acc = 0.85546875\n",
      "Batch 406: loss = 0.517126202583313, acc = 0.8232421875\n",
      "Batch 407: loss = 0.44802823662757874, acc = 0.8603515625\n",
      "Batch 408: loss = 0.4893224835395813, acc = 0.837890625\n",
      "Batch 409: loss = 0.42252975702285767, acc = 0.8486328125\n",
      "Batch 410: loss = 0.4512651264667511, acc = 0.84375\n",
      "Batch 411: loss = 0.3814108371734619, acc = 0.8642578125\n",
      "Batch 412: loss = 0.45648831129074097, acc = 0.84375\n",
      "Batch 413: loss = 0.38060468435287476, acc = 0.873046875\n",
      "Batch 414: loss = 0.4011155962944031, acc = 0.8759765625\n",
      "Batch 415: loss = 0.43050169944763184, acc = 0.8466796875\n",
      "Batch 416: loss = 0.4903281331062317, acc = 0.83984375\n",
      "Batch 417: loss = 0.42936259508132935, acc = 0.8603515625\n",
      "Batch 418: loss = 0.5216842293739319, acc = 0.8369140625\n",
      "Batch 419: loss = 0.6007173657417297, acc = 0.818359375\n",
      "Batch 420: loss = 0.5404118299484253, acc = 0.83203125\n",
      "Batch 421: loss = 0.49680331349372864, acc = 0.8388671875\n",
      "Batch 422: loss = 0.4643654227256775, acc = 0.8466796875\n",
      "Batch 423: loss = 0.4186159670352936, acc = 0.8583984375\n",
      "Batch 424: loss = 0.4413969814777374, acc = 0.8388671875\n",
      "Batch 425: loss = 0.46339261531829834, acc = 0.845703125\n",
      "Batch 426: loss = 0.4321745038032532, acc = 0.841796875\n",
      "Batch 427: loss = 0.41653865575790405, acc = 0.8603515625\n",
      "Batch 428: loss = 0.3806615471839905, acc = 0.873046875\n",
      "Batch 429: loss = 0.4053887128829956, acc = 0.857421875\n",
      "Batch 430: loss = 0.4160483181476593, acc = 0.8642578125\n",
      "Batch 431: loss = 0.4134064316749573, acc = 0.85546875\n",
      "Batch 432: loss = 0.4143573045730591, acc = 0.861328125\n",
      "Batch 433: loss = 0.372270405292511, acc = 0.8671875\n",
      "Batch 434: loss = 0.41902679204940796, acc = 0.84765625\n",
      "Batch 435: loss = 0.4441395103931427, acc = 0.8427734375\n",
      "Batch 436: loss = 0.3972945809364319, acc = 0.865234375\n",
      "Batch 437: loss = 0.4484827220439911, acc = 0.84765625\n",
      "Batch 438: loss = 0.43149250745773315, acc = 0.8583984375\n",
      "Batch 439: loss = 0.36794906854629517, acc = 0.873046875\n",
      "Batch 440: loss = 0.4064481258392334, acc = 0.859375\n",
      "Batch 441: loss = 0.3949911594390869, acc = 0.8759765625\n",
      "\n",
      "Epoch 92/100\n",
      "Batch 1: loss = 0.5533657073974609, acc = 0.8369140625\n",
      "Batch 2: loss = 0.39686062932014465, acc = 0.86328125\n",
      "Batch 3: loss = 0.4297112822532654, acc = 0.8564453125\n",
      "Batch 4: loss = 0.4449792802333832, acc = 0.8466796875\n",
      "Batch 5: loss = 0.4627337157726288, acc = 0.8408203125\n",
      "Batch 6: loss = 0.37599968910217285, acc = 0.8740234375\n",
      "Batch 7: loss = 0.38337454199790955, acc = 0.8662109375\n",
      "Batch 8: loss = 0.3845631182193756, acc = 0.865234375\n",
      "Batch 9: loss = 0.42120662331581116, acc = 0.8544921875\n",
      "Batch 10: loss = 0.447140097618103, acc = 0.8544921875\n",
      "Batch 11: loss = 0.41669517755508423, acc = 0.85546875\n",
      "Batch 12: loss = 0.3964303731918335, acc = 0.8642578125\n",
      "Batch 13: loss = 0.4611743092536926, acc = 0.84765625\n",
      "Batch 14: loss = 0.40028274059295654, acc = 0.869140625\n",
      "Batch 15: loss = 0.3843252658843994, acc = 0.8662109375\n",
      "Batch 16: loss = 0.40438589453697205, acc = 0.8701171875\n",
      "Batch 17: loss = 0.34790077805519104, acc = 0.88671875\n",
      "Batch 18: loss = 0.39606645703315735, acc = 0.8583984375\n",
      "Batch 19: loss = 0.43470749258995056, acc = 0.845703125\n",
      "Batch 20: loss = 0.45656412839889526, acc = 0.8349609375\n",
      "Batch 21: loss = 0.43484601378440857, acc = 0.85546875\n",
      "Batch 22: loss = 0.4446355700492859, acc = 0.85546875\n",
      "Batch 23: loss = 0.42735224962234497, acc = 0.8505859375\n",
      "Batch 24: loss = 0.3884430229663849, acc = 0.87890625\n",
      "Batch 25: loss = 0.445911169052124, acc = 0.8525390625\n",
      "Batch 26: loss = 0.4254620373249054, acc = 0.8603515625\n",
      "Batch 27: loss = 0.4481911063194275, acc = 0.8564453125\n",
      "Batch 28: loss = 0.41459938883781433, acc = 0.8564453125\n",
      "Batch 29: loss = 0.4851233959197998, acc = 0.8359375\n",
      "Batch 30: loss = 0.4491576552391052, acc = 0.84375\n",
      "Batch 31: loss = 0.4282194972038269, acc = 0.8603515625\n",
      "Batch 32: loss = 0.3718985319137573, acc = 0.873046875\n",
      "Batch 33: loss = 0.3497161567211151, acc = 0.888671875\n",
      "Batch 34: loss = 0.35508590936660767, acc = 0.8798828125\n",
      "Batch 35: loss = 0.39623701572418213, acc = 0.8681640625\n",
      "Batch 36: loss = 0.42887037992477417, acc = 0.8671875\n",
      "Batch 37: loss = 0.39490216970443726, acc = 0.8583984375\n",
      "Batch 38: loss = 0.4145597219467163, acc = 0.8662109375\n",
      "Batch 39: loss = 0.34865710139274597, acc = 0.888671875\n",
      "Batch 40: loss = 0.42160654067993164, acc = 0.8681640625\n",
      "Batch 41: loss = 0.3355024456977844, acc = 0.8916015625\n",
      "Batch 42: loss = 0.4136662185192108, acc = 0.859375\n",
      "Batch 43: loss = 0.4695616364479065, acc = 0.845703125\n",
      "Batch 44: loss = 0.4192677438259125, acc = 0.86328125\n",
      "Batch 45: loss = 0.36391687393188477, acc = 0.875\n",
      "Batch 46: loss = 0.40179067850112915, acc = 0.859375\n",
      "Batch 47: loss = 0.41207006573677063, acc = 0.85546875\n",
      "Batch 48: loss = 0.3764398694038391, acc = 0.875\n",
      "Batch 49: loss = 0.42139148712158203, acc = 0.85546875\n",
      "Batch 50: loss = 0.4398624002933502, acc = 0.865234375\n",
      "Batch 51: loss = 0.44691985845565796, acc = 0.8515625\n",
      "Batch 52: loss = 0.3575786352157593, acc = 0.8779296875\n",
      "Batch 53: loss = 0.4433571994304657, acc = 0.845703125\n",
      "Batch 54: loss = 0.3760152757167816, acc = 0.859375\n",
      "Batch 55: loss = 0.4157627820968628, acc = 0.8701171875\n",
      "Batch 56: loss = 0.42778852581977844, acc = 0.8515625\n",
      "Batch 57: loss = 0.42670854926109314, acc = 0.85546875\n",
      "Batch 58: loss = 0.41109228134155273, acc = 0.8544921875\n",
      "Batch 59: loss = 0.4149248003959656, acc = 0.8662109375\n",
      "Batch 60: loss = 0.39364951848983765, acc = 0.87109375\n",
      "Batch 61: loss = 0.4211655855178833, acc = 0.845703125\n",
      "Batch 62: loss = 0.44082367420196533, acc = 0.845703125\n",
      "Batch 63: loss = 0.4474717378616333, acc = 0.845703125\n",
      "Batch 64: loss = 0.38133835792541504, acc = 0.876953125\n",
      "Batch 65: loss = 0.35409054160118103, acc = 0.880859375\n",
      "Batch 66: loss = 0.37457606196403503, acc = 0.873046875\n",
      "Batch 67: loss = 0.45624634623527527, acc = 0.8388671875\n",
      "Batch 68: loss = 0.4695417881011963, acc = 0.8466796875\n",
      "Batch 69: loss = 0.383556991815567, acc = 0.87109375\n",
      "Batch 70: loss = 0.4193980097770691, acc = 0.8427734375\n",
      "Batch 71: loss = 0.4479439854621887, acc = 0.8525390625\n",
      "Batch 72: loss = 0.45514118671417236, acc = 0.830078125\n",
      "Batch 73: loss = 0.4180334806442261, acc = 0.87109375\n",
      "Batch 74: loss = 0.4655255675315857, acc = 0.837890625\n",
      "Batch 75: loss = 0.3368470072746277, acc = 0.8818359375\n",
      "Batch 76: loss = 0.4720765948295593, acc = 0.82421875\n",
      "Batch 77: loss = 0.48694881796836853, acc = 0.826171875\n",
      "Batch 78: loss = 0.4528549909591675, acc = 0.8486328125\n",
      "Batch 79: loss = 0.3935803472995758, acc = 0.8662109375\n",
      "Batch 80: loss = 0.5234214067459106, acc = 0.818359375\n",
      "Batch 81: loss = 0.38465046882629395, acc = 0.8720703125\n",
      "Batch 82: loss = 0.40188494324684143, acc = 0.8642578125\n",
      "Batch 83: loss = 0.4319983124732971, acc = 0.849609375\n",
      "Batch 84: loss = 0.3821762204170227, acc = 0.8720703125\n",
      "Batch 85: loss = 0.45424193143844604, acc = 0.83984375\n",
      "Batch 86: loss = 0.4389088451862335, acc = 0.849609375\n",
      "Batch 87: loss = 0.39269328117370605, acc = 0.8701171875\n",
      "Batch 88: loss = 0.43522435426712036, acc = 0.859375\n",
      "Batch 89: loss = 0.4911877512931824, acc = 0.83984375\n",
      "Batch 90: loss = 0.4132991135120392, acc = 0.8623046875\n",
      "Batch 91: loss = 0.3948122262954712, acc = 0.8681640625\n",
      "Batch 92: loss = 0.45239758491516113, acc = 0.8486328125\n",
      "Batch 93: loss = 0.45449864864349365, acc = 0.8349609375\n",
      "Batch 94: loss = 0.43178367614746094, acc = 0.865234375\n",
      "Batch 95: loss = 0.4077592194080353, acc = 0.87109375\n",
      "Batch 96: loss = 0.3874184489250183, acc = 0.8720703125\n",
      "Batch 97: loss = 0.44281575083732605, acc = 0.8447265625\n",
      "Batch 98: loss = 0.48456311225891113, acc = 0.8388671875\n",
      "Batch 99: loss = 0.42320796847343445, acc = 0.8544921875\n",
      "Batch 100: loss = 0.46501192450523376, acc = 0.845703125\n",
      "Batch 101: loss = 0.4033343195915222, acc = 0.8759765625\n",
      "Batch 102: loss = 0.3615536093711853, acc = 0.8740234375\n",
      "Batch 103: loss = 0.3721831142902374, acc = 0.876953125\n",
      "Batch 104: loss = 0.37664341926574707, acc = 0.87109375\n",
      "Batch 105: loss = 0.4295418858528137, acc = 0.841796875\n",
      "Batch 106: loss = 0.4556474983692169, acc = 0.85546875\n",
      "Batch 107: loss = 0.4091240167617798, acc = 0.873046875\n",
      "Batch 108: loss = 0.4620234966278076, acc = 0.845703125\n",
      "Batch 109: loss = 0.39421308040618896, acc = 0.87109375\n",
      "Batch 110: loss = 0.46006685495376587, acc = 0.8466796875\n",
      "Batch 111: loss = 0.44426190853118896, acc = 0.8515625\n",
      "Batch 112: loss = 0.4472188949584961, acc = 0.8447265625\n",
      "Batch 113: loss = 0.43342331051826477, acc = 0.8603515625\n",
      "Batch 114: loss = 0.32967427372932434, acc = 0.8896484375\n",
      "Batch 115: loss = 0.44439131021499634, acc = 0.8447265625\n",
      "Batch 116: loss = 0.39275774359703064, acc = 0.86328125\n",
      "Batch 117: loss = 0.39724019169807434, acc = 0.8759765625\n",
      "Batch 118: loss = 0.4344122111797333, acc = 0.8583984375\n",
      "Batch 119: loss = 0.4205888509750366, acc = 0.8515625\n",
      "Batch 120: loss = 0.46874943375587463, acc = 0.8515625\n",
      "Batch 121: loss = 0.4731019139289856, acc = 0.8486328125\n",
      "Batch 122: loss = 0.3660556375980377, acc = 0.8681640625\n",
      "Batch 123: loss = 0.4069141745567322, acc = 0.8583984375\n",
      "Batch 124: loss = 0.4026569724082947, acc = 0.8564453125\n",
      "Batch 125: loss = 0.36901921033859253, acc = 0.876953125\n",
      "Batch 126: loss = 0.3409326672554016, acc = 0.87890625\n",
      "Batch 127: loss = 0.4333786368370056, acc = 0.8544921875\n",
      "Batch 128: loss = 0.42863649129867554, acc = 0.8583984375\n",
      "Batch 129: loss = 0.38059544563293457, acc = 0.869140625\n",
      "Batch 130: loss = 0.4234253168106079, acc = 0.8447265625\n",
      "Batch 131: loss = 0.34045007824897766, acc = 0.88671875\n",
      "Batch 132: loss = 0.30856770277023315, acc = 0.8974609375\n",
      "Batch 133: loss = 0.34653329849243164, acc = 0.880859375\n",
      "Batch 134: loss = 0.3836333453655243, acc = 0.875\n",
      "Batch 135: loss = 0.42689138650894165, acc = 0.865234375\n",
      "Batch 136: loss = 0.3855096101760864, acc = 0.8740234375\n",
      "Batch 137: loss = 0.3810049295425415, acc = 0.8681640625\n",
      "Batch 138: loss = 0.3804675042629242, acc = 0.880859375\n",
      "Batch 139: loss = 0.3939746916294098, acc = 0.8720703125\n",
      "Batch 140: loss = 0.3928137421607971, acc = 0.8759765625\n",
      "Batch 141: loss = 0.4199371635913849, acc = 0.8671875\n",
      "Batch 142: loss = 0.4608992040157318, acc = 0.84375\n",
      "Batch 143: loss = 0.45481735467910767, acc = 0.8466796875\n",
      "Batch 144: loss = 0.4360330104827881, acc = 0.8603515625\n",
      "Batch 145: loss = 0.39492520689964294, acc = 0.86328125\n",
      "Batch 146: loss = 0.4048007130622864, acc = 0.865234375\n",
      "Batch 147: loss = 0.46231019496917725, acc = 0.845703125\n",
      "Batch 148: loss = 0.3666873872280121, acc = 0.8779296875\n",
      "Batch 149: loss = 0.40665602684020996, acc = 0.865234375\n",
      "Batch 150: loss = 0.4334530234336853, acc = 0.853515625\n",
      "Batch 151: loss = 0.47889846563339233, acc = 0.8359375\n",
      "Batch 152: loss = 0.4067077040672302, acc = 0.8564453125\n",
      "Batch 153: loss = 0.42011120915412903, acc = 0.8623046875\n",
      "Batch 154: loss = 0.4323035478591919, acc = 0.8525390625\n",
      "Batch 155: loss = 0.4368576407432556, acc = 0.8544921875\n",
      "Batch 156: loss = 0.4595530927181244, acc = 0.8388671875\n",
      "Batch 157: loss = 0.4166485369205475, acc = 0.857421875\n",
      "Batch 158: loss = 0.3829202651977539, acc = 0.875\n",
      "Batch 159: loss = 0.4426179826259613, acc = 0.8447265625\n",
      "Batch 160: loss = 0.40236181020736694, acc = 0.8515625\n",
      "Batch 161: loss = 0.45249640941619873, acc = 0.857421875\n",
      "Batch 162: loss = 0.4618260860443115, acc = 0.830078125\n",
      "Batch 163: loss = 0.4362300932407379, acc = 0.87109375\n",
      "Batch 164: loss = 0.44589555263519287, acc = 0.8603515625\n",
      "Batch 165: loss = 0.45043325424194336, acc = 0.849609375\n",
      "Batch 166: loss = 0.3623684048652649, acc = 0.876953125\n",
      "Batch 167: loss = 0.4045867621898651, acc = 0.8466796875\n",
      "Batch 168: loss = 0.4075884521007538, acc = 0.859375\n",
      "Batch 169: loss = 0.36763525009155273, acc = 0.8701171875\n",
      "Batch 170: loss = 0.3567006587982178, acc = 0.8701171875\n",
      "Batch 171: loss = 0.42875707149505615, acc = 0.8662109375\n",
      "Batch 172: loss = 0.35900411009788513, acc = 0.884765625\n",
      "Batch 173: loss = 0.4039169251918793, acc = 0.8662109375\n",
      "Batch 174: loss = 0.3758825659751892, acc = 0.8818359375\n",
      "Batch 175: loss = 0.4230676293373108, acc = 0.849609375\n",
      "Batch 176: loss = 0.4063990116119385, acc = 0.8642578125\n",
      "Batch 177: loss = 0.34810009598731995, acc = 0.875\n",
      "Batch 178: loss = 0.3838885426521301, acc = 0.8662109375\n",
      "Batch 179: loss = 0.4087495505809784, acc = 0.85546875\n",
      "Batch 180: loss = 0.3940495252609253, acc = 0.8720703125\n",
      "Batch 181: loss = 0.39680925011634827, acc = 0.8623046875\n",
      "Batch 182: loss = 0.40606531500816345, acc = 0.8564453125\n",
      "Batch 183: loss = 0.39160841703414917, acc = 0.875\n",
      "Batch 184: loss = 0.40372008085250854, acc = 0.8681640625\n",
      "Batch 185: loss = 0.43253934383392334, acc = 0.87109375\n",
      "Batch 186: loss = 0.40148454904556274, acc = 0.87109375\n",
      "Batch 187: loss = 0.433467835187912, acc = 0.8583984375\n",
      "Batch 188: loss = 0.40019458532333374, acc = 0.8583984375\n",
      "Batch 189: loss = 0.3827660083770752, acc = 0.87109375\n",
      "Batch 190: loss = 0.4824458360671997, acc = 0.8369140625\n",
      "Batch 191: loss = 0.39864420890808105, acc = 0.865234375\n",
      "Batch 192: loss = 0.35723066329956055, acc = 0.876953125\n",
      "Batch 193: loss = 0.42500635981559753, acc = 0.861328125\n",
      "Batch 194: loss = 0.43647706508636475, acc = 0.8623046875\n",
      "Batch 195: loss = 0.4482749402523041, acc = 0.85546875\n",
      "Batch 196: loss = 0.500728964805603, acc = 0.830078125\n",
      "Batch 197: loss = 0.45660775899887085, acc = 0.853515625\n",
      "Batch 198: loss = 0.38658109307289124, acc = 0.876953125\n",
      "Batch 199: loss = 0.4056183397769928, acc = 0.8603515625\n",
      "Batch 200: loss = 0.5022793412208557, acc = 0.837890625\n",
      "Batch 201: loss = 0.4349401593208313, acc = 0.841796875\n",
      "Batch 202: loss = 0.5154790878295898, acc = 0.8291015625\n",
      "Batch 203: loss = 0.38325127959251404, acc = 0.8642578125\n",
      "Batch 204: loss = 0.4533245265483856, acc = 0.83203125\n",
      "Batch 205: loss = 0.4664130210876465, acc = 0.8447265625\n",
      "Batch 206: loss = 0.4333226680755615, acc = 0.8505859375\n",
      "Batch 207: loss = 0.4784696102142334, acc = 0.8388671875\n",
      "Batch 208: loss = 0.4608035683631897, acc = 0.83984375\n",
      "Batch 209: loss = 0.4246101677417755, acc = 0.8486328125\n",
      "Batch 210: loss = 0.42707324028015137, acc = 0.8623046875\n",
      "Batch 211: loss = 0.42336681485176086, acc = 0.8525390625\n",
      "Batch 212: loss = 0.43243318796157837, acc = 0.8583984375\n",
      "Batch 213: loss = 0.4129796028137207, acc = 0.853515625\n",
      "Batch 214: loss = 0.4052802622318268, acc = 0.86328125\n",
      "Batch 215: loss = 0.3707208037376404, acc = 0.87109375\n",
      "Batch 216: loss = 0.35623785853385925, acc = 0.8701171875\n",
      "Batch 217: loss = 0.374244749546051, acc = 0.869140625\n",
      "Batch 218: loss = 0.4293779730796814, acc = 0.8486328125\n",
      "Batch 219: loss = 0.46384039521217346, acc = 0.8515625\n",
      "Batch 220: loss = 0.38524311780929565, acc = 0.8671875\n",
      "Batch 221: loss = 0.4663129448890686, acc = 0.8369140625\n",
      "Batch 222: loss = 0.3961808681488037, acc = 0.869140625\n",
      "Batch 223: loss = 0.3518562316894531, acc = 0.880859375\n",
      "Batch 224: loss = 0.36436915397644043, acc = 0.87109375\n",
      "Batch 225: loss = 0.37407103180885315, acc = 0.8671875\n",
      "Batch 226: loss = 0.4387722611427307, acc = 0.8505859375\n",
      "Batch 227: loss = 0.39472874999046326, acc = 0.869140625\n",
      "Batch 228: loss = 0.4171820878982544, acc = 0.8564453125\n",
      "Batch 229: loss = 0.347750723361969, acc = 0.8876953125\n",
      "Batch 230: loss = 0.3661491274833679, acc = 0.8759765625\n",
      "Batch 231: loss = 0.4704709053039551, acc = 0.8466796875\n",
      "Batch 232: loss = 0.37817519903182983, acc = 0.8779296875\n",
      "Batch 233: loss = 0.47371193766593933, acc = 0.830078125\n",
      "Batch 234: loss = 0.4234151840209961, acc = 0.8544921875\n",
      "Batch 235: loss = 0.42429935932159424, acc = 0.8544921875\n",
      "Batch 236: loss = 0.4429168701171875, acc = 0.8544921875\n",
      "Batch 237: loss = 0.3925144076347351, acc = 0.8681640625\n",
      "Batch 238: loss = 0.44538164138793945, acc = 0.8486328125\n",
      "Batch 239: loss = 0.37327104806900024, acc = 0.869140625\n",
      "Batch 240: loss = 0.41488218307495117, acc = 0.861328125\n",
      "Batch 241: loss = 0.421832799911499, acc = 0.8515625\n",
      "Batch 242: loss = 0.45889440178871155, acc = 0.841796875\n",
      "Batch 243: loss = 0.47065937519073486, acc = 0.833984375\n",
      "Batch 244: loss = 0.46716898679733276, acc = 0.8359375\n",
      "Batch 245: loss = 0.39916980266571045, acc = 0.8671875\n",
      "Batch 246: loss = 0.3916642665863037, acc = 0.8662109375\n",
      "Batch 247: loss = 0.43329867720603943, acc = 0.8359375\n",
      "Batch 248: loss = 0.4072822630405426, acc = 0.85546875\n",
      "Batch 249: loss = 0.3711480498313904, acc = 0.892578125\n",
      "Batch 250: loss = 0.4225933253765106, acc = 0.8505859375\n",
      "Batch 251: loss = 0.33962392807006836, acc = 0.876953125\n",
      "Batch 252: loss = 0.3762616515159607, acc = 0.87109375\n",
      "Batch 253: loss = 0.44372066855430603, acc = 0.8447265625\n",
      "Batch 254: loss = 0.4546452760696411, acc = 0.8388671875\n",
      "Batch 255: loss = 0.5007237195968628, acc = 0.8388671875\n",
      "Batch 256: loss = 0.4265033006668091, acc = 0.8671875\n",
      "Batch 257: loss = 0.5135443210601807, acc = 0.8203125\n",
      "Batch 258: loss = 0.46942034363746643, acc = 0.8349609375\n",
      "Batch 259: loss = 0.539014458656311, acc = 0.8203125\n",
      "Batch 260: loss = 0.4918242394924164, acc = 0.8271484375\n",
      "Batch 261: loss = 0.44670990109443665, acc = 0.8486328125\n",
      "Batch 262: loss = 0.4478267729282379, acc = 0.83984375\n",
      "Batch 263: loss = 0.4094201922416687, acc = 0.853515625\n",
      "Batch 264: loss = 0.4134764075279236, acc = 0.8671875\n",
      "Batch 265: loss = 0.3947068750858307, acc = 0.8642578125\n",
      "Batch 266: loss = 0.3792341947555542, acc = 0.876953125\n",
      "Batch 267: loss = 0.354549765586853, acc = 0.8876953125\n",
      "Batch 268: loss = 0.40725284814834595, acc = 0.8642578125\n",
      "Batch 269: loss = 0.44364744424819946, acc = 0.8408203125\n",
      "Batch 270: loss = 0.42097586393356323, acc = 0.857421875\n",
      "Batch 271: loss = 0.40188539028167725, acc = 0.8603515625\n",
      "Batch 272: loss = 0.3963525593280792, acc = 0.8701171875\n",
      "Batch 273: loss = 0.4059564769268036, acc = 0.861328125\n",
      "Batch 274: loss = 0.38987112045288086, acc = 0.875\n",
      "Batch 275: loss = 0.3595775067806244, acc = 0.8798828125\n",
      "Batch 276: loss = 0.42879754304885864, acc = 0.853515625\n",
      "Batch 277: loss = 0.4659471809864044, acc = 0.84765625\n",
      "Batch 278: loss = 0.3747681975364685, acc = 0.865234375\n",
      "Batch 279: loss = 0.4801788330078125, acc = 0.8505859375\n",
      "Batch 280: loss = 0.44623205065727234, acc = 0.8466796875\n",
      "Batch 281: loss = 0.3992173671722412, acc = 0.8583984375\n",
      "Batch 282: loss = 0.469485878944397, acc = 0.8544921875\n",
      "Batch 283: loss = 0.5053670406341553, acc = 0.8212890625\n",
      "Batch 284: loss = 0.396852970123291, acc = 0.8701171875\n",
      "Batch 285: loss = 0.44308793544769287, acc = 0.83984375\n",
      "Batch 286: loss = 0.4764871597290039, acc = 0.8544921875\n",
      "Batch 287: loss = 0.4721863865852356, acc = 0.8486328125\n",
      "Batch 288: loss = 0.4546448588371277, acc = 0.837890625\n",
      "Batch 289: loss = 0.41499361395835876, acc = 0.853515625\n",
      "Batch 290: loss = 0.43374356627464294, acc = 0.8369140625\n",
      "Batch 291: loss = 0.46838071942329407, acc = 0.8486328125\n",
      "Batch 292: loss = 0.4582234025001526, acc = 0.8388671875\n",
      "Batch 293: loss = 0.39474108815193176, acc = 0.859375\n",
      "Batch 294: loss = 0.4499781131744385, acc = 0.8359375\n",
      "Batch 295: loss = 0.39802607893943787, acc = 0.85546875\n",
      "Batch 296: loss = 0.41359347105026245, acc = 0.8671875\n",
      "Batch 297: loss = 0.3949369788169861, acc = 0.8701171875\n",
      "Batch 298: loss = 0.34404733777046204, acc = 0.8798828125\n",
      "Batch 299: loss = 0.3398604393005371, acc = 0.8935546875\n",
      "Batch 300: loss = 0.44412049651145935, acc = 0.8623046875\n",
      "Batch 301: loss = 0.3780187666416168, acc = 0.8740234375\n",
      "Batch 302: loss = 0.42568808794021606, acc = 0.8671875\n",
      "Batch 303: loss = 0.45519882440567017, acc = 0.8515625\n",
      "Batch 304: loss = 0.37520599365234375, acc = 0.8828125\n",
      "Batch 305: loss = 0.43654298782348633, acc = 0.8515625\n",
      "Batch 306: loss = 0.4304719865322113, acc = 0.8564453125\n",
      "Batch 307: loss = 0.3332611322402954, acc = 0.8935546875\n",
      "Batch 308: loss = 0.41734227538108826, acc = 0.8662109375\n",
      "Batch 309: loss = 0.40479937195777893, acc = 0.8662109375\n",
      "Batch 310: loss = 0.4864690899848938, acc = 0.828125\n",
      "Batch 311: loss = 0.4389204680919647, acc = 0.8583984375\n",
      "Batch 312: loss = 0.40161651372909546, acc = 0.861328125\n",
      "Batch 313: loss = 0.46211886405944824, acc = 0.8388671875\n",
      "Batch 314: loss = 0.4275902509689331, acc = 0.861328125\n",
      "Batch 315: loss = 0.412306010723114, acc = 0.861328125\n",
      "Batch 316: loss = 0.40954869985580444, acc = 0.857421875\n",
      "Batch 317: loss = 0.37939468026161194, acc = 0.86328125\n",
      "Batch 318: loss = 0.43231940269470215, acc = 0.845703125\n",
      "Batch 319: loss = 0.46127742528915405, acc = 0.8544921875\n",
      "Batch 320: loss = 0.421905517578125, acc = 0.8486328125\n",
      "Batch 321: loss = 0.4487798810005188, acc = 0.849609375\n",
      "Batch 322: loss = 0.40931957960128784, acc = 0.8720703125\n",
      "Batch 323: loss = 0.4529893100261688, acc = 0.853515625\n",
      "Batch 324: loss = 0.44111040234565735, acc = 0.8603515625\n",
      "Batch 325: loss = 0.4624578356742859, acc = 0.830078125\n",
      "Batch 326: loss = 0.4093588888645172, acc = 0.8564453125\n",
      "Batch 327: loss = 0.432524710893631, acc = 0.8515625\n",
      "Batch 328: loss = 0.4098604619503021, acc = 0.8603515625\n",
      "Batch 329: loss = 0.4943891763687134, acc = 0.833984375\n",
      "Batch 330: loss = 0.3624115586280823, acc = 0.875\n",
      "Batch 331: loss = 0.40808337926864624, acc = 0.859375\n",
      "Batch 332: loss = 0.4196615517139435, acc = 0.853515625\n",
      "Batch 333: loss = 0.40641507506370544, acc = 0.8515625\n",
      "Batch 334: loss = 0.3620266020298004, acc = 0.8857421875\n",
      "Batch 335: loss = 0.4705308973789215, acc = 0.8505859375\n",
      "Batch 336: loss = 0.44258368015289307, acc = 0.8505859375\n",
      "Batch 337: loss = 0.49203842878341675, acc = 0.837890625\n",
      "Batch 338: loss = 0.3852514624595642, acc = 0.8671875\n",
      "Batch 339: loss = 0.42100951075553894, acc = 0.8701171875\n",
      "Batch 340: loss = 0.40846219658851624, acc = 0.8603515625\n",
      "Batch 341: loss = 0.41952061653137207, acc = 0.85546875\n",
      "Batch 342: loss = 0.43441155552864075, acc = 0.8544921875\n",
      "Batch 343: loss = 0.3807819187641144, acc = 0.8759765625\n",
      "Batch 344: loss = 0.3726164996623993, acc = 0.8876953125\n",
      "Batch 345: loss = 0.389757364988327, acc = 0.8740234375\n",
      "Batch 346: loss = 0.35727062821388245, acc = 0.880859375\n",
      "Batch 347: loss = 0.4008220136165619, acc = 0.8583984375\n",
      "Batch 348: loss = 0.41079598665237427, acc = 0.859375\n",
      "Batch 349: loss = 0.37018051743507385, acc = 0.8662109375\n",
      "Batch 350: loss = 0.34348464012145996, acc = 0.8837890625\n",
      "Batch 351: loss = 0.33980125188827515, acc = 0.88671875\n",
      "Batch 352: loss = 0.40596920251846313, acc = 0.8583984375\n",
      "Batch 353: loss = 0.37180089950561523, acc = 0.884765625\n",
      "Batch 354: loss = 0.33952096104621887, acc = 0.8837890625\n",
      "Batch 355: loss = 0.32184410095214844, acc = 0.8857421875\n",
      "Batch 356: loss = 0.3643977642059326, acc = 0.8798828125\n",
      "Batch 357: loss = 0.36099138855934143, acc = 0.8818359375\n",
      "Batch 358: loss = 0.3544617295265198, acc = 0.875\n",
      "Batch 359: loss = 0.4068202078342438, acc = 0.849609375\n",
      "Batch 360: loss = 0.38920795917510986, acc = 0.875\n",
      "Batch 361: loss = 0.38277578353881836, acc = 0.87109375\n",
      "Batch 362: loss = 0.36462539434432983, acc = 0.8828125\n",
      "Batch 363: loss = 0.386875182390213, acc = 0.8642578125\n",
      "Batch 364: loss = 0.4115182161331177, acc = 0.8564453125\n",
      "Batch 365: loss = 0.3916458487510681, acc = 0.8671875\n",
      "Batch 366: loss = 0.37848424911499023, acc = 0.865234375\n",
      "Batch 367: loss = 0.3764609098434448, acc = 0.87109375\n",
      "Batch 368: loss = 0.45538854598999023, acc = 0.8525390625\n",
      "Batch 369: loss = 0.45710328221321106, acc = 0.8544921875\n",
      "Batch 370: loss = 0.3684951364994049, acc = 0.8876953125\n",
      "Batch 371: loss = 0.46388953924179077, acc = 0.845703125\n",
      "Batch 372: loss = 0.36162546277046204, acc = 0.8828125\n",
      "Batch 373: loss = 0.3958774209022522, acc = 0.8583984375\n",
      "Batch 374: loss = 0.41808637976646423, acc = 0.8466796875\n",
      "Batch 375: loss = 0.4626699388027191, acc = 0.8427734375\n",
      "Batch 376: loss = 0.4361550211906433, acc = 0.8564453125\n",
      "Batch 377: loss = 0.4702175259590149, acc = 0.84375\n",
      "Batch 378: loss = 0.3998725712299347, acc = 0.8623046875\n",
      "Batch 379: loss = 0.4658477306365967, acc = 0.8388671875\n",
      "Batch 380: loss = 0.357893168926239, acc = 0.8818359375\n",
      "Batch 381: loss = 0.367790162563324, acc = 0.8798828125\n",
      "Batch 382: loss = 0.4220566153526306, acc = 0.8544921875\n",
      "Batch 383: loss = 0.36553600430488586, acc = 0.8623046875\n",
      "Batch 384: loss = 0.4183777868747711, acc = 0.8642578125\n",
      "Batch 385: loss = 0.3913741409778595, acc = 0.865234375\n",
      "Batch 386: loss = 0.4191700220108032, acc = 0.857421875\n",
      "Batch 387: loss = 0.3807719349861145, acc = 0.8662109375\n",
      "Batch 388: loss = 0.4466164708137512, acc = 0.84765625\n",
      "Batch 389: loss = 0.40677154064178467, acc = 0.8603515625\n",
      "Batch 390: loss = 0.45685863494873047, acc = 0.8466796875\n",
      "Batch 391: loss = 0.4332382380962372, acc = 0.861328125\n",
      "Batch 392: loss = 0.42361629009246826, acc = 0.8525390625\n",
      "Batch 393: loss = 0.44460529088974, acc = 0.841796875\n",
      "Batch 394: loss = 0.3740956783294678, acc = 0.880859375\n",
      "Batch 395: loss = 0.4039061665534973, acc = 0.8525390625\n",
      "Batch 396: loss = 0.43662410974502563, acc = 0.8671875\n",
      "Batch 397: loss = 0.3627554178237915, acc = 0.8759765625\n",
      "Batch 398: loss = 0.3587418496608734, acc = 0.8701171875\n",
      "Batch 399: loss = 0.3949928283691406, acc = 0.8779296875\n",
      "Batch 400: loss = 0.40117180347442627, acc = 0.86328125\n",
      "Batch 401: loss = 0.4025787115097046, acc = 0.8701171875\n",
      "Batch 402: loss = 0.4166967272758484, acc = 0.8662109375\n",
      "Batch 403: loss = 0.37461918592453003, acc = 0.8720703125\n",
      "Batch 404: loss = 0.45793959498405457, acc = 0.84375\n",
      "Batch 405: loss = 0.42199164628982544, acc = 0.857421875\n",
      "Batch 406: loss = 0.5277611613273621, acc = 0.8125\n",
      "Batch 407: loss = 0.4633325934410095, acc = 0.8525390625\n",
      "Batch 408: loss = 0.5279455184936523, acc = 0.830078125\n",
      "Batch 409: loss = 0.42112258076667786, acc = 0.849609375\n",
      "Batch 410: loss = 0.47263818979263306, acc = 0.8388671875\n",
      "Batch 411: loss = 0.3595423996448517, acc = 0.87109375\n",
      "Batch 412: loss = 0.39631834626197815, acc = 0.8662109375\n",
      "Batch 413: loss = 0.39217522740364075, acc = 0.8662109375\n",
      "Batch 414: loss = 0.42406803369522095, acc = 0.8681640625\n",
      "Batch 415: loss = 0.42149239778518677, acc = 0.8466796875\n",
      "Batch 416: loss = 0.4080701470375061, acc = 0.86328125\n",
      "Batch 417: loss = 0.42140835523605347, acc = 0.85546875\n",
      "Batch 418: loss = 0.4568858742713928, acc = 0.849609375\n",
      "Batch 419: loss = 0.5199063420295715, acc = 0.8291015625\n",
      "Batch 420: loss = 0.47628334164619446, acc = 0.83984375\n",
      "Batch 421: loss = 0.48263323307037354, acc = 0.8408203125\n",
      "Batch 422: loss = 0.47844213247299194, acc = 0.8359375\n",
      "Batch 423: loss = 0.42077934741973877, acc = 0.85546875\n",
      "Batch 424: loss = 0.44121479988098145, acc = 0.8388671875\n",
      "Batch 425: loss = 0.43582683801651, acc = 0.8466796875\n",
      "Batch 426: loss = 0.4560796916484833, acc = 0.853515625\n",
      "Batch 427: loss = 0.43144655227661133, acc = 0.85546875\n",
      "Batch 428: loss = 0.43180274963378906, acc = 0.853515625\n",
      "Batch 429: loss = 0.42170023918151855, acc = 0.8544921875\n",
      "Batch 430: loss = 0.4112408459186554, acc = 0.8662109375\n",
      "Batch 431: loss = 0.4379711151123047, acc = 0.853515625\n",
      "Batch 432: loss = 0.4533858597278595, acc = 0.849609375\n",
      "Batch 433: loss = 0.3594130575656891, acc = 0.873046875\n",
      "Batch 434: loss = 0.42475345730781555, acc = 0.859375\n",
      "Batch 435: loss = 0.4485396444797516, acc = 0.841796875\n",
      "Batch 436: loss = 0.36086326837539673, acc = 0.8740234375\n",
      "Batch 437: loss = 0.4709929823875427, acc = 0.8447265625\n",
      "Batch 438: loss = 0.3931445777416229, acc = 0.869140625\n",
      "Batch 439: loss = 0.3581048250198364, acc = 0.8671875\n",
      "Batch 440: loss = 0.4754626452922821, acc = 0.8466796875\n",
      "Batch 441: loss = 0.3960755169391632, acc = 0.8623046875\n",
      "\n",
      "Epoch 93/100\n",
      "Batch 1: loss = 0.5485707521438599, acc = 0.82421875\n",
      "Batch 2: loss = 0.4315841495990753, acc = 0.8388671875\n",
      "Batch 3: loss = 0.42303672432899475, acc = 0.8544921875\n",
      "Batch 4: loss = 0.4405377507209778, acc = 0.845703125\n",
      "Batch 5: loss = 0.4568931460380554, acc = 0.8544921875\n",
      "Batch 6: loss = 0.35551249980926514, acc = 0.8935546875\n",
      "Batch 7: loss = 0.36767324805259705, acc = 0.8740234375\n",
      "Batch 8: loss = 0.4352739155292511, acc = 0.8505859375\n",
      "Batch 9: loss = 0.4287246763706207, acc = 0.857421875\n",
      "Batch 10: loss = 0.43320977687835693, acc = 0.8486328125\n",
      "Batch 11: loss = 0.4219454526901245, acc = 0.8544921875\n",
      "Batch 12: loss = 0.4320180416107178, acc = 0.8515625\n",
      "Batch 13: loss = 0.46379554271698, acc = 0.8408203125\n",
      "Batch 14: loss = 0.39054420590400696, acc = 0.859375\n",
      "Batch 15: loss = 0.43031129240989685, acc = 0.8466796875\n",
      "Batch 16: loss = 0.4181325137615204, acc = 0.8671875\n",
      "Batch 17: loss = 0.3625739812850952, acc = 0.8759765625\n",
      "Batch 18: loss = 0.43569597601890564, acc = 0.8466796875\n",
      "Batch 19: loss = 0.42833974957466125, acc = 0.8623046875\n",
      "Batch 20: loss = 0.42828884720802307, acc = 0.84765625\n",
      "Batch 21: loss = 0.46728867292404175, acc = 0.8291015625\n",
      "Batch 22: loss = 0.4342220425605774, acc = 0.8564453125\n",
      "Batch 23: loss = 0.4368012845516205, acc = 0.859375\n",
      "Batch 24: loss = 0.38193491101264954, acc = 0.8828125\n",
      "Batch 25: loss = 0.46257415413856506, acc = 0.8359375\n",
      "Batch 26: loss = 0.3874968886375427, acc = 0.87890625\n",
      "Batch 27: loss = 0.46592962741851807, acc = 0.84375\n",
      "Batch 28: loss = 0.3940262198448181, acc = 0.873046875\n",
      "Batch 29: loss = 0.48183274269104004, acc = 0.8359375\n",
      "Batch 30: loss = 0.4377046823501587, acc = 0.8486328125\n",
      "Batch 31: loss = 0.42533186078071594, acc = 0.8642578125\n",
      "Batch 32: loss = 0.36970609426498413, acc = 0.873046875\n",
      "Batch 33: loss = 0.32741713523864746, acc = 0.8876953125\n",
      "Batch 34: loss = 0.34860414266586304, acc = 0.8837890625\n",
      "Batch 35: loss = 0.3898624777793884, acc = 0.873046875\n",
      "Batch 36: loss = 0.4392215311527252, acc = 0.8662109375\n",
      "Batch 37: loss = 0.3890509009361267, acc = 0.8681640625\n",
      "Batch 38: loss = 0.4115384519100189, acc = 0.861328125\n",
      "Batch 39: loss = 0.32285526394844055, acc = 0.90234375\n",
      "Batch 40: loss = 0.39230993390083313, acc = 0.873046875\n",
      "Batch 41: loss = 0.3629275858402252, acc = 0.875\n",
      "Batch 42: loss = 0.45363759994506836, acc = 0.853515625\n",
      "Batch 43: loss = 0.460690438747406, acc = 0.8369140625\n",
      "Batch 44: loss = 0.47647029161453247, acc = 0.8369140625\n",
      "Batch 45: loss = 0.35392534732818604, acc = 0.8720703125\n",
      "Batch 46: loss = 0.4187612533569336, acc = 0.859375\n",
      "Batch 47: loss = 0.42302390933036804, acc = 0.8623046875\n",
      "Batch 48: loss = 0.3625147044658661, acc = 0.876953125\n",
      "Batch 49: loss = 0.417263925075531, acc = 0.869140625\n",
      "Batch 50: loss = 0.4206337630748749, acc = 0.8564453125\n",
      "Batch 51: loss = 0.4441847801208496, acc = 0.84375\n",
      "Batch 52: loss = 0.36546140909194946, acc = 0.865234375\n",
      "Batch 53: loss = 0.4213508665561676, acc = 0.853515625\n",
      "Batch 54: loss = 0.3860829472541809, acc = 0.861328125\n",
      "Batch 55: loss = 0.4290461838245392, acc = 0.85546875\n",
      "Batch 56: loss = 0.40955930948257446, acc = 0.8564453125\n",
      "Batch 57: loss = 0.4076746702194214, acc = 0.8583984375\n",
      "Batch 58: loss = 0.3965766429901123, acc = 0.865234375\n",
      "Batch 59: loss = 0.4026012122631073, acc = 0.853515625\n",
      "Batch 60: loss = 0.39915797114372253, acc = 0.873046875\n",
      "Batch 61: loss = 0.4135226905345917, acc = 0.85546875\n",
      "Batch 62: loss = 0.44575807452201843, acc = 0.84765625\n",
      "Batch 63: loss = 0.4414210021495819, acc = 0.853515625\n",
      "Batch 64: loss = 0.37258589267730713, acc = 0.8798828125\n",
      "Batch 65: loss = 0.3476727604866028, acc = 0.8896484375\n",
      "Batch 66: loss = 0.3452569246292114, acc = 0.8837890625\n",
      "Batch 67: loss = 0.4294050633907318, acc = 0.857421875\n",
      "Batch 68: loss = 0.43624693155288696, acc = 0.8603515625\n",
      "Batch 69: loss = 0.3812934160232544, acc = 0.873046875\n",
      "Batch 70: loss = 0.4444868564605713, acc = 0.841796875\n",
      "Batch 71: loss = 0.4402492940425873, acc = 0.8515625\n",
      "Batch 72: loss = 0.43263816833496094, acc = 0.849609375\n",
      "Batch 73: loss = 0.38989925384521484, acc = 0.86328125\n",
      "Batch 74: loss = 0.4321467876434326, acc = 0.8447265625\n",
      "Batch 75: loss = 0.3530106842517853, acc = 0.8798828125\n",
      "Batch 76: loss = 0.4490197002887726, acc = 0.845703125\n",
      "Batch 77: loss = 0.46729886531829834, acc = 0.83984375\n",
      "Batch 78: loss = 0.43866899609565735, acc = 0.86328125\n",
      "Batch 79: loss = 0.38647201657295227, acc = 0.8681640625\n",
      "Batch 80: loss = 0.5179188251495361, acc = 0.82421875\n",
      "Batch 81: loss = 0.37587475776672363, acc = 0.8740234375\n",
      "Batch 82: loss = 0.4248059093952179, acc = 0.8544921875\n",
      "Batch 83: loss = 0.448093444108963, acc = 0.8447265625\n",
      "Batch 84: loss = 0.36369574069976807, acc = 0.8837890625\n",
      "Batch 85: loss = 0.4575796127319336, acc = 0.8515625\n",
      "Batch 86: loss = 0.4328324496746063, acc = 0.859375\n",
      "Batch 87: loss = 0.3870004117488861, acc = 0.8720703125\n",
      "Batch 88: loss = 0.39497900009155273, acc = 0.859375\n",
      "Batch 89: loss = 0.47022953629493713, acc = 0.833984375\n",
      "Batch 90: loss = 0.4566388428211212, acc = 0.853515625\n",
      "Batch 91: loss = 0.4088880717754364, acc = 0.865234375\n",
      "Batch 92: loss = 0.44649678468704224, acc = 0.8427734375\n",
      "Batch 93: loss = 0.4332301616668701, acc = 0.8505859375\n",
      "Batch 94: loss = 0.43106400966644287, acc = 0.8603515625\n",
      "Batch 95: loss = 0.4174189269542694, acc = 0.8525390625\n",
      "Batch 96: loss = 0.3729144036769867, acc = 0.8740234375\n",
      "Batch 97: loss = 0.4401892125606537, acc = 0.84765625\n",
      "Batch 98: loss = 0.45720964670181274, acc = 0.849609375\n",
      "Batch 99: loss = 0.4056422710418701, acc = 0.865234375\n",
      "Batch 100: loss = 0.4608697295188904, acc = 0.84375\n",
      "Batch 101: loss = 0.3563602566719055, acc = 0.8828125\n",
      "Batch 102: loss = 0.3422205150127411, acc = 0.8798828125\n",
      "Batch 103: loss = 0.39762935042381287, acc = 0.8603515625\n",
      "Batch 104: loss = 0.39895108342170715, acc = 0.85546875\n",
      "Batch 105: loss = 0.4846069812774658, acc = 0.83203125\n",
      "Batch 106: loss = 0.4245426058769226, acc = 0.8662109375\n",
      "Batch 107: loss = 0.4008403420448303, acc = 0.8623046875\n",
      "Batch 108: loss = 0.468332439661026, acc = 0.833984375\n",
      "Batch 109: loss = 0.3762523829936981, acc = 0.8798828125\n",
      "Batch 110: loss = 0.4379122853279114, acc = 0.8544921875\n",
      "Batch 111: loss = 0.47191137075424194, acc = 0.8408203125\n",
      "Batch 112: loss = 0.435935378074646, acc = 0.8544921875\n",
      "Batch 113: loss = 0.4140916168689728, acc = 0.8623046875\n",
      "Batch 114: loss = 0.3652428388595581, acc = 0.8671875\n",
      "Batch 115: loss = 0.4653664827346802, acc = 0.8330078125\n",
      "Batch 116: loss = 0.41548630595207214, acc = 0.853515625\n",
      "Batch 117: loss = 0.4121319651603699, acc = 0.8505859375\n",
      "Batch 118: loss = 0.4480857849121094, acc = 0.841796875\n",
      "Batch 119: loss = 0.44096654653549194, acc = 0.859375\n",
      "Batch 120: loss = 0.447700560092926, acc = 0.8583984375\n",
      "Batch 121: loss = 0.4450080692768097, acc = 0.845703125\n",
      "Batch 122: loss = 0.3989207148551941, acc = 0.8662109375\n",
      "Batch 123: loss = 0.3833267390727997, acc = 0.8642578125\n",
      "Batch 124: loss = 0.4699390232563019, acc = 0.83984375\n",
      "Batch 125: loss = 0.36905398964881897, acc = 0.884765625\n",
      "Batch 126: loss = 0.36739158630371094, acc = 0.8662109375\n",
      "Batch 127: loss = 0.44017502665519714, acc = 0.83984375\n",
      "Batch 128: loss = 0.42679810523986816, acc = 0.86328125\n",
      "Batch 129: loss = 0.37159430980682373, acc = 0.8740234375\n",
      "Batch 130: loss = 0.3885869085788727, acc = 0.86328125\n",
      "Batch 131: loss = 0.3445464074611664, acc = 0.8837890625\n",
      "Batch 132: loss = 0.3202160596847534, acc = 0.896484375\n",
      "Batch 133: loss = 0.3589416742324829, acc = 0.8818359375\n",
      "Batch 134: loss = 0.3949904441833496, acc = 0.88671875\n",
      "Batch 135: loss = 0.4301219880580902, acc = 0.859375\n",
      "Batch 136: loss = 0.40637537837028503, acc = 0.857421875\n",
      "Batch 137: loss = 0.36787641048431396, acc = 0.8759765625\n",
      "Batch 138: loss = 0.38753828406333923, acc = 0.8701171875\n",
      "Batch 139: loss = 0.3587435185909271, acc = 0.8720703125\n",
      "Batch 140: loss = 0.38672274351119995, acc = 0.8828125\n",
      "Batch 141: loss = 0.40957289934158325, acc = 0.87890625\n",
      "Batch 142: loss = 0.43015992641448975, acc = 0.8486328125\n",
      "Batch 143: loss = 0.3894207775592804, acc = 0.865234375\n",
      "Batch 144: loss = 0.43640562891960144, acc = 0.8623046875\n",
      "Batch 145: loss = 0.38488057255744934, acc = 0.875\n",
      "Batch 146: loss = 0.40882185101509094, acc = 0.869140625\n",
      "Batch 147: loss = 0.43440139293670654, acc = 0.84375\n",
      "Batch 148: loss = 0.3632291257381439, acc = 0.869140625\n",
      "Batch 149: loss = 0.4107353091239929, acc = 0.8681640625\n",
      "Batch 150: loss = 0.41550904512405396, acc = 0.8623046875\n",
      "Batch 151: loss = 0.41947802901268005, acc = 0.8583984375\n",
      "Batch 152: loss = 0.3688375949859619, acc = 0.8740234375\n",
      "Batch 153: loss = 0.3821513056755066, acc = 0.8603515625\n",
      "Batch 154: loss = 0.3881422281265259, acc = 0.869140625\n",
      "Batch 155: loss = 0.37744125723838806, acc = 0.87890625\n",
      "Batch 156: loss = 0.48185548186302185, acc = 0.833984375\n",
      "Batch 157: loss = 0.4045558273792267, acc = 0.87109375\n",
      "Batch 158: loss = 0.4142718017101288, acc = 0.8662109375\n",
      "Batch 159: loss = 0.4416300654411316, acc = 0.8486328125\n",
      "Batch 160: loss = 0.39531153440475464, acc = 0.857421875\n",
      "Batch 161: loss = 0.4276916980743408, acc = 0.859375\n",
      "Batch 162: loss = 0.447845458984375, acc = 0.845703125\n",
      "Batch 163: loss = 0.41284361481666565, acc = 0.8701171875\n",
      "Batch 164: loss = 0.4149797558784485, acc = 0.8671875\n",
      "Batch 165: loss = 0.44516026973724365, acc = 0.8447265625\n",
      "Batch 166: loss = 0.36957061290740967, acc = 0.8720703125\n",
      "Batch 167: loss = 0.4316515326499939, acc = 0.8486328125\n",
      "Batch 168: loss = 0.4182673692703247, acc = 0.85546875\n",
      "Batch 169: loss = 0.3619880974292755, acc = 0.8798828125\n",
      "Batch 170: loss = 0.36953994631767273, acc = 0.869140625\n",
      "Batch 171: loss = 0.4258432984352112, acc = 0.8544921875\n",
      "Batch 172: loss = 0.3917366862297058, acc = 0.869140625\n",
      "Batch 173: loss = 0.4011428952217102, acc = 0.8681640625\n",
      "Batch 174: loss = 0.38755011558532715, acc = 0.8701171875\n",
      "Batch 175: loss = 0.3875669538974762, acc = 0.8564453125\n",
      "Batch 176: loss = 0.3904232084751129, acc = 0.869140625\n",
      "Batch 177: loss = 0.36450105905532837, acc = 0.87890625\n",
      "Batch 178: loss = 0.39137130975723267, acc = 0.859375\n",
      "Batch 179: loss = 0.4229362905025482, acc = 0.8447265625\n",
      "Batch 180: loss = 0.404458224773407, acc = 0.869140625\n",
      "Batch 181: loss = 0.4003613591194153, acc = 0.8583984375\n",
      "Batch 182: loss = 0.41608524322509766, acc = 0.8505859375\n",
      "Batch 183: loss = 0.3817058205604553, acc = 0.869140625\n",
      "Batch 184: loss = 0.41193175315856934, acc = 0.8564453125\n",
      "Batch 185: loss = 0.43411850929260254, acc = 0.8525390625\n",
      "Batch 186: loss = 0.3877037465572357, acc = 0.8759765625\n",
      "Batch 187: loss = 0.42515629529953003, acc = 0.8544921875\n",
      "Batch 188: loss = 0.42314934730529785, acc = 0.8662109375\n",
      "Batch 189: loss = 0.3942781984806061, acc = 0.859375\n",
      "Batch 190: loss = 0.394850492477417, acc = 0.8671875\n",
      "Batch 191: loss = 0.3852793574333191, acc = 0.873046875\n",
      "Batch 192: loss = 0.3828437924385071, acc = 0.8740234375\n",
      "Batch 193: loss = 0.4129670262336731, acc = 0.8642578125\n",
      "Batch 194: loss = 0.43361353874206543, acc = 0.857421875\n",
      "Batch 195: loss = 0.42998722195625305, acc = 0.8544921875\n",
      "Batch 196: loss = 0.47175461053848267, acc = 0.8505859375\n",
      "Batch 197: loss = 0.46926751732826233, acc = 0.8505859375\n",
      "Batch 198: loss = 0.40870627760887146, acc = 0.8662109375\n",
      "Batch 199: loss = 0.4692419767379761, acc = 0.84375\n",
      "Batch 200: loss = 0.4405868351459503, acc = 0.861328125\n",
      "Batch 201: loss = 0.44146233797073364, acc = 0.8525390625\n",
      "Batch 202: loss = 0.5062217712402344, acc = 0.82421875\n",
      "Batch 203: loss = 0.38580989837646484, acc = 0.865234375\n",
      "Batch 204: loss = 0.4414995312690735, acc = 0.853515625\n",
      "Batch 205: loss = 0.4558018147945404, acc = 0.849609375\n",
      "Batch 206: loss = 0.4152032136917114, acc = 0.849609375\n",
      "Batch 207: loss = 0.5035523772239685, acc = 0.8310546875\n",
      "Batch 208: loss = 0.41709715127944946, acc = 0.86328125\n",
      "Batch 209: loss = 0.43960243463516235, acc = 0.8447265625\n",
      "Batch 210: loss = 0.40481048822402954, acc = 0.861328125\n",
      "Batch 211: loss = 0.42473432421684265, acc = 0.8623046875\n",
      "Batch 212: loss = 0.46781444549560547, acc = 0.84375\n",
      "Batch 213: loss = 0.4557430148124695, acc = 0.8369140625\n",
      "Batch 214: loss = 0.4408276379108429, acc = 0.85546875\n",
      "Batch 215: loss = 0.3922572135925293, acc = 0.86328125\n",
      "Batch 216: loss = 0.3754119873046875, acc = 0.8681640625\n",
      "Batch 217: loss = 0.3784179985523224, acc = 0.8779296875\n",
      "Batch 218: loss = 0.40222373604774475, acc = 0.8603515625\n",
      "Batch 219: loss = 0.4250072240829468, acc = 0.8583984375\n",
      "Batch 220: loss = 0.38688603043556213, acc = 0.8671875\n",
      "Batch 221: loss = 0.4594598710536957, acc = 0.837890625\n",
      "Batch 222: loss = 0.3917732834815979, acc = 0.8671875\n",
      "Batch 223: loss = 0.3608519732952118, acc = 0.8681640625\n",
      "Batch 224: loss = 0.35062873363494873, acc = 0.8779296875\n",
      "Batch 225: loss = 0.3843745291233063, acc = 0.8564453125\n",
      "Batch 226: loss = 0.44617119431495667, acc = 0.849609375\n",
      "Batch 227: loss = 0.4204450845718384, acc = 0.859375\n",
      "Batch 228: loss = 0.4001651406288147, acc = 0.8662109375\n",
      "Batch 229: loss = 0.3941022753715515, acc = 0.87890625\n",
      "Batch 230: loss = 0.349586546421051, acc = 0.8828125\n",
      "Batch 231: loss = 0.4874095320701599, acc = 0.84375\n",
      "Batch 232: loss = 0.4181500971317291, acc = 0.8662109375\n",
      "Batch 233: loss = 0.4888056218624115, acc = 0.8291015625\n",
      "Batch 234: loss = 0.4282725751399994, acc = 0.869140625\n",
      "Batch 235: loss = 0.44327685236930847, acc = 0.8515625\n",
      "Batch 236: loss = 0.4481726288795471, acc = 0.8544921875\n",
      "Batch 237: loss = 0.3857574164867401, acc = 0.8681640625\n",
      "Batch 238: loss = 0.42667338252067566, acc = 0.8564453125\n",
      "Batch 239: loss = 0.37636661529541016, acc = 0.8623046875\n",
      "Batch 240: loss = 0.4377179741859436, acc = 0.861328125\n",
      "Batch 241: loss = 0.39984285831451416, acc = 0.8671875\n",
      "Batch 242: loss = 0.4538784623146057, acc = 0.8427734375\n",
      "Batch 243: loss = 0.4410116970539093, acc = 0.8525390625\n",
      "Batch 244: loss = 0.43670815229415894, acc = 0.8544921875\n",
      "Batch 245: loss = 0.36583027243614197, acc = 0.8671875\n",
      "Batch 246: loss = 0.41056162118911743, acc = 0.8544921875\n",
      "Batch 247: loss = 0.45664817094802856, acc = 0.8369140625\n",
      "Batch 248: loss = 0.39265206456184387, acc = 0.8623046875\n",
      "Batch 249: loss = 0.35772770643234253, acc = 0.8798828125\n",
      "Batch 250: loss = 0.45568716526031494, acc = 0.8505859375\n",
      "Batch 251: loss = 0.35512012243270874, acc = 0.875\n",
      "Batch 252: loss = 0.3520463705062866, acc = 0.888671875\n",
      "Batch 253: loss = 0.4372873604297638, acc = 0.8564453125\n",
      "Batch 254: loss = 0.4744842052459717, acc = 0.8330078125\n",
      "Batch 255: loss = 0.45692840218544006, acc = 0.8369140625\n",
      "Batch 256: loss = 0.4471195936203003, acc = 0.853515625\n",
      "Batch 257: loss = 0.5004761219024658, acc = 0.8359375\n",
      "Batch 258: loss = 0.4450911283493042, acc = 0.8525390625\n",
      "Batch 259: loss = 0.5223702788352966, acc = 0.83203125\n",
      "Batch 260: loss = 0.5302431583404541, acc = 0.8271484375\n",
      "Batch 261: loss = 0.45727962255477905, acc = 0.849609375\n",
      "Batch 262: loss = 0.4199795126914978, acc = 0.85546875\n",
      "Batch 263: loss = 0.4220467507839203, acc = 0.8564453125\n",
      "Batch 264: loss = 0.38604846596717834, acc = 0.8662109375\n",
      "Batch 265: loss = 0.3925561308860779, acc = 0.873046875\n",
      "Batch 266: loss = 0.40643948316574097, acc = 0.87109375\n",
      "Batch 267: loss = 0.32770663499832153, acc = 0.8935546875\n",
      "Batch 268: loss = 0.45587286353111267, acc = 0.857421875\n",
      "Batch 269: loss = 0.42303329706192017, acc = 0.85546875\n",
      "Batch 270: loss = 0.4267975091934204, acc = 0.8623046875\n",
      "Batch 271: loss = 0.41619956493377686, acc = 0.8603515625\n",
      "Batch 272: loss = 0.4203011393547058, acc = 0.8583984375\n",
      "Batch 273: loss = 0.4065968990325928, acc = 0.857421875\n",
      "Batch 274: loss = 0.43007493019104004, acc = 0.8671875\n",
      "Batch 275: loss = 0.34933239221572876, acc = 0.8935546875\n",
      "Batch 276: loss = 0.4404873847961426, acc = 0.845703125\n",
      "Batch 277: loss = 0.48076337575912476, acc = 0.837890625\n",
      "Batch 278: loss = 0.3986492455005646, acc = 0.8583984375\n",
      "Batch 279: loss = 0.47221240401268005, acc = 0.828125\n",
      "Batch 280: loss = 0.43638715147972107, acc = 0.8544921875\n",
      "Batch 281: loss = 0.42815831303596497, acc = 0.85546875\n",
      "Batch 282: loss = 0.4492540955543518, acc = 0.8427734375\n",
      "Batch 283: loss = 0.5033494234085083, acc = 0.8310546875\n",
      "Batch 284: loss = 0.4088769257068634, acc = 0.8486328125\n",
      "Batch 285: loss = 0.4507947862148285, acc = 0.84765625\n",
      "Batch 286: loss = 0.46042734384536743, acc = 0.845703125\n",
      "Batch 287: loss = 0.4583740532398224, acc = 0.8486328125\n",
      "Batch 288: loss = 0.46360042691230774, acc = 0.83984375\n",
      "Batch 289: loss = 0.4047560691833496, acc = 0.865234375\n",
      "Batch 290: loss = 0.42123517394065857, acc = 0.857421875\n",
      "Batch 291: loss = 0.45336228609085083, acc = 0.845703125\n",
      "Batch 292: loss = 0.45654597878456116, acc = 0.8505859375\n",
      "Batch 293: loss = 0.39481016993522644, acc = 0.8701171875\n",
      "Batch 294: loss = 0.3979235589504242, acc = 0.8642578125\n",
      "Batch 295: loss = 0.38615116477012634, acc = 0.857421875\n",
      "Batch 296: loss = 0.424071729183197, acc = 0.8515625\n",
      "Batch 297: loss = 0.38850346207618713, acc = 0.869140625\n",
      "Batch 298: loss = 0.36894381046295166, acc = 0.880859375\n",
      "Batch 299: loss = 0.3476785123348236, acc = 0.884765625\n",
      "Batch 300: loss = 0.4177321791648865, acc = 0.8505859375\n",
      "Batch 301: loss = 0.44127100706100464, acc = 0.8486328125\n",
      "Batch 302: loss = 0.4159201383590698, acc = 0.8544921875\n",
      "Batch 303: loss = 0.4506843090057373, acc = 0.8505859375\n",
      "Batch 304: loss = 0.4080762565135956, acc = 0.8662109375\n",
      "Batch 305: loss = 0.3730614483356476, acc = 0.876953125\n",
      "Batch 306: loss = 0.4185839891433716, acc = 0.8681640625\n",
      "Batch 307: loss = 0.40488502383232117, acc = 0.8564453125\n",
      "Batch 308: loss = 0.40320754051208496, acc = 0.8671875\n",
      "Batch 309: loss = 0.4448377192020416, acc = 0.849609375\n",
      "Batch 310: loss = 0.42162102460861206, acc = 0.84375\n",
      "Batch 311: loss = 0.4155850410461426, acc = 0.861328125\n",
      "Batch 312: loss = 0.3856024146080017, acc = 0.8740234375\n",
      "Batch 313: loss = 0.4283275008201599, acc = 0.8466796875\n",
      "Batch 314: loss = 0.45849356055259705, acc = 0.8486328125\n",
      "Batch 315: loss = 0.421632319688797, acc = 0.8525390625\n",
      "Batch 316: loss = 0.40087956190109253, acc = 0.8623046875\n",
      "Batch 317: loss = 0.40976643562316895, acc = 0.8642578125\n",
      "Batch 318: loss = 0.424733966588974, acc = 0.849609375\n",
      "Batch 319: loss = 0.43614569306373596, acc = 0.8603515625\n",
      "Batch 320: loss = 0.4560307264328003, acc = 0.841796875\n",
      "Batch 321: loss = 0.4383299946784973, acc = 0.8486328125\n",
      "Batch 322: loss = 0.3982018828392029, acc = 0.86328125\n",
      "Batch 323: loss = 0.4946553111076355, acc = 0.8251953125\n",
      "Batch 324: loss = 0.3989519476890564, acc = 0.8759765625\n",
      "Batch 325: loss = 0.4215245246887207, acc = 0.8564453125\n",
      "Batch 326: loss = 0.41270798444747925, acc = 0.8603515625\n",
      "Batch 327: loss = 0.4274897575378418, acc = 0.859375\n",
      "Batch 328: loss = 0.4475928246974945, acc = 0.8486328125\n",
      "Batch 329: loss = 0.459604412317276, acc = 0.8427734375\n",
      "Batch 330: loss = 0.3605143129825592, acc = 0.875\n",
      "Batch 331: loss = 0.42407071590423584, acc = 0.8544921875\n",
      "Batch 332: loss = 0.4125840961933136, acc = 0.857421875\n",
      "Batch 333: loss = 0.4108840823173523, acc = 0.859375\n",
      "Batch 334: loss = 0.34631410241127014, acc = 0.8876953125\n",
      "Batch 335: loss = 0.4281901717185974, acc = 0.853515625\n",
      "Batch 336: loss = 0.4517006278038025, acc = 0.8427734375\n",
      "Batch 337: loss = 0.4883728623390198, acc = 0.845703125\n",
      "Batch 338: loss = 0.3902318775653839, acc = 0.876953125\n",
      "Batch 339: loss = 0.43854644894599915, acc = 0.83984375\n",
      "Batch 340: loss = 0.37845638394355774, acc = 0.8837890625\n",
      "Batch 341: loss = 0.4293421506881714, acc = 0.857421875\n",
      "Batch 342: loss = 0.46906059980392456, acc = 0.84375\n",
      "Batch 343: loss = 0.39415234327316284, acc = 0.859375\n",
      "Batch 344: loss = 0.3504585027694702, acc = 0.88671875\n",
      "Batch 345: loss = 0.3888883888721466, acc = 0.8681640625\n",
      "Batch 346: loss = 0.36849430203437805, acc = 0.86328125\n",
      "Batch 347: loss = 0.39514991641044617, acc = 0.8623046875\n",
      "Batch 348: loss = 0.3956785500049591, acc = 0.857421875\n",
      "Batch 349: loss = 0.34363535046577454, acc = 0.8779296875\n",
      "Batch 350: loss = 0.37190479040145874, acc = 0.875\n",
      "Batch 351: loss = 0.3552173376083374, acc = 0.8779296875\n",
      "Batch 352: loss = 0.4079614281654358, acc = 0.853515625\n",
      "Batch 353: loss = 0.3676774799823761, acc = 0.8759765625\n",
      "Batch 354: loss = 0.34977197647094727, acc = 0.8857421875\n",
      "Batch 355: loss = 0.275594562292099, acc = 0.9033203125\n",
      "Batch 356: loss = 0.3751314878463745, acc = 0.8701171875\n",
      "Batch 357: loss = 0.38395652174949646, acc = 0.8740234375\n",
      "Batch 358: loss = 0.3583970367908478, acc = 0.876953125\n",
      "Batch 359: loss = 0.3946131765842438, acc = 0.8564453125\n",
      "Batch 360: loss = 0.38028979301452637, acc = 0.8720703125\n",
      "Batch 361: loss = 0.4135194420814514, acc = 0.85546875\n",
      "Batch 362: loss = 0.36450618505477905, acc = 0.8701171875\n",
      "Batch 363: loss = 0.38304460048675537, acc = 0.87890625\n",
      "Batch 364: loss = 0.38534265756607056, acc = 0.8564453125\n",
      "Batch 365: loss = 0.33903712034225464, acc = 0.8828125\n",
      "Batch 366: loss = 0.42051056027412415, acc = 0.85546875\n",
      "Batch 367: loss = 0.383723646402359, acc = 0.8759765625\n",
      "Batch 368: loss = 0.44377630949020386, acc = 0.8515625\n",
      "Batch 369: loss = 0.4912900924682617, acc = 0.8271484375\n",
      "Batch 370: loss = 0.37578532099723816, acc = 0.8701171875\n",
      "Batch 371: loss = 0.4815727472305298, acc = 0.833984375\n",
      "Batch 372: loss = 0.3717016279697418, acc = 0.873046875\n",
      "Batch 373: loss = 0.42563024163246155, acc = 0.8388671875\n",
      "Batch 374: loss = 0.43694281578063965, acc = 0.85546875\n",
      "Batch 375: loss = 0.4790995717048645, acc = 0.8388671875\n",
      "Batch 376: loss = 0.44545894861221313, acc = 0.8564453125\n",
      "Batch 377: loss = 0.4740588665008545, acc = 0.841796875\n",
      "Batch 378: loss = 0.4239519238471985, acc = 0.84375\n",
      "Batch 379: loss = 0.44493937492370605, acc = 0.853515625\n",
      "Batch 380: loss = 0.3975609540939331, acc = 0.87109375\n",
      "Batch 381: loss = 0.3480743169784546, acc = 0.88671875\n",
      "Batch 382: loss = 0.4138358533382416, acc = 0.859375\n",
      "Batch 383: loss = 0.3872356712818146, acc = 0.8740234375\n",
      "Batch 384: loss = 0.45138871669769287, acc = 0.845703125\n",
      "Batch 385: loss = 0.41186508536338806, acc = 0.85546875\n",
      "Batch 386: loss = 0.38361096382141113, acc = 0.8642578125\n",
      "Batch 387: loss = 0.35514262318611145, acc = 0.873046875\n",
      "Batch 388: loss = 0.4434386193752289, acc = 0.8564453125\n",
      "Batch 389: loss = 0.41223686933517456, acc = 0.8671875\n",
      "Batch 390: loss = 0.45373302698135376, acc = 0.84765625\n",
      "Batch 391: loss = 0.39930352568626404, acc = 0.853515625\n",
      "Batch 392: loss = 0.4511820077896118, acc = 0.8388671875\n",
      "Batch 393: loss = 0.4563266932964325, acc = 0.8447265625\n",
      "Batch 394: loss = 0.380214661359787, acc = 0.873046875\n",
      "Batch 395: loss = 0.4133346974849701, acc = 0.85546875\n",
      "Batch 396: loss = 0.4307229518890381, acc = 0.8525390625\n",
      "Batch 397: loss = 0.3457087576389313, acc = 0.8798828125\n",
      "Batch 398: loss = 0.3361590802669525, acc = 0.888671875\n",
      "Batch 399: loss = 0.39198189973831177, acc = 0.8701171875\n",
      "Batch 400: loss = 0.38519081473350525, acc = 0.875\n",
      "Batch 401: loss = 0.41475361585617065, acc = 0.8681640625\n",
      "Batch 402: loss = 0.4333166480064392, acc = 0.84765625\n",
      "Batch 403: loss = 0.3946848511695862, acc = 0.8681640625\n",
      "Batch 404: loss = 0.386861652135849, acc = 0.8759765625\n",
      "Batch 405: loss = 0.4598853588104248, acc = 0.84375\n",
      "Batch 406: loss = 0.48951372504234314, acc = 0.8369140625\n",
      "Batch 407: loss = 0.4277334213256836, acc = 0.8564453125\n",
      "Batch 408: loss = 0.4999689757823944, acc = 0.8271484375\n",
      "Batch 409: loss = 0.42540401220321655, acc = 0.8681640625\n",
      "Batch 410: loss = 0.5055018067359924, acc = 0.82421875\n",
      "Batch 411: loss = 0.42681756615638733, acc = 0.8564453125\n",
      "Batch 412: loss = 0.44840240478515625, acc = 0.849609375\n",
      "Batch 413: loss = 0.3883773982524872, acc = 0.86328125\n",
      "Batch 414: loss = 0.39173322916030884, acc = 0.875\n",
      "Batch 415: loss = 0.4272138476371765, acc = 0.8583984375\n",
      "Batch 416: loss = 0.43816766142845154, acc = 0.853515625\n",
      "Batch 417: loss = 0.4261559844017029, acc = 0.85546875\n",
      "Batch 418: loss = 0.4536348581314087, acc = 0.841796875\n",
      "Batch 419: loss = 0.521337628364563, acc = 0.822265625\n",
      "Batch 420: loss = 0.4929357171058655, acc = 0.837890625\n",
      "Batch 421: loss = 0.46100425720214844, acc = 0.8408203125\n",
      "Batch 422: loss = 0.46118712425231934, acc = 0.8369140625\n",
      "Batch 423: loss = 0.4285687506198883, acc = 0.8466796875\n",
      "Batch 424: loss = 0.46833398938179016, acc = 0.8447265625\n",
      "Batch 425: loss = 0.4453352689743042, acc = 0.8427734375\n",
      "Batch 426: loss = 0.4382803738117218, acc = 0.8515625\n",
      "Batch 427: loss = 0.4302496612071991, acc = 0.8466796875\n",
      "Batch 428: loss = 0.40415191650390625, acc = 0.85546875\n",
      "Batch 429: loss = 0.430275559425354, acc = 0.8466796875\n",
      "Batch 430: loss = 0.4210427403450012, acc = 0.8564453125\n",
      "Batch 431: loss = 0.40756791830062866, acc = 0.8642578125\n",
      "Batch 432: loss = 0.4405364990234375, acc = 0.8447265625\n",
      "Batch 433: loss = 0.35247817635536194, acc = 0.880859375\n",
      "Batch 434: loss = 0.39711934328079224, acc = 0.8642578125\n",
      "Batch 435: loss = 0.4544326066970825, acc = 0.8369140625\n",
      "Batch 436: loss = 0.39313241839408875, acc = 0.875\n",
      "Batch 437: loss = 0.4399945139884949, acc = 0.853515625\n",
      "Batch 438: loss = 0.4078275263309479, acc = 0.865234375\n",
      "Batch 439: loss = 0.39568522572517395, acc = 0.8740234375\n",
      "Batch 440: loss = 0.4126931428909302, acc = 0.86328125\n",
      "Batch 441: loss = 0.3946160078048706, acc = 0.873046875\n",
      "\n",
      "Epoch 94/100\n",
      "Batch 1: loss = 0.5201604962348938, acc = 0.8359375\n",
      "Batch 2: loss = 0.392805814743042, acc = 0.8544921875\n",
      "Batch 3: loss = 0.43881916999816895, acc = 0.8466796875\n",
      "Batch 4: loss = 0.4426027536392212, acc = 0.8486328125\n",
      "Batch 5: loss = 0.4364425241947174, acc = 0.857421875\n",
      "Batch 6: loss = 0.3977893590927124, acc = 0.8798828125\n",
      "Batch 7: loss = 0.3816194534301758, acc = 0.8681640625\n",
      "Batch 8: loss = 0.36529994010925293, acc = 0.8720703125\n",
      "Batch 9: loss = 0.458219051361084, acc = 0.859375\n",
      "Batch 10: loss = 0.45054522156715393, acc = 0.8427734375\n",
      "Batch 11: loss = 0.4344455599784851, acc = 0.853515625\n",
      "Batch 12: loss = 0.40430784225463867, acc = 0.853515625\n",
      "Batch 13: loss = 0.4296351671218872, acc = 0.861328125\n",
      "Batch 14: loss = 0.37895697355270386, acc = 0.8798828125\n",
      "Batch 15: loss = 0.3941354751586914, acc = 0.8681640625\n",
      "Batch 16: loss = 0.3936147093772888, acc = 0.87109375\n",
      "Batch 17: loss = 0.35248643159866333, acc = 0.8896484375\n",
      "Batch 18: loss = 0.45261144638061523, acc = 0.857421875\n",
      "Batch 19: loss = 0.4244774281978607, acc = 0.8564453125\n",
      "Batch 20: loss = 0.4326251745223999, acc = 0.853515625\n",
      "Batch 21: loss = 0.4142332077026367, acc = 0.8623046875\n",
      "Batch 22: loss = 0.43554723262786865, acc = 0.8544921875\n",
      "Batch 23: loss = 0.42303556203842163, acc = 0.8427734375\n",
      "Batch 24: loss = 0.37254440784454346, acc = 0.8818359375\n",
      "Batch 25: loss = 0.4740335941314697, acc = 0.845703125\n",
      "Batch 26: loss = 0.3954645097255707, acc = 0.8740234375\n",
      "Batch 27: loss = 0.43553024530410767, acc = 0.8544921875\n",
      "Batch 28: loss = 0.4117800295352936, acc = 0.859375\n",
      "Batch 29: loss = 0.48388880491256714, acc = 0.841796875\n",
      "Batch 30: loss = 0.4270363450050354, acc = 0.8505859375\n",
      "Batch 31: loss = 0.407381147146225, acc = 0.8720703125\n",
      "Batch 32: loss = 0.39030182361602783, acc = 0.873046875\n",
      "Batch 33: loss = 0.3324039578437805, acc = 0.8857421875\n",
      "Batch 34: loss = 0.34466689825057983, acc = 0.8798828125\n",
      "Batch 35: loss = 0.37324365973472595, acc = 0.87109375\n",
      "Batch 36: loss = 0.4393197298049927, acc = 0.859375\n",
      "Batch 37: loss = 0.40023326873779297, acc = 0.8662109375\n",
      "Batch 38: loss = 0.4084085524082184, acc = 0.8603515625\n",
      "Batch 39: loss = 0.338375985622406, acc = 0.890625\n",
      "Batch 40: loss = 0.3663436770439148, acc = 0.8818359375\n",
      "Batch 41: loss = 0.3588562309741974, acc = 0.890625\n",
      "Batch 42: loss = 0.43332576751708984, acc = 0.8447265625\n",
      "Batch 43: loss = 0.47155123949050903, acc = 0.8359375\n",
      "Batch 44: loss = 0.42646920680999756, acc = 0.8486328125\n",
      "Batch 45: loss = 0.3615908920764923, acc = 0.8779296875\n",
      "Batch 46: loss = 0.4045373797416687, acc = 0.8623046875\n",
      "Batch 47: loss = 0.37574946880340576, acc = 0.87890625\n",
      "Batch 48: loss = 0.3872600793838501, acc = 0.869140625\n",
      "Batch 49: loss = 0.41757699847221375, acc = 0.857421875\n",
      "Batch 50: loss = 0.4110802412033081, acc = 0.8583984375\n",
      "Batch 51: loss = 0.42951351404190063, acc = 0.861328125\n",
      "Batch 52: loss = 0.35107260942459106, acc = 0.8837890625\n",
      "Batch 53: loss = 0.4583844244480133, acc = 0.8515625\n",
      "Batch 54: loss = 0.39114490151405334, acc = 0.8720703125\n",
      "Batch 55: loss = 0.4513450264930725, acc = 0.83984375\n",
      "Batch 56: loss = 0.41556113958358765, acc = 0.859375\n",
      "Batch 57: loss = 0.39384010434150696, acc = 0.8828125\n",
      "Batch 58: loss = 0.36003828048706055, acc = 0.8798828125\n",
      "Batch 59: loss = 0.4089701175689697, acc = 0.8623046875\n",
      "Batch 60: loss = 0.37444955110549927, acc = 0.8837890625\n",
      "Batch 61: loss = 0.437779039144516, acc = 0.8505859375\n",
      "Batch 62: loss = 0.41158628463745117, acc = 0.857421875\n",
      "Batch 63: loss = 0.45362576842308044, acc = 0.8505859375\n",
      "Batch 64: loss = 0.35671287775039673, acc = 0.880859375\n",
      "Batch 65: loss = 0.3583224415779114, acc = 0.884765625\n",
      "Batch 66: loss = 0.39563363790512085, acc = 0.86328125\n",
      "Batch 67: loss = 0.4324216842651367, acc = 0.859375\n",
      "Batch 68: loss = 0.4469231069087982, acc = 0.845703125\n",
      "Batch 69: loss = 0.4008035361766815, acc = 0.869140625\n",
      "Batch 70: loss = 0.46711739897727966, acc = 0.849609375\n",
      "Batch 71: loss = 0.41159042716026306, acc = 0.865234375\n",
      "Batch 72: loss = 0.4532232880592346, acc = 0.8408203125\n",
      "Batch 73: loss = 0.3963989019393921, acc = 0.857421875\n",
      "Batch 74: loss = 0.3999451696872711, acc = 0.873046875\n",
      "Batch 75: loss = 0.3315446674823761, acc = 0.8974609375\n",
      "Batch 76: loss = 0.4446197748184204, acc = 0.8466796875\n",
      "Batch 77: loss = 0.47409582138061523, acc = 0.8330078125\n",
      "Batch 78: loss = 0.4736477732658386, acc = 0.849609375\n",
      "Batch 79: loss = 0.40000978112220764, acc = 0.859375\n",
      "Batch 80: loss = 0.5188451409339905, acc = 0.82421875\n",
      "Batch 81: loss = 0.3721795976161957, acc = 0.8818359375\n",
      "Batch 82: loss = 0.38819602131843567, acc = 0.8623046875\n",
      "Batch 83: loss = 0.42844220995903015, acc = 0.857421875\n",
      "Batch 84: loss = 0.3450780510902405, acc = 0.8759765625\n",
      "Batch 85: loss = 0.45186594128608704, acc = 0.8408203125\n",
      "Batch 86: loss = 0.4290148913860321, acc = 0.859375\n",
      "Batch 87: loss = 0.383713960647583, acc = 0.8701171875\n",
      "Batch 88: loss = 0.4426764249801636, acc = 0.8505859375\n",
      "Batch 89: loss = 0.47303861379623413, acc = 0.84375\n",
      "Batch 90: loss = 0.42276906967163086, acc = 0.8564453125\n",
      "Batch 91: loss = 0.38643714785575867, acc = 0.8701171875\n",
      "Batch 92: loss = 0.4307151436805725, acc = 0.861328125\n",
      "Batch 93: loss = 0.4458385705947876, acc = 0.8427734375\n",
      "Batch 94: loss = 0.4504890441894531, acc = 0.8505859375\n",
      "Batch 95: loss = 0.4192048907279968, acc = 0.861328125\n",
      "Batch 96: loss = 0.42759719491004944, acc = 0.853515625\n",
      "Batch 97: loss = 0.4283459186553955, acc = 0.8564453125\n",
      "Batch 98: loss = 0.45612573623657227, acc = 0.84765625\n",
      "Batch 99: loss = 0.4317142963409424, acc = 0.8642578125\n",
      "Batch 100: loss = 0.4640355110168457, acc = 0.8515625\n",
      "Batch 101: loss = 0.3738519549369812, acc = 0.884765625\n",
      "Batch 102: loss = 0.35414519906044006, acc = 0.880859375\n",
      "Batch 103: loss = 0.3644639253616333, acc = 0.8740234375\n",
      "Batch 104: loss = 0.3843345642089844, acc = 0.8681640625\n",
      "Batch 105: loss = 0.4027542471885681, acc = 0.865234375\n",
      "Batch 106: loss = 0.45237070322036743, acc = 0.8466796875\n",
      "Batch 107: loss = 0.44057589769363403, acc = 0.861328125\n",
      "Batch 108: loss = 0.44798165559768677, acc = 0.849609375\n",
      "Batch 109: loss = 0.3618990182876587, acc = 0.880859375\n",
      "Batch 110: loss = 0.45857685804367065, acc = 0.841796875\n",
      "Batch 111: loss = 0.45626649260520935, acc = 0.8330078125\n",
      "Batch 112: loss = 0.43491271138191223, acc = 0.84765625\n",
      "Batch 113: loss = 0.3801265060901642, acc = 0.873046875\n",
      "Batch 114: loss = 0.3664255738258362, acc = 0.876953125\n",
      "Batch 115: loss = 0.452566921710968, acc = 0.8486328125\n",
      "Batch 116: loss = 0.39062801003456116, acc = 0.8740234375\n",
      "Batch 117: loss = 0.41099676489830017, acc = 0.857421875\n",
      "Batch 118: loss = 0.4037749767303467, acc = 0.8642578125\n",
      "Batch 119: loss = 0.4172337055206299, acc = 0.8564453125\n",
      "Batch 120: loss = 0.44918161630630493, acc = 0.8505859375\n",
      "Batch 121: loss = 0.4211478531360626, acc = 0.84765625\n",
      "Batch 122: loss = 0.38907480239868164, acc = 0.86328125\n",
      "Batch 123: loss = 0.4025004506111145, acc = 0.8544921875\n",
      "Batch 124: loss = 0.39912548661231995, acc = 0.8681640625\n",
      "Batch 125: loss = 0.37762901186943054, acc = 0.8681640625\n",
      "Batch 126: loss = 0.37742894887924194, acc = 0.8759765625\n",
      "Batch 127: loss = 0.41790294647216797, acc = 0.8486328125\n",
      "Batch 128: loss = 0.3972885012626648, acc = 0.86328125\n",
      "Batch 129: loss = 0.35350534319877625, acc = 0.8857421875\n",
      "Batch 130: loss = 0.3885635435581207, acc = 0.869140625\n",
      "Batch 131: loss = 0.3478514552116394, acc = 0.888671875\n",
      "Batch 132: loss = 0.3139592409133911, acc = 0.8984375\n",
      "Batch 133: loss = 0.3190265893936157, acc = 0.8896484375\n",
      "Batch 134: loss = 0.3715536594390869, acc = 0.8662109375\n",
      "Batch 135: loss = 0.44475969672203064, acc = 0.8505859375\n",
      "Batch 136: loss = 0.4006342887878418, acc = 0.865234375\n",
      "Batch 137: loss = 0.3401845693588257, acc = 0.8876953125\n",
      "Batch 138: loss = 0.4023473858833313, acc = 0.8642578125\n",
      "Batch 139: loss = 0.3699115216732025, acc = 0.8671875\n",
      "Batch 140: loss = 0.3863335847854614, acc = 0.8701171875\n",
      "Batch 141: loss = 0.39120474457740784, acc = 0.876953125\n",
      "Batch 142: loss = 0.45819994807243347, acc = 0.8427734375\n",
      "Batch 143: loss = 0.4614220857620239, acc = 0.83203125\n",
      "Batch 144: loss = 0.4289974570274353, acc = 0.85546875\n",
      "Batch 145: loss = 0.3762018382549286, acc = 0.857421875\n",
      "Batch 146: loss = 0.4149041175842285, acc = 0.859375\n",
      "Batch 147: loss = 0.40496039390563965, acc = 0.8623046875\n",
      "Batch 148: loss = 0.3497287631034851, acc = 0.8857421875\n",
      "Batch 149: loss = 0.38992685079574585, acc = 0.8662109375\n",
      "Batch 150: loss = 0.4285127520561218, acc = 0.85546875\n",
      "Batch 151: loss = 0.44233137369155884, acc = 0.85546875\n",
      "Batch 152: loss = 0.36342403292655945, acc = 0.8798828125\n",
      "Batch 153: loss = 0.42052438855171204, acc = 0.8447265625\n",
      "Batch 154: loss = 0.41557568311691284, acc = 0.859375\n",
      "Batch 155: loss = 0.36343470215797424, acc = 0.880859375\n",
      "Batch 156: loss = 0.4183691143989563, acc = 0.859375\n",
      "Batch 157: loss = 0.3965512812137604, acc = 0.8583984375\n",
      "Batch 158: loss = 0.42395928502082825, acc = 0.857421875\n",
      "Batch 159: loss = 0.419790118932724, acc = 0.859375\n",
      "Batch 160: loss = 0.393745094537735, acc = 0.8642578125\n",
      "Batch 161: loss = 0.4442966878414154, acc = 0.8603515625\n",
      "Batch 162: loss = 0.46708792448043823, acc = 0.8544921875\n",
      "Batch 163: loss = 0.40945032238960266, acc = 0.8642578125\n",
      "Batch 164: loss = 0.4689522087574005, acc = 0.83984375\n",
      "Batch 165: loss = 0.43419256806373596, acc = 0.85546875\n",
      "Batch 166: loss = 0.36115050315856934, acc = 0.8671875\n",
      "Batch 167: loss = 0.41077640652656555, acc = 0.8515625\n",
      "Batch 168: loss = 0.3912768065929413, acc = 0.8759765625\n",
      "Batch 169: loss = 0.35745877027511597, acc = 0.875\n",
      "Batch 170: loss = 0.35809066891670227, acc = 0.8798828125\n",
      "Batch 171: loss = 0.41139885783195496, acc = 0.8642578125\n",
      "Batch 172: loss = 0.3855384588241577, acc = 0.876953125\n",
      "Batch 173: loss = 0.37550947070121765, acc = 0.8671875\n",
      "Batch 174: loss = 0.4005029797554016, acc = 0.86328125\n",
      "Batch 175: loss = 0.40242332220077515, acc = 0.8642578125\n",
      "Batch 176: loss = 0.3956058621406555, acc = 0.8564453125\n",
      "Batch 177: loss = 0.3829598128795624, acc = 0.8857421875\n",
      "Batch 178: loss = 0.3755050003528595, acc = 0.8681640625\n",
      "Batch 179: loss = 0.42780497670173645, acc = 0.8505859375\n",
      "Batch 180: loss = 0.3904848098754883, acc = 0.8681640625\n",
      "Batch 181: loss = 0.41029292345046997, acc = 0.8603515625\n",
      "Batch 182: loss = 0.4415121078491211, acc = 0.8505859375\n",
      "Batch 183: loss = 0.37571024894714355, acc = 0.8642578125\n",
      "Batch 184: loss = 0.4408004879951477, acc = 0.85546875\n",
      "Batch 185: loss = 0.4468083083629608, acc = 0.849609375\n",
      "Batch 186: loss = 0.4153650104999542, acc = 0.8671875\n",
      "Batch 187: loss = 0.4251362979412079, acc = 0.85546875\n",
      "Batch 188: loss = 0.4181724488735199, acc = 0.8466796875\n",
      "Batch 189: loss = 0.33342158794403076, acc = 0.880859375\n",
      "Batch 190: loss = 0.46299803256988525, acc = 0.84375\n",
      "Batch 191: loss = 0.40044596791267395, acc = 0.8671875\n",
      "Batch 192: loss = 0.3750321865081787, acc = 0.8740234375\n",
      "Batch 193: loss = 0.40389546751976013, acc = 0.8671875\n",
      "Batch 194: loss = 0.3992617726325989, acc = 0.861328125\n",
      "Batch 195: loss = 0.4499090909957886, acc = 0.8427734375\n",
      "Batch 196: loss = 0.4796708822250366, acc = 0.8349609375\n",
      "Batch 197: loss = 0.4652009606361389, acc = 0.8427734375\n",
      "Batch 198: loss = 0.39948156476020813, acc = 0.86328125\n",
      "Batch 199: loss = 0.46470844745635986, acc = 0.8388671875\n",
      "Batch 200: loss = 0.464585542678833, acc = 0.8388671875\n",
      "Batch 201: loss = 0.4439380168914795, acc = 0.8369140625\n",
      "Batch 202: loss = 0.4951101541519165, acc = 0.826171875\n",
      "Batch 203: loss = 0.3760570287704468, acc = 0.87109375\n",
      "Batch 204: loss = 0.41417422890663147, acc = 0.85546875\n",
      "Batch 205: loss = 0.4274581968784332, acc = 0.8583984375\n",
      "Batch 206: loss = 0.44585171341896057, acc = 0.85546875\n",
      "Batch 207: loss = 0.4934074580669403, acc = 0.8330078125\n",
      "Batch 208: loss = 0.46161630749702454, acc = 0.8427734375\n",
      "Batch 209: loss = 0.41638022661209106, acc = 0.853515625\n",
      "Batch 210: loss = 0.4586887061595917, acc = 0.8408203125\n",
      "Batch 211: loss = 0.43268054723739624, acc = 0.8515625\n",
      "Batch 212: loss = 0.45782366394996643, acc = 0.85546875\n",
      "Batch 213: loss = 0.45493340492248535, acc = 0.845703125\n",
      "Batch 214: loss = 0.444966197013855, acc = 0.8408203125\n",
      "Batch 215: loss = 0.3909311294555664, acc = 0.8681640625\n",
      "Batch 216: loss = 0.39196494221687317, acc = 0.873046875\n",
      "Batch 217: loss = 0.3773024380207062, acc = 0.87109375\n",
      "Batch 218: loss = 0.41342854499816895, acc = 0.8681640625\n",
      "Batch 219: loss = 0.42435863614082336, acc = 0.8671875\n",
      "Batch 220: loss = 0.3806816339492798, acc = 0.8681640625\n",
      "Batch 221: loss = 0.5113874077796936, acc = 0.83203125\n",
      "Batch 222: loss = 0.36601316928863525, acc = 0.8779296875\n",
      "Batch 223: loss = 0.36079269647598267, acc = 0.8701171875\n",
      "Batch 224: loss = 0.3586501181125641, acc = 0.876953125\n",
      "Batch 225: loss = 0.39408034086227417, acc = 0.8671875\n",
      "Batch 226: loss = 0.4181106686592102, acc = 0.853515625\n",
      "Batch 227: loss = 0.37163692712783813, acc = 0.876953125\n",
      "Batch 228: loss = 0.3653618395328522, acc = 0.8740234375\n",
      "Batch 229: loss = 0.36800694465637207, acc = 0.8779296875\n",
      "Batch 230: loss = 0.3405812084674835, acc = 0.8935546875\n",
      "Batch 231: loss = 0.4579252600669861, acc = 0.8466796875\n",
      "Batch 232: loss = 0.37501630187034607, acc = 0.8662109375\n",
      "Batch 233: loss = 0.47593727707862854, acc = 0.8427734375\n",
      "Batch 234: loss = 0.38656309247016907, acc = 0.857421875\n",
      "Batch 235: loss = 0.43221595883369446, acc = 0.85546875\n",
      "Batch 236: loss = 0.4328835606575012, acc = 0.8525390625\n",
      "Batch 237: loss = 0.3682882785797119, acc = 0.8759765625\n",
      "Batch 238: loss = 0.4219677746295929, acc = 0.8671875\n",
      "Batch 239: loss = 0.3384477198123932, acc = 0.884765625\n",
      "Batch 240: loss = 0.4363177716732025, acc = 0.8583984375\n",
      "Batch 241: loss = 0.383932501077652, acc = 0.8701171875\n",
      "Batch 242: loss = 0.43874022364616394, acc = 0.84765625\n",
      "Batch 243: loss = 0.4425390362739563, acc = 0.8544921875\n",
      "Batch 244: loss = 0.4872783422470093, acc = 0.8447265625\n",
      "Batch 245: loss = 0.4022092819213867, acc = 0.8720703125\n",
      "Batch 246: loss = 0.38601770997047424, acc = 0.8740234375\n",
      "Batch 247: loss = 0.4410366714000702, acc = 0.853515625\n",
      "Batch 248: loss = 0.3893963396549225, acc = 0.8779296875\n",
      "Batch 249: loss = 0.3872048258781433, acc = 0.8681640625\n",
      "Batch 250: loss = 0.4124945402145386, acc = 0.86328125\n",
      "Batch 251: loss = 0.33017390966415405, acc = 0.888671875\n",
      "Batch 252: loss = 0.3891943693161011, acc = 0.8837890625\n",
      "Batch 253: loss = 0.4231252670288086, acc = 0.8603515625\n",
      "Batch 254: loss = 0.45144954323768616, acc = 0.8349609375\n",
      "Batch 255: loss = 0.4656898081302643, acc = 0.8349609375\n",
      "Batch 256: loss = 0.4165908396244049, acc = 0.85546875\n",
      "Batch 257: loss = 0.47582459449768066, acc = 0.830078125\n",
      "Batch 258: loss = 0.43539679050445557, acc = 0.8388671875\n",
      "Batch 259: loss = 0.5242656469345093, acc = 0.830078125\n",
      "Batch 260: loss = 0.5241241455078125, acc = 0.8203125\n",
      "Batch 261: loss = 0.45323365926742554, acc = 0.841796875\n",
      "Batch 262: loss = 0.4606396555900574, acc = 0.8525390625\n",
      "Batch 263: loss = 0.37246769666671753, acc = 0.8720703125\n",
      "Batch 264: loss = 0.433616578578949, acc = 0.8544921875\n",
      "Batch 265: loss = 0.41587916016578674, acc = 0.8505859375\n",
      "Batch 266: loss = 0.38074660301208496, acc = 0.8759765625\n",
      "Batch 267: loss = 0.34991759061813354, acc = 0.8876953125\n",
      "Batch 268: loss = 0.4170314073562622, acc = 0.8662109375\n",
      "Batch 269: loss = 0.40778225660324097, acc = 0.8701171875\n",
      "Batch 270: loss = 0.40971970558166504, acc = 0.865234375\n",
      "Batch 271: loss = 0.37005406618118286, acc = 0.8681640625\n",
      "Batch 272: loss = 0.39528316259384155, acc = 0.8671875\n",
      "Batch 273: loss = 0.3934718370437622, acc = 0.8671875\n",
      "Batch 274: loss = 0.40135207772254944, acc = 0.865234375\n",
      "Batch 275: loss = 0.356401264667511, acc = 0.8818359375\n",
      "Batch 276: loss = 0.4083787202835083, acc = 0.8623046875\n",
      "Batch 277: loss = 0.47636517882347107, acc = 0.845703125\n",
      "Batch 278: loss = 0.37097400426864624, acc = 0.876953125\n",
      "Batch 279: loss = 0.45123526453971863, acc = 0.84375\n",
      "Batch 280: loss = 0.43460530042648315, acc = 0.85546875\n",
      "Batch 281: loss = 0.42567142844200134, acc = 0.8583984375\n",
      "Batch 282: loss = 0.44218435883522034, acc = 0.85546875\n",
      "Batch 283: loss = 0.4740231931209564, acc = 0.8369140625\n",
      "Batch 284: loss = 0.4130175709724426, acc = 0.865234375\n",
      "Batch 285: loss = 0.47250381112098694, acc = 0.8388671875\n",
      "Batch 286: loss = 0.47400790452957153, acc = 0.8408203125\n",
      "Batch 287: loss = 0.5036337375640869, acc = 0.830078125\n",
      "Batch 288: loss = 0.4497869312763214, acc = 0.84375\n",
      "Batch 289: loss = 0.41109561920166016, acc = 0.8671875\n",
      "Batch 290: loss = 0.43644624948501587, acc = 0.8427734375\n",
      "Batch 291: loss = 0.5201331973075867, acc = 0.822265625\n",
      "Batch 292: loss = 0.42585375905036926, acc = 0.84765625\n",
      "Batch 293: loss = 0.37727275490760803, acc = 0.87109375\n",
      "Batch 294: loss = 0.44594669342041016, acc = 0.853515625\n",
      "Batch 295: loss = 0.41067731380462646, acc = 0.8583984375\n",
      "Batch 296: loss = 0.4141131341457367, acc = 0.8642578125\n",
      "Batch 297: loss = 0.37835144996643066, acc = 0.8564453125\n",
      "Batch 298: loss = 0.3801323473453522, acc = 0.8779296875\n",
      "Batch 299: loss = 0.38966378569602966, acc = 0.8759765625\n",
      "Batch 300: loss = 0.4082429111003876, acc = 0.8662109375\n",
      "Batch 301: loss = 0.4236869513988495, acc = 0.8564453125\n",
      "Batch 302: loss = 0.3891405463218689, acc = 0.869140625\n",
      "Batch 303: loss = 0.4383821189403534, acc = 0.85546875\n",
      "Batch 304: loss = 0.40393269062042236, acc = 0.8671875\n",
      "Batch 305: loss = 0.3975958526134491, acc = 0.8583984375\n",
      "Batch 306: loss = 0.46885955333709717, acc = 0.845703125\n",
      "Batch 307: loss = 0.3733987808227539, acc = 0.8759765625\n",
      "Batch 308: loss = 0.4118563234806061, acc = 0.861328125\n",
      "Batch 309: loss = 0.43781131505966187, acc = 0.8544921875\n",
      "Batch 310: loss = 0.42790040373802185, acc = 0.84765625\n",
      "Batch 311: loss = 0.41891932487487793, acc = 0.8681640625\n",
      "Batch 312: loss = 0.34399986267089844, acc = 0.8798828125\n",
      "Batch 313: loss = 0.44943544268608093, acc = 0.8408203125\n",
      "Batch 314: loss = 0.44857120513916016, acc = 0.8486328125\n",
      "Batch 315: loss = 0.42840737104415894, acc = 0.8515625\n",
      "Batch 316: loss = 0.38152825832366943, acc = 0.86328125\n",
      "Batch 317: loss = 0.43862470984458923, acc = 0.865234375\n",
      "Batch 318: loss = 0.40845975279808044, acc = 0.8544921875\n",
      "Batch 319: loss = 0.4491407573223114, acc = 0.84765625\n",
      "Batch 320: loss = 0.429313063621521, acc = 0.8466796875\n",
      "Batch 321: loss = 0.46564847230911255, acc = 0.849609375\n",
      "Batch 322: loss = 0.36513444781303406, acc = 0.8857421875\n",
      "Batch 323: loss = 0.4500826597213745, acc = 0.8388671875\n",
      "Batch 324: loss = 0.40197187662124634, acc = 0.869140625\n",
      "Batch 325: loss = 0.45652276277542114, acc = 0.8486328125\n",
      "Batch 326: loss = 0.36902615427970886, acc = 0.86328125\n",
      "Batch 327: loss = 0.41550299525260925, acc = 0.8623046875\n",
      "Batch 328: loss = 0.47069820761680603, acc = 0.837890625\n",
      "Batch 329: loss = 0.48417970538139343, acc = 0.83203125\n",
      "Batch 330: loss = 0.3964625597000122, acc = 0.8681640625\n",
      "Batch 331: loss = 0.3982633054256439, acc = 0.8681640625\n",
      "Batch 332: loss = 0.4185647666454315, acc = 0.8505859375\n",
      "Batch 333: loss = 0.40582719445228577, acc = 0.869140625\n",
      "Batch 334: loss = 0.35765978693962097, acc = 0.88671875\n",
      "Batch 335: loss = 0.44045883417129517, acc = 0.845703125\n",
      "Batch 336: loss = 0.47424808144569397, acc = 0.8369140625\n",
      "Batch 337: loss = 0.44900718331336975, acc = 0.8583984375\n",
      "Batch 338: loss = 0.39568397402763367, acc = 0.8662109375\n",
      "Batch 339: loss = 0.4238228499889374, acc = 0.8466796875\n",
      "Batch 340: loss = 0.37069445848464966, acc = 0.87890625\n",
      "Batch 341: loss = 0.43138331174850464, acc = 0.83984375\n",
      "Batch 342: loss = 0.4046488404273987, acc = 0.8603515625\n",
      "Batch 343: loss = 0.35318323969841003, acc = 0.8740234375\n",
      "Batch 344: loss = 0.38929587602615356, acc = 0.865234375\n",
      "Batch 345: loss = 0.3482954800128937, acc = 0.880859375\n",
      "Batch 346: loss = 0.35368433594703674, acc = 0.880859375\n",
      "Batch 347: loss = 0.4308236539363861, acc = 0.8408203125\n",
      "Batch 348: loss = 0.3859082758426666, acc = 0.8759765625\n",
      "Batch 349: loss = 0.3759274482727051, acc = 0.8828125\n",
      "Batch 350: loss = 0.33810099959373474, acc = 0.8857421875\n",
      "Batch 351: loss = 0.36122387647628784, acc = 0.8798828125\n",
      "Batch 352: loss = 0.45751070976257324, acc = 0.84375\n",
      "Batch 353: loss = 0.3497403860092163, acc = 0.888671875\n",
      "Batch 354: loss = 0.37080609798431396, acc = 0.876953125\n",
      "Batch 355: loss = 0.30209052562713623, acc = 0.9013671875\n",
      "Batch 356: loss = 0.403579443693161, acc = 0.8662109375\n",
      "Batch 357: loss = 0.40584444999694824, acc = 0.8583984375\n",
      "Batch 358: loss = 0.38784462213516235, acc = 0.8701171875\n",
      "Batch 359: loss = 0.3788141906261444, acc = 0.8623046875\n",
      "Batch 360: loss = 0.36270684003829956, acc = 0.884765625\n",
      "Batch 361: loss = 0.4140486419200897, acc = 0.8515625\n",
      "Batch 362: loss = 0.3814789354801178, acc = 0.8583984375\n",
      "Batch 363: loss = 0.4143279194831848, acc = 0.865234375\n",
      "Batch 364: loss = 0.4507875144481659, acc = 0.853515625\n",
      "Batch 365: loss = 0.37429216504096985, acc = 0.8759765625\n",
      "Batch 366: loss = 0.38498932123184204, acc = 0.876953125\n",
      "Batch 367: loss = 0.38731998205184937, acc = 0.8740234375\n",
      "Batch 368: loss = 0.4315090477466583, acc = 0.8583984375\n",
      "Batch 369: loss = 0.4652060270309448, acc = 0.83984375\n",
      "Batch 370: loss = 0.36652350425720215, acc = 0.880859375\n",
      "Batch 371: loss = 0.458284854888916, acc = 0.833984375\n",
      "Batch 372: loss = 0.4009159207344055, acc = 0.85546875\n",
      "Batch 373: loss = 0.45809125900268555, acc = 0.845703125\n",
      "Batch 374: loss = 0.43564891815185547, acc = 0.8583984375\n",
      "Batch 375: loss = 0.4388329088687897, acc = 0.8447265625\n",
      "Batch 376: loss = 0.41980645060539246, acc = 0.865234375\n",
      "Batch 377: loss = 0.46493738889694214, acc = 0.8525390625\n",
      "Batch 378: loss = 0.4315863847732544, acc = 0.8544921875\n",
      "Batch 379: loss = 0.46635717153549194, acc = 0.8486328125\n",
      "Batch 380: loss = 0.37792983651161194, acc = 0.875\n",
      "Batch 381: loss = 0.3500889539718628, acc = 0.8818359375\n",
      "Batch 382: loss = 0.43445855379104614, acc = 0.84375\n",
      "Batch 383: loss = 0.37129196524620056, acc = 0.8662109375\n",
      "Batch 384: loss = 0.42425620555877686, acc = 0.8681640625\n",
      "Batch 385: loss = 0.3930361568927765, acc = 0.857421875\n",
      "Batch 386: loss = 0.3955382704734802, acc = 0.8623046875\n",
      "Batch 387: loss = 0.38093340396881104, acc = 0.8701171875\n",
      "Batch 388: loss = 0.4331880211830139, acc = 0.853515625\n",
      "Batch 389: loss = 0.3980022072792053, acc = 0.861328125\n",
      "Batch 390: loss = 0.4880107045173645, acc = 0.8349609375\n",
      "Batch 391: loss = 0.4152742922306061, acc = 0.8623046875\n",
      "Batch 392: loss = 0.40589675307273865, acc = 0.8515625\n",
      "Batch 393: loss = 0.44445979595184326, acc = 0.857421875\n",
      "Batch 394: loss = 0.37422865629196167, acc = 0.8759765625\n",
      "Batch 395: loss = 0.38650503754615784, acc = 0.8515625\n",
      "Batch 396: loss = 0.4521118700504303, acc = 0.8330078125\n",
      "Batch 397: loss = 0.3409019708633423, acc = 0.8681640625\n",
      "Batch 398: loss = 0.3449094891548157, acc = 0.873046875\n",
      "Batch 399: loss = 0.3936924934387207, acc = 0.875\n",
      "Batch 400: loss = 0.40725961327552795, acc = 0.8671875\n",
      "Batch 401: loss = 0.4420067071914673, acc = 0.8515625\n",
      "Batch 402: loss = 0.43425431847572327, acc = 0.853515625\n",
      "Batch 403: loss = 0.39655178785324097, acc = 0.859375\n",
      "Batch 404: loss = 0.4362717866897583, acc = 0.8623046875\n",
      "Batch 405: loss = 0.47815072536468506, acc = 0.837890625\n",
      "Batch 406: loss = 0.5057798027992249, acc = 0.841796875\n",
      "Batch 407: loss = 0.4156121015548706, acc = 0.8642578125\n",
      "Batch 408: loss = 0.49411699175834656, acc = 0.8310546875\n",
      "Batch 409: loss = 0.43302109837532043, acc = 0.8583984375\n",
      "Batch 410: loss = 0.46646371483802795, acc = 0.837890625\n",
      "Batch 411: loss = 0.3918665051460266, acc = 0.865234375\n",
      "Batch 412: loss = 0.4202880263328552, acc = 0.85546875\n",
      "Batch 413: loss = 0.3963046967983246, acc = 0.8623046875\n",
      "Batch 414: loss = 0.4542817175388336, acc = 0.845703125\n",
      "Batch 415: loss = 0.4479922652244568, acc = 0.8564453125\n",
      "Batch 416: loss = 0.45943889021873474, acc = 0.849609375\n",
      "Batch 417: loss = 0.4371469020843506, acc = 0.8603515625\n",
      "Batch 418: loss = 0.5073414444923401, acc = 0.833984375\n",
      "Batch 419: loss = 0.49719512462615967, acc = 0.83203125\n",
      "Batch 420: loss = 0.4953145980834961, acc = 0.8427734375\n",
      "Batch 421: loss = 0.47265467047691345, acc = 0.84765625\n",
      "Batch 422: loss = 0.4619196057319641, acc = 0.8466796875\n",
      "Batch 423: loss = 0.47445666790008545, acc = 0.8486328125\n",
      "Batch 424: loss = 0.46108394861221313, acc = 0.841796875\n",
      "Batch 425: loss = 0.45612096786499023, acc = 0.84765625\n",
      "Batch 426: loss = 0.4424152672290802, acc = 0.837890625\n",
      "Batch 427: loss = 0.4486443102359772, acc = 0.853515625\n",
      "Batch 428: loss = 0.444582462310791, acc = 0.83984375\n",
      "Batch 429: loss = 0.40492257475852966, acc = 0.875\n",
      "Batch 430: loss = 0.4027893841266632, acc = 0.8720703125\n",
      "Batch 431: loss = 0.413809210062027, acc = 0.85546875\n",
      "Batch 432: loss = 0.43726661801338196, acc = 0.845703125\n",
      "Batch 433: loss = 0.3710269033908844, acc = 0.8818359375\n",
      "Batch 434: loss = 0.4235662519931793, acc = 0.8583984375\n",
      "Batch 435: loss = 0.48343828320503235, acc = 0.8271484375\n",
      "Batch 436: loss = 0.3838992416858673, acc = 0.8740234375\n",
      "Batch 437: loss = 0.43981418013572693, acc = 0.8525390625\n",
      "Batch 438: loss = 0.43845313787460327, acc = 0.859375\n",
      "Batch 439: loss = 0.3832843005657196, acc = 0.873046875\n",
      "Batch 440: loss = 0.40500694513320923, acc = 0.8544921875\n",
      "Batch 441: loss = 0.4197537899017334, acc = 0.853515625\n",
      "\n",
      "Epoch 95/100\n",
      "Batch 1: loss = 0.5318197011947632, acc = 0.8251953125\n",
      "Batch 2: loss = 0.40224698185920715, acc = 0.859375\n",
      "Batch 3: loss = 0.45075345039367676, acc = 0.8466796875\n",
      "Batch 4: loss = 0.4400351345539093, acc = 0.841796875\n",
      "Batch 5: loss = 0.45344576239585876, acc = 0.845703125\n",
      "Batch 6: loss = 0.3667495548725128, acc = 0.8818359375\n",
      "Batch 7: loss = 0.35987919569015503, acc = 0.8681640625\n",
      "Batch 8: loss = 0.37860652804374695, acc = 0.8671875\n",
      "Batch 9: loss = 0.4326721429824829, acc = 0.8310546875\n",
      "Batch 10: loss = 0.4397433400154114, acc = 0.857421875\n",
      "Batch 11: loss = 0.4811666011810303, acc = 0.83984375\n",
      "Batch 12: loss = 0.4167630672454834, acc = 0.8544921875\n",
      "Batch 13: loss = 0.43907949328422546, acc = 0.8330078125\n",
      "Batch 14: loss = 0.40411075949668884, acc = 0.8583984375\n",
      "Batch 15: loss = 0.3730457127094269, acc = 0.861328125\n",
      "Batch 16: loss = 0.4052698016166687, acc = 0.8583984375\n",
      "Batch 17: loss = 0.3492157459259033, acc = 0.884765625\n",
      "Batch 18: loss = 0.4329797923564911, acc = 0.857421875\n",
      "Batch 19: loss = 0.44620105624198914, acc = 0.849609375\n",
      "Batch 20: loss = 0.4234023690223694, acc = 0.8505859375\n",
      "Batch 21: loss = 0.42441102862358093, acc = 0.8544921875\n",
      "Batch 22: loss = 0.4348941147327423, acc = 0.8583984375\n",
      "Batch 23: loss = 0.415181040763855, acc = 0.857421875\n",
      "Batch 24: loss = 0.41588345170021057, acc = 0.87109375\n",
      "Batch 25: loss = 0.46783408522605896, acc = 0.84765625\n",
      "Batch 26: loss = 0.39599332213401794, acc = 0.8623046875\n",
      "Batch 27: loss = 0.46373820304870605, acc = 0.8486328125\n",
      "Batch 28: loss = 0.41511866450309753, acc = 0.8671875\n",
      "Batch 29: loss = 0.5170496106147766, acc = 0.826171875\n",
      "Batch 30: loss = 0.45406389236450195, acc = 0.8544921875\n",
      "Batch 31: loss = 0.3961111009120941, acc = 0.8720703125\n",
      "Batch 32: loss = 0.3876951038837433, acc = 0.8662109375\n",
      "Batch 33: loss = 0.35571199655532837, acc = 0.876953125\n",
      "Batch 34: loss = 0.349460244178772, acc = 0.8837890625\n",
      "Batch 35: loss = 0.3791363537311554, acc = 0.8701171875\n",
      "Batch 36: loss = 0.4052479565143585, acc = 0.8623046875\n",
      "Batch 37: loss = 0.40020355582237244, acc = 0.880859375\n",
      "Batch 38: loss = 0.3800666928291321, acc = 0.8828125\n",
      "Batch 39: loss = 0.35686391592025757, acc = 0.8798828125\n",
      "Batch 40: loss = 0.40057095885276794, acc = 0.8720703125\n",
      "Batch 41: loss = 0.31798186898231506, acc = 0.89453125\n",
      "Batch 42: loss = 0.4714920222759247, acc = 0.8369140625\n",
      "Batch 43: loss = 0.4632551074028015, acc = 0.830078125\n",
      "Batch 44: loss = 0.4455740451812744, acc = 0.859375\n",
      "Batch 45: loss = 0.375502347946167, acc = 0.87890625\n",
      "Batch 46: loss = 0.356088250875473, acc = 0.8798828125\n",
      "Batch 47: loss = 0.37475472688674927, acc = 0.8818359375\n",
      "Batch 48: loss = 0.37514394521713257, acc = 0.875\n",
      "Batch 49: loss = 0.410444051027298, acc = 0.8701171875\n",
      "Batch 50: loss = 0.3974341154098511, acc = 0.8583984375\n",
      "Batch 51: loss = 0.47383856773376465, acc = 0.833984375\n",
      "Batch 52: loss = 0.34615159034729004, acc = 0.88671875\n",
      "Batch 53: loss = 0.4269324541091919, acc = 0.8525390625\n",
      "Batch 54: loss = 0.36955368518829346, acc = 0.8740234375\n",
      "Batch 55: loss = 0.43214282393455505, acc = 0.8427734375\n",
      "Batch 56: loss = 0.3871958553791046, acc = 0.8720703125\n",
      "Batch 57: loss = 0.4081098139286041, acc = 0.8642578125\n",
      "Batch 58: loss = 0.36610493063926697, acc = 0.8779296875\n",
      "Batch 59: loss = 0.42544373869895935, acc = 0.859375\n",
      "Batch 60: loss = 0.41319188475608826, acc = 0.8662109375\n",
      "Batch 61: loss = 0.4334321618080139, acc = 0.8603515625\n",
      "Batch 62: loss = 0.44330543279647827, acc = 0.8505859375\n",
      "Batch 63: loss = 0.44532692432403564, acc = 0.8515625\n",
      "Batch 64: loss = 0.3759702444076538, acc = 0.8701171875\n",
      "Batch 65: loss = 0.35738855600357056, acc = 0.8759765625\n",
      "Batch 66: loss = 0.3717990219593048, acc = 0.876953125\n",
      "Batch 67: loss = 0.46158888936042786, acc = 0.8466796875\n",
      "Batch 68: loss = 0.4361027479171753, acc = 0.8544921875\n",
      "Batch 69: loss = 0.40500426292419434, acc = 0.8701171875\n",
      "Batch 70: loss = 0.3986892104148865, acc = 0.857421875\n",
      "Batch 71: loss = 0.3806116580963135, acc = 0.865234375\n",
      "Batch 72: loss = 0.43326273560523987, acc = 0.845703125\n",
      "Batch 73: loss = 0.40628546476364136, acc = 0.86328125\n",
      "Batch 74: loss = 0.433765172958374, acc = 0.8515625\n",
      "Batch 75: loss = 0.35277557373046875, acc = 0.88671875\n",
      "Batch 76: loss = 0.44770708680152893, acc = 0.849609375\n",
      "Batch 77: loss = 0.4449111521244049, acc = 0.845703125\n",
      "Batch 78: loss = 0.45658761262893677, acc = 0.8505859375\n",
      "Batch 79: loss = 0.3921603262424469, acc = 0.857421875\n",
      "Batch 80: loss = 0.5007970333099365, acc = 0.8349609375\n",
      "Batch 81: loss = 0.38803014159202576, acc = 0.865234375\n",
      "Batch 82: loss = 0.3883773386478424, acc = 0.8671875\n",
      "Batch 83: loss = 0.46240106225013733, acc = 0.8427734375\n",
      "Batch 84: loss = 0.3773227035999298, acc = 0.873046875\n",
      "Batch 85: loss = 0.43661680817604065, acc = 0.853515625\n",
      "Batch 86: loss = 0.43731045722961426, acc = 0.8486328125\n",
      "Batch 87: loss = 0.391823410987854, acc = 0.8623046875\n",
      "Batch 88: loss = 0.3949638605117798, acc = 0.859375\n",
      "Batch 89: loss = 0.4615952968597412, acc = 0.8525390625\n",
      "Batch 90: loss = 0.424212783575058, acc = 0.84765625\n",
      "Batch 91: loss = 0.4091954231262207, acc = 0.8603515625\n",
      "Batch 92: loss = 0.4355964958667755, acc = 0.857421875\n",
      "Batch 93: loss = 0.47015130519866943, acc = 0.8310546875\n",
      "Batch 94: loss = 0.46613404154777527, acc = 0.8447265625\n",
      "Batch 95: loss = 0.3937728703022003, acc = 0.853515625\n",
      "Batch 96: loss = 0.40263044834136963, acc = 0.85546875\n",
      "Batch 97: loss = 0.43078017234802246, acc = 0.8505859375\n",
      "Batch 98: loss = 0.46953892707824707, acc = 0.833984375\n",
      "Batch 99: loss = 0.45988768339157104, acc = 0.8515625\n",
      "Batch 100: loss = 0.46282410621643066, acc = 0.8515625\n",
      "Batch 101: loss = 0.3713410496711731, acc = 0.875\n",
      "Batch 102: loss = 0.3616681396961212, acc = 0.8837890625\n",
      "Batch 103: loss = 0.39238253235816956, acc = 0.85546875\n",
      "Batch 104: loss = 0.3914887607097626, acc = 0.8671875\n",
      "Batch 105: loss = 0.4502165913581848, acc = 0.861328125\n",
      "Batch 106: loss = 0.4420149326324463, acc = 0.8642578125\n",
      "Batch 107: loss = 0.40605562925338745, acc = 0.859375\n",
      "Batch 108: loss = 0.45323455333709717, acc = 0.8369140625\n",
      "Batch 109: loss = 0.3576716482639313, acc = 0.8740234375\n",
      "Batch 110: loss = 0.45419183373451233, acc = 0.84765625\n",
      "Batch 111: loss = 0.48062190413475037, acc = 0.8388671875\n",
      "Batch 112: loss = 0.4355754852294922, acc = 0.8447265625\n",
      "Batch 113: loss = 0.43391990661621094, acc = 0.853515625\n",
      "Batch 114: loss = 0.38281118869781494, acc = 0.8701171875\n",
      "Batch 115: loss = 0.4727586507797241, acc = 0.8486328125\n",
      "Batch 116: loss = 0.40387746691703796, acc = 0.8642578125\n",
      "Batch 117: loss = 0.4151519238948822, acc = 0.8583984375\n",
      "Batch 118: loss = 0.43148115277290344, acc = 0.8671875\n",
      "Batch 119: loss = 0.3970107436180115, acc = 0.8525390625\n",
      "Batch 120: loss = 0.4518963098526001, acc = 0.849609375\n",
      "Batch 121: loss = 0.4369269609451294, acc = 0.8486328125\n",
      "Batch 122: loss = 0.3795921504497528, acc = 0.875\n",
      "Batch 123: loss = 0.39546895027160645, acc = 0.8671875\n",
      "Batch 124: loss = 0.45916616916656494, acc = 0.8486328125\n",
      "Batch 125: loss = 0.3858112096786499, acc = 0.8662109375\n",
      "Batch 126: loss = 0.38306358456611633, acc = 0.87109375\n",
      "Batch 127: loss = 0.44437748193740845, acc = 0.8505859375\n",
      "Batch 128: loss = 0.38622286915779114, acc = 0.8720703125\n",
      "Batch 129: loss = 0.412163108587265, acc = 0.8564453125\n",
      "Batch 130: loss = 0.4010906219482422, acc = 0.865234375\n",
      "Batch 131: loss = 0.3140976130962372, acc = 0.8935546875\n",
      "Batch 132: loss = 0.30526918172836304, acc = 0.890625\n",
      "Batch 133: loss = 0.3746694326400757, acc = 0.8837890625\n",
      "Batch 134: loss = 0.36995017528533936, acc = 0.8759765625\n",
      "Batch 135: loss = 0.4659386873245239, acc = 0.83984375\n",
      "Batch 136: loss = 0.4066547453403473, acc = 0.8603515625\n",
      "Batch 137: loss = 0.3669012486934662, acc = 0.8798828125\n",
      "Batch 138: loss = 0.3998190462589264, acc = 0.861328125\n",
      "Batch 139: loss = 0.33701062202453613, acc = 0.880859375\n",
      "Batch 140: loss = 0.3595970571041107, acc = 0.880859375\n",
      "Batch 141: loss = 0.40132835507392883, acc = 0.8759765625\n",
      "Batch 142: loss = 0.42007026076316833, acc = 0.8583984375\n",
      "Batch 143: loss = 0.4814055860042572, acc = 0.83984375\n",
      "Batch 144: loss = 0.38630953431129456, acc = 0.865234375\n",
      "Batch 145: loss = 0.3605642020702362, acc = 0.875\n",
      "Batch 146: loss = 0.4160889983177185, acc = 0.85546875\n",
      "Batch 147: loss = 0.45697078108787537, acc = 0.837890625\n",
      "Batch 148: loss = 0.3742086589336395, acc = 0.8681640625\n",
      "Batch 149: loss = 0.3906323313713074, acc = 0.859375\n",
      "Batch 150: loss = 0.4101773798465729, acc = 0.861328125\n",
      "Batch 151: loss = 0.4339829683303833, acc = 0.84765625\n",
      "Batch 152: loss = 0.37565964460372925, acc = 0.8740234375\n",
      "Batch 153: loss = 0.40304869413375854, acc = 0.8671875\n",
      "Batch 154: loss = 0.38989806175231934, acc = 0.8603515625\n",
      "Batch 155: loss = 0.37859809398651123, acc = 0.8720703125\n",
      "Batch 156: loss = 0.46272993087768555, acc = 0.8291015625\n",
      "Batch 157: loss = 0.40170782804489136, acc = 0.8662109375\n",
      "Batch 158: loss = 0.38446855545043945, acc = 0.865234375\n",
      "Batch 159: loss = 0.44721853733062744, acc = 0.845703125\n",
      "Batch 160: loss = 0.4732903838157654, acc = 0.849609375\n",
      "Batch 161: loss = 0.4423685371875763, acc = 0.8544921875\n",
      "Batch 162: loss = 0.45789623260498047, acc = 0.8447265625\n",
      "Batch 163: loss = 0.4191552996635437, acc = 0.8603515625\n",
      "Batch 164: loss = 0.4229365587234497, acc = 0.8466796875\n",
      "Batch 165: loss = 0.4335462749004364, acc = 0.845703125\n",
      "Batch 166: loss = 0.3503004014492035, acc = 0.8701171875\n",
      "Batch 167: loss = 0.3727220594882965, acc = 0.87890625\n",
      "Batch 168: loss = 0.3847024440765381, acc = 0.8759765625\n",
      "Batch 169: loss = 0.3420877158641815, acc = 0.8740234375\n",
      "Batch 170: loss = 0.34418827295303345, acc = 0.8798828125\n",
      "Batch 171: loss = 0.4094439744949341, acc = 0.8525390625\n",
      "Batch 172: loss = 0.362110435962677, acc = 0.876953125\n",
      "Batch 173: loss = 0.4179401397705078, acc = 0.8505859375\n",
      "Batch 174: loss = 0.41188377141952515, acc = 0.8701171875\n",
      "Batch 175: loss = 0.4097183048725128, acc = 0.859375\n",
      "Batch 176: loss = 0.41129419207572937, acc = 0.86328125\n",
      "Batch 177: loss = 0.32030224800109863, acc = 0.888671875\n",
      "Batch 178: loss = 0.3921680450439453, acc = 0.8701171875\n",
      "Batch 179: loss = 0.39487677812576294, acc = 0.8564453125\n",
      "Batch 180: loss = 0.420667827129364, acc = 0.853515625\n",
      "Batch 181: loss = 0.4189513623714447, acc = 0.8515625\n",
      "Batch 182: loss = 0.43409818410873413, acc = 0.84765625\n",
      "Batch 183: loss = 0.3970702886581421, acc = 0.865234375\n",
      "Batch 184: loss = 0.45435336232185364, acc = 0.845703125\n",
      "Batch 185: loss = 0.43663734197616577, acc = 0.853515625\n",
      "Batch 186: loss = 0.3716603219509125, acc = 0.8857421875\n",
      "Batch 187: loss = 0.397897332906723, acc = 0.86328125\n",
      "Batch 188: loss = 0.421004056930542, acc = 0.873046875\n",
      "Batch 189: loss = 0.438917338848114, acc = 0.84375\n",
      "Batch 190: loss = 0.41113385558128357, acc = 0.859375\n",
      "Batch 191: loss = 0.39328011870384216, acc = 0.8681640625\n",
      "Batch 192: loss = 0.38694530725479126, acc = 0.869140625\n",
      "Batch 193: loss = 0.41645562648773193, acc = 0.8525390625\n",
      "Batch 194: loss = 0.4025781452655792, acc = 0.8583984375\n",
      "Batch 195: loss = 0.40161561965942383, acc = 0.87109375\n",
      "Batch 196: loss = 0.46943598985671997, acc = 0.841796875\n",
      "Batch 197: loss = 0.4838777780532837, acc = 0.84765625\n",
      "Batch 198: loss = 0.40242478251457214, acc = 0.8583984375\n",
      "Batch 199: loss = 0.42856544256210327, acc = 0.8564453125\n",
      "Batch 200: loss = 0.43327152729034424, acc = 0.8544921875\n",
      "Batch 201: loss = 0.46755462884902954, acc = 0.833984375\n",
      "Batch 202: loss = 0.48011794686317444, acc = 0.8359375\n",
      "Batch 203: loss = 0.39764365553855896, acc = 0.869140625\n",
      "Batch 204: loss = 0.4378374516963959, acc = 0.853515625\n",
      "Batch 205: loss = 0.43830302357673645, acc = 0.859375\n",
      "Batch 206: loss = 0.42558491230010986, acc = 0.85546875\n",
      "Batch 207: loss = 0.49904635548591614, acc = 0.826171875\n",
      "Batch 208: loss = 0.44974085688591003, acc = 0.8486328125\n",
      "Batch 209: loss = 0.43496188521385193, acc = 0.8515625\n",
      "Batch 210: loss = 0.40622565150260925, acc = 0.8623046875\n",
      "Batch 211: loss = 0.4183928072452545, acc = 0.85546875\n",
      "Batch 212: loss = 0.4722440838813782, acc = 0.84375\n",
      "Batch 213: loss = 0.4442876875400543, acc = 0.84375\n",
      "Batch 214: loss = 0.39885860681533813, acc = 0.8671875\n",
      "Batch 215: loss = 0.37121397256851196, acc = 0.87109375\n",
      "Batch 216: loss = 0.34430405497550964, acc = 0.8896484375\n",
      "Batch 217: loss = 0.3746562600135803, acc = 0.87109375\n",
      "Batch 218: loss = 0.41019558906555176, acc = 0.8662109375\n",
      "Batch 219: loss = 0.38208094239234924, acc = 0.8818359375\n",
      "Batch 220: loss = 0.40328484773635864, acc = 0.8583984375\n",
      "Batch 221: loss = 0.4743422567844391, acc = 0.8447265625\n",
      "Batch 222: loss = 0.3760761022567749, acc = 0.880859375\n",
      "Batch 223: loss = 0.3552360236644745, acc = 0.8701171875\n",
      "Batch 224: loss = 0.3562655448913574, acc = 0.8779296875\n",
      "Batch 225: loss = 0.38579848408699036, acc = 0.865234375\n",
      "Batch 226: loss = 0.45021548867225647, acc = 0.8369140625\n",
      "Batch 227: loss = 0.3940722644329071, acc = 0.865234375\n",
      "Batch 228: loss = 0.391145795583725, acc = 0.8671875\n",
      "Batch 229: loss = 0.38439133763313293, acc = 0.8779296875\n",
      "Batch 230: loss = 0.35494473576545715, acc = 0.8759765625\n",
      "Batch 231: loss = 0.4750744104385376, acc = 0.837890625\n",
      "Batch 232: loss = 0.3885350823402405, acc = 0.869140625\n",
      "Batch 233: loss = 0.5059502124786377, acc = 0.8125\n",
      "Batch 234: loss = 0.37529247999191284, acc = 0.873046875\n",
      "Batch 235: loss = 0.41747593879699707, acc = 0.853515625\n",
      "Batch 236: loss = 0.4579964578151703, acc = 0.8447265625\n",
      "Batch 237: loss = 0.3891497552394867, acc = 0.8701171875\n",
      "Batch 238: loss = 0.41480255126953125, acc = 0.8447265625\n",
      "Batch 239: loss = 0.35562264919281006, acc = 0.8896484375\n",
      "Batch 240: loss = 0.48817116022109985, acc = 0.8515625\n",
      "Batch 241: loss = 0.4019973874092102, acc = 0.8681640625\n",
      "Batch 242: loss = 0.4370700418949127, acc = 0.861328125\n",
      "Batch 243: loss = 0.4326043128967285, acc = 0.8486328125\n",
      "Batch 244: loss = 0.46561455726623535, acc = 0.841796875\n",
      "Batch 245: loss = 0.3610314428806305, acc = 0.880859375\n",
      "Batch 246: loss = 0.4086141288280487, acc = 0.8525390625\n",
      "Batch 247: loss = 0.41968369483947754, acc = 0.86328125\n",
      "Batch 248: loss = 0.38935577869415283, acc = 0.8701171875\n",
      "Batch 249: loss = 0.3473415672779083, acc = 0.8662109375\n",
      "Batch 250: loss = 0.3923383355140686, acc = 0.873046875\n",
      "Batch 251: loss = 0.36179280281066895, acc = 0.87109375\n",
      "Batch 252: loss = 0.37327176332473755, acc = 0.8779296875\n",
      "Batch 253: loss = 0.4197962284088135, acc = 0.8642578125\n",
      "Batch 254: loss = 0.4787338078022003, acc = 0.826171875\n",
      "Batch 255: loss = 0.4589669704437256, acc = 0.8447265625\n",
      "Batch 256: loss = 0.4463353753089905, acc = 0.853515625\n",
      "Batch 257: loss = 0.5198565125465393, acc = 0.8154296875\n",
      "Batch 258: loss = 0.4497290849685669, acc = 0.8515625\n",
      "Batch 259: loss = 0.47281432151794434, acc = 0.8505859375\n",
      "Batch 260: loss = 0.5108691453933716, acc = 0.8271484375\n",
      "Batch 261: loss = 0.41495591402053833, acc = 0.8466796875\n",
      "Batch 262: loss = 0.4319147765636444, acc = 0.8515625\n",
      "Batch 263: loss = 0.39906686544418335, acc = 0.8662109375\n",
      "Batch 264: loss = 0.4193876087665558, acc = 0.857421875\n",
      "Batch 265: loss = 0.4106861352920532, acc = 0.86328125\n",
      "Batch 266: loss = 0.35294750332832336, acc = 0.8798828125\n",
      "Batch 267: loss = 0.32510778307914734, acc = 0.892578125\n",
      "Batch 268: loss = 0.41177770495414734, acc = 0.86328125\n",
      "Batch 269: loss = 0.44318780303001404, acc = 0.85546875\n",
      "Batch 270: loss = 0.4203089475631714, acc = 0.8642578125\n",
      "Batch 271: loss = 0.37111350893974304, acc = 0.8720703125\n",
      "Batch 272: loss = 0.4038640558719635, acc = 0.8583984375\n",
      "Batch 273: loss = 0.42726489901542664, acc = 0.84375\n",
      "Batch 274: loss = 0.40019112825393677, acc = 0.8603515625\n",
      "Batch 275: loss = 0.3653331398963928, acc = 0.875\n",
      "Batch 276: loss = 0.3976817727088928, acc = 0.8681640625\n",
      "Batch 277: loss = 0.44203251600265503, acc = 0.845703125\n",
      "Batch 278: loss = 0.34804433584213257, acc = 0.8857421875\n",
      "Batch 279: loss = 0.46534448862075806, acc = 0.85546875\n",
      "Batch 280: loss = 0.45879802107810974, acc = 0.857421875\n",
      "Batch 281: loss = 0.43264925479888916, acc = 0.853515625\n",
      "Batch 282: loss = 0.45453035831451416, acc = 0.845703125\n",
      "Batch 283: loss = 0.4665464758872986, acc = 0.845703125\n",
      "Batch 284: loss = 0.39382362365722656, acc = 0.8720703125\n",
      "Batch 285: loss = 0.4583757221698761, acc = 0.8408203125\n",
      "Batch 286: loss = 0.44522225856781006, acc = 0.8564453125\n",
      "Batch 287: loss = 0.46611055731773376, acc = 0.837890625\n",
      "Batch 288: loss = 0.4490317702293396, acc = 0.8515625\n",
      "Batch 289: loss = 0.3877919316291809, acc = 0.8662109375\n",
      "Batch 290: loss = 0.43111732602119446, acc = 0.8505859375\n",
      "Batch 291: loss = 0.4106472432613373, acc = 0.86328125\n",
      "Batch 292: loss = 0.41981980204582214, acc = 0.8603515625\n",
      "Batch 293: loss = 0.3824658989906311, acc = 0.8759765625\n",
      "Batch 294: loss = 0.4290687143802643, acc = 0.8515625\n",
      "Batch 295: loss = 0.39417925477027893, acc = 0.85546875\n",
      "Batch 296: loss = 0.39952802658081055, acc = 0.8564453125\n",
      "Batch 297: loss = 0.40010595321655273, acc = 0.8662109375\n",
      "Batch 298: loss = 0.38988542556762695, acc = 0.865234375\n",
      "Batch 299: loss = 0.3669670820236206, acc = 0.8701171875\n",
      "Batch 300: loss = 0.4131665825843811, acc = 0.86328125\n",
      "Batch 301: loss = 0.3801439702510834, acc = 0.8720703125\n",
      "Batch 302: loss = 0.44823387265205383, acc = 0.8466796875\n",
      "Batch 303: loss = 0.49732133746147156, acc = 0.8359375\n",
      "Batch 304: loss = 0.3687354624271393, acc = 0.8818359375\n",
      "Batch 305: loss = 0.39053982496261597, acc = 0.873046875\n",
      "Batch 306: loss = 0.4227321445941925, acc = 0.86328125\n",
      "Batch 307: loss = 0.36368224024772644, acc = 0.8837890625\n",
      "Batch 308: loss = 0.3997647166252136, acc = 0.8642578125\n",
      "Batch 309: loss = 0.4481714963912964, acc = 0.84765625\n",
      "Batch 310: loss = 0.427947998046875, acc = 0.8623046875\n",
      "Batch 311: loss = 0.42464679479599, acc = 0.8583984375\n",
      "Batch 312: loss = 0.389760285615921, acc = 0.8642578125\n",
      "Batch 313: loss = 0.4468420743942261, acc = 0.8486328125\n",
      "Batch 314: loss = 0.418277770280838, acc = 0.849609375\n",
      "Batch 315: loss = 0.4189260005950928, acc = 0.859375\n",
      "Batch 316: loss = 0.37191951274871826, acc = 0.8740234375\n",
      "Batch 317: loss = 0.4189336895942688, acc = 0.8603515625\n",
      "Batch 318: loss = 0.41355812549591064, acc = 0.8544921875\n",
      "Batch 319: loss = 0.47499164938926697, acc = 0.8505859375\n",
      "Batch 320: loss = 0.39988917112350464, acc = 0.859375\n",
      "Batch 321: loss = 0.4816250801086426, acc = 0.8388671875\n",
      "Batch 322: loss = 0.4068114459514618, acc = 0.8623046875\n",
      "Batch 323: loss = 0.4331359565258026, acc = 0.8583984375\n",
      "Batch 324: loss = 0.41038480401039124, acc = 0.8544921875\n",
      "Batch 325: loss = 0.4760832190513611, acc = 0.8388671875\n",
      "Batch 326: loss = 0.3812626302242279, acc = 0.8662109375\n",
      "Batch 327: loss = 0.44083157181739807, acc = 0.8525390625\n",
      "Batch 328: loss = 0.4331700801849365, acc = 0.8583984375\n",
      "Batch 329: loss = 0.4800167679786682, acc = 0.84375\n",
      "Batch 330: loss = 0.4043771028518677, acc = 0.857421875\n",
      "Batch 331: loss = 0.3901523947715759, acc = 0.8671875\n",
      "Batch 332: loss = 0.4083153009414673, acc = 0.8720703125\n",
      "Batch 333: loss = 0.403495192527771, acc = 0.845703125\n",
      "Batch 334: loss = 0.33922716975212097, acc = 0.888671875\n",
      "Batch 335: loss = 0.42604050040245056, acc = 0.8583984375\n",
      "Batch 336: loss = 0.4238351285457611, acc = 0.853515625\n",
      "Batch 337: loss = 0.47657445073127747, acc = 0.828125\n",
      "Batch 338: loss = 0.3582761883735657, acc = 0.875\n",
      "Batch 339: loss = 0.41572561860084534, acc = 0.8544921875\n",
      "Batch 340: loss = 0.4089239835739136, acc = 0.861328125\n",
      "Batch 341: loss = 0.4435763359069824, acc = 0.84765625\n",
      "Batch 342: loss = 0.4037330746650696, acc = 0.8671875\n",
      "Batch 343: loss = 0.382518470287323, acc = 0.87890625\n",
      "Batch 344: loss = 0.36943763494491577, acc = 0.8720703125\n",
      "Batch 345: loss = 0.38335806131362915, acc = 0.8603515625\n",
      "Batch 346: loss = 0.3543502390384674, acc = 0.8818359375\n",
      "Batch 347: loss = 0.4097885489463806, acc = 0.8662109375\n",
      "Batch 348: loss = 0.375827819108963, acc = 0.8720703125\n",
      "Batch 349: loss = 0.38810795545578003, acc = 0.8642578125\n",
      "Batch 350: loss = 0.31187015771865845, acc = 0.8935546875\n",
      "Batch 351: loss = 0.35157400369644165, acc = 0.8818359375\n",
      "Batch 352: loss = 0.41905149817466736, acc = 0.8583984375\n",
      "Batch 353: loss = 0.3787355124950409, acc = 0.869140625\n",
      "Batch 354: loss = 0.35544949769973755, acc = 0.8828125\n",
      "Batch 355: loss = 0.27736321091651917, acc = 0.9033203125\n",
      "Batch 356: loss = 0.3527325987815857, acc = 0.880859375\n",
      "Batch 357: loss = 0.3572222590446472, acc = 0.876953125\n",
      "Batch 358: loss = 0.3741433918476105, acc = 0.87890625\n",
      "Batch 359: loss = 0.41162002086639404, acc = 0.857421875\n",
      "Batch 360: loss = 0.36907029151916504, acc = 0.8896484375\n",
      "Batch 361: loss = 0.3931053876876831, acc = 0.869140625\n",
      "Batch 362: loss = 0.383941113948822, acc = 0.865234375\n",
      "Batch 363: loss = 0.4175443649291992, acc = 0.8583984375\n",
      "Batch 364: loss = 0.42462921142578125, acc = 0.8564453125\n",
      "Batch 365: loss = 0.360675185918808, acc = 0.87890625\n",
      "Batch 366: loss = 0.37724608182907104, acc = 0.8701171875\n",
      "Batch 367: loss = 0.37389177083969116, acc = 0.8828125\n",
      "Batch 368: loss = 0.4205456078052521, acc = 0.8544921875\n",
      "Batch 369: loss = 0.48377203941345215, acc = 0.841796875\n",
      "Batch 370: loss = 0.38673800230026245, acc = 0.861328125\n",
      "Batch 371: loss = 0.4496680498123169, acc = 0.8447265625\n",
      "Batch 372: loss = 0.359112411737442, acc = 0.8798828125\n",
      "Batch 373: loss = 0.39260417222976685, acc = 0.86328125\n",
      "Batch 374: loss = 0.4226098954677582, acc = 0.8515625\n",
      "Batch 375: loss = 0.477001816034317, acc = 0.83203125\n",
      "Batch 376: loss = 0.40534836053848267, acc = 0.87109375\n",
      "Batch 377: loss = 0.4602152705192566, acc = 0.849609375\n",
      "Batch 378: loss = 0.4567694067955017, acc = 0.85546875\n",
      "Batch 379: loss = 0.4670145511627197, acc = 0.845703125\n",
      "Batch 380: loss = 0.4007124602794647, acc = 0.86328125\n",
      "Batch 381: loss = 0.4027283787727356, acc = 0.8544921875\n",
      "Batch 382: loss = 0.40405189990997314, acc = 0.861328125\n",
      "Batch 383: loss = 0.38044533133506775, acc = 0.8701171875\n",
      "Batch 384: loss = 0.45966705679893494, acc = 0.8359375\n",
      "Batch 385: loss = 0.40583938360214233, acc = 0.84765625\n",
      "Batch 386: loss = 0.379015177488327, acc = 0.873046875\n",
      "Batch 387: loss = 0.3681449294090271, acc = 0.8740234375\n",
      "Batch 388: loss = 0.45394062995910645, acc = 0.837890625\n",
      "Batch 389: loss = 0.40352538228034973, acc = 0.865234375\n",
      "Batch 390: loss = 0.4481731951236725, acc = 0.8564453125\n",
      "Batch 391: loss = 0.4335549473762512, acc = 0.8544921875\n",
      "Batch 392: loss = 0.4296188950538635, acc = 0.853515625\n",
      "Batch 393: loss = 0.43674418330192566, acc = 0.8486328125\n",
      "Batch 394: loss = 0.40510669350624084, acc = 0.8671875\n",
      "Batch 395: loss = 0.37827566266059875, acc = 0.8671875\n",
      "Batch 396: loss = 0.45441776514053345, acc = 0.853515625\n",
      "Batch 397: loss = 0.3567318916320801, acc = 0.875\n",
      "Batch 398: loss = 0.33166056871414185, acc = 0.88671875\n",
      "Batch 399: loss = 0.3715589940547943, acc = 0.869140625\n",
      "Batch 400: loss = 0.4305502772331238, acc = 0.8564453125\n",
      "Batch 401: loss = 0.37293899059295654, acc = 0.87109375\n",
      "Batch 402: loss = 0.47930994629859924, acc = 0.845703125\n",
      "Batch 403: loss = 0.3800557553768158, acc = 0.8681640625\n",
      "Batch 404: loss = 0.4693751335144043, acc = 0.845703125\n",
      "Batch 405: loss = 0.42832624912261963, acc = 0.8544921875\n",
      "Batch 406: loss = 0.5236148238182068, acc = 0.818359375\n",
      "Batch 407: loss = 0.4419902563095093, acc = 0.85546875\n",
      "Batch 408: loss = 0.5017623901367188, acc = 0.828125\n",
      "Batch 409: loss = 0.4219515323638916, acc = 0.857421875\n",
      "Batch 410: loss = 0.47741562128067017, acc = 0.8427734375\n",
      "Batch 411: loss = 0.39105409383773804, acc = 0.8671875\n",
      "Batch 412: loss = 0.4389389455318451, acc = 0.8564453125\n",
      "Batch 413: loss = 0.4238660931587219, acc = 0.861328125\n",
      "Batch 414: loss = 0.4355836510658264, acc = 0.85546875\n",
      "Batch 415: loss = 0.4304100275039673, acc = 0.8525390625\n",
      "Batch 416: loss = 0.46180474758148193, acc = 0.8486328125\n",
      "Batch 417: loss = 0.40858080983161926, acc = 0.8583984375\n",
      "Batch 418: loss = 0.4735119044780731, acc = 0.8515625\n",
      "Batch 419: loss = 0.5017919540405273, acc = 0.8291015625\n",
      "Batch 420: loss = 0.4923624098300934, acc = 0.833984375\n",
      "Batch 421: loss = 0.4722888469696045, acc = 0.8447265625\n",
      "Batch 422: loss = 0.4481865465641022, acc = 0.8427734375\n",
      "Batch 423: loss = 0.42932918667793274, acc = 0.8583984375\n",
      "Batch 424: loss = 0.4785420596599579, acc = 0.833984375\n",
      "Batch 425: loss = 0.4398627281188965, acc = 0.861328125\n",
      "Batch 426: loss = 0.4333350360393524, acc = 0.837890625\n",
      "Batch 427: loss = 0.43547672033309937, acc = 0.8505859375\n",
      "Batch 428: loss = 0.3628109097480774, acc = 0.8837890625\n",
      "Batch 429: loss = 0.4196935296058655, acc = 0.859375\n",
      "Batch 430: loss = 0.40541312098503113, acc = 0.865234375\n",
      "Batch 431: loss = 0.4279066026210785, acc = 0.84765625\n",
      "Batch 432: loss = 0.44652384519577026, acc = 0.8564453125\n",
      "Batch 433: loss = 0.34568995237350464, acc = 0.8837890625\n",
      "Batch 434: loss = 0.41805580258369446, acc = 0.857421875\n",
      "Batch 435: loss = 0.4666177034378052, acc = 0.83984375\n",
      "Batch 436: loss = 0.36710330843925476, acc = 0.8798828125\n",
      "Batch 437: loss = 0.43852007389068604, acc = 0.8466796875\n",
      "Batch 438: loss = 0.4533524215221405, acc = 0.84765625\n",
      "Batch 439: loss = 0.37356433272361755, acc = 0.869140625\n",
      "Batch 440: loss = 0.4312642812728882, acc = 0.857421875\n",
      "Batch 441: loss = 0.3931494653224945, acc = 0.8623046875\n",
      "\n",
      "Epoch 96/100\n",
      "Batch 1: loss = 0.5310953855514526, acc = 0.8291015625\n",
      "Batch 2: loss = 0.38901546597480774, acc = 0.8701171875\n",
      "Batch 3: loss = 0.4234757125377655, acc = 0.857421875\n",
      "Batch 4: loss = 0.45669910311698914, acc = 0.8349609375\n",
      "Batch 5: loss = 0.4478720426559448, acc = 0.853515625\n",
      "Batch 6: loss = 0.3601519465446472, acc = 0.8828125\n",
      "Batch 7: loss = 0.38555872440338135, acc = 0.861328125\n",
      "Batch 8: loss = 0.38835275173187256, acc = 0.8779296875\n",
      "Batch 9: loss = 0.3959132432937622, acc = 0.8603515625\n",
      "Batch 10: loss = 0.4666297435760498, acc = 0.849609375\n",
      "Batch 11: loss = 0.43563687801361084, acc = 0.841796875\n",
      "Batch 12: loss = 0.4443405866622925, acc = 0.84765625\n",
      "Batch 13: loss = 0.43613800406455994, acc = 0.84375\n",
      "Batch 14: loss = 0.40841907262802124, acc = 0.8759765625\n",
      "Batch 15: loss = 0.41262558102607727, acc = 0.8671875\n",
      "Batch 16: loss = 0.3965736925601959, acc = 0.8642578125\n",
      "Batch 17: loss = 0.32597672939300537, acc = 0.8798828125\n",
      "Batch 18: loss = 0.4652317762374878, acc = 0.8388671875\n",
      "Batch 19: loss = 0.40883636474609375, acc = 0.859375\n",
      "Batch 20: loss = 0.4647114872932434, acc = 0.857421875\n",
      "Batch 21: loss = 0.44765162467956543, acc = 0.853515625\n",
      "Batch 22: loss = 0.4397920072078705, acc = 0.853515625\n",
      "Batch 23: loss = 0.4090161621570587, acc = 0.8564453125\n",
      "Batch 24: loss = 0.3852441608905792, acc = 0.890625\n",
      "Batch 25: loss = 0.46922874450683594, acc = 0.8515625\n",
      "Batch 26: loss = 0.3899407386779785, acc = 0.8701171875\n",
      "Batch 27: loss = 0.4612286686897278, acc = 0.8515625\n",
      "Batch 28: loss = 0.4021768867969513, acc = 0.8544921875\n",
      "Batch 29: loss = 0.46351349353790283, acc = 0.84765625\n",
      "Batch 30: loss = 0.41719484329223633, acc = 0.8623046875\n",
      "Batch 31: loss = 0.3867344260215759, acc = 0.8701171875\n",
      "Batch 32: loss = 0.3963020443916321, acc = 0.8671875\n",
      "Batch 33: loss = 0.3571986258029938, acc = 0.888671875\n",
      "Batch 34: loss = 0.3374776244163513, acc = 0.8857421875\n",
      "Batch 35: loss = 0.3558099865913391, acc = 0.8857421875\n",
      "Batch 36: loss = 0.3961457908153534, acc = 0.869140625\n",
      "Batch 37: loss = 0.3942086100578308, acc = 0.8720703125\n",
      "Batch 38: loss = 0.3718510866165161, acc = 0.8798828125\n",
      "Batch 39: loss = 0.3329242467880249, acc = 0.8876953125\n",
      "Batch 40: loss = 0.37697842717170715, acc = 0.87109375\n",
      "Batch 41: loss = 0.33869457244873047, acc = 0.884765625\n",
      "Batch 42: loss = 0.43676137924194336, acc = 0.8466796875\n",
      "Batch 43: loss = 0.43402546644210815, acc = 0.8388671875\n",
      "Batch 44: loss = 0.4455956816673279, acc = 0.85546875\n",
      "Batch 45: loss = 0.3359019458293915, acc = 0.8828125\n",
      "Batch 46: loss = 0.42657148838043213, acc = 0.853515625\n",
      "Batch 47: loss = 0.4142819046974182, acc = 0.8603515625\n",
      "Batch 48: loss = 0.37286877632141113, acc = 0.8759765625\n",
      "Batch 49: loss = 0.4402133822441101, acc = 0.849609375\n",
      "Batch 50: loss = 0.4059648811817169, acc = 0.8671875\n",
      "Batch 51: loss = 0.46800175309181213, acc = 0.8369140625\n",
      "Batch 52: loss = 0.36442601680755615, acc = 0.869140625\n",
      "Batch 53: loss = 0.44375234842300415, acc = 0.853515625\n",
      "Batch 54: loss = 0.3896979093551636, acc = 0.86328125\n",
      "Batch 55: loss = 0.4410144090652466, acc = 0.8505859375\n",
      "Batch 56: loss = 0.40974071621894836, acc = 0.85546875\n",
      "Batch 57: loss = 0.41984936594963074, acc = 0.8564453125\n",
      "Batch 58: loss = 0.3813199996948242, acc = 0.859375\n",
      "Batch 59: loss = 0.4171063005924225, acc = 0.8662109375\n",
      "Batch 60: loss = 0.3953988254070282, acc = 0.8671875\n",
      "Batch 61: loss = 0.43682149052619934, acc = 0.8525390625\n",
      "Batch 62: loss = 0.41335776448249817, acc = 0.87109375\n",
      "Batch 63: loss = 0.4671599864959717, acc = 0.83203125\n",
      "Batch 64: loss = 0.39141011238098145, acc = 0.8779296875\n",
      "Batch 65: loss = 0.35023850202560425, acc = 0.8837890625\n",
      "Batch 66: loss = 0.38067251443862915, acc = 0.8720703125\n",
      "Batch 67: loss = 0.4040062725543976, acc = 0.8642578125\n",
      "Batch 68: loss = 0.4572632908821106, acc = 0.853515625\n",
      "Batch 69: loss = 0.3984198570251465, acc = 0.875\n",
      "Batch 70: loss = 0.43266648054122925, acc = 0.841796875\n",
      "Batch 71: loss = 0.43992459774017334, acc = 0.83203125\n",
      "Batch 72: loss = 0.4599974751472473, acc = 0.8515625\n",
      "Batch 73: loss = 0.42001935839653015, acc = 0.859375\n",
      "Batch 74: loss = 0.4522123336791992, acc = 0.849609375\n",
      "Batch 75: loss = 0.3620704710483551, acc = 0.876953125\n",
      "Batch 76: loss = 0.45962297916412354, acc = 0.84375\n",
      "Batch 77: loss = 0.47311246395111084, acc = 0.830078125\n",
      "Batch 78: loss = 0.4483013451099396, acc = 0.8447265625\n",
      "Batch 79: loss = 0.3927757143974304, acc = 0.857421875\n",
      "Batch 80: loss = 0.5001289248466492, acc = 0.8251953125\n",
      "Batch 81: loss = 0.38040637969970703, acc = 0.875\n",
      "Batch 82: loss = 0.4203062355518341, acc = 0.861328125\n",
      "Batch 83: loss = 0.42938053607940674, acc = 0.8525390625\n",
      "Batch 84: loss = 0.3817102015018463, acc = 0.8740234375\n",
      "Batch 85: loss = 0.4322223365306854, acc = 0.853515625\n",
      "Batch 86: loss = 0.42138057947158813, acc = 0.86328125\n",
      "Batch 87: loss = 0.37958937883377075, acc = 0.87890625\n",
      "Batch 88: loss = 0.39534735679626465, acc = 0.861328125\n",
      "Batch 89: loss = 0.47013479471206665, acc = 0.8349609375\n",
      "Batch 90: loss = 0.4385008215904236, acc = 0.8466796875\n",
      "Batch 91: loss = 0.3841988146305084, acc = 0.8681640625\n",
      "Batch 92: loss = 0.43286949396133423, acc = 0.84765625\n",
      "Batch 93: loss = 0.4871739447116852, acc = 0.841796875\n",
      "Batch 94: loss = 0.5028836131095886, acc = 0.837890625\n",
      "Batch 95: loss = 0.3987619876861572, acc = 0.876953125\n",
      "Batch 96: loss = 0.4328775405883789, acc = 0.8583984375\n",
      "Batch 97: loss = 0.4563308358192444, acc = 0.8466796875\n",
      "Batch 98: loss = 0.46438220143318176, acc = 0.837890625\n",
      "Batch 99: loss = 0.41433870792388916, acc = 0.8623046875\n",
      "Batch 100: loss = 0.45814377069473267, acc = 0.8486328125\n",
      "Batch 101: loss = 0.39558351039886475, acc = 0.880859375\n",
      "Batch 102: loss = 0.34587061405181885, acc = 0.8828125\n",
      "Batch 103: loss = 0.36906078457832336, acc = 0.873046875\n",
      "Batch 104: loss = 0.3836991786956787, acc = 0.869140625\n",
      "Batch 105: loss = 0.4442506432533264, acc = 0.8388671875\n",
      "Batch 106: loss = 0.4468156099319458, acc = 0.8623046875\n",
      "Batch 107: loss = 0.37546586990356445, acc = 0.875\n",
      "Batch 108: loss = 0.4382827579975128, acc = 0.8544921875\n",
      "Batch 109: loss = 0.3756026327610016, acc = 0.8798828125\n",
      "Batch 110: loss = 0.44050273299217224, acc = 0.8427734375\n",
      "Batch 111: loss = 0.45909327268600464, acc = 0.84375\n",
      "Batch 112: loss = 0.46551841497421265, acc = 0.84375\n",
      "Batch 113: loss = 0.39198926091194153, acc = 0.8662109375\n",
      "Batch 114: loss = 0.32011061906814575, acc = 0.890625\n",
      "Batch 115: loss = 0.45162028074264526, acc = 0.845703125\n",
      "Batch 116: loss = 0.40012460947036743, acc = 0.85546875\n",
      "Batch 117: loss = 0.3845318555831909, acc = 0.8671875\n",
      "Batch 118: loss = 0.44100096821784973, acc = 0.8564453125\n",
      "Batch 119: loss = 0.44053465127944946, acc = 0.8427734375\n",
      "Batch 120: loss = 0.41930171847343445, acc = 0.861328125\n",
      "Batch 121: loss = 0.4132509231567383, acc = 0.8544921875\n",
      "Batch 122: loss = 0.34162670373916626, acc = 0.8818359375\n",
      "Batch 123: loss = 0.3984246850013733, acc = 0.8642578125\n",
      "Batch 124: loss = 0.4054551124572754, acc = 0.8603515625\n",
      "Batch 125: loss = 0.3943788409233093, acc = 0.869140625\n",
      "Batch 126: loss = 0.35074058175086975, acc = 0.876953125\n",
      "Batch 127: loss = 0.45308858156204224, acc = 0.8486328125\n",
      "Batch 128: loss = 0.366099089384079, acc = 0.875\n",
      "Batch 129: loss = 0.3918597102165222, acc = 0.87109375\n",
      "Batch 130: loss = 0.39575594663619995, acc = 0.8701171875\n",
      "Batch 131: loss = 0.34709614515304565, acc = 0.890625\n",
      "Batch 132: loss = 0.3119138479232788, acc = 0.892578125\n",
      "Batch 133: loss = 0.32766714692115784, acc = 0.8779296875\n",
      "Batch 134: loss = 0.38753220438957214, acc = 0.86328125\n",
      "Batch 135: loss = 0.4238118827342987, acc = 0.85546875\n",
      "Batch 136: loss = 0.38718849420547485, acc = 0.8720703125\n",
      "Batch 137: loss = 0.32414156198501587, acc = 0.888671875\n",
      "Batch 138: loss = 0.3896971642971039, acc = 0.8759765625\n",
      "Batch 139: loss = 0.3566216826438904, acc = 0.8701171875\n",
      "Batch 140: loss = 0.3580460548400879, acc = 0.884765625\n",
      "Batch 141: loss = 0.38845646381378174, acc = 0.8671875\n",
      "Batch 142: loss = 0.3893064558506012, acc = 0.859375\n",
      "Batch 143: loss = 0.45074543356895447, acc = 0.8447265625\n",
      "Batch 144: loss = 0.4279678761959076, acc = 0.853515625\n",
      "Batch 145: loss = 0.37816178798675537, acc = 0.8779296875\n",
      "Batch 146: loss = 0.4239800274372101, acc = 0.8505859375\n",
      "Batch 147: loss = 0.45883145928382874, acc = 0.853515625\n",
      "Batch 148: loss = 0.3440082371234894, acc = 0.890625\n",
      "Batch 149: loss = 0.39588409662246704, acc = 0.859375\n",
      "Batch 150: loss = 0.440191388130188, acc = 0.8515625\n",
      "Batch 151: loss = 0.4206051528453827, acc = 0.8603515625\n",
      "Batch 152: loss = 0.3758670389652252, acc = 0.8720703125\n",
      "Batch 153: loss = 0.39681345224380493, acc = 0.8720703125\n",
      "Batch 154: loss = 0.3987777829170227, acc = 0.8642578125\n",
      "Batch 155: loss = 0.3877445459365845, acc = 0.8642578125\n",
      "Batch 156: loss = 0.44119542837142944, acc = 0.8486328125\n",
      "Batch 157: loss = 0.4252273440361023, acc = 0.8544921875\n",
      "Batch 158: loss = 0.3882858455181122, acc = 0.859375\n",
      "Batch 159: loss = 0.43423712253570557, acc = 0.8525390625\n",
      "Batch 160: loss = 0.4215429425239563, acc = 0.8564453125\n",
      "Batch 161: loss = 0.49915802478790283, acc = 0.83984375\n",
      "Batch 162: loss = 0.42225292325019836, acc = 0.8564453125\n",
      "Batch 163: loss = 0.4507887363433838, acc = 0.8583984375\n",
      "Batch 164: loss = 0.4173778295516968, acc = 0.85546875\n",
      "Batch 165: loss = 0.45807719230651855, acc = 0.8349609375\n",
      "Batch 166: loss = 0.3407723605632782, acc = 0.8798828125\n",
      "Batch 167: loss = 0.40372785925865173, acc = 0.861328125\n",
      "Batch 168: loss = 0.39590024948120117, acc = 0.8642578125\n",
      "Batch 169: loss = 0.3719027638435364, acc = 0.857421875\n",
      "Batch 170: loss = 0.3359023332595825, acc = 0.900390625\n",
      "Batch 171: loss = 0.4299113154411316, acc = 0.8671875\n",
      "Batch 172: loss = 0.3790760040283203, acc = 0.869140625\n",
      "Batch 173: loss = 0.3830585181713104, acc = 0.880859375\n",
      "Batch 174: loss = 0.41596490144729614, acc = 0.8671875\n",
      "Batch 175: loss = 0.4288417398929596, acc = 0.849609375\n",
      "Batch 176: loss = 0.40793657302856445, acc = 0.8681640625\n",
      "Batch 177: loss = 0.3375440239906311, acc = 0.892578125\n",
      "Batch 178: loss = 0.35168102383613586, acc = 0.8828125\n",
      "Batch 179: loss = 0.4531702399253845, acc = 0.84375\n",
      "Batch 180: loss = 0.3829277455806732, acc = 0.86328125\n",
      "Batch 181: loss = 0.4103091359138489, acc = 0.859375\n",
      "Batch 182: loss = 0.423489511013031, acc = 0.85546875\n",
      "Batch 183: loss = 0.37024277448654175, acc = 0.873046875\n",
      "Batch 184: loss = 0.45857515931129456, acc = 0.8564453125\n",
      "Batch 185: loss = 0.4167238175868988, acc = 0.8623046875\n",
      "Batch 186: loss = 0.38120871782302856, acc = 0.873046875\n",
      "Batch 187: loss = 0.39189010858535767, acc = 0.849609375\n",
      "Batch 188: loss = 0.4302700161933899, acc = 0.86328125\n",
      "Batch 189: loss = 0.3592096269130707, acc = 0.880859375\n",
      "Batch 190: loss = 0.408716082572937, acc = 0.853515625\n",
      "Batch 191: loss = 0.37394875288009644, acc = 0.875\n",
      "Batch 192: loss = 0.4063137173652649, acc = 0.8623046875\n",
      "Batch 193: loss = 0.44103091955184937, acc = 0.8583984375\n",
      "Batch 194: loss = 0.3965419828891754, acc = 0.8759765625\n",
      "Batch 195: loss = 0.4656549096107483, acc = 0.841796875\n",
      "Batch 196: loss = 0.45179980993270874, acc = 0.8447265625\n",
      "Batch 197: loss = 0.48017939925193787, acc = 0.828125\n",
      "Batch 198: loss = 0.4317827820777893, acc = 0.8642578125\n",
      "Batch 199: loss = 0.41177985072135925, acc = 0.85546875\n",
      "Batch 200: loss = 0.47441744804382324, acc = 0.84765625\n",
      "Batch 201: loss = 0.43021681904792786, acc = 0.8505859375\n",
      "Batch 202: loss = 0.48752421140670776, acc = 0.8447265625\n",
      "Batch 203: loss = 0.4048224687576294, acc = 0.8681640625\n",
      "Batch 204: loss = 0.4169064164161682, acc = 0.8583984375\n",
      "Batch 205: loss = 0.4363275170326233, acc = 0.85546875\n",
      "Batch 206: loss = 0.4287415146827698, acc = 0.8603515625\n",
      "Batch 207: loss = 0.49801579117774963, acc = 0.8349609375\n",
      "Batch 208: loss = 0.42058539390563965, acc = 0.8681640625\n",
      "Batch 209: loss = 0.40139108896255493, acc = 0.8583984375\n",
      "Batch 210: loss = 0.3954586982727051, acc = 0.8623046875\n",
      "Batch 211: loss = 0.37187811732292175, acc = 0.8671875\n",
      "Batch 212: loss = 0.42047274112701416, acc = 0.8642578125\n",
      "Batch 213: loss = 0.43481504917144775, acc = 0.8544921875\n",
      "Batch 214: loss = 0.41853439807891846, acc = 0.8603515625\n",
      "Batch 215: loss = 0.4028087258338928, acc = 0.8720703125\n",
      "Batch 216: loss = 0.39085814356803894, acc = 0.85546875\n",
      "Batch 217: loss = 0.34573328495025635, acc = 0.8857421875\n",
      "Batch 218: loss = 0.40769529342651367, acc = 0.8642578125\n",
      "Batch 219: loss = 0.4004005193710327, acc = 0.8623046875\n",
      "Batch 220: loss = 0.38540416955947876, acc = 0.8701171875\n",
      "Batch 221: loss = 0.4605844020843506, acc = 0.849609375\n",
      "Batch 222: loss = 0.4039822816848755, acc = 0.875\n",
      "Batch 223: loss = 0.3579370677471161, acc = 0.876953125\n",
      "Batch 224: loss = 0.3402780294418335, acc = 0.8818359375\n",
      "Batch 225: loss = 0.3779040277004242, acc = 0.859375\n",
      "Batch 226: loss = 0.44082146883010864, acc = 0.845703125\n",
      "Batch 227: loss = 0.4277881979942322, acc = 0.859375\n",
      "Batch 228: loss = 0.36234357953071594, acc = 0.875\n",
      "Batch 229: loss = 0.3661096692085266, acc = 0.8779296875\n",
      "Batch 230: loss = 0.3471411466598511, acc = 0.876953125\n",
      "Batch 231: loss = 0.47164782881736755, acc = 0.8466796875\n",
      "Batch 232: loss = 0.3660487234592438, acc = 0.8623046875\n",
      "Batch 233: loss = 0.4520016312599182, acc = 0.8466796875\n",
      "Batch 234: loss = 0.38498857617378235, acc = 0.857421875\n",
      "Batch 235: loss = 0.39720556139945984, acc = 0.86328125\n",
      "Batch 236: loss = 0.44935595989227295, acc = 0.8544921875\n",
      "Batch 237: loss = 0.3780532479286194, acc = 0.8662109375\n",
      "Batch 238: loss = 0.42804402112960815, acc = 0.8505859375\n",
      "Batch 239: loss = 0.3543410897254944, acc = 0.8720703125\n",
      "Batch 240: loss = 0.4522184729576111, acc = 0.85546875\n",
      "Batch 241: loss = 0.4051586389541626, acc = 0.8759765625\n",
      "Batch 242: loss = 0.4323953688144684, acc = 0.8623046875\n",
      "Batch 243: loss = 0.4285067319869995, acc = 0.8603515625\n",
      "Batch 244: loss = 0.46445924043655396, acc = 0.845703125\n",
      "Batch 245: loss = 0.43943631649017334, acc = 0.8486328125\n",
      "Batch 246: loss = 0.4109739363193512, acc = 0.861328125\n",
      "Batch 247: loss = 0.4341757595539093, acc = 0.8505859375\n",
      "Batch 248: loss = 0.42281413078308105, acc = 0.8447265625\n",
      "Batch 249: loss = 0.34592145681381226, acc = 0.88671875\n",
      "Batch 250: loss = 0.467571496963501, acc = 0.83984375\n",
      "Batch 251: loss = 0.33557888865470886, acc = 0.8818359375\n",
      "Batch 252: loss = 0.39263904094696045, acc = 0.8720703125\n",
      "Batch 253: loss = 0.4165025055408478, acc = 0.859375\n",
      "Batch 254: loss = 0.4672127962112427, acc = 0.8369140625\n",
      "Batch 255: loss = 0.49186569452285767, acc = 0.8369140625\n",
      "Batch 256: loss = 0.4700772166252136, acc = 0.833984375\n",
      "Batch 257: loss = 0.4891184866428375, acc = 0.830078125\n",
      "Batch 258: loss = 0.41750600934028625, acc = 0.8623046875\n",
      "Batch 259: loss = 0.5037910342216492, acc = 0.8310546875\n",
      "Batch 260: loss = 0.5018450021743774, acc = 0.822265625\n",
      "Batch 261: loss = 0.4732882082462311, acc = 0.8369140625\n",
      "Batch 262: loss = 0.433474600315094, acc = 0.841796875\n",
      "Batch 263: loss = 0.41948363184928894, acc = 0.8564453125\n",
      "Batch 264: loss = 0.40451309084892273, acc = 0.8662109375\n",
      "Batch 265: loss = 0.4221189618110657, acc = 0.8671875\n",
      "Batch 266: loss = 0.40568724274635315, acc = 0.85546875\n",
      "Batch 267: loss = 0.34252989292144775, acc = 0.88671875\n",
      "Batch 268: loss = 0.418487012386322, acc = 0.857421875\n",
      "Batch 269: loss = 0.4773619472980499, acc = 0.83984375\n",
      "Batch 270: loss = 0.4073356091976166, acc = 0.865234375\n",
      "Batch 271: loss = 0.36995771527290344, acc = 0.8779296875\n",
      "Batch 272: loss = 0.41046473383903503, acc = 0.869140625\n",
      "Batch 273: loss = 0.3971695303916931, acc = 0.859375\n",
      "Batch 274: loss = 0.4152078628540039, acc = 0.859375\n",
      "Batch 275: loss = 0.37666141986846924, acc = 0.8701171875\n",
      "Batch 276: loss = 0.43443337082862854, acc = 0.857421875\n",
      "Batch 277: loss = 0.4409259259700775, acc = 0.84375\n",
      "Batch 278: loss = 0.3890566825866699, acc = 0.869140625\n",
      "Batch 279: loss = 0.45731592178344727, acc = 0.8359375\n",
      "Batch 280: loss = 0.45229631662368774, acc = 0.849609375\n",
      "Batch 281: loss = 0.42624780535697937, acc = 0.8583984375\n",
      "Batch 282: loss = 0.4139898717403412, acc = 0.8662109375\n",
      "Batch 283: loss = 0.5007402300834656, acc = 0.8271484375\n",
      "Batch 284: loss = 0.4143158197402954, acc = 0.8740234375\n",
      "Batch 285: loss = 0.4304332733154297, acc = 0.853515625\n",
      "Batch 286: loss = 0.48133373260498047, acc = 0.83203125\n",
      "Batch 287: loss = 0.4628519117832184, acc = 0.849609375\n",
      "Batch 288: loss = 0.4127359986305237, acc = 0.8662109375\n",
      "Batch 289: loss = 0.41258394718170166, acc = 0.861328125\n",
      "Batch 290: loss = 0.4290715754032135, acc = 0.859375\n",
      "Batch 291: loss = 0.45028814673423767, acc = 0.8525390625\n",
      "Batch 292: loss = 0.4047456681728363, acc = 0.865234375\n",
      "Batch 293: loss = 0.36744633316993713, acc = 0.8740234375\n",
      "Batch 294: loss = 0.4365566670894623, acc = 0.8525390625\n",
      "Batch 295: loss = 0.4147319793701172, acc = 0.86328125\n",
      "Batch 296: loss = 0.4057161509990692, acc = 0.859375\n",
      "Batch 297: loss = 0.37464413046836853, acc = 0.8681640625\n",
      "Batch 298: loss = 0.3945085108280182, acc = 0.8798828125\n",
      "Batch 299: loss = 0.3566904366016388, acc = 0.87109375\n",
      "Batch 300: loss = 0.4008442759513855, acc = 0.8662109375\n",
      "Batch 301: loss = 0.3942028284072876, acc = 0.86328125\n",
      "Batch 302: loss = 0.4491831362247467, acc = 0.8544921875\n",
      "Batch 303: loss = 0.45293721556663513, acc = 0.853515625\n",
      "Batch 304: loss = 0.3669024109840393, acc = 0.8798828125\n",
      "Batch 305: loss = 0.4002308249473572, acc = 0.8623046875\n",
      "Batch 306: loss = 0.4064711630344391, acc = 0.86328125\n",
      "Batch 307: loss = 0.3622756600379944, acc = 0.875\n",
      "Batch 308: loss = 0.40194883942604065, acc = 0.8623046875\n",
      "Batch 309: loss = 0.4296919107437134, acc = 0.8564453125\n",
      "Batch 310: loss = 0.407991886138916, acc = 0.861328125\n",
      "Batch 311: loss = 0.4276169538497925, acc = 0.859375\n",
      "Batch 312: loss = 0.3760261833667755, acc = 0.8740234375\n",
      "Batch 313: loss = 0.462069034576416, acc = 0.8427734375\n",
      "Batch 314: loss = 0.4567157030105591, acc = 0.8447265625\n",
      "Batch 315: loss = 0.4526902437210083, acc = 0.8466796875\n",
      "Batch 316: loss = 0.3667864203453064, acc = 0.876953125\n",
      "Batch 317: loss = 0.4615851640701294, acc = 0.837890625\n",
      "Batch 318: loss = 0.41151162981987, acc = 0.86328125\n",
      "Batch 319: loss = 0.4160608649253845, acc = 0.86328125\n",
      "Batch 320: loss = 0.46059077978134155, acc = 0.84375\n",
      "Batch 321: loss = 0.5003822445869446, acc = 0.8388671875\n",
      "Batch 322: loss = 0.36976760625839233, acc = 0.87109375\n",
      "Batch 323: loss = 0.4719529449939728, acc = 0.8408203125\n",
      "Batch 324: loss = 0.41677355766296387, acc = 0.859375\n",
      "Batch 325: loss = 0.4474778175354004, acc = 0.845703125\n",
      "Batch 326: loss = 0.38914984464645386, acc = 0.87109375\n",
      "Batch 327: loss = 0.4155346751213074, acc = 0.8525390625\n",
      "Batch 328: loss = 0.44061940908432007, acc = 0.8564453125\n",
      "Batch 329: loss = 0.4892791509628296, acc = 0.8330078125\n",
      "Batch 330: loss = 0.3872416913509369, acc = 0.873046875\n",
      "Batch 331: loss = 0.4172847270965576, acc = 0.8642578125\n",
      "Batch 332: loss = 0.4209003448486328, acc = 0.85546875\n",
      "Batch 333: loss = 0.37890151143074036, acc = 0.86328125\n",
      "Batch 334: loss = 0.3543054461479187, acc = 0.8828125\n",
      "Batch 335: loss = 0.436598539352417, acc = 0.8466796875\n",
      "Batch 336: loss = 0.4312520921230316, acc = 0.8466796875\n",
      "Batch 337: loss = 0.5029038190841675, acc = 0.8291015625\n",
      "Batch 338: loss = 0.3408365249633789, acc = 0.884765625\n",
      "Batch 339: loss = 0.47294971346855164, acc = 0.845703125\n",
      "Batch 340: loss = 0.3809919059276581, acc = 0.87109375\n",
      "Batch 341: loss = 0.4310666620731354, acc = 0.85546875\n",
      "Batch 342: loss = 0.4007346034049988, acc = 0.8662109375\n",
      "Batch 343: loss = 0.36020225286483765, acc = 0.8828125\n",
      "Batch 344: loss = 0.3280871510505676, acc = 0.892578125\n",
      "Batch 345: loss = 0.36648663878440857, acc = 0.87109375\n",
      "Batch 346: loss = 0.3765857219696045, acc = 0.8720703125\n",
      "Batch 347: loss = 0.39508265256881714, acc = 0.87109375\n",
      "Batch 348: loss = 0.37104594707489014, acc = 0.87109375\n",
      "Batch 349: loss = 0.33532270789146423, acc = 0.8916015625\n",
      "Batch 350: loss = 0.3437144160270691, acc = 0.8916015625\n",
      "Batch 351: loss = 0.3429498076438904, acc = 0.8828125\n",
      "Batch 352: loss = 0.42315277457237244, acc = 0.8486328125\n",
      "Batch 353: loss = 0.37994620203971863, acc = 0.869140625\n",
      "Batch 354: loss = 0.3346845507621765, acc = 0.880859375\n",
      "Batch 355: loss = 0.28672415018081665, acc = 0.90625\n",
      "Batch 356: loss = 0.3637617230415344, acc = 0.87890625\n",
      "Batch 357: loss = 0.3933532238006592, acc = 0.869140625\n",
      "Batch 358: loss = 0.39843541383743286, acc = 0.8662109375\n",
      "Batch 359: loss = 0.39104652404785156, acc = 0.8681640625\n",
      "Batch 360: loss = 0.3753829896450043, acc = 0.880859375\n",
      "Batch 361: loss = 0.3888384699821472, acc = 0.8740234375\n",
      "Batch 362: loss = 0.3558618724346161, acc = 0.8828125\n",
      "Batch 363: loss = 0.41047075390815735, acc = 0.86328125\n",
      "Batch 364: loss = 0.4099404215812683, acc = 0.859375\n",
      "Batch 365: loss = 0.3831714391708374, acc = 0.869140625\n",
      "Batch 366: loss = 0.38939058780670166, acc = 0.8603515625\n",
      "Batch 367: loss = 0.39724209904670715, acc = 0.8564453125\n",
      "Batch 368: loss = 0.45334064960479736, acc = 0.8525390625\n",
      "Batch 369: loss = 0.4702449440956116, acc = 0.837890625\n",
      "Batch 370: loss = 0.3795596659183502, acc = 0.8759765625\n",
      "Batch 371: loss = 0.4647682309150696, acc = 0.8515625\n",
      "Batch 372: loss = 0.39529216289520264, acc = 0.853515625\n",
      "Batch 373: loss = 0.4522286653518677, acc = 0.84765625\n",
      "Batch 374: loss = 0.41579076647758484, acc = 0.86328125\n",
      "Batch 375: loss = 0.4418013095855713, acc = 0.8564453125\n",
      "Batch 376: loss = 0.4274764060974121, acc = 0.85546875\n",
      "Batch 377: loss = 0.4586947560310364, acc = 0.83984375\n",
      "Batch 378: loss = 0.39858144521713257, acc = 0.869140625\n",
      "Batch 379: loss = 0.4852184057235718, acc = 0.84765625\n",
      "Batch 380: loss = 0.3625737726688385, acc = 0.876953125\n",
      "Batch 381: loss = 0.3399590849876404, acc = 0.8916015625\n",
      "Batch 382: loss = 0.39434921741485596, acc = 0.869140625\n",
      "Batch 383: loss = 0.3594653308391571, acc = 0.8837890625\n",
      "Batch 384: loss = 0.45080283284187317, acc = 0.8447265625\n",
      "Batch 385: loss = 0.40179771184921265, acc = 0.8466796875\n",
      "Batch 386: loss = 0.3728412687778473, acc = 0.873046875\n",
      "Batch 387: loss = 0.3620610535144806, acc = 0.8681640625\n",
      "Batch 388: loss = 0.43558210134506226, acc = 0.85546875\n",
      "Batch 389: loss = 0.4206152558326721, acc = 0.861328125\n",
      "Batch 390: loss = 0.5030072927474976, acc = 0.8193359375\n",
      "Batch 391: loss = 0.4238693118095398, acc = 0.8603515625\n",
      "Batch 392: loss = 0.4308801293373108, acc = 0.84765625\n",
      "Batch 393: loss = 0.47108614444732666, acc = 0.8466796875\n",
      "Batch 394: loss = 0.3692355155944824, acc = 0.8701171875\n",
      "Batch 395: loss = 0.40076744556427, acc = 0.84765625\n",
      "Batch 396: loss = 0.4274481236934662, acc = 0.8515625\n",
      "Batch 397: loss = 0.35869795083999634, acc = 0.8720703125\n",
      "Batch 398: loss = 0.3830935060977936, acc = 0.8681640625\n",
      "Batch 399: loss = 0.41375109553337097, acc = 0.859375\n",
      "Batch 400: loss = 0.4080384075641632, acc = 0.861328125\n",
      "Batch 401: loss = 0.46128377318382263, acc = 0.8408203125\n",
      "Batch 402: loss = 0.4530303478240967, acc = 0.849609375\n",
      "Batch 403: loss = 0.35015806555747986, acc = 0.892578125\n",
      "Batch 404: loss = 0.42594677209854126, acc = 0.8623046875\n",
      "Batch 405: loss = 0.43854400515556335, acc = 0.8505859375\n",
      "Batch 406: loss = 0.516311526298523, acc = 0.837890625\n",
      "Batch 407: loss = 0.41121283173561096, acc = 0.869140625\n",
      "Batch 408: loss = 0.5004613399505615, acc = 0.8330078125\n",
      "Batch 409: loss = 0.4235648512840271, acc = 0.8583984375\n",
      "Batch 410: loss = 0.4171178340911865, acc = 0.8681640625\n",
      "Batch 411: loss = 0.39221689105033875, acc = 0.87109375\n",
      "Batch 412: loss = 0.42228588461875916, acc = 0.8603515625\n",
      "Batch 413: loss = 0.36636364459991455, acc = 0.8740234375\n",
      "Batch 414: loss = 0.37036699056625366, acc = 0.873046875\n",
      "Batch 415: loss = 0.4646691381931305, acc = 0.8388671875\n",
      "Batch 416: loss = 0.41965168714523315, acc = 0.8671875\n",
      "Batch 417: loss = 0.4108487069606781, acc = 0.8662109375\n",
      "Batch 418: loss = 0.4960651993751526, acc = 0.830078125\n",
      "Batch 419: loss = 0.5277131199836731, acc = 0.818359375\n",
      "Batch 420: loss = 0.46396011114120483, acc = 0.84375\n",
      "Batch 421: loss = 0.4542045593261719, acc = 0.849609375\n",
      "Batch 422: loss = 0.4792262613773346, acc = 0.84765625\n",
      "Batch 423: loss = 0.4539059102535248, acc = 0.8466796875\n",
      "Batch 424: loss = 0.4465884864330292, acc = 0.8388671875\n",
      "Batch 425: loss = 0.4267394542694092, acc = 0.865234375\n",
      "Batch 426: loss = 0.40371090173721313, acc = 0.8564453125\n",
      "Batch 427: loss = 0.4531722366809845, acc = 0.853515625\n",
      "Batch 428: loss = 0.41645756363868713, acc = 0.861328125\n",
      "Batch 429: loss = 0.40732452273368835, acc = 0.859375\n",
      "Batch 430: loss = 0.4177423417568207, acc = 0.8544921875\n",
      "Batch 431: loss = 0.4177507162094116, acc = 0.85546875\n",
      "Batch 432: loss = 0.397480845451355, acc = 0.8642578125\n",
      "Batch 433: loss = 0.3603082299232483, acc = 0.87890625\n",
      "Batch 434: loss = 0.3993871808052063, acc = 0.8623046875\n",
      "Batch 435: loss = 0.4525204300880432, acc = 0.84375\n",
      "Batch 436: loss = 0.35219553112983704, acc = 0.875\n",
      "Batch 437: loss = 0.4265996813774109, acc = 0.861328125\n",
      "Batch 438: loss = 0.41654959321022034, acc = 0.8515625\n",
      "Batch 439: loss = 0.3840188980102539, acc = 0.8759765625\n",
      "Batch 440: loss = 0.40268850326538086, acc = 0.859375\n",
      "Batch 441: loss = 0.36675071716308594, acc = 0.876953125\n",
      "\n",
      "Epoch 97/100\n",
      "Batch 1: loss = 0.48837214708328247, acc = 0.8505859375\n",
      "Batch 2: loss = 0.3891681134700775, acc = 0.8603515625\n",
      "Batch 3: loss = 0.42620348930358887, acc = 0.8486328125\n",
      "Batch 4: loss = 0.43815353512763977, acc = 0.8525390625\n",
      "Batch 5: loss = 0.4723765254020691, acc = 0.8349609375\n",
      "Batch 6: loss = 0.35371533036231995, acc = 0.8828125\n",
      "Batch 7: loss = 0.39016667008399963, acc = 0.86328125\n",
      "Batch 8: loss = 0.4007195234298706, acc = 0.8564453125\n",
      "Batch 9: loss = 0.39272406697273254, acc = 0.857421875\n",
      "Batch 10: loss = 0.4248802065849304, acc = 0.857421875\n",
      "Batch 11: loss = 0.41945838928222656, acc = 0.8681640625\n",
      "Batch 12: loss = 0.41578957438468933, acc = 0.845703125\n",
      "Batch 13: loss = 0.44662219285964966, acc = 0.8447265625\n",
      "Batch 14: loss = 0.37003231048583984, acc = 0.8779296875\n",
      "Batch 15: loss = 0.361427903175354, acc = 0.87109375\n",
      "Batch 16: loss = 0.41997599601745605, acc = 0.8642578125\n",
      "Batch 17: loss = 0.35375523567199707, acc = 0.8818359375\n",
      "Batch 18: loss = 0.4494335949420929, acc = 0.8388671875\n",
      "Batch 19: loss = 0.41449734568595886, acc = 0.861328125\n",
      "Batch 20: loss = 0.44838201999664307, acc = 0.8447265625\n",
      "Batch 21: loss = 0.4598580002784729, acc = 0.8505859375\n",
      "Batch 22: loss = 0.4263870120048523, acc = 0.8642578125\n",
      "Batch 23: loss = 0.44890594482421875, acc = 0.849609375\n",
      "Batch 24: loss = 0.430270254611969, acc = 0.8603515625\n",
      "Batch 25: loss = 0.47567927837371826, acc = 0.8544921875\n",
      "Batch 26: loss = 0.3724500238895416, acc = 0.876953125\n",
      "Batch 27: loss = 0.4905116856098175, acc = 0.82421875\n",
      "Batch 28: loss = 0.443749338388443, acc = 0.8603515625\n",
      "Batch 29: loss = 0.4585535228252411, acc = 0.8515625\n",
      "Batch 30: loss = 0.42141497135162354, acc = 0.859375\n",
      "Batch 31: loss = 0.4211505055427551, acc = 0.845703125\n",
      "Batch 32: loss = 0.36980050802230835, acc = 0.8740234375\n",
      "Batch 33: loss = 0.33480745553970337, acc = 0.90234375\n",
      "Batch 34: loss = 0.34691235423088074, acc = 0.8818359375\n",
      "Batch 35: loss = 0.3653036057949066, acc = 0.8798828125\n",
      "Batch 36: loss = 0.41191229224205017, acc = 0.8623046875\n",
      "Batch 37: loss = 0.40722334384918213, acc = 0.8564453125\n",
      "Batch 38: loss = 0.40986061096191406, acc = 0.857421875\n",
      "Batch 39: loss = 0.3316342830657959, acc = 0.8916015625\n",
      "Batch 40: loss = 0.3611013889312744, acc = 0.8798828125\n",
      "Batch 41: loss = 0.3420729637145996, acc = 0.8828125\n",
      "Batch 42: loss = 0.4621031880378723, acc = 0.82421875\n",
      "Batch 43: loss = 0.4380745589733124, acc = 0.84765625\n",
      "Batch 44: loss = 0.43320709466934204, acc = 0.857421875\n",
      "Batch 45: loss = 0.3928025960922241, acc = 0.869140625\n",
      "Batch 46: loss = 0.3787227272987366, acc = 0.86328125\n",
      "Batch 47: loss = 0.4192875921726227, acc = 0.853515625\n",
      "Batch 48: loss = 0.37406325340270996, acc = 0.8779296875\n",
      "Batch 49: loss = 0.41914039850234985, acc = 0.859375\n",
      "Batch 50: loss = 0.44044923782348633, acc = 0.849609375\n",
      "Batch 51: loss = 0.4699223041534424, acc = 0.8466796875\n",
      "Batch 52: loss = 0.3548651933670044, acc = 0.880859375\n",
      "Batch 53: loss = 0.44431260228157043, acc = 0.8515625\n",
      "Batch 54: loss = 0.38527387380599976, acc = 0.87109375\n",
      "Batch 55: loss = 0.46380606293678284, acc = 0.84375\n",
      "Batch 56: loss = 0.39184948801994324, acc = 0.861328125\n",
      "Batch 57: loss = 0.3910093605518341, acc = 0.8642578125\n",
      "Batch 58: loss = 0.3637266457080841, acc = 0.8740234375\n",
      "Batch 59: loss = 0.38854560256004333, acc = 0.873046875\n",
      "Batch 60: loss = 0.37032899260520935, acc = 0.8603515625\n",
      "Batch 61: loss = 0.43028610944747925, acc = 0.8525390625\n",
      "Batch 62: loss = 0.3933769762516022, acc = 0.8544921875\n",
      "Batch 63: loss = 0.4432150721549988, acc = 0.845703125\n",
      "Batch 64: loss = 0.4001844823360443, acc = 0.8701171875\n",
      "Batch 65: loss = 0.3723221719264984, acc = 0.87890625\n",
      "Batch 66: loss = 0.36550000309944153, acc = 0.8837890625\n",
      "Batch 67: loss = 0.41118210554122925, acc = 0.859375\n",
      "Batch 68: loss = 0.4682270586490631, acc = 0.8388671875\n",
      "Batch 69: loss = 0.3949992060661316, acc = 0.8671875\n",
      "Batch 70: loss = 0.4366537928581238, acc = 0.837890625\n",
      "Batch 71: loss = 0.4316246211528778, acc = 0.845703125\n",
      "Batch 72: loss = 0.3994249701499939, acc = 0.8798828125\n",
      "Batch 73: loss = 0.4326513409614563, acc = 0.849609375\n",
      "Batch 74: loss = 0.4087241590023041, acc = 0.8681640625\n",
      "Batch 75: loss = 0.3538888692855835, acc = 0.87890625\n",
      "Batch 76: loss = 0.46181657910346985, acc = 0.8515625\n",
      "Batch 77: loss = 0.477596640586853, acc = 0.841796875\n",
      "Batch 78: loss = 0.44973382353782654, acc = 0.845703125\n",
      "Batch 79: loss = 0.3824250102043152, acc = 0.8720703125\n",
      "Batch 80: loss = 0.4877837896347046, acc = 0.8505859375\n",
      "Batch 81: loss = 0.33964040875434875, acc = 0.8837890625\n",
      "Batch 82: loss = 0.3853948712348938, acc = 0.8798828125\n",
      "Batch 83: loss = 0.4479265511035919, acc = 0.8515625\n",
      "Batch 84: loss = 0.3675702214241028, acc = 0.8837890625\n",
      "Batch 85: loss = 0.4252530336380005, acc = 0.8486328125\n",
      "Batch 86: loss = 0.43110209703445435, acc = 0.8701171875\n",
      "Batch 87: loss = 0.3807207942008972, acc = 0.8798828125\n",
      "Batch 88: loss = 0.4430919587612152, acc = 0.8486328125\n",
      "Batch 89: loss = 0.47628578543663025, acc = 0.84375\n",
      "Batch 90: loss = 0.4351317286491394, acc = 0.8486328125\n",
      "Batch 91: loss = 0.4032597243785858, acc = 0.859375\n",
      "Batch 92: loss = 0.42114558815956116, acc = 0.8564453125\n",
      "Batch 93: loss = 0.42810842394828796, acc = 0.849609375\n",
      "Batch 94: loss = 0.4216545820236206, acc = 0.8486328125\n",
      "Batch 95: loss = 0.40837231278419495, acc = 0.8662109375\n",
      "Batch 96: loss = 0.36956652998924255, acc = 0.8662109375\n",
      "Batch 97: loss = 0.42216750979423523, acc = 0.8603515625\n",
      "Batch 98: loss = 0.4499461054801941, acc = 0.84375\n",
      "Batch 99: loss = 0.4254845678806305, acc = 0.86328125\n",
      "Batch 100: loss = 0.4546184539794922, acc = 0.8466796875\n",
      "Batch 101: loss = 0.3769148588180542, acc = 0.880859375\n",
      "Batch 102: loss = 0.38481655716896057, acc = 0.87109375\n",
      "Batch 103: loss = 0.3748895525932312, acc = 0.873046875\n",
      "Batch 104: loss = 0.3927136957645416, acc = 0.8681640625\n",
      "Batch 105: loss = 0.4164218306541443, acc = 0.8486328125\n",
      "Batch 106: loss = 0.4424075186252594, acc = 0.8603515625\n",
      "Batch 107: loss = 0.4137546420097351, acc = 0.8671875\n",
      "Batch 108: loss = 0.454582154750824, acc = 0.8486328125\n",
      "Batch 109: loss = 0.3489002287387848, acc = 0.8818359375\n",
      "Batch 110: loss = 0.45195889472961426, acc = 0.853515625\n",
      "Batch 111: loss = 0.49342867732048035, acc = 0.83203125\n",
      "Batch 112: loss = 0.4167328178882599, acc = 0.8447265625\n",
      "Batch 113: loss = 0.41821199655532837, acc = 0.85546875\n",
      "Batch 114: loss = 0.3716508746147156, acc = 0.8701171875\n",
      "Batch 115: loss = 0.4697297215461731, acc = 0.84375\n",
      "Batch 116: loss = 0.40605053305625916, acc = 0.859375\n",
      "Batch 117: loss = 0.3793658912181854, acc = 0.8779296875\n",
      "Batch 118: loss = 0.4024435877799988, acc = 0.86328125\n",
      "Batch 119: loss = 0.40984904766082764, acc = 0.859375\n",
      "Batch 120: loss = 0.45287463068962097, acc = 0.8408203125\n",
      "Batch 121: loss = 0.43435633182525635, acc = 0.8564453125\n",
      "Batch 122: loss = 0.3374834656715393, acc = 0.8857421875\n",
      "Batch 123: loss = 0.39309993386268616, acc = 0.8701171875\n",
      "Batch 124: loss = 0.4145010709762573, acc = 0.861328125\n",
      "Batch 125: loss = 0.40824639797210693, acc = 0.8623046875\n",
      "Batch 126: loss = 0.3659142255783081, acc = 0.8701171875\n",
      "Batch 127: loss = 0.4154497981071472, acc = 0.8544921875\n",
      "Batch 128: loss = 0.3815018832683563, acc = 0.8720703125\n",
      "Batch 129: loss = 0.45200902223587036, acc = 0.85546875\n",
      "Batch 130: loss = 0.4030298590660095, acc = 0.8642578125\n",
      "Batch 131: loss = 0.33907708525657654, acc = 0.8935546875\n",
      "Batch 132: loss = 0.2929375171661377, acc = 0.9033203125\n",
      "Batch 133: loss = 0.353152871131897, acc = 0.8740234375\n",
      "Batch 134: loss = 0.33153337240219116, acc = 0.888671875\n",
      "Batch 135: loss = 0.4359171986579895, acc = 0.8505859375\n",
      "Batch 136: loss = 0.4044076204299927, acc = 0.8671875\n",
      "Batch 137: loss = 0.362048476934433, acc = 0.8759765625\n",
      "Batch 138: loss = 0.36141738295555115, acc = 0.8828125\n",
      "Batch 139: loss = 0.37508657574653625, acc = 0.8740234375\n",
      "Batch 140: loss = 0.3974149823188782, acc = 0.865234375\n",
      "Batch 141: loss = 0.40473586320877075, acc = 0.8623046875\n",
      "Batch 142: loss = 0.4158566892147064, acc = 0.8564453125\n",
      "Batch 143: loss = 0.4335598647594452, acc = 0.8515625\n",
      "Batch 144: loss = 0.41933733224868774, acc = 0.8603515625\n",
      "Batch 145: loss = 0.3474026620388031, acc = 0.8740234375\n",
      "Batch 146: loss = 0.4115368723869324, acc = 0.84765625\n",
      "Batch 147: loss = 0.44115254282951355, acc = 0.85546875\n",
      "Batch 148: loss = 0.3800598680973053, acc = 0.8681640625\n",
      "Batch 149: loss = 0.4098132252693176, acc = 0.8603515625\n",
      "Batch 150: loss = 0.4061354994773865, acc = 0.8671875\n",
      "Batch 151: loss = 0.48833078145980835, acc = 0.8388671875\n",
      "Batch 152: loss = 0.389247864484787, acc = 0.869140625\n",
      "Batch 153: loss = 0.3918581008911133, acc = 0.8623046875\n",
      "Batch 154: loss = 0.4416322708129883, acc = 0.8447265625\n",
      "Batch 155: loss = 0.3671477138996124, acc = 0.873046875\n",
      "Batch 156: loss = 0.4507928490638733, acc = 0.8486328125\n",
      "Batch 157: loss = 0.4397395849227905, acc = 0.8583984375\n",
      "Batch 158: loss = 0.40086233615875244, acc = 0.8564453125\n",
      "Batch 159: loss = 0.45733213424682617, acc = 0.845703125\n",
      "Batch 160: loss = 0.43056997656822205, acc = 0.8662109375\n",
      "Batch 161: loss = 0.4275144636631012, acc = 0.8564453125\n",
      "Batch 162: loss = 0.4238080680370331, acc = 0.859375\n",
      "Batch 163: loss = 0.3900514245033264, acc = 0.8798828125\n",
      "Batch 164: loss = 0.4072791337966919, acc = 0.8603515625\n",
      "Batch 165: loss = 0.42389798164367676, acc = 0.8564453125\n",
      "Batch 166: loss = 0.3185216188430786, acc = 0.8876953125\n",
      "Batch 167: loss = 0.4066508412361145, acc = 0.859375\n",
      "Batch 168: loss = 0.4096786081790924, acc = 0.861328125\n",
      "Batch 169: loss = 0.35774174332618713, acc = 0.8759765625\n",
      "Batch 170: loss = 0.3617950975894928, acc = 0.8759765625\n",
      "Batch 171: loss = 0.4416865408420563, acc = 0.84765625\n",
      "Batch 172: loss = 0.38293054699897766, acc = 0.876953125\n",
      "Batch 173: loss = 0.3816094994544983, acc = 0.8671875\n",
      "Batch 174: loss = 0.37598752975463867, acc = 0.8681640625\n",
      "Batch 175: loss = 0.43611589074134827, acc = 0.845703125\n",
      "Batch 176: loss = 0.3986530005931854, acc = 0.8544921875\n",
      "Batch 177: loss = 0.3580286502838135, acc = 0.880859375\n",
      "Batch 178: loss = 0.38609662652015686, acc = 0.8662109375\n",
      "Batch 179: loss = 0.44918930530548096, acc = 0.8515625\n",
      "Batch 180: loss = 0.38449010252952576, acc = 0.875\n",
      "Batch 181: loss = 0.3942277133464813, acc = 0.8759765625\n",
      "Batch 182: loss = 0.41472968459129333, acc = 0.859375\n",
      "Batch 183: loss = 0.38436853885650635, acc = 0.865234375\n",
      "Batch 184: loss = 0.41567349433898926, acc = 0.8525390625\n",
      "Batch 185: loss = 0.42099857330322266, acc = 0.865234375\n",
      "Batch 186: loss = 0.39801400899887085, acc = 0.8759765625\n",
      "Batch 187: loss = 0.4101642370223999, acc = 0.8515625\n",
      "Batch 188: loss = 0.39746353030204773, acc = 0.8701171875\n",
      "Batch 189: loss = 0.38320016860961914, acc = 0.869140625\n",
      "Batch 190: loss = 0.43735411763191223, acc = 0.8623046875\n",
      "Batch 191: loss = 0.3725491762161255, acc = 0.8779296875\n",
      "Batch 192: loss = 0.3673790991306305, acc = 0.876953125\n",
      "Batch 193: loss = 0.4567449688911438, acc = 0.8544921875\n",
      "Batch 194: loss = 0.42945852875709534, acc = 0.8642578125\n",
      "Batch 195: loss = 0.4412763714790344, acc = 0.8486328125\n",
      "Batch 196: loss = 0.48202836513519287, acc = 0.84375\n",
      "Batch 197: loss = 0.47449541091918945, acc = 0.8466796875\n",
      "Batch 198: loss = 0.40936335921287537, acc = 0.8583984375\n",
      "Batch 199: loss = 0.483792245388031, acc = 0.8515625\n",
      "Batch 200: loss = 0.46526163816452026, acc = 0.8388671875\n",
      "Batch 201: loss = 0.4714115560054779, acc = 0.849609375\n",
      "Batch 202: loss = 0.48382169008255005, acc = 0.845703125\n",
      "Batch 203: loss = 0.3904739022254944, acc = 0.8671875\n",
      "Batch 204: loss = 0.4184010624885559, acc = 0.859375\n",
      "Batch 205: loss = 0.4695712625980377, acc = 0.841796875\n",
      "Batch 206: loss = 0.4145067632198334, acc = 0.84765625\n",
      "Batch 207: loss = 0.48446208238601685, acc = 0.83203125\n",
      "Batch 208: loss = 0.45585542917251587, acc = 0.853515625\n",
      "Batch 209: loss = 0.41621658205986023, acc = 0.8564453125\n",
      "Batch 210: loss = 0.38477012515068054, acc = 0.876953125\n",
      "Batch 211: loss = 0.4462083578109741, acc = 0.84375\n",
      "Batch 212: loss = 0.4611362814903259, acc = 0.8525390625\n",
      "Batch 213: loss = 0.43683069944381714, acc = 0.8505859375\n",
      "Batch 214: loss = 0.4397289752960205, acc = 0.861328125\n",
      "Batch 215: loss = 0.3758392632007599, acc = 0.8720703125\n",
      "Batch 216: loss = 0.3606918752193451, acc = 0.87890625\n",
      "Batch 217: loss = 0.36128100752830505, acc = 0.890625\n",
      "Batch 218: loss = 0.41089683771133423, acc = 0.857421875\n",
      "Batch 219: loss = 0.42571258544921875, acc = 0.85546875\n",
      "Batch 220: loss = 0.4017784595489502, acc = 0.8701171875\n",
      "Batch 221: loss = 0.4547625184059143, acc = 0.8486328125\n",
      "Batch 222: loss = 0.3773350715637207, acc = 0.880859375\n",
      "Batch 223: loss = 0.3372920751571655, acc = 0.8837890625\n",
      "Batch 224: loss = 0.3245275616645813, acc = 0.89453125\n",
      "Batch 225: loss = 0.34819796681404114, acc = 0.87890625\n",
      "Batch 226: loss = 0.45299065113067627, acc = 0.8427734375\n",
      "Batch 227: loss = 0.3834836483001709, acc = 0.859375\n",
      "Batch 228: loss = 0.3848934769630432, acc = 0.8701171875\n",
      "Batch 229: loss = 0.3972177505493164, acc = 0.86328125\n",
      "Batch 230: loss = 0.36395519971847534, acc = 0.884765625\n",
      "Batch 231: loss = 0.4840903878211975, acc = 0.8447265625\n",
      "Batch 232: loss = 0.3763405680656433, acc = 0.8798828125\n",
      "Batch 233: loss = 0.49753355979919434, acc = 0.8349609375\n",
      "Batch 234: loss = 0.3823183476924896, acc = 0.857421875\n",
      "Batch 235: loss = 0.4248213768005371, acc = 0.8427734375\n",
      "Batch 236: loss = 0.42846453189849854, acc = 0.86328125\n",
      "Batch 237: loss = 0.3762999475002289, acc = 0.8681640625\n",
      "Batch 238: loss = 0.44274386763572693, acc = 0.8466796875\n",
      "Batch 239: loss = 0.3668196201324463, acc = 0.8740234375\n",
      "Batch 240: loss = 0.44495663046836853, acc = 0.849609375\n",
      "Batch 241: loss = 0.4110572636127472, acc = 0.8623046875\n",
      "Batch 242: loss = 0.4236319363117218, acc = 0.8642578125\n",
      "Batch 243: loss = 0.4475899338722229, acc = 0.8583984375\n",
      "Batch 244: loss = 0.45661330223083496, acc = 0.8515625\n",
      "Batch 245: loss = 0.41145968437194824, acc = 0.85546875\n",
      "Batch 246: loss = 0.4203862249851227, acc = 0.857421875\n",
      "Batch 247: loss = 0.4189545214176178, acc = 0.84765625\n",
      "Batch 248: loss = 0.4001137614250183, acc = 0.8642578125\n",
      "Batch 249: loss = 0.3656185269355774, acc = 0.8701171875\n",
      "Batch 250: loss = 0.39891743659973145, acc = 0.875\n",
      "Batch 251: loss = 0.35168319940567017, acc = 0.8837890625\n",
      "Batch 252: loss = 0.3866201639175415, acc = 0.8798828125\n",
      "Batch 253: loss = 0.4488412141799927, acc = 0.849609375\n",
      "Batch 254: loss = 0.4611349403858185, acc = 0.849609375\n",
      "Batch 255: loss = 0.43897366523742676, acc = 0.84375\n",
      "Batch 256: loss = 0.4348483979701996, acc = 0.8525390625\n",
      "Batch 257: loss = 0.5171903967857361, acc = 0.828125\n",
      "Batch 258: loss = 0.4616599977016449, acc = 0.8349609375\n",
      "Batch 259: loss = 0.5134400725364685, acc = 0.8193359375\n",
      "Batch 260: loss = 0.4926900565624237, acc = 0.8330078125\n",
      "Batch 261: loss = 0.4290682077407837, acc = 0.8681640625\n",
      "Batch 262: loss = 0.4267992377281189, acc = 0.865234375\n",
      "Batch 263: loss = 0.4092220067977905, acc = 0.8701171875\n",
      "Batch 264: loss = 0.43414637446403503, acc = 0.8505859375\n",
      "Batch 265: loss = 0.4117462933063507, acc = 0.8740234375\n",
      "Batch 266: loss = 0.39416342973709106, acc = 0.8662109375\n",
      "Batch 267: loss = 0.34827372431755066, acc = 0.888671875\n",
      "Batch 268: loss = 0.39890778064727783, acc = 0.8681640625\n",
      "Batch 269: loss = 0.4681456983089447, acc = 0.8505859375\n",
      "Batch 270: loss = 0.42925918102264404, acc = 0.8564453125\n",
      "Batch 271: loss = 0.3916267156600952, acc = 0.8603515625\n",
      "Batch 272: loss = 0.4278486967086792, acc = 0.8583984375\n",
      "Batch 273: loss = 0.41955775022506714, acc = 0.8525390625\n",
      "Batch 274: loss = 0.37641584873199463, acc = 0.8671875\n",
      "Batch 275: loss = 0.36073189973831177, acc = 0.880859375\n",
      "Batch 276: loss = 0.41445106267929077, acc = 0.853515625\n",
      "Batch 277: loss = 0.44761180877685547, acc = 0.86328125\n",
      "Batch 278: loss = 0.366860568523407, acc = 0.8779296875\n",
      "Batch 279: loss = 0.4376547634601593, acc = 0.8583984375\n",
      "Batch 280: loss = 0.45726948976516724, acc = 0.8564453125\n",
      "Batch 281: loss = 0.46970680356025696, acc = 0.84375\n",
      "Batch 282: loss = 0.47806882858276367, acc = 0.84375\n",
      "Batch 283: loss = 0.4916984438896179, acc = 0.84375\n",
      "Batch 284: loss = 0.4483908712863922, acc = 0.8486328125\n",
      "Batch 285: loss = 0.45509374141693115, acc = 0.8330078125\n",
      "Batch 286: loss = 0.48638513684272766, acc = 0.82421875\n",
      "Batch 287: loss = 0.4670984148979187, acc = 0.84765625\n",
      "Batch 288: loss = 0.45254528522491455, acc = 0.8359375\n",
      "Batch 289: loss = 0.3869020938873291, acc = 0.8798828125\n",
      "Batch 290: loss = 0.4445537328720093, acc = 0.845703125\n",
      "Batch 291: loss = 0.44158878922462463, acc = 0.861328125\n",
      "Batch 292: loss = 0.4133690893650055, acc = 0.8662109375\n",
      "Batch 293: loss = 0.39224740862846375, acc = 0.8681640625\n",
      "Batch 294: loss = 0.419053316116333, acc = 0.8603515625\n",
      "Batch 295: loss = 0.37507766485214233, acc = 0.8720703125\n",
      "Batch 296: loss = 0.39976656436920166, acc = 0.86328125\n",
      "Batch 297: loss = 0.3809472918510437, acc = 0.880859375\n",
      "Batch 298: loss = 0.3806045651435852, acc = 0.8798828125\n",
      "Batch 299: loss = 0.3685227930545807, acc = 0.8779296875\n",
      "Batch 300: loss = 0.47042590379714966, acc = 0.8447265625\n",
      "Batch 301: loss = 0.4153551161289215, acc = 0.8623046875\n",
      "Batch 302: loss = 0.4108291268348694, acc = 0.8642578125\n",
      "Batch 303: loss = 0.46169573068618774, acc = 0.8486328125\n",
      "Batch 304: loss = 0.38659268617630005, acc = 0.8759765625\n",
      "Batch 305: loss = 0.3730781674385071, acc = 0.87890625\n",
      "Batch 306: loss = 0.45039689540863037, acc = 0.8447265625\n",
      "Batch 307: loss = 0.3528294265270233, acc = 0.8828125\n",
      "Batch 308: loss = 0.4707081913948059, acc = 0.8369140625\n",
      "Batch 309: loss = 0.4594804346561432, acc = 0.8505859375\n",
      "Batch 310: loss = 0.40526050329208374, acc = 0.865234375\n",
      "Batch 311: loss = 0.4430650770664215, acc = 0.8505859375\n",
      "Batch 312: loss = 0.3685130178928375, acc = 0.8740234375\n",
      "Batch 313: loss = 0.47748830914497375, acc = 0.84375\n",
      "Batch 314: loss = 0.41725876927375793, acc = 0.8642578125\n",
      "Batch 315: loss = 0.4471249282360077, acc = 0.8427734375\n",
      "Batch 316: loss = 0.39289677143096924, acc = 0.8623046875\n",
      "Batch 317: loss = 0.4145401418209076, acc = 0.8466796875\n",
      "Batch 318: loss = 0.41441118717193604, acc = 0.8515625\n",
      "Batch 319: loss = 0.4481614828109741, acc = 0.8515625\n",
      "Batch 320: loss = 0.43765515089035034, acc = 0.83984375\n",
      "Batch 321: loss = 0.46810439229011536, acc = 0.8369140625\n",
      "Batch 322: loss = 0.3960989713668823, acc = 0.875\n",
      "Batch 323: loss = 0.4603458046913147, acc = 0.845703125\n",
      "Batch 324: loss = 0.42734307050704956, acc = 0.8564453125\n",
      "Batch 325: loss = 0.4612652063369751, acc = 0.84375\n",
      "Batch 326: loss = 0.4068230986595154, acc = 0.8701171875\n",
      "Batch 327: loss = 0.39979076385498047, acc = 0.859375\n",
      "Batch 328: loss = 0.44086727499961853, acc = 0.8486328125\n",
      "Batch 329: loss = 0.5165302753448486, acc = 0.8203125\n",
      "Batch 330: loss = 0.3884828984737396, acc = 0.8671875\n",
      "Batch 331: loss = 0.4165935218334198, acc = 0.876953125\n",
      "Batch 332: loss = 0.41267961263656616, acc = 0.8544921875\n",
      "Batch 333: loss = 0.4002665579319, acc = 0.86328125\n",
      "Batch 334: loss = 0.35751014947891235, acc = 0.8876953125\n",
      "Batch 335: loss = 0.4617827534675598, acc = 0.8310546875\n",
      "Batch 336: loss = 0.4348253607749939, acc = 0.8564453125\n",
      "Batch 337: loss = 0.4542035162448883, acc = 0.8623046875\n",
      "Batch 338: loss = 0.3899643123149872, acc = 0.87109375\n",
      "Batch 339: loss = 0.41710537672042847, acc = 0.8623046875\n",
      "Batch 340: loss = 0.3813587427139282, acc = 0.8740234375\n",
      "Batch 341: loss = 0.40974220633506775, acc = 0.8515625\n",
      "Batch 342: loss = 0.45132315158843994, acc = 0.837890625\n",
      "Batch 343: loss = 0.40639728307724, acc = 0.86328125\n",
      "Batch 344: loss = 0.36830437183380127, acc = 0.869140625\n",
      "Batch 345: loss = 0.3889589011669159, acc = 0.869140625\n",
      "Batch 346: loss = 0.33512067794799805, acc = 0.8818359375\n",
      "Batch 347: loss = 0.41852501034736633, acc = 0.8603515625\n",
      "Batch 348: loss = 0.3853316307067871, acc = 0.8681640625\n",
      "Batch 349: loss = 0.370017409324646, acc = 0.884765625\n",
      "Batch 350: loss = 0.34563830494880676, acc = 0.8818359375\n",
      "Batch 351: loss = 0.3318268060684204, acc = 0.876953125\n",
      "Batch 352: loss = 0.3954666554927826, acc = 0.865234375\n",
      "Batch 353: loss = 0.38122686743736267, acc = 0.8837890625\n",
      "Batch 354: loss = 0.3465726673603058, acc = 0.87890625\n",
      "Batch 355: loss = 0.26652780175209045, acc = 0.91796875\n",
      "Batch 356: loss = 0.35438644886016846, acc = 0.8701171875\n",
      "Batch 357: loss = 0.37718304991722107, acc = 0.8720703125\n",
      "Batch 358: loss = 0.369827538728714, acc = 0.8701171875\n",
      "Batch 359: loss = 0.43086913228034973, acc = 0.8681640625\n",
      "Batch 360: loss = 0.3929499685764313, acc = 0.873046875\n",
      "Batch 361: loss = 0.390963613986969, acc = 0.87890625\n",
      "Batch 362: loss = 0.3539407551288605, acc = 0.873046875\n",
      "Batch 363: loss = 0.39566612243652344, acc = 0.8623046875\n",
      "Batch 364: loss = 0.42589420080184937, acc = 0.8564453125\n",
      "Batch 365: loss = 0.3846890330314636, acc = 0.8681640625\n",
      "Batch 366: loss = 0.4026375412940979, acc = 0.8740234375\n",
      "Batch 367: loss = 0.39341479539871216, acc = 0.861328125\n",
      "Batch 368: loss = 0.4407157897949219, acc = 0.8544921875\n",
      "Batch 369: loss = 0.464381605386734, acc = 0.845703125\n",
      "Batch 370: loss = 0.3887864649295807, acc = 0.8681640625\n",
      "Batch 371: loss = 0.44464534521102905, acc = 0.849609375\n",
      "Batch 372: loss = 0.3736439347267151, acc = 0.8720703125\n",
      "Batch 373: loss = 0.3983021676540375, acc = 0.8623046875\n",
      "Batch 374: loss = 0.43645408749580383, acc = 0.8515625\n",
      "Batch 375: loss = 0.48418062925338745, acc = 0.828125\n",
      "Batch 376: loss = 0.4173174500465393, acc = 0.861328125\n",
      "Batch 377: loss = 0.45360350608825684, acc = 0.830078125\n",
      "Batch 378: loss = 0.40487104654312134, acc = 0.865234375\n",
      "Batch 379: loss = 0.50660640001297, acc = 0.8369140625\n",
      "Batch 380: loss = 0.3764422535896301, acc = 0.87109375\n",
      "Batch 381: loss = 0.36845430731773376, acc = 0.869140625\n",
      "Batch 382: loss = 0.41898292303085327, acc = 0.8623046875\n",
      "Batch 383: loss = 0.39432814717292786, acc = 0.861328125\n",
      "Batch 384: loss = 0.4005870819091797, acc = 0.861328125\n",
      "Batch 385: loss = 0.3996586799621582, acc = 0.859375\n",
      "Batch 386: loss = 0.3717692494392395, acc = 0.8740234375\n",
      "Batch 387: loss = 0.3871636390686035, acc = 0.87890625\n",
      "Batch 388: loss = 0.42815667390823364, acc = 0.853515625\n",
      "Batch 389: loss = 0.4093153774738312, acc = 0.8681640625\n",
      "Batch 390: loss = 0.4421459138393402, acc = 0.857421875\n",
      "Batch 391: loss = 0.4463801383972168, acc = 0.8515625\n",
      "Batch 392: loss = 0.4224086403846741, acc = 0.8583984375\n",
      "Batch 393: loss = 0.41806867718696594, acc = 0.8544921875\n",
      "Batch 394: loss = 0.3871658146381378, acc = 0.87109375\n",
      "Batch 395: loss = 0.3964535892009735, acc = 0.8603515625\n",
      "Batch 396: loss = 0.4369989335536957, acc = 0.8505859375\n",
      "Batch 397: loss = 0.3086969256401062, acc = 0.8955078125\n",
      "Batch 398: loss = 0.3451288938522339, acc = 0.8779296875\n",
      "Batch 399: loss = 0.413398802280426, acc = 0.8671875\n",
      "Batch 400: loss = 0.43030399084091187, acc = 0.8544921875\n",
      "Batch 401: loss = 0.41137591004371643, acc = 0.8662109375\n",
      "Batch 402: loss = 0.4670066237449646, acc = 0.85546875\n",
      "Batch 403: loss = 0.36254698038101196, acc = 0.875\n",
      "Batch 404: loss = 0.43676725029945374, acc = 0.859375\n",
      "Batch 405: loss = 0.4004581570625305, acc = 0.8759765625\n",
      "Batch 406: loss = 0.5396019220352173, acc = 0.8203125\n",
      "Batch 407: loss = 0.41442233324050903, acc = 0.8544921875\n",
      "Batch 408: loss = 0.5264737010002136, acc = 0.826171875\n",
      "Batch 409: loss = 0.3763934373855591, acc = 0.87890625\n",
      "Batch 410: loss = 0.45218193531036377, acc = 0.84375\n",
      "Batch 411: loss = 0.40037640929222107, acc = 0.8701171875\n",
      "Batch 412: loss = 0.41687506437301636, acc = 0.849609375\n",
      "Batch 413: loss = 0.35168927907943726, acc = 0.8701171875\n",
      "Batch 414: loss = 0.3877524435520172, acc = 0.873046875\n",
      "Batch 415: loss = 0.39687100052833557, acc = 0.8671875\n",
      "Batch 416: loss = 0.4298836886882782, acc = 0.8544921875\n",
      "Batch 417: loss = 0.41174450516700745, acc = 0.8515625\n",
      "Batch 418: loss = 0.45037007331848145, acc = 0.8427734375\n",
      "Batch 419: loss = 0.5885708928108215, acc = 0.8076171875\n",
      "Batch 420: loss = 0.47874030470848083, acc = 0.845703125\n",
      "Batch 421: loss = 0.4619452953338623, acc = 0.8466796875\n",
      "Batch 422: loss = 0.4602290689945221, acc = 0.845703125\n",
      "Batch 423: loss = 0.44743412733078003, acc = 0.8466796875\n",
      "Batch 424: loss = 0.4831544756889343, acc = 0.8359375\n",
      "Batch 425: loss = 0.43032306432724, acc = 0.8623046875\n",
      "Batch 426: loss = 0.4500819444656372, acc = 0.841796875\n",
      "Batch 427: loss = 0.41933828592300415, acc = 0.8515625\n",
      "Batch 428: loss = 0.4326527416706085, acc = 0.849609375\n",
      "Batch 429: loss = 0.38722601532936096, acc = 0.875\n",
      "Batch 430: loss = 0.3922872841358185, acc = 0.865234375\n",
      "Batch 431: loss = 0.41842177510261536, acc = 0.8505859375\n",
      "Batch 432: loss = 0.4353839159011841, acc = 0.853515625\n",
      "Batch 433: loss = 0.35207298398017883, acc = 0.8857421875\n",
      "Batch 434: loss = 0.397041380405426, acc = 0.8603515625\n",
      "Batch 435: loss = 0.45900216698646545, acc = 0.8447265625\n",
      "Batch 436: loss = 0.4032834470272064, acc = 0.859375\n",
      "Batch 437: loss = 0.44754457473754883, acc = 0.8603515625\n",
      "Batch 438: loss = 0.39772534370422363, acc = 0.861328125\n",
      "Batch 439: loss = 0.38898906111717224, acc = 0.876953125\n",
      "Batch 440: loss = 0.4376114308834076, acc = 0.8603515625\n",
      "Batch 441: loss = 0.35745447874069214, acc = 0.8701171875\n",
      "\n",
      "Epoch 98/100\n",
      "Batch 1: loss = 0.5418398380279541, acc = 0.84375\n",
      "Batch 2: loss = 0.39496341347694397, acc = 0.86328125\n",
      "Batch 3: loss = 0.45988929271698, acc = 0.841796875\n",
      "Batch 4: loss = 0.4314652979373932, acc = 0.8515625\n",
      "Batch 5: loss = 0.4583854079246521, acc = 0.845703125\n",
      "Batch 6: loss = 0.3776378631591797, acc = 0.880859375\n",
      "Batch 7: loss = 0.36367619037628174, acc = 0.880859375\n",
      "Batch 8: loss = 0.3596450388431549, acc = 0.8720703125\n",
      "Batch 9: loss = 0.4140138626098633, acc = 0.8466796875\n",
      "Batch 10: loss = 0.4661397933959961, acc = 0.8515625\n",
      "Batch 11: loss = 0.4405994415283203, acc = 0.8427734375\n",
      "Batch 12: loss = 0.37792471051216125, acc = 0.8701171875\n",
      "Batch 13: loss = 0.45710039138793945, acc = 0.8525390625\n",
      "Batch 14: loss = 0.37304630875587463, acc = 0.8779296875\n",
      "Batch 15: loss = 0.39993229508399963, acc = 0.8515625\n",
      "Batch 16: loss = 0.41976067423820496, acc = 0.8701171875\n",
      "Batch 17: loss = 0.3484782874584198, acc = 0.8798828125\n",
      "Batch 18: loss = 0.41837212443351746, acc = 0.8525390625\n",
      "Batch 19: loss = 0.409551739692688, acc = 0.8544921875\n",
      "Batch 20: loss = 0.4027292728424072, acc = 0.8701171875\n",
      "Batch 21: loss = 0.4464739263057709, acc = 0.861328125\n",
      "Batch 22: loss = 0.43904411792755127, acc = 0.845703125\n",
      "Batch 23: loss = 0.39941808581352234, acc = 0.8623046875\n",
      "Batch 24: loss = 0.39550215005874634, acc = 0.8828125\n",
      "Batch 25: loss = 0.4155747890472412, acc = 0.8525390625\n",
      "Batch 26: loss = 0.4204554855823517, acc = 0.8642578125\n",
      "Batch 27: loss = 0.4862222671508789, acc = 0.83203125\n",
      "Batch 28: loss = 0.40558236837387085, acc = 0.861328125\n",
      "Batch 29: loss = 0.41037517786026, acc = 0.85546875\n",
      "Batch 30: loss = 0.459011435508728, acc = 0.8505859375\n",
      "Batch 31: loss = 0.4244645833969116, acc = 0.8603515625\n",
      "Batch 32: loss = 0.39320552349090576, acc = 0.8642578125\n",
      "Batch 33: loss = 0.35671472549438477, acc = 0.8779296875\n",
      "Batch 34: loss = 0.35898131132125854, acc = 0.87890625\n",
      "Batch 35: loss = 0.38011300563812256, acc = 0.875\n",
      "Batch 36: loss = 0.4008306562900543, acc = 0.8623046875\n",
      "Batch 37: loss = 0.4216434061527252, acc = 0.85546875\n",
      "Batch 38: loss = 0.3896118104457855, acc = 0.86328125\n",
      "Batch 39: loss = 0.3352805972099304, acc = 0.8916015625\n",
      "Batch 40: loss = 0.3808766007423401, acc = 0.8828125\n",
      "Batch 41: loss = 0.3404742479324341, acc = 0.8759765625\n",
      "Batch 42: loss = 0.45294737815856934, acc = 0.8583984375\n",
      "Batch 43: loss = 0.48842883110046387, acc = 0.8330078125\n",
      "Batch 44: loss = 0.425129771232605, acc = 0.86328125\n",
      "Batch 45: loss = 0.33287978172302246, acc = 0.8779296875\n",
      "Batch 46: loss = 0.3840201497077942, acc = 0.865234375\n",
      "Batch 47: loss = 0.36658376455307007, acc = 0.87890625\n",
      "Batch 48: loss = 0.3667116165161133, acc = 0.8798828125\n",
      "Batch 49: loss = 0.40011367201805115, acc = 0.853515625\n",
      "Batch 50: loss = 0.40487024188041687, acc = 0.8544921875\n",
      "Batch 51: loss = 0.46476101875305176, acc = 0.8359375\n",
      "Batch 52: loss = 0.36187008023262024, acc = 0.873046875\n",
      "Batch 53: loss = 0.4210454821586609, acc = 0.8544921875\n",
      "Batch 54: loss = 0.3660765588283539, acc = 0.87109375\n",
      "Batch 55: loss = 0.3911578059196472, acc = 0.8544921875\n",
      "Batch 56: loss = 0.40042752027511597, acc = 0.859375\n",
      "Batch 57: loss = 0.40029922127723694, acc = 0.8662109375\n",
      "Batch 58: loss = 0.36882126331329346, acc = 0.8720703125\n",
      "Batch 59: loss = 0.41971275210380554, acc = 0.8564453125\n",
      "Batch 60: loss = 0.37964603304862976, acc = 0.8779296875\n",
      "Batch 61: loss = 0.41790837049484253, acc = 0.857421875\n",
      "Batch 62: loss = 0.4093168079853058, acc = 0.8525390625\n",
      "Batch 63: loss = 0.46229028701782227, acc = 0.8330078125\n",
      "Batch 64: loss = 0.3486863672733307, acc = 0.8896484375\n",
      "Batch 65: loss = 0.3579547107219696, acc = 0.8857421875\n",
      "Batch 66: loss = 0.389669805765152, acc = 0.873046875\n",
      "Batch 67: loss = 0.437637597322464, acc = 0.8583984375\n",
      "Batch 68: loss = 0.46165937185287476, acc = 0.849609375\n",
      "Batch 69: loss = 0.4312671720981598, acc = 0.8623046875\n",
      "Batch 70: loss = 0.44266462326049805, acc = 0.841796875\n",
      "Batch 71: loss = 0.43750593066215515, acc = 0.8544921875\n",
      "Batch 72: loss = 0.44215357303619385, acc = 0.8515625\n",
      "Batch 73: loss = 0.40488940477371216, acc = 0.853515625\n",
      "Batch 74: loss = 0.4559859037399292, acc = 0.8466796875\n",
      "Batch 75: loss = 0.35063809156417847, acc = 0.88671875\n",
      "Batch 76: loss = 0.4385659098625183, acc = 0.8486328125\n",
      "Batch 77: loss = 0.43303924798965454, acc = 0.85546875\n",
      "Batch 78: loss = 0.45717400312423706, acc = 0.853515625\n",
      "Batch 79: loss = 0.3996134400367737, acc = 0.861328125\n",
      "Batch 80: loss = 0.5353514552116394, acc = 0.826171875\n",
      "Batch 81: loss = 0.36075857281684875, acc = 0.8720703125\n",
      "Batch 82: loss = 0.3923640847206116, acc = 0.865234375\n",
      "Batch 83: loss = 0.4578099846839905, acc = 0.8369140625\n",
      "Batch 84: loss = 0.3716963827610016, acc = 0.873046875\n",
      "Batch 85: loss = 0.45609593391418457, acc = 0.8505859375\n",
      "Batch 86: loss = 0.4075557589530945, acc = 0.8515625\n",
      "Batch 87: loss = 0.37965425848960876, acc = 0.865234375\n",
      "Batch 88: loss = 0.4320299029350281, acc = 0.8583984375\n",
      "Batch 89: loss = 0.4808835983276367, acc = 0.833984375\n",
      "Batch 90: loss = 0.42806386947631836, acc = 0.8505859375\n",
      "Batch 91: loss = 0.3908139169216156, acc = 0.8662109375\n",
      "Batch 92: loss = 0.42283186316490173, acc = 0.86328125\n",
      "Batch 93: loss = 0.39596718549728394, acc = 0.869140625\n",
      "Batch 94: loss = 0.42621880769729614, acc = 0.8583984375\n",
      "Batch 95: loss = 0.4435039162635803, acc = 0.859375\n",
      "Batch 96: loss = 0.39855092763900757, acc = 0.87109375\n",
      "Batch 97: loss = 0.4459838569164276, acc = 0.84765625\n",
      "Batch 98: loss = 0.4358186423778534, acc = 0.8505859375\n",
      "Batch 99: loss = 0.41276684403419495, acc = 0.853515625\n",
      "Batch 100: loss = 0.49494487047195435, acc = 0.8271484375\n",
      "Batch 101: loss = 0.3677259087562561, acc = 0.873046875\n",
      "Batch 102: loss = 0.3665694296360016, acc = 0.8681640625\n",
      "Batch 103: loss = 0.3945906460285187, acc = 0.8525390625\n",
      "Batch 104: loss = 0.3786787688732147, acc = 0.8662109375\n",
      "Batch 105: loss = 0.446286141872406, acc = 0.8505859375\n",
      "Batch 106: loss = 0.4255498945713043, acc = 0.8583984375\n",
      "Batch 107: loss = 0.39260926842689514, acc = 0.869140625\n",
      "Batch 108: loss = 0.4512179493904114, acc = 0.8486328125\n",
      "Batch 109: loss = 0.3514483571052551, acc = 0.8720703125\n",
      "Batch 110: loss = 0.44313040375709534, acc = 0.85546875\n",
      "Batch 111: loss = 0.5018981099128723, acc = 0.83203125\n",
      "Batch 112: loss = 0.38737136125564575, acc = 0.857421875\n",
      "Batch 113: loss = 0.40400925278663635, acc = 0.8564453125\n",
      "Batch 114: loss = 0.34490466117858887, acc = 0.88671875\n",
      "Batch 115: loss = 0.4616052508354187, acc = 0.8349609375\n",
      "Batch 116: loss = 0.3824092745780945, acc = 0.8759765625\n",
      "Batch 117: loss = 0.4149390459060669, acc = 0.87109375\n",
      "Batch 118: loss = 0.44005635380744934, acc = 0.85546875\n",
      "Batch 119: loss = 0.4532053768634796, acc = 0.849609375\n",
      "Batch 120: loss = 0.4259260296821594, acc = 0.8583984375\n",
      "Batch 121: loss = 0.4228673279285431, acc = 0.861328125\n",
      "Batch 122: loss = 0.4021419584751129, acc = 0.865234375\n",
      "Batch 123: loss = 0.4080522954463959, acc = 0.8720703125\n",
      "Batch 124: loss = 0.4447135925292969, acc = 0.84375\n",
      "Batch 125: loss = 0.4129643142223358, acc = 0.8623046875\n",
      "Batch 126: loss = 0.3696882426738739, acc = 0.875\n",
      "Batch 127: loss = 0.431595116853714, acc = 0.8525390625\n",
      "Batch 128: loss = 0.3786922097206116, acc = 0.8779296875\n",
      "Batch 129: loss = 0.38110867142677307, acc = 0.87109375\n",
      "Batch 130: loss = 0.35109448432922363, acc = 0.87890625\n",
      "Batch 131: loss = 0.3302156627178192, acc = 0.8857421875\n",
      "Batch 132: loss = 0.3260895907878876, acc = 0.88671875\n",
      "Batch 133: loss = 0.322904109954834, acc = 0.8837890625\n",
      "Batch 134: loss = 0.35697242617607117, acc = 0.873046875\n",
      "Batch 135: loss = 0.4254310727119446, acc = 0.859375\n",
      "Batch 136: loss = 0.4149964451789856, acc = 0.853515625\n",
      "Batch 137: loss = 0.363727331161499, acc = 0.87109375\n",
      "Batch 138: loss = 0.4117944538593292, acc = 0.8603515625\n",
      "Batch 139: loss = 0.37961602210998535, acc = 0.8701171875\n",
      "Batch 140: loss = 0.3657597303390503, acc = 0.8720703125\n",
      "Batch 141: loss = 0.39740464091300964, acc = 0.8681640625\n",
      "Batch 142: loss = 0.41078102588653564, acc = 0.865234375\n",
      "Batch 143: loss = 0.43497827649116516, acc = 0.8525390625\n",
      "Batch 144: loss = 0.4254228472709656, acc = 0.8525390625\n",
      "Batch 145: loss = 0.3547945022583008, acc = 0.8681640625\n",
      "Batch 146: loss = 0.4324948191642761, acc = 0.849609375\n",
      "Batch 147: loss = 0.4151502549648285, acc = 0.8662109375\n",
      "Batch 148: loss = 0.3522816002368927, acc = 0.892578125\n",
      "Batch 149: loss = 0.38933873176574707, acc = 0.8662109375\n",
      "Batch 150: loss = 0.42805957794189453, acc = 0.8515625\n",
      "Batch 151: loss = 0.4894317090511322, acc = 0.837890625\n",
      "Batch 152: loss = 0.3769112825393677, acc = 0.8818359375\n",
      "Batch 153: loss = 0.37977683544158936, acc = 0.869140625\n",
      "Batch 154: loss = 0.37722644209861755, acc = 0.8720703125\n",
      "Batch 155: loss = 0.4010354280471802, acc = 0.859375\n",
      "Batch 156: loss = 0.4878872334957123, acc = 0.830078125\n",
      "Batch 157: loss = 0.43383097648620605, acc = 0.8603515625\n",
      "Batch 158: loss = 0.4087192416191101, acc = 0.8603515625\n",
      "Batch 159: loss = 0.5054770708084106, acc = 0.8291015625\n",
      "Batch 160: loss = 0.42085951566696167, acc = 0.8564453125\n",
      "Batch 161: loss = 0.4096544086933136, acc = 0.86328125\n",
      "Batch 162: loss = 0.42753949761390686, acc = 0.8544921875\n",
      "Batch 163: loss = 0.4499205946922302, acc = 0.8623046875\n",
      "Batch 164: loss = 0.41875484585762024, acc = 0.8642578125\n",
      "Batch 165: loss = 0.43245190382003784, acc = 0.85546875\n",
      "Batch 166: loss = 0.3644983172416687, acc = 0.8681640625\n",
      "Batch 167: loss = 0.4007648527622223, acc = 0.8544921875\n",
      "Batch 168: loss = 0.4188249707221985, acc = 0.8544921875\n",
      "Batch 169: loss = 0.36411750316619873, acc = 0.87109375\n",
      "Batch 170: loss = 0.3594052195549011, acc = 0.892578125\n",
      "Batch 171: loss = 0.4506698250770569, acc = 0.8525390625\n",
      "Batch 172: loss = 0.3726397156715393, acc = 0.87109375\n",
      "Batch 173: loss = 0.39700499176979065, acc = 0.8828125\n",
      "Batch 174: loss = 0.3946457505226135, acc = 0.869140625\n",
      "Batch 175: loss = 0.4757731556892395, acc = 0.8388671875\n",
      "Batch 176: loss = 0.4237871766090393, acc = 0.8701171875\n",
      "Batch 177: loss = 0.3585820198059082, acc = 0.880859375\n",
      "Batch 178: loss = 0.3709823787212372, acc = 0.875\n",
      "Batch 179: loss = 0.390608549118042, acc = 0.869140625\n",
      "Batch 180: loss = 0.38562920689582825, acc = 0.8681640625\n",
      "Batch 181: loss = 0.36765605211257935, acc = 0.873046875\n",
      "Batch 182: loss = 0.38693252205848694, acc = 0.8798828125\n",
      "Batch 183: loss = 0.403531938791275, acc = 0.859375\n",
      "Batch 184: loss = 0.4220230281352997, acc = 0.8583984375\n",
      "Batch 185: loss = 0.3987053632736206, acc = 0.8662109375\n",
      "Batch 186: loss = 0.37915053963661194, acc = 0.876953125\n",
      "Batch 187: loss = 0.4139031767845154, acc = 0.85546875\n",
      "Batch 188: loss = 0.3680969476699829, acc = 0.892578125\n",
      "Batch 189: loss = 0.3583710491657257, acc = 0.876953125\n",
      "Batch 190: loss = 0.4081401824951172, acc = 0.8642578125\n",
      "Batch 191: loss = 0.4040963053703308, acc = 0.861328125\n",
      "Batch 192: loss = 0.39785638451576233, acc = 0.8662109375\n",
      "Batch 193: loss = 0.4416063129901886, acc = 0.8447265625\n",
      "Batch 194: loss = 0.40962645411491394, acc = 0.86328125\n",
      "Batch 195: loss = 0.41407716274261475, acc = 0.8583984375\n",
      "Batch 196: loss = 0.48710235953330994, acc = 0.837890625\n",
      "Batch 197: loss = 0.46101242303848267, acc = 0.8427734375\n",
      "Batch 198: loss = 0.36581456661224365, acc = 0.8798828125\n",
      "Batch 199: loss = 0.41538891196250916, acc = 0.857421875\n",
      "Batch 200: loss = 0.482774019241333, acc = 0.8447265625\n",
      "Batch 201: loss = 0.469418466091156, acc = 0.8427734375\n",
      "Batch 202: loss = 0.470712810754776, acc = 0.8515625\n",
      "Batch 203: loss = 0.40631425380706787, acc = 0.8662109375\n",
      "Batch 204: loss = 0.41813987493515015, acc = 0.8623046875\n",
      "Batch 205: loss = 0.42968884110450745, acc = 0.85546875\n",
      "Batch 206: loss = 0.423406720161438, acc = 0.8515625\n",
      "Batch 207: loss = 0.49890267848968506, acc = 0.828125\n",
      "Batch 208: loss = 0.4340152442455292, acc = 0.8525390625\n",
      "Batch 209: loss = 0.4177892208099365, acc = 0.8544921875\n",
      "Batch 210: loss = 0.4128468632698059, acc = 0.859375\n",
      "Batch 211: loss = 0.43480828404426575, acc = 0.8525390625\n",
      "Batch 212: loss = 0.4693959057331085, acc = 0.83984375\n",
      "Batch 213: loss = 0.4391940236091614, acc = 0.853515625\n",
      "Batch 214: loss = 0.41360703110694885, acc = 0.8525390625\n",
      "Batch 215: loss = 0.4157993197441101, acc = 0.8740234375\n",
      "Batch 216: loss = 0.3664400577545166, acc = 0.8701171875\n",
      "Batch 217: loss = 0.33619123697280884, acc = 0.8837890625\n",
      "Batch 218: loss = 0.3864215612411499, acc = 0.875\n",
      "Batch 219: loss = 0.4632616937160492, acc = 0.833984375\n",
      "Batch 220: loss = 0.3750196695327759, acc = 0.8662109375\n",
      "Batch 221: loss = 0.4719526767730713, acc = 0.833984375\n",
      "Batch 222: loss = 0.3855305016040802, acc = 0.8671875\n",
      "Batch 223: loss = 0.35355523228645325, acc = 0.8818359375\n",
      "Batch 224: loss = 0.3378951847553253, acc = 0.8671875\n",
      "Batch 225: loss = 0.3694138526916504, acc = 0.873046875\n",
      "Batch 226: loss = 0.4491868317127228, acc = 0.845703125\n",
      "Batch 227: loss = 0.3777439296245575, acc = 0.869140625\n",
      "Batch 228: loss = 0.3582216501235962, acc = 0.8837890625\n",
      "Batch 229: loss = 0.3727121949195862, acc = 0.8740234375\n",
      "Batch 230: loss = 0.3518616557121277, acc = 0.876953125\n",
      "Batch 231: loss = 0.4397949278354645, acc = 0.83984375\n",
      "Batch 232: loss = 0.3775986135005951, acc = 0.875\n",
      "Batch 233: loss = 0.46799659729003906, acc = 0.8447265625\n",
      "Batch 234: loss = 0.3818478584289551, acc = 0.869140625\n",
      "Batch 235: loss = 0.4323154091835022, acc = 0.8486328125\n",
      "Batch 236: loss = 0.44996178150177, acc = 0.861328125\n",
      "Batch 237: loss = 0.3971184492111206, acc = 0.86328125\n",
      "Batch 238: loss = 0.41916337609291077, acc = 0.84765625\n",
      "Batch 239: loss = 0.377855509519577, acc = 0.8759765625\n",
      "Batch 240: loss = 0.4418056607246399, acc = 0.8525390625\n",
      "Batch 241: loss = 0.38529181480407715, acc = 0.875\n",
      "Batch 242: loss = 0.44626858830451965, acc = 0.8466796875\n",
      "Batch 243: loss = 0.45885583758354187, acc = 0.8525390625\n",
      "Batch 244: loss = 0.4313080608844757, acc = 0.85546875\n",
      "Batch 245: loss = 0.37507110834121704, acc = 0.869140625\n",
      "Batch 246: loss = 0.4375626742839813, acc = 0.849609375\n",
      "Batch 247: loss = 0.44962894916534424, acc = 0.8486328125\n",
      "Batch 248: loss = 0.39473652839660645, acc = 0.8603515625\n",
      "Batch 249: loss = 0.3773059844970703, acc = 0.87890625\n",
      "Batch 250: loss = 0.42202919721603394, acc = 0.859375\n",
      "Batch 251: loss = 0.33164656162261963, acc = 0.87890625\n",
      "Batch 252: loss = 0.39306411147117615, acc = 0.8740234375\n",
      "Batch 253: loss = 0.4215376377105713, acc = 0.8583984375\n",
      "Batch 254: loss = 0.42708539962768555, acc = 0.845703125\n",
      "Batch 255: loss = 0.4892802834510803, acc = 0.8330078125\n",
      "Batch 256: loss = 0.42601215839385986, acc = 0.861328125\n",
      "Batch 257: loss = 0.49489495158195496, acc = 0.8369140625\n",
      "Batch 258: loss = 0.4305779039859772, acc = 0.841796875\n",
      "Batch 259: loss = 0.5183289647102356, acc = 0.83984375\n",
      "Batch 260: loss = 0.5172332525253296, acc = 0.8330078125\n",
      "Batch 261: loss = 0.41282278299331665, acc = 0.8603515625\n",
      "Batch 262: loss = 0.4449176788330078, acc = 0.8515625\n",
      "Batch 263: loss = 0.40648871660232544, acc = 0.8642578125\n",
      "Batch 264: loss = 0.43543702363967896, acc = 0.8515625\n",
      "Batch 265: loss = 0.4086553454399109, acc = 0.859375\n",
      "Batch 266: loss = 0.36944615840911865, acc = 0.880859375\n",
      "Batch 267: loss = 0.34128373861312866, acc = 0.8720703125\n",
      "Batch 268: loss = 0.40066373348236084, acc = 0.8583984375\n",
      "Batch 269: loss = 0.43280529975891113, acc = 0.8447265625\n",
      "Batch 270: loss = 0.39983731508255005, acc = 0.859375\n",
      "Batch 271: loss = 0.37417012453079224, acc = 0.8740234375\n",
      "Batch 272: loss = 0.38436636328697205, acc = 0.86328125\n",
      "Batch 273: loss = 0.38057228922843933, acc = 0.873046875\n",
      "Batch 274: loss = 0.41592803597450256, acc = 0.859375\n",
      "Batch 275: loss = 0.3844340443611145, acc = 0.86328125\n",
      "Batch 276: loss = 0.4610869288444519, acc = 0.83984375\n",
      "Batch 277: loss = 0.44178688526153564, acc = 0.859375\n",
      "Batch 278: loss = 0.3559468686580658, acc = 0.8681640625\n",
      "Batch 279: loss = 0.4303654432296753, acc = 0.8515625\n",
      "Batch 280: loss = 0.46505773067474365, acc = 0.841796875\n",
      "Batch 281: loss = 0.4346754550933838, acc = 0.85546875\n",
      "Batch 282: loss = 0.4497085213661194, acc = 0.8427734375\n",
      "Batch 283: loss = 0.4493713080883026, acc = 0.8515625\n",
      "Batch 284: loss = 0.4187595546245575, acc = 0.865234375\n",
      "Batch 285: loss = 0.46841058135032654, acc = 0.837890625\n",
      "Batch 286: loss = 0.4800663888454437, acc = 0.8330078125\n",
      "Batch 287: loss = 0.4625217616558075, acc = 0.84765625\n",
      "Batch 288: loss = 0.45736849308013916, acc = 0.853515625\n",
      "Batch 289: loss = 0.3827497661113739, acc = 0.8759765625\n",
      "Batch 290: loss = 0.41262662410736084, acc = 0.8505859375\n",
      "Batch 291: loss = 0.4563639163970947, acc = 0.84375\n",
      "Batch 292: loss = 0.40948134660720825, acc = 0.8681640625\n",
      "Batch 293: loss = 0.37484440207481384, acc = 0.869140625\n",
      "Batch 294: loss = 0.3963055908679962, acc = 0.8720703125\n",
      "Batch 295: loss = 0.40693938732147217, acc = 0.86328125\n",
      "Batch 296: loss = 0.38312816619873047, acc = 0.8779296875\n",
      "Batch 297: loss = 0.38375943899154663, acc = 0.873046875\n",
      "Batch 298: loss = 0.3756925165653229, acc = 0.8720703125\n",
      "Batch 299: loss = 0.37975451350212097, acc = 0.8740234375\n",
      "Batch 300: loss = 0.42148512601852417, acc = 0.8505859375\n",
      "Batch 301: loss = 0.4081915616989136, acc = 0.8623046875\n",
      "Batch 302: loss = 0.421294629573822, acc = 0.861328125\n",
      "Batch 303: loss = 0.4488399028778076, acc = 0.853515625\n",
      "Batch 304: loss = 0.37776118516921997, acc = 0.875\n",
      "Batch 305: loss = 0.3949165642261505, acc = 0.8671875\n",
      "Batch 306: loss = 0.4256819486618042, acc = 0.8583984375\n",
      "Batch 307: loss = 0.3374176025390625, acc = 0.8828125\n",
      "Batch 308: loss = 0.39797529578208923, acc = 0.853515625\n",
      "Batch 309: loss = 0.4044032692909241, acc = 0.86328125\n",
      "Batch 310: loss = 0.4201386868953705, acc = 0.857421875\n",
      "Batch 311: loss = 0.4231911599636078, acc = 0.8662109375\n",
      "Batch 312: loss = 0.33794131875038147, acc = 0.8857421875\n",
      "Batch 313: loss = 0.44900384545326233, acc = 0.8369140625\n",
      "Batch 314: loss = 0.45403343439102173, acc = 0.845703125\n",
      "Batch 315: loss = 0.38502785563468933, acc = 0.8671875\n",
      "Batch 316: loss = 0.3998822569847107, acc = 0.865234375\n",
      "Batch 317: loss = 0.409126877784729, acc = 0.8623046875\n",
      "Batch 318: loss = 0.41365960240364075, acc = 0.853515625\n",
      "Batch 319: loss = 0.44123247265815735, acc = 0.8515625\n",
      "Batch 320: loss = 0.4345718026161194, acc = 0.8525390625\n",
      "Batch 321: loss = 0.45551034808158875, acc = 0.8515625\n",
      "Batch 322: loss = 0.3877929151058197, acc = 0.876953125\n",
      "Batch 323: loss = 0.4700673818588257, acc = 0.84375\n",
      "Batch 324: loss = 0.4220045208930969, acc = 0.8603515625\n",
      "Batch 325: loss = 0.4658276438713074, acc = 0.83984375\n",
      "Batch 326: loss = 0.3897935748100281, acc = 0.87109375\n",
      "Batch 327: loss = 0.4028133153915405, acc = 0.84765625\n",
      "Batch 328: loss = 0.40704649686813354, acc = 0.8564453125\n",
      "Batch 329: loss = 0.43270760774612427, acc = 0.8505859375\n",
      "Batch 330: loss = 0.3849623501300812, acc = 0.8720703125\n",
      "Batch 331: loss = 0.40935570001602173, acc = 0.859375\n",
      "Batch 332: loss = 0.4125972390174866, acc = 0.8564453125\n",
      "Batch 333: loss = 0.4095907211303711, acc = 0.8583984375\n",
      "Batch 334: loss = 0.34942391514778137, acc = 0.8759765625\n",
      "Batch 335: loss = 0.3916299343109131, acc = 0.861328125\n",
      "Batch 336: loss = 0.42083656787872314, acc = 0.853515625\n",
      "Batch 337: loss = 0.45340365171432495, acc = 0.8486328125\n",
      "Batch 338: loss = 0.3884963095188141, acc = 0.8681640625\n",
      "Batch 339: loss = 0.4373611807823181, acc = 0.857421875\n",
      "Batch 340: loss = 0.39283323287963867, acc = 0.87109375\n",
      "Batch 341: loss = 0.4108566641807556, acc = 0.861328125\n",
      "Batch 342: loss = 0.45338577032089233, acc = 0.845703125\n",
      "Batch 343: loss = 0.36181437969207764, acc = 0.8779296875\n",
      "Batch 344: loss = 0.3447495400905609, acc = 0.890625\n",
      "Batch 345: loss = 0.38542434573173523, acc = 0.869140625\n",
      "Batch 346: loss = 0.36267250776290894, acc = 0.8740234375\n",
      "Batch 347: loss = 0.4346622824668884, acc = 0.8564453125\n",
      "Batch 348: loss = 0.37665218114852905, acc = 0.873046875\n",
      "Batch 349: loss = 0.34191372990608215, acc = 0.8798828125\n",
      "Batch 350: loss = 0.36059069633483887, acc = 0.8759765625\n",
      "Batch 351: loss = 0.32855698466300964, acc = 0.884765625\n",
      "Batch 352: loss = 0.39507749676704407, acc = 0.8466796875\n",
      "Batch 353: loss = 0.3887595236301422, acc = 0.869140625\n",
      "Batch 354: loss = 0.34534314274787903, acc = 0.8857421875\n",
      "Batch 355: loss = 0.2983091473579407, acc = 0.9052734375\n",
      "Batch 356: loss = 0.3534930348396301, acc = 0.8798828125\n",
      "Batch 357: loss = 0.3638079762458801, acc = 0.8701171875\n",
      "Batch 358: loss = 0.39593368768692017, acc = 0.8564453125\n",
      "Batch 359: loss = 0.3829250931739807, acc = 0.876953125\n",
      "Batch 360: loss = 0.3525121212005615, acc = 0.8876953125\n",
      "Batch 361: loss = 0.3741909861564636, acc = 0.875\n",
      "Batch 362: loss = 0.3616229295730591, acc = 0.884765625\n",
      "Batch 363: loss = 0.389240026473999, acc = 0.865234375\n",
      "Batch 364: loss = 0.4245540201663971, acc = 0.8564453125\n",
      "Batch 365: loss = 0.3940477967262268, acc = 0.8701171875\n",
      "Batch 366: loss = 0.37117862701416016, acc = 0.873046875\n",
      "Batch 367: loss = 0.35337668657302856, acc = 0.884765625\n",
      "Batch 368: loss = 0.41381293535232544, acc = 0.853515625\n",
      "Batch 369: loss = 0.4622400403022766, acc = 0.8359375\n",
      "Batch 370: loss = 0.3676438331604004, acc = 0.8818359375\n",
      "Batch 371: loss = 0.4416704773902893, acc = 0.8623046875\n",
      "Batch 372: loss = 0.37491488456726074, acc = 0.8720703125\n",
      "Batch 373: loss = 0.417793869972229, acc = 0.8544921875\n",
      "Batch 374: loss = 0.4636416435241699, acc = 0.8447265625\n",
      "Batch 375: loss = 0.45324626564979553, acc = 0.849609375\n",
      "Batch 376: loss = 0.4247497320175171, acc = 0.86328125\n",
      "Batch 377: loss = 0.44703051447868347, acc = 0.833984375\n",
      "Batch 378: loss = 0.41035670042037964, acc = 0.859375\n",
      "Batch 379: loss = 0.47515517473220825, acc = 0.8427734375\n",
      "Batch 380: loss = 0.402950257062912, acc = 0.85546875\n",
      "Batch 381: loss = 0.353651225566864, acc = 0.876953125\n",
      "Batch 382: loss = 0.39667144417762756, acc = 0.8740234375\n",
      "Batch 383: loss = 0.39214515686035156, acc = 0.8671875\n",
      "Batch 384: loss = 0.4317016303539276, acc = 0.861328125\n",
      "Batch 385: loss = 0.386101633310318, acc = 0.8740234375\n",
      "Batch 386: loss = 0.3632701635360718, acc = 0.876953125\n",
      "Batch 387: loss = 0.35204803943634033, acc = 0.876953125\n",
      "Batch 388: loss = 0.43007832765579224, acc = 0.85546875\n",
      "Batch 389: loss = 0.3930235505104065, acc = 0.8740234375\n",
      "Batch 390: loss = 0.46409183740615845, acc = 0.84765625\n",
      "Batch 391: loss = 0.44459861516952515, acc = 0.8291015625\n",
      "Batch 392: loss = 0.4026373326778412, acc = 0.86328125\n",
      "Batch 393: loss = 0.44484254717826843, acc = 0.8427734375\n",
      "Batch 394: loss = 0.39629247784614563, acc = 0.869140625\n",
      "Batch 395: loss = 0.38246792554855347, acc = 0.8623046875\n",
      "Batch 396: loss = 0.4000607132911682, acc = 0.8603515625\n",
      "Batch 397: loss = 0.3153713643550873, acc = 0.8935546875\n",
      "Batch 398: loss = 0.3514958918094635, acc = 0.8759765625\n",
      "Batch 399: loss = 0.37195006012916565, acc = 0.8779296875\n",
      "Batch 400: loss = 0.4001063406467438, acc = 0.8701171875\n",
      "Batch 401: loss = 0.3986801505088806, acc = 0.873046875\n",
      "Batch 402: loss = 0.42643409967422485, acc = 0.8515625\n",
      "Batch 403: loss = 0.36734190583229065, acc = 0.8740234375\n",
      "Batch 404: loss = 0.436240017414093, acc = 0.8515625\n",
      "Batch 405: loss = 0.43353933095932007, acc = 0.8505859375\n",
      "Batch 406: loss = 0.49171000719070435, acc = 0.833984375\n",
      "Batch 407: loss = 0.45093661546707153, acc = 0.849609375\n",
      "Batch 408: loss = 0.5356037616729736, acc = 0.8193359375\n",
      "Batch 409: loss = 0.44859784841537476, acc = 0.8466796875\n",
      "Batch 410: loss = 0.4760475158691406, acc = 0.8447265625\n",
      "Batch 411: loss = 0.4001525938510895, acc = 0.8701171875\n",
      "Batch 412: loss = 0.42004871368408203, acc = 0.86328125\n",
      "Batch 413: loss = 0.3864671587944031, acc = 0.875\n",
      "Batch 414: loss = 0.41299235820770264, acc = 0.8603515625\n",
      "Batch 415: loss = 0.398910254240036, acc = 0.857421875\n",
      "Batch 416: loss = 0.41590195894241333, acc = 0.8466796875\n",
      "Batch 417: loss = 0.3989405035972595, acc = 0.859375\n",
      "Batch 418: loss = 0.4609682559967041, acc = 0.8623046875\n",
      "Batch 419: loss = 0.5174108743667603, acc = 0.8212890625\n",
      "Batch 420: loss = 0.5005818605422974, acc = 0.8291015625\n",
      "Batch 421: loss = 0.4740430414676666, acc = 0.84375\n",
      "Batch 422: loss = 0.4723297357559204, acc = 0.8447265625\n",
      "Batch 423: loss = 0.4329543113708496, acc = 0.849609375\n",
      "Batch 424: loss = 0.45407015085220337, acc = 0.8466796875\n",
      "Batch 425: loss = 0.4209003448486328, acc = 0.8583984375\n",
      "Batch 426: loss = 0.44992905855178833, acc = 0.841796875\n",
      "Batch 427: loss = 0.42078378796577454, acc = 0.865234375\n",
      "Batch 428: loss = 0.4015655815601349, acc = 0.865234375\n",
      "Batch 429: loss = 0.39305272698402405, acc = 0.86328125\n",
      "Batch 430: loss = 0.3728504776954651, acc = 0.880859375\n",
      "Batch 431: loss = 0.40001925826072693, acc = 0.8623046875\n",
      "Batch 432: loss = 0.39355382323265076, acc = 0.8720703125\n",
      "Batch 433: loss = 0.3561950922012329, acc = 0.8759765625\n",
      "Batch 434: loss = 0.3886297643184662, acc = 0.8662109375\n",
      "Batch 435: loss = 0.4261946380138397, acc = 0.8447265625\n",
      "Batch 436: loss = 0.33790627121925354, acc = 0.89453125\n",
      "Batch 437: loss = 0.41666561365127563, acc = 0.85546875\n",
      "Batch 438: loss = 0.43516597151756287, acc = 0.841796875\n",
      "Batch 439: loss = 0.365390419960022, acc = 0.87890625\n",
      "Batch 440: loss = 0.42265650629997253, acc = 0.853515625\n",
      "Batch 441: loss = 0.3721460700035095, acc = 0.87109375\n",
      "\n",
      "Epoch 99/100\n",
      "Batch 1: loss = 0.510526180267334, acc = 0.830078125\n",
      "Batch 2: loss = 0.4106520414352417, acc = 0.859375\n",
      "Batch 3: loss = 0.4450058341026306, acc = 0.857421875\n",
      "Batch 4: loss = 0.4503329396247864, acc = 0.8466796875\n",
      "Batch 5: loss = 0.4466933012008667, acc = 0.8486328125\n",
      "Batch 6: loss = 0.3173179030418396, acc = 0.8984375\n",
      "Batch 7: loss = 0.3781648278236389, acc = 0.87890625\n",
      "Batch 8: loss = 0.37014660239219666, acc = 0.8779296875\n",
      "Batch 9: loss = 0.46249547600746155, acc = 0.8349609375\n",
      "Batch 10: loss = 0.4480746388435364, acc = 0.8486328125\n",
      "Batch 11: loss = 0.40968409180641174, acc = 0.8671875\n",
      "Batch 12: loss = 0.40529921650886536, acc = 0.8544921875\n",
      "Batch 13: loss = 0.47994381189346313, acc = 0.837890625\n",
      "Batch 14: loss = 0.3792679011821747, acc = 0.87109375\n",
      "Batch 15: loss = 0.3857133388519287, acc = 0.8564453125\n",
      "Batch 16: loss = 0.4110102653503418, acc = 0.8642578125\n",
      "Batch 17: loss = 0.3378194272518158, acc = 0.87890625\n",
      "Batch 18: loss = 0.43463781476020813, acc = 0.86328125\n",
      "Batch 19: loss = 0.42547595500946045, acc = 0.8564453125\n",
      "Batch 20: loss = 0.4828590750694275, acc = 0.8369140625\n",
      "Batch 21: loss = 0.4254125654697418, acc = 0.853515625\n",
      "Batch 22: loss = 0.4213152229785919, acc = 0.8564453125\n",
      "Batch 23: loss = 0.4363761246204376, acc = 0.8486328125\n",
      "Batch 24: loss = 0.39125537872314453, acc = 0.875\n",
      "Batch 25: loss = 0.44081738591194153, acc = 0.857421875\n",
      "Batch 26: loss = 0.38392186164855957, acc = 0.8662109375\n",
      "Batch 27: loss = 0.48096662759780884, acc = 0.8349609375\n",
      "Batch 28: loss = 0.41143593192100525, acc = 0.8623046875\n",
      "Batch 29: loss = 0.5112482309341431, acc = 0.8291015625\n",
      "Batch 30: loss = 0.47192615270614624, acc = 0.845703125\n",
      "Batch 31: loss = 0.3918348252773285, acc = 0.859375\n",
      "Batch 32: loss = 0.3337039053440094, acc = 0.8837890625\n",
      "Batch 33: loss = 0.3526887595653534, acc = 0.8779296875\n",
      "Batch 34: loss = 0.3305811882019043, acc = 0.8916015625\n",
      "Batch 35: loss = 0.3542790412902832, acc = 0.884765625\n",
      "Batch 36: loss = 0.4180753231048584, acc = 0.857421875\n",
      "Batch 37: loss = 0.3748065233230591, acc = 0.8779296875\n",
      "Batch 38: loss = 0.3927953243255615, acc = 0.8701171875\n",
      "Batch 39: loss = 0.33410322666168213, acc = 0.892578125\n",
      "Batch 40: loss = 0.3805495798587799, acc = 0.8671875\n",
      "Batch 41: loss = 0.3427431285381317, acc = 0.8876953125\n",
      "Batch 42: loss = 0.4255583882331848, acc = 0.853515625\n",
      "Batch 43: loss = 0.44259148836135864, acc = 0.845703125\n",
      "Batch 44: loss = 0.44035398960113525, acc = 0.845703125\n",
      "Batch 45: loss = 0.404737263917923, acc = 0.8759765625\n",
      "Batch 46: loss = 0.39540788531303406, acc = 0.8681640625\n",
      "Batch 47: loss = 0.378658652305603, acc = 0.869140625\n",
      "Batch 48: loss = 0.380249559879303, acc = 0.8701171875\n",
      "Batch 49: loss = 0.3937446177005768, acc = 0.8623046875\n",
      "Batch 50: loss = 0.4177587628364563, acc = 0.8544921875\n",
      "Batch 51: loss = 0.4049907624721527, acc = 0.8623046875\n",
      "Batch 52: loss = 0.38004040718078613, acc = 0.87890625\n",
      "Batch 53: loss = 0.4179064631462097, acc = 0.86328125\n",
      "Batch 54: loss = 0.3785342574119568, acc = 0.8720703125\n",
      "Batch 55: loss = 0.40544652938842773, acc = 0.8505859375\n",
      "Batch 56: loss = 0.4319130480289459, acc = 0.8564453125\n",
      "Batch 57: loss = 0.4181366562843323, acc = 0.857421875\n",
      "Batch 58: loss = 0.35285133123397827, acc = 0.8798828125\n",
      "Batch 59: loss = 0.43748050928115845, acc = 0.8564453125\n",
      "Batch 60: loss = 0.38587069511413574, acc = 0.8759765625\n",
      "Batch 61: loss = 0.40825507044792175, acc = 0.865234375\n",
      "Batch 62: loss = 0.4057038128376007, acc = 0.8583984375\n",
      "Batch 63: loss = 0.42410942912101746, acc = 0.8505859375\n",
      "Batch 64: loss = 0.3537582457065582, acc = 0.884765625\n",
      "Batch 65: loss = 0.3379015326499939, acc = 0.890625\n",
      "Batch 66: loss = 0.382293701171875, acc = 0.876953125\n",
      "Batch 67: loss = 0.4081982374191284, acc = 0.859375\n",
      "Batch 68: loss = 0.4487307071685791, acc = 0.8525390625\n",
      "Batch 69: loss = 0.3962191045284271, acc = 0.8759765625\n",
      "Batch 70: loss = 0.42975592613220215, acc = 0.86328125\n",
      "Batch 71: loss = 0.43595826625823975, acc = 0.8427734375\n",
      "Batch 72: loss = 0.4600702226161957, acc = 0.837890625\n",
      "Batch 73: loss = 0.3954971432685852, acc = 0.865234375\n",
      "Batch 74: loss = 0.4367395341396332, acc = 0.869140625\n",
      "Batch 75: loss = 0.35040396451950073, acc = 0.8798828125\n",
      "Batch 76: loss = 0.46753284335136414, acc = 0.8330078125\n",
      "Batch 77: loss = 0.47448304295539856, acc = 0.82421875\n",
      "Batch 78: loss = 0.4539873003959656, acc = 0.8427734375\n",
      "Batch 79: loss = 0.38796013593673706, acc = 0.865234375\n",
      "Batch 80: loss = 0.5180556774139404, acc = 0.830078125\n",
      "Batch 81: loss = 0.42139098048210144, acc = 0.8525390625\n",
      "Batch 82: loss = 0.40494096279144287, acc = 0.869140625\n",
      "Batch 83: loss = 0.41641080379486084, acc = 0.8583984375\n",
      "Batch 84: loss = 0.3737378716468811, acc = 0.88671875\n",
      "Batch 85: loss = 0.43201616406440735, acc = 0.8544921875\n",
      "Batch 86: loss = 0.4194919764995575, acc = 0.859375\n",
      "Batch 87: loss = 0.3675805926322937, acc = 0.876953125\n",
      "Batch 88: loss = 0.4334738254547119, acc = 0.861328125\n",
      "Batch 89: loss = 0.47418949007987976, acc = 0.841796875\n",
      "Batch 90: loss = 0.42451274394989014, acc = 0.865234375\n",
      "Batch 91: loss = 0.4254755973815918, acc = 0.8525390625\n",
      "Batch 92: loss = 0.41257622838020325, acc = 0.85546875\n",
      "Batch 93: loss = 0.46325233578681946, acc = 0.8310546875\n",
      "Batch 94: loss = 0.45543867349624634, acc = 0.853515625\n",
      "Batch 95: loss = 0.40284261107444763, acc = 0.869140625\n",
      "Batch 96: loss = 0.37176549434661865, acc = 0.8701171875\n",
      "Batch 97: loss = 0.4560149908065796, acc = 0.8369140625\n",
      "Batch 98: loss = 0.4690403938293457, acc = 0.8408203125\n",
      "Batch 99: loss = 0.4563116431236267, acc = 0.8447265625\n",
      "Batch 100: loss = 0.4723762273788452, acc = 0.8349609375\n",
      "Batch 101: loss = 0.39098232984542847, acc = 0.865234375\n",
      "Batch 102: loss = 0.3728335499763489, acc = 0.87890625\n",
      "Batch 103: loss = 0.37984389066696167, acc = 0.8642578125\n",
      "Batch 104: loss = 0.4305691719055176, acc = 0.8525390625\n",
      "Batch 105: loss = 0.3961024284362793, acc = 0.87109375\n",
      "Batch 106: loss = 0.4223081171512604, acc = 0.8583984375\n",
      "Batch 107: loss = 0.4284164011478424, acc = 0.865234375\n",
      "Batch 108: loss = 0.48029953241348267, acc = 0.849609375\n",
      "Batch 109: loss = 0.3609793782234192, acc = 0.87890625\n",
      "Batch 110: loss = 0.43605732917785645, acc = 0.861328125\n",
      "Batch 111: loss = 0.4705173969268799, acc = 0.8349609375\n",
      "Batch 112: loss = 0.41442885994911194, acc = 0.861328125\n",
      "Batch 113: loss = 0.3909320533275604, acc = 0.8720703125\n",
      "Batch 114: loss = 0.3391404449939728, acc = 0.8828125\n",
      "Batch 115: loss = 0.4461580514907837, acc = 0.8427734375\n",
      "Batch 116: loss = 0.40085816383361816, acc = 0.859375\n",
      "Batch 117: loss = 0.42390820384025574, acc = 0.861328125\n",
      "Batch 118: loss = 0.4155064821243286, acc = 0.8583984375\n",
      "Batch 119: loss = 0.4298557937145233, acc = 0.84765625\n",
      "Batch 120: loss = 0.43700966238975525, acc = 0.8486328125\n",
      "Batch 121: loss = 0.44341355562210083, acc = 0.86328125\n",
      "Batch 122: loss = 0.41454562544822693, acc = 0.857421875\n",
      "Batch 123: loss = 0.40360140800476074, acc = 0.865234375\n",
      "Batch 124: loss = 0.4222700595855713, acc = 0.857421875\n",
      "Batch 125: loss = 0.42374342679977417, acc = 0.8681640625\n",
      "Batch 126: loss = 0.38173797726631165, acc = 0.873046875\n",
      "Batch 127: loss = 0.42799240350723267, acc = 0.875\n",
      "Batch 128: loss = 0.41574716567993164, acc = 0.8603515625\n",
      "Batch 129: loss = 0.3932725191116333, acc = 0.8720703125\n",
      "Batch 130: loss = 0.3955504298210144, acc = 0.861328125\n",
      "Batch 131: loss = 0.33886173367500305, acc = 0.88671875\n",
      "Batch 132: loss = 0.31196385622024536, acc = 0.890625\n",
      "Batch 133: loss = 0.36821043491363525, acc = 0.876953125\n",
      "Batch 134: loss = 0.3817329406738281, acc = 0.87109375\n",
      "Batch 135: loss = 0.4756426215171814, acc = 0.8544921875\n",
      "Batch 136: loss = 0.418154776096344, acc = 0.8564453125\n",
      "Batch 137: loss = 0.38066962361335754, acc = 0.8720703125\n",
      "Batch 138: loss = 0.3898105323314667, acc = 0.8701171875\n",
      "Batch 139: loss = 0.37542620301246643, acc = 0.875\n",
      "Batch 140: loss = 0.375482439994812, acc = 0.8798828125\n",
      "Batch 141: loss = 0.406603068113327, acc = 0.865234375\n",
      "Batch 142: loss = 0.4546760618686676, acc = 0.8515625\n",
      "Batch 143: loss = 0.43661314249038696, acc = 0.8505859375\n",
      "Batch 144: loss = 0.4421139657497406, acc = 0.859375\n",
      "Batch 145: loss = 0.3660554587841034, acc = 0.865234375\n",
      "Batch 146: loss = 0.4255674481391907, acc = 0.8564453125\n",
      "Batch 147: loss = 0.3838312029838562, acc = 0.8681640625\n",
      "Batch 148: loss = 0.3624763786792755, acc = 0.8740234375\n",
      "Batch 149: loss = 0.4094744920730591, acc = 0.8515625\n",
      "Batch 150: loss = 0.4460415542125702, acc = 0.853515625\n",
      "Batch 151: loss = 0.42007410526275635, acc = 0.85546875\n",
      "Batch 152: loss = 0.4071900248527527, acc = 0.861328125\n",
      "Batch 153: loss = 0.4316027760505676, acc = 0.8486328125\n",
      "Batch 154: loss = 0.43610602617263794, acc = 0.8623046875\n",
      "Batch 155: loss = 0.38578000664711, acc = 0.8701171875\n",
      "Batch 156: loss = 0.4703587293624878, acc = 0.830078125\n",
      "Batch 157: loss = 0.4372963309288025, acc = 0.8623046875\n",
      "Batch 158: loss = 0.4141416549682617, acc = 0.8583984375\n",
      "Batch 159: loss = 0.44738471508026123, acc = 0.841796875\n",
      "Batch 160: loss = 0.43710246682167053, acc = 0.859375\n",
      "Batch 161: loss = 0.4489596486091614, acc = 0.837890625\n",
      "Batch 162: loss = 0.42442381381988525, acc = 0.8583984375\n",
      "Batch 163: loss = 0.40388715267181396, acc = 0.865234375\n",
      "Batch 164: loss = 0.40516841411590576, acc = 0.865234375\n",
      "Batch 165: loss = 0.39767614006996155, acc = 0.8515625\n",
      "Batch 166: loss = 0.3827534019947052, acc = 0.8642578125\n",
      "Batch 167: loss = 0.36800578236579895, acc = 0.8759765625\n",
      "Batch 168: loss = 0.40774834156036377, acc = 0.86328125\n",
      "Batch 169: loss = 0.3510090708732605, acc = 0.87890625\n",
      "Batch 170: loss = 0.38812246918678284, acc = 0.8681640625\n",
      "Batch 171: loss = 0.3969441056251526, acc = 0.86328125\n",
      "Batch 172: loss = 0.382432758808136, acc = 0.8818359375\n",
      "Batch 173: loss = 0.3715752363204956, acc = 0.865234375\n",
      "Batch 174: loss = 0.3867887854576111, acc = 0.87109375\n",
      "Batch 175: loss = 0.41738229990005493, acc = 0.8544921875\n",
      "Batch 176: loss = 0.42082011699676514, acc = 0.861328125\n",
      "Batch 177: loss = 0.35311242938041687, acc = 0.8837890625\n",
      "Batch 178: loss = 0.3741084337234497, acc = 0.873046875\n",
      "Batch 179: loss = 0.4798907935619354, acc = 0.828125\n",
      "Batch 180: loss = 0.3861088156700134, acc = 0.8681640625\n",
      "Batch 181: loss = 0.4182477295398712, acc = 0.8544921875\n",
      "Batch 182: loss = 0.41151776909828186, acc = 0.84765625\n",
      "Batch 183: loss = 0.3823385536670685, acc = 0.861328125\n",
      "Batch 184: loss = 0.4515507221221924, acc = 0.8486328125\n",
      "Batch 185: loss = 0.43406879901885986, acc = 0.8623046875\n",
      "Batch 186: loss = 0.3872703015804291, acc = 0.876953125\n",
      "Batch 187: loss = 0.405936062335968, acc = 0.859375\n",
      "Batch 188: loss = 0.3917694687843323, acc = 0.8720703125\n",
      "Batch 189: loss = 0.3874848484992981, acc = 0.8701171875\n",
      "Batch 190: loss = 0.4435955584049225, acc = 0.8486328125\n",
      "Batch 191: loss = 0.43014979362487793, acc = 0.841796875\n",
      "Batch 192: loss = 0.35344284772872925, acc = 0.8896484375\n",
      "Batch 193: loss = 0.43656885623931885, acc = 0.8515625\n",
      "Batch 194: loss = 0.39399027824401855, acc = 0.8701171875\n",
      "Batch 195: loss = 0.39651036262512207, acc = 0.857421875\n",
      "Batch 196: loss = 0.5012737512588501, acc = 0.8291015625\n",
      "Batch 197: loss = 0.4802019000053406, acc = 0.84375\n",
      "Batch 198: loss = 0.3827206790447235, acc = 0.8759765625\n",
      "Batch 199: loss = 0.4434581398963928, acc = 0.85546875\n",
      "Batch 200: loss = 0.44835346937179565, acc = 0.84765625\n",
      "Batch 201: loss = 0.418573796749115, acc = 0.859375\n",
      "Batch 202: loss = 0.4652218520641327, acc = 0.84375\n",
      "Batch 203: loss = 0.4096013009548187, acc = 0.8623046875\n",
      "Batch 204: loss = 0.435528963804245, acc = 0.85546875\n",
      "Batch 205: loss = 0.430685430765152, acc = 0.8583984375\n",
      "Batch 206: loss = 0.44521525502204895, acc = 0.8544921875\n",
      "Batch 207: loss = 0.5156757831573486, acc = 0.833984375\n",
      "Batch 208: loss = 0.44345030188560486, acc = 0.853515625\n",
      "Batch 209: loss = 0.4146840572357178, acc = 0.8623046875\n",
      "Batch 210: loss = 0.41696977615356445, acc = 0.8544921875\n",
      "Batch 211: loss = 0.4089308977127075, acc = 0.86328125\n",
      "Batch 212: loss = 0.4557642936706543, acc = 0.849609375\n",
      "Batch 213: loss = 0.43865767121315, acc = 0.8466796875\n",
      "Batch 214: loss = 0.40897366404533386, acc = 0.8603515625\n",
      "Batch 215: loss = 0.3912944793701172, acc = 0.8662109375\n",
      "Batch 216: loss = 0.36114779114723206, acc = 0.8798828125\n",
      "Batch 217: loss = 0.3575397729873657, acc = 0.87890625\n",
      "Batch 218: loss = 0.39125409722328186, acc = 0.8603515625\n",
      "Batch 219: loss = 0.43271583318710327, acc = 0.8701171875\n",
      "Batch 220: loss = 0.37902623414993286, acc = 0.87890625\n",
      "Batch 221: loss = 0.4144623279571533, acc = 0.8583984375\n",
      "Batch 222: loss = 0.37335091829299927, acc = 0.87890625\n",
      "Batch 223: loss = 0.355442613363266, acc = 0.87109375\n",
      "Batch 224: loss = 0.3534471392631531, acc = 0.873046875\n",
      "Batch 225: loss = 0.37590715289115906, acc = 0.87109375\n",
      "Batch 226: loss = 0.41783374547958374, acc = 0.857421875\n",
      "Batch 227: loss = 0.4169502854347229, acc = 0.8662109375\n",
      "Batch 228: loss = 0.3622027635574341, acc = 0.8837890625\n",
      "Batch 229: loss = 0.35002124309539795, acc = 0.8759765625\n",
      "Batch 230: loss = 0.34240373969078064, acc = 0.8916015625\n",
      "Batch 231: loss = 0.45608097314834595, acc = 0.8486328125\n",
      "Batch 232: loss = 0.41639015078544617, acc = 0.8544921875\n",
      "Batch 233: loss = 0.4923155903816223, acc = 0.8349609375\n",
      "Batch 234: loss = 0.4020914137363434, acc = 0.8701171875\n",
      "Batch 235: loss = 0.39257878065109253, acc = 0.8623046875\n",
      "Batch 236: loss = 0.4576800763607025, acc = 0.8525390625\n",
      "Batch 237: loss = 0.38963252305984497, acc = 0.8701171875\n",
      "Batch 238: loss = 0.42545995116233826, acc = 0.857421875\n",
      "Batch 239: loss = 0.3536612093448639, acc = 0.8779296875\n",
      "Batch 240: loss = 0.4096599817276001, acc = 0.873046875\n",
      "Batch 241: loss = 0.4147660434246063, acc = 0.869140625\n",
      "Batch 242: loss = 0.46654587984085083, acc = 0.8447265625\n",
      "Batch 243: loss = 0.43747594952583313, acc = 0.8564453125\n",
      "Batch 244: loss = 0.45885494351387024, acc = 0.845703125\n",
      "Batch 245: loss = 0.4015596807003021, acc = 0.865234375\n",
      "Batch 246: loss = 0.45297715067863464, acc = 0.85546875\n",
      "2022-07-23 07:02:50.712437: W tensorflow/core/data/root_dataset.cc:200] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "Batch 247: loss = 0.42002108693122864, acc = 0.8603515625\n",
      "2022-07-23 07:02:50.739803: W tensorflow/core/data/root_dataset.cc:200] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "Batch 248: loss = 0.40360668301582336, acc = 0.8623046875\n",
      "Batch 249: loss = 0.3471011519432068, acc = 0.88671875\n",
      "Batch 250: loss = 0.41716715693473816, acc = 0.8603515625\n",
      "Batch 251: loss = 0.32313311100006104, acc = 0.8994140625\n",
      "Batch 252: loss = 0.3470558524131775, acc = 0.890625\n",
      "Batch 253: loss = 0.4312674105167389, acc = 0.853515625\n",
      "Batch 254: loss = 0.467441588640213, acc = 0.8310546875\n",
      "Batch 255: loss = 0.48680317401885986, acc = 0.8330078125\n",
      "Batch 256: loss = 0.40924572944641113, acc = 0.8544921875\n",
      "Batch 257: loss = 0.4655784070491791, acc = 0.8271484375\n",
      "Batch 258: loss = 0.44986939430236816, acc = 0.84765625\n",
      "Batch 259: loss = 0.5063934922218323, acc = 0.8310546875\n",
      "Batch 260: loss = 0.5183466672897339, acc = 0.82421875\n",
      "Batch 261: loss = 0.44113242626190186, acc = 0.861328125\n",
      "Batch 262: loss = 0.43525752425193787, acc = 0.8359375\n",
      "Batch 263: loss = 0.4189673662185669, acc = 0.8544921875\n",
      "Batch 264: loss = 0.4200315773487091, acc = 0.8466796875\n",
      "Batch 265: loss = 0.3834937512874603, acc = 0.869140625\n",
      "Batch 266: loss = 0.37023282051086426, acc = 0.8701171875\n",
      "Batch 267: loss = 0.3441072702407837, acc = 0.8740234375\n",
      "Batch 268: loss = 0.4051775336265564, acc = 0.87109375\n",
      "Batch 269: loss = 0.4427642822265625, acc = 0.8544921875\n",
      "Batch 270: loss = 0.390870064496994, acc = 0.8701171875\n",
      "Batch 271: loss = 0.3985064625740051, acc = 0.8544921875\n",
      "Batch 272: loss = 0.4214995205402374, acc = 0.841796875\n",
      "Batch 273: loss = 0.47948962450027466, acc = 0.8544921875\n",
      "Batch 274: loss = 0.44718092679977417, acc = 0.8544921875\n",
      "Batch 275: loss = 0.38521260023117065, acc = 0.8671875\n",
      "Batch 276: loss = 0.4413904845714569, acc = 0.849609375\n",
      "Batch 277: loss = 0.4437980055809021, acc = 0.845703125\n",
      "2022-07-23 07:02:51.592467: W tensorflow/core/data/root_dataset.cc:200] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "Batch 278: loss = 0.38923022150993347, acc = 0.8779296875\n",
      "Batch 279: loss = 0.4385966956615448, acc = 0.8505859375\n",
      "Batch 280: loss = 0.49009954929351807, acc = 0.84375\n",
      "Batch 281: loss = 0.44815531373023987, acc = 0.8369140625\n",
      "Batch 282: loss = 0.4141947329044342, acc = 0.8642578125\n",
      "Batch 283: loss = 0.47480660676956177, acc = 0.8388671875\n",
      "Batch 284: loss = 0.47553378343582153, acc = 0.845703125\n",
      "Batch 285: loss = 0.44071266055107117, acc = 0.849609375\n",
      "Batch 286: loss = 0.4652049243450165, acc = 0.83984375\n",
      "Batch 287: loss = 0.49304908514022827, acc = 0.83984375\n",
      "Batch 288: loss = 0.45303088426589966, acc = 0.8388671875\n",
      "Batch 289: loss = 0.3903524577617645, acc = 0.869140625\n",
      "Batch 290: loss = 0.4570538103580475, acc = 0.837890625\n",
      "Batch 291: loss = 0.4454817771911621, acc = 0.8564453125\n",
      "Batch 292: loss = 0.44390201568603516, acc = 0.8466796875\n",
      "Batch 293: loss = 0.40991294384002686, acc = 0.859375\n",
      "Batch 294: loss = 0.3980812430381775, acc = 0.8583984375\n",
      "Batch 295: loss = 0.40160077810287476, acc = 0.861328125\n",
      "Batch 296: loss = 0.3910274803638458, acc = 0.869140625\n",
      "Batch 297: loss = 0.35293689370155334, acc = 0.880859375\n",
      "Batch 298: loss = 0.3351709544658661, acc = 0.890625\n",
      "Batch 299: loss = 0.3716219961643219, acc = 0.8701171875\n",
      "2022-07-23 07:02:52.247921: W tensorflow/core/data/root_dataset.cc:200] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "Batch 300: loss = 0.4368715286254883, acc = 0.859375\n",
      "Batch 301: loss = 0.45134738087654114, acc = 0.861328125\n",
      "Batch 302: loss = 0.3759844899177551, acc = 0.8876953125\n",
      "2022-07-23 07:02:52.348021: W tensorflow/core/data/root_dataset.cc:200] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "Batch 303: loss = 0.4545493721961975, acc = 0.853515625\n",
      "Batch 304: loss = 0.3757002055644989, acc = 0.869140625\n",
      "Batch 305: loss = 0.40290504693984985, acc = 0.8525390625\n",
      "Batch 306: loss = 0.45237740874290466, acc = 0.8515625\n",
      "Batch 307: loss = 0.3549956977367401, acc = 0.8818359375\n",
      "Batch 308: loss = 0.4472821056842804, acc = 0.849609375\n",
      "Batch 309: loss = 0.39966821670532227, acc = 0.8671875\n",
      "Batch 310: loss = 0.4394732117652893, acc = 0.8447265625\n",
      "2022-07-23 07:02:52.633519: W tensorflow/core/data/root_dataset.cc:200] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "Batch 311: loss = 0.4403716027736664, acc = 0.861328125\n",
      "Batch 312: loss = 0.3595331311225891, acc = 0.880859375\n",
      "Batch 313: loss = 0.46755707263946533, acc = 0.84375\n",
      "2022-07-23 07:02:52.734501: W tensorflow/core/data/root_dataset.cc:200] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "Batch 314: loss = 0.43886327743530273, acc = 0.845703125\n",
      "Batch 315: loss = 0.4260127544403076, acc = 0.84765625\n",
      "2022-07-23 07:02:52.786689: W tensorflow/core/data/root_dataset.cc:200] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "Batch 316: loss = 0.3852119743824005, acc = 0.8623046875\n",
      "Batch 317: loss = 0.43733343482017517, acc = 0.8486328125\n",
      "Batch 318: loss = 0.41119205951690674, acc = 0.8564453125\n",
      "Batch 319: loss = 0.4384429454803467, acc = 0.8466796875\n",
      "Batch 320: loss = 0.4198352098464966, acc = 0.8564453125\n",
      "Batch 321: loss = 0.4489724040031433, acc = 0.8564453125\n",
      "Batch 322: loss = 0.38419654965400696, acc = 0.8720703125\n",
      "Batch 323: loss = 0.4333627223968506, acc = 0.849609375\n",
      "Batch 324: loss = 0.39221125841140747, acc = 0.86328125\n",
      "Batch 325: loss = 0.4285111427307129, acc = 0.8515625\n",
      "2022-07-23 07:02:53.068924: W tensorflow/core/data/root_dataset.cc:200] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "Batch 326: loss = 0.395612895488739, acc = 0.86328125\n",
      "2022-07-23 07:02:53.098448: W tensorflow/core/data/root_dataset.cc:200] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "Batch 327: loss = 0.3755927085876465, acc = 0.875\n",
      "Batch 328: loss = 0.4253356158733368, acc = 0.861328125\n",
      "Batch 329: loss = 0.488231360912323, acc = 0.84765625\n",
      "Batch 330: loss = 0.39779171347618103, acc = 0.859375\n",
      "Batch 331: loss = 0.4065237045288086, acc = 0.8662109375\n",
      "2022-07-23 07:02:53.242618: W tensorflow/core/data/root_dataset.cc:200] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "Batch 332: loss = 0.38893380761146545, acc = 0.8623046875\n",
      "Batch 333: loss = 0.40488263964653015, acc = 0.857421875\n",
      "2022-07-23 07:02:53.300826: W tensorflow/core/data/root_dataset.cc:200] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "Batch 334: loss = 0.3273504674434662, acc = 0.8857421875\n",
      "Batch 335: loss = 0.4448093771934509, acc = 0.849609375\n",
      "2022-07-23 07:02:53.359629: W tensorflow/core/data/root_dataset.cc:200] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "Batch 336: loss = 0.4374412000179291, acc = 0.8564453125\n",
      "Batch 337: loss = 0.4460206627845764, acc = 0.8447265625\n",
      "Batch 338: loss = 0.37929078936576843, acc = 0.8740234375\n",
      "Batch 339: loss = 0.4071875214576721, acc = 0.8662109375\n",
      "Batch 340: loss = 0.3749288320541382, acc = 0.87890625\n",
      "Batch 341: loss = 0.40330302715301514, acc = 0.8671875\n",
      "Batch 342: loss = 0.4408663511276245, acc = 0.857421875\n",
      "Batch 343: loss = 0.35150617361068726, acc = 0.8720703125\n",
      "Batch 344: loss = 0.37027862668037415, acc = 0.8779296875\n",
      "Batch 345: loss = 0.3607836365699768, acc = 0.8779296875\n",
      "Batch 346: loss = 0.35350847244262695, acc = 0.8798828125\n",
      "Batch 347: loss = 0.44490522146224976, acc = 0.849609375\n",
      "Batch 348: loss = 0.39803218841552734, acc = 0.8505859375\n",
      "Batch 349: loss = 0.3924156427383423, acc = 0.8662109375\n",
      "Batch 350: loss = 0.3405969738960266, acc = 0.890625\n",
      "Batch 351: loss = 0.3496773838996887, acc = 0.884765625\n",
      "Batch 352: loss = 0.4073615074157715, acc = 0.853515625\n",
      "Batch 353: loss = 0.3855476379394531, acc = 0.8701171875\n",
      "Batch 354: loss = 0.3329394459724426, acc = 0.8876953125\n",
      "Batch 355: loss = 0.31712064146995544, acc = 0.8974609375\n",
      "Batch 356: loss = 0.3655618727207184, acc = 0.8818359375\n",
      "Batch 357: loss = 0.3836633265018463, acc = 0.865234375\n",
      "Batch 358: loss = 0.38918447494506836, acc = 0.86328125\n",
      "Batch 359: loss = 0.416237473487854, acc = 0.8544921875\n",
      "Batch 360: loss = 0.37300601601600647, acc = 0.87890625\n",
      "Batch 361: loss = 0.3850620985031128, acc = 0.8623046875\n",
      "Batch 362: loss = 0.36242368817329407, acc = 0.8837890625\n",
      "Batch 363: loss = 0.404470294713974, acc = 0.85546875\n",
      "Batch 364: loss = 0.3927174210548401, acc = 0.8671875\n",
      "Batch 365: loss = 0.39510083198547363, acc = 0.857421875\n",
      "Batch 366: loss = 0.4047723412513733, acc = 0.85546875\n",
      "Batch 367: loss = 0.3904346525669098, acc = 0.865234375\n",
      "Batch 368: loss = 0.4201246201992035, acc = 0.84375\n",
      "Batch 369: loss = 0.47436878085136414, acc = 0.8388671875\n",
      "Batch 370: loss = 0.37539049983024597, acc = 0.876953125\n",
      "Batch 371: loss = 0.4629785716533661, acc = 0.83984375\n",
      "Batch 372: loss = 0.36023837327957153, acc = 0.8720703125\n",
      "Batch 373: loss = 0.40470269322395325, acc = 0.8515625\n",
      "Batch 374: loss = 0.42885714769363403, acc = 0.85546875\n",
      "Batch 375: loss = 0.46544507145881653, acc = 0.83984375\n",
      "Batch 376: loss = 0.4109533131122589, acc = 0.8505859375\n",
      "Batch 377: loss = 0.4533516764640808, acc = 0.8466796875\n",
      "Batch 378: loss = 0.40867501497268677, acc = 0.869140625\n",
      "Batch 379: loss = 0.4433348774909973, acc = 0.8525390625\n",
      "Batch 380: loss = 0.36932116746902466, acc = 0.8837890625\n",
      "Batch 381: loss = 0.3536496162414551, acc = 0.87890625\n",
      "Batch 382: loss = 0.43366891145706177, acc = 0.861328125\n",
      "Batch 383: loss = 0.3813353180885315, acc = 0.8662109375\n",
      "Batch 384: loss = 0.4231750965118408, acc = 0.8515625\n",
      "Batch 385: loss = 0.3817186653614044, acc = 0.8720703125\n",
      "Batch 386: loss = 0.3982052505016327, acc = 0.8671875\n",
      "Batch 387: loss = 0.34664252400398254, acc = 0.8798828125\n",
      "Batch 388: loss = 0.4169635474681854, acc = 0.8544921875\n",
      "Batch 389: loss = 0.4024640917778015, acc = 0.8583984375\n",
      "Batch 390: loss = 0.4281283915042877, acc = 0.8486328125\n",
      "Batch 391: loss = 0.39839452505111694, acc = 0.8671875\n",
      "Batch 392: loss = 0.4325145184993744, acc = 0.853515625\n",
      "Batch 393: loss = 0.45339179039001465, acc = 0.8447265625\n",
      "Batch 394: loss = 0.36365780234336853, acc = 0.880859375\n",
      "Batch 395: loss = 0.3735477328300476, acc = 0.8603515625\n",
      "Batch 396: loss = 0.40506190061569214, acc = 0.8603515625\n",
      "Batch 397: loss = 0.34814631938934326, acc = 0.8779296875\n",
      "Batch 398: loss = 0.3498710095882416, acc = 0.8798828125\n",
      "Batch 399: loss = 0.4041656255722046, acc = 0.861328125\n",
      "Batch 400: loss = 0.39588114619255066, acc = 0.8779296875\n",
      "Batch 401: loss = 0.39434054493904114, acc = 0.8720703125\n",
      "Batch 402: loss = 0.4523221552371979, acc = 0.845703125\n",
      "Batch 403: loss = 0.3814198076725006, acc = 0.8720703125\n",
      "Batch 404: loss = 0.45606935024261475, acc = 0.84375\n",
      "Batch 405: loss = 0.4752543568611145, acc = 0.8525390625\n",
      "Batch 406: loss = 0.48342135548591614, acc = 0.849609375\n",
      "Batch 407: loss = 0.42435115575790405, acc = 0.8525390625\n",
      "Batch 408: loss = 0.5383341312408447, acc = 0.822265625\n",
      "Batch 409: loss = 0.43899205327033997, acc = 0.8486328125\n",
      "Batch 410: loss = 0.46267691254615784, acc = 0.8505859375\n",
      "Batch 411: loss = 0.39367491006851196, acc = 0.869140625\n",
      "Batch 412: loss = 0.43309542536735535, acc = 0.84765625\n",
      "Batch 413: loss = 0.4021214246749878, acc = 0.8642578125\n",
      "Batch 414: loss = 0.41106072068214417, acc = 0.861328125\n",
      "Batch 415: loss = 0.4354320764541626, acc = 0.857421875\n",
      "Batch 416: loss = 0.42141038179397583, acc = 0.857421875\n",
      "Batch 417: loss = 0.3883313536643982, acc = 0.8623046875\n",
      "Batch 418: loss = 0.4860919713973999, acc = 0.828125\n",
      "Batch 419: loss = 0.5175202488899231, acc = 0.8193359375\n",
      "Batch 420: loss = 0.480633407831192, acc = 0.8388671875\n",
      "Batch 421: loss = 0.4342717230319977, acc = 0.8671875\n",
      "Batch 422: loss = 0.4595834016799927, acc = 0.8447265625\n",
      "Batch 423: loss = 0.4286597967147827, acc = 0.8544921875\n",
      "Batch 424: loss = 0.46270766854286194, acc = 0.84375\n",
      "Batch 425: loss = 0.4476017355918884, acc = 0.859375\n",
      "Batch 426: loss = 0.40833863615989685, acc = 0.8564453125\n",
      "Batch 427: loss = 0.4149938225746155, acc = 0.8544921875\n",
      "Batch 428: loss = 0.4280470907688141, acc = 0.853515625\n",
      "Batch 429: loss = 0.38788893818855286, acc = 0.869140625\n",
      "Batch 430: loss = 0.40499937534332275, acc = 0.865234375\n",
      "Batch 431: loss = 0.3845277428627014, acc = 0.87109375\n",
      "Batch 432: loss = 0.411821573972702, acc = 0.86328125\n",
      "Batch 433: loss = 0.33272117376327515, acc = 0.8974609375\n",
      "Batch 434: loss = 0.3913608491420746, acc = 0.873046875\n",
      "Batch 435: loss = 0.44704100489616394, acc = 0.8447265625\n",
      "Batch 436: loss = 0.3469928801059723, acc = 0.888671875\n",
      "Batch 437: loss = 0.42662543058395386, acc = 0.865234375\n",
      "Batch 438: loss = 0.4244321882724762, acc = 0.859375\n",
      "Batch 439: loss = 0.37473899126052856, acc = 0.875\n",
      "Batch 440: loss = 0.4488857388496399, acc = 0.841796875\n",
      "Batch 441: loss = 0.3960670828819275, acc = 0.8662109375\n",
      "\n",
      "Epoch 100/100\n",
      "Batch 1: loss = 0.5274538993835449, acc = 0.8369140625\n",
      "Batch 2: loss = 0.4200144410133362, acc = 0.8564453125\n",
      "Batch 3: loss = 0.42042675614356995, acc = 0.8603515625\n",
      "Batch 4: loss = 0.46601468324661255, acc = 0.84375\n",
      "Batch 5: loss = 0.43508079648017883, acc = 0.8642578125\n",
      "Batch 6: loss = 0.3473843038082123, acc = 0.890625\n",
      "Batch 7: loss = 0.38283488154411316, acc = 0.8681640625\n",
      "Batch 8: loss = 0.3804992139339447, acc = 0.87109375\n",
      "Batch 9: loss = 0.423902690410614, acc = 0.8583984375\n",
      "Batch 10: loss = 0.4701763987541199, acc = 0.8466796875\n",
      "Batch 11: loss = 0.41123563051223755, acc = 0.8642578125\n",
      "Batch 12: loss = 0.4077081084251404, acc = 0.86328125\n",
      "Batch 13: loss = 0.4163517653942108, acc = 0.849609375\n",
      "Batch 14: loss = 0.3878060579299927, acc = 0.8681640625\n",
      "Batch 15: loss = 0.3918566107749939, acc = 0.8583984375\n",
      "Batch 16: loss = 0.3993704915046692, acc = 0.8671875\n",
      "Batch 17: loss = 0.34530991315841675, acc = 0.8779296875\n",
      "Batch 18: loss = 0.40565025806427, acc = 0.853515625\n",
      "Batch 19: loss = 0.3915031850337982, acc = 0.86328125\n",
      "Batch 20: loss = 0.4500911235809326, acc = 0.853515625\n",
      "Batch 21: loss = 0.44410714507102966, acc = 0.857421875\n",
      "Batch 22: loss = 0.43354514241218567, acc = 0.861328125\n",
      "Batch 23: loss = 0.43433594703674316, acc = 0.8408203125\n",
      "Batch 24: loss = 0.42936646938323975, acc = 0.87109375\n",
      "Batch 25: loss = 0.43238306045532227, acc = 0.857421875\n",
      "Batch 26: loss = 0.3859691023826599, acc = 0.8642578125\n",
      "Batch 27: loss = 0.47732532024383545, acc = 0.8408203125\n",
      "Batch 28: loss = 0.39316123723983765, acc = 0.8623046875\n",
      "Batch 29: loss = 0.46586453914642334, acc = 0.8369140625\n",
      "Batch 30: loss = 0.42828571796417236, acc = 0.8466796875\n",
      "Batch 31: loss = 0.43316158652305603, acc = 0.85546875\n",
      "Batch 32: loss = 0.3983078598976135, acc = 0.8662109375\n",
      "Batch 33: loss = 0.3403477072715759, acc = 0.888671875\n",
      "Batch 34: loss = 0.34844574332237244, acc = 0.884765625\n",
      "Batch 35: loss = 0.34920990467071533, acc = 0.8857421875\n",
      "Batch 36: loss = 0.40103667974472046, acc = 0.8681640625\n",
      "Batch 37: loss = 0.37094560265541077, acc = 0.8798828125\n",
      "Batch 38: loss = 0.38513240218162537, acc = 0.8642578125\n",
      "Batch 39: loss = 0.3234884738922119, acc = 0.8974609375\n",
      "Batch 40: loss = 0.35208660364151, acc = 0.8876953125\n",
      "Batch 41: loss = 0.3191198408603668, acc = 0.8935546875\n",
      "Batch 42: loss = 0.4103553891181946, acc = 0.865234375\n",
      "Batch 43: loss = 0.4321659803390503, acc = 0.845703125\n",
      "Batch 44: loss = 0.44161131978034973, acc = 0.849609375\n",
      "Batch 45: loss = 0.3595937490463257, acc = 0.87890625\n",
      "Batch 46: loss = 0.3872721791267395, acc = 0.86328125\n",
      "Batch 47: loss = 0.3824411928653717, acc = 0.8603515625\n",
      "Batch 48: loss = 0.3713673949241638, acc = 0.8720703125\n",
      "Batch 49: loss = 0.3835649788379669, acc = 0.8740234375\n",
      "Batch 50: loss = 0.361971914768219, acc = 0.8759765625\n",
      "Batch 51: loss = 0.43521785736083984, acc = 0.8525390625\n",
      "Batch 52: loss = 0.3521431088447571, acc = 0.8837890625\n",
      "Batch 53: loss = 0.4053195118904114, acc = 0.8623046875\n",
      "Batch 54: loss = 0.3914506733417511, acc = 0.865234375\n",
      "Batch 55: loss = 0.41754621267318726, acc = 0.8466796875\n",
      "Batch 56: loss = 0.39127105474472046, acc = 0.85546875\n",
      "Batch 57: loss = 0.39185166358947754, acc = 0.859375\n",
      "Batch 58: loss = 0.38361403346061707, acc = 0.8623046875\n",
      "Batch 59: loss = 0.41048985719680786, acc = 0.865234375\n",
      "Batch 60: loss = 0.399680495262146, acc = 0.873046875\n",
      "Batch 61: loss = 0.4010847806930542, acc = 0.861328125\n",
      "Batch 62: loss = 0.4574629068374634, acc = 0.84765625\n",
      "Batch 63: loss = 0.40764957666397095, acc = 0.8544921875\n",
      "Batch 64: loss = 0.337875634431839, acc = 0.896484375\n",
      "Batch 65: loss = 0.34810811281204224, acc = 0.8828125\n",
      "Batch 66: loss = 0.3437955379486084, acc = 0.8759765625\n",
      "Batch 67: loss = 0.3794406056404114, acc = 0.8740234375\n",
      "Batch 68: loss = 0.49929729104042053, acc = 0.833984375\n",
      "Batch 69: loss = 0.3651023507118225, acc = 0.875\n",
      "Batch 70: loss = 0.42163601517677307, acc = 0.8466796875\n",
      "Batch 71: loss = 0.44313129782676697, acc = 0.84765625\n",
      "Batch 72: loss = 0.423829585313797, acc = 0.865234375\n",
      "Batch 73: loss = 0.39826443791389465, acc = 0.8564453125\n",
      "Batch 74: loss = 0.412856787443161, acc = 0.8671875\n",
      "Batch 75: loss = 0.37889978289604187, acc = 0.8681640625\n",
      "Batch 76: loss = 0.43119484186172485, acc = 0.861328125\n",
      "Batch 77: loss = 0.46466517448425293, acc = 0.8388671875\n",
      "Batch 78: loss = 0.46124276518821716, acc = 0.8466796875\n",
      "Batch 79: loss = 0.3714908957481384, acc = 0.869140625\n",
      "Batch 80: loss = 0.5166529417037964, acc = 0.82421875\n",
      "Batch 81: loss = 0.3641200661659241, acc = 0.87109375\n",
      "Batch 82: loss = 0.43595197796821594, acc = 0.8623046875\n",
      "Batch 83: loss = 0.4427773356437683, acc = 0.8515625\n",
      "Batch 84: loss = 0.37672483921051025, acc = 0.8720703125\n",
      "Batch 85: loss = 0.41059598326683044, acc = 0.8603515625\n",
      "Batch 86: loss = 0.41779449582099915, acc = 0.861328125\n",
      "Batch 87: loss = 0.3929802477359772, acc = 0.8564453125\n",
      "Batch 88: loss = 0.43124711513519287, acc = 0.8486328125\n",
      "Batch 89: loss = 0.4878547191619873, acc = 0.84765625\n",
      "Batch 90: loss = 0.4403827488422394, acc = 0.84765625\n",
      "Batch 91: loss = 0.4031459093093872, acc = 0.8798828125\n",
      "Batch 92: loss = 0.40829285979270935, acc = 0.8681640625\n",
      "Batch 93: loss = 0.4338824152946472, acc = 0.8505859375\n",
      "Batch 94: loss = 0.4500390291213989, acc = 0.8447265625\n",
      "Batch 95: loss = 0.42282477021217346, acc = 0.859375\n",
      "Batch 96: loss = 0.41938406229019165, acc = 0.8544921875\n",
      "Batch 97: loss = 0.42495378851890564, acc = 0.85546875\n",
      "Batch 98: loss = 0.4837331175804138, acc = 0.8251953125\n",
      "Batch 99: loss = 0.42133256793022156, acc = 0.86328125\n",
      "Batch 100: loss = 0.5126873850822449, acc = 0.8203125\n",
      "Batch 101: loss = 0.40542274713516235, acc = 0.8583984375\n",
      "Batch 102: loss = 0.37189221382141113, acc = 0.8759765625\n",
      "Batch 103: loss = 0.37642577290534973, acc = 0.8671875\n",
      "Batch 104: loss = 0.36757129430770874, acc = 0.8828125\n",
      "Batch 105: loss = 0.4278287887573242, acc = 0.857421875\n",
      "Batch 106: loss = 0.4323942959308624, acc = 0.8642578125\n",
      "Batch 107: loss = 0.36213305592536926, acc = 0.880859375\n",
      "Batch 108: loss = 0.43675732612609863, acc = 0.8642578125\n",
      "Batch 109: loss = 0.3570520877838135, acc = 0.875\n",
      "Batch 110: loss = 0.42238855361938477, acc = 0.8544921875\n",
      "Batch 111: loss = 0.4523436427116394, acc = 0.8349609375\n",
      "Batch 112: loss = 0.4358457922935486, acc = 0.8603515625\n",
      "Batch 113: loss = 0.3981286883354187, acc = 0.87109375\n",
      "Batch 114: loss = 0.3757772445678711, acc = 0.8583984375\n",
      "Batch 115: loss = 0.4439265727996826, acc = 0.8486328125\n",
      "Batch 116: loss = 0.393282949924469, acc = 0.8623046875\n",
      "Batch 117: loss = 0.39690378308296204, acc = 0.8701171875\n",
      "Batch 118: loss = 0.3847005367279053, acc = 0.87109375\n",
      "Batch 119: loss = 0.3986136317253113, acc = 0.865234375\n",
      "Batch 120: loss = 0.4606693387031555, acc = 0.8564453125\n",
      "Batch 121: loss = 0.43349790573120117, acc = 0.8623046875\n",
      "Batch 122: loss = 0.39009520411491394, acc = 0.8681640625\n",
      "Batch 123: loss = 0.39217156171798706, acc = 0.873046875\n",
      "Batch 124: loss = 0.4446103870868683, acc = 0.845703125\n",
      "Batch 125: loss = 0.4360275864601135, acc = 0.8544921875\n",
      "Batch 126: loss = 0.3667752146720886, acc = 0.8798828125\n",
      "Batch 127: loss = 0.43502572178840637, acc = 0.8447265625\n",
      "Batch 128: loss = 0.40235891938209534, acc = 0.857421875\n",
      "Batch 129: loss = 0.40952542424201965, acc = 0.8642578125\n",
      "Batch 130: loss = 0.38683706521987915, acc = 0.8720703125\n",
      "Batch 131: loss = 0.3542964458465576, acc = 0.8828125\n",
      "Batch 132: loss = 0.29975298047065735, acc = 0.8935546875\n",
      "Batch 133: loss = 0.3490278124809265, acc = 0.892578125\n",
      "Batch 134: loss = 0.3689574599266052, acc = 0.873046875\n",
      "Batch 135: loss = 0.4266873896121979, acc = 0.85546875\n",
      "Batch 136: loss = 0.40257883071899414, acc = 0.8603515625\n",
      "Batch 137: loss = 0.3436840772628784, acc = 0.8818359375\n",
      "Batch 138: loss = 0.3443696200847626, acc = 0.8798828125\n",
      "Batch 139: loss = 0.323930025100708, acc = 0.888671875\n",
      "Batch 140: loss = 0.382610946893692, acc = 0.869140625\n",
      "Batch 141: loss = 0.37952324748039246, acc = 0.869140625\n",
      "Batch 142: loss = 0.4460647702217102, acc = 0.8466796875\n",
      "Batch 143: loss = 0.43886563181877136, acc = 0.845703125\n",
      "Batch 144: loss = 0.42846494913101196, acc = 0.85546875\n",
      "Batch 145: loss = 0.3692057132720947, acc = 0.876953125\n",
      "Batch 146: loss = 0.43534159660339355, acc = 0.8603515625\n",
      "Batch 147: loss = 0.4038082957267761, acc = 0.8720703125\n",
      "Batch 148: loss = 0.3612000346183777, acc = 0.880859375\n",
      "Batch 149: loss = 0.3965054154396057, acc = 0.8720703125\n",
      "Batch 150: loss = 0.39551424980163574, acc = 0.87109375\n",
      "Batch 151: loss = 0.4717927873134613, acc = 0.83984375\n",
      "Batch 152: loss = 0.3907921612262726, acc = 0.859375\n",
      "Batch 153: loss = 0.364035040140152, acc = 0.875\n",
      "Batch 154: loss = 0.3982139527797699, acc = 0.875\n",
      "Batch 155: loss = 0.41238054633140564, acc = 0.859375\n",
      "Batch 156: loss = 0.43752798438072205, acc = 0.8544921875\n",
      "Batch 157: loss = 0.3863014578819275, acc = 0.8779296875\n",
      "Batch 158: loss = 0.40815436840057373, acc = 0.859375\n",
      "Batch 159: loss = 0.42335808277130127, acc = 0.8544921875\n",
      "Batch 160: loss = 0.4239085614681244, acc = 0.8486328125\n",
      "Batch 161: loss = 0.4480287432670593, acc = 0.841796875\n",
      "Batch 162: loss = 0.41408517956733704, acc = 0.869140625\n",
      "Batch 163: loss = 0.42119401693344116, acc = 0.8701171875\n",
      "Batch 164: loss = 0.4298422634601593, acc = 0.85546875\n",
      "Batch 165: loss = 0.45091527700424194, acc = 0.83984375\n",
      "Batch 166: loss = 0.33269554376602173, acc = 0.880859375\n",
      "Batch 167: loss = 0.45552000403404236, acc = 0.8408203125\n",
      "Batch 168: loss = 0.3754577934741974, acc = 0.8759765625\n",
      "Batch 169: loss = 0.3563220202922821, acc = 0.8701171875\n",
      "Batch 170: loss = 0.3731578588485718, acc = 0.876953125\n",
      "Batch 171: loss = 0.38882070779800415, acc = 0.8662109375\n",
      "Batch 172: loss = 0.34528741240501404, acc = 0.8740234375\n",
      "Batch 173: loss = 0.3944827616214752, acc = 0.8720703125\n",
      "Batch 174: loss = 0.4026615023612976, acc = 0.8662109375\n",
      "Batch 175: loss = 0.4057968258857727, acc = 0.853515625\n",
      "Batch 176: loss = 0.4255463480949402, acc = 0.8583984375\n",
      "Batch 177: loss = 0.36504682898521423, acc = 0.87890625\n",
      "Batch 178: loss = 0.34320104122161865, acc = 0.8857421875\n",
      "Batch 179: loss = 0.4133743643760681, acc = 0.8505859375\n",
      "Batch 180: loss = 0.4195849597454071, acc = 0.861328125\n",
      "Batch 181: loss = 0.4023246169090271, acc = 0.8662109375\n",
      "Batch 182: loss = 0.3979794979095459, acc = 0.85546875\n",
      "Batch 183: loss = 0.38276124000549316, acc = 0.865234375\n",
      "Batch 184: loss = 0.4267856776714325, acc = 0.8515625\n",
      "Batch 185: loss = 0.41038990020751953, acc = 0.8740234375\n",
      "Batch 186: loss = 0.3979451656341553, acc = 0.875\n",
      "Batch 187: loss = 0.42392346262931824, acc = 0.8505859375\n",
      "Batch 188: loss = 0.38650617003440857, acc = 0.8662109375\n",
      "Batch 189: loss = 0.3551065921783447, acc = 0.880859375\n",
      "Batch 190: loss = 0.412322461605072, acc = 0.84375\n",
      "Batch 191: loss = 0.3857243061065674, acc = 0.8681640625\n",
      "Batch 192: loss = 0.3739655911922455, acc = 0.8759765625\n",
      "Batch 193: loss = 0.4244599938392639, acc = 0.865234375\n",
      "Batch 194: loss = 0.3954114615917206, acc = 0.8564453125\n",
      "Batch 195: loss = 0.42711111903190613, acc = 0.859375\n",
      "Batch 196: loss = 0.4763028919696808, acc = 0.8544921875\n",
      "Batch 197: loss = 0.46035605669021606, acc = 0.830078125\n",
      "Batch 198: loss = 0.38224661350250244, acc = 0.8740234375\n",
      "Batch 199: loss = 0.4179582893848419, acc = 0.853515625\n",
      "Batch 200: loss = 0.47227999567985535, acc = 0.83203125\n",
      "Batch 201: loss = 0.41822972893714905, acc = 0.8427734375\n",
      "Batch 202: loss = 0.4663897752761841, acc = 0.84765625\n",
      "Batch 203: loss = 0.40529632568359375, acc = 0.8701171875\n",
      "Batch 204: loss = 0.4244973659515381, acc = 0.853515625\n",
      "Batch 205: loss = 0.4363033175468445, acc = 0.8505859375\n",
      "Batch 206: loss = 0.4013423025608063, acc = 0.859375\n",
      "Batch 207: loss = 0.5204567909240723, acc = 0.822265625\n",
      "Batch 208: loss = 0.46933436393737793, acc = 0.84765625\n",
      "Batch 209: loss = 0.42783623933792114, acc = 0.85546875\n",
      "Batch 210: loss = 0.38987281918525696, acc = 0.865234375\n",
      "Batch 211: loss = 0.4416959881782532, acc = 0.849609375\n",
      "Batch 212: loss = 0.4719621539115906, acc = 0.8408203125\n",
      "Batch 213: loss = 0.4248826205730438, acc = 0.8544921875\n",
      "Batch 214: loss = 0.40011364221572876, acc = 0.85546875\n",
      "Batch 215: loss = 0.39632874727249146, acc = 0.8740234375\n",
      "Batch 216: loss = 0.3424438536167145, acc = 0.8798828125\n",
      "Batch 217: loss = 0.3866596817970276, acc = 0.87109375\n",
      "Batch 218: loss = 0.42144107818603516, acc = 0.8603515625\n",
      "Batch 219: loss = 0.42177146673202515, acc = 0.85546875\n",
      "Batch 220: loss = 0.3859311044216156, acc = 0.8603515625\n",
      "Batch 221: loss = 0.47061699628829956, acc = 0.841796875\n",
      "Batch 222: loss = 0.39427536725997925, acc = 0.869140625\n",
      "Batch 223: loss = 0.33658289909362793, acc = 0.884765625\n",
      "Batch 224: loss = 0.340272456407547, acc = 0.880859375\n",
      "Batch 225: loss = 0.34898990392684937, acc = 0.8798828125\n",
      "Batch 226: loss = 0.4498973786830902, acc = 0.84765625\n",
      "Batch 227: loss = 0.37572503089904785, acc = 0.8720703125\n",
      "Batch 228: loss = 0.37945181131362915, acc = 0.8759765625\n",
      "Batch 229: loss = 0.39176860451698303, acc = 0.87890625\n",
      "Batch 230: loss = 0.3403882682323456, acc = 0.8740234375\n",
      "Batch 231: loss = 0.45657315850257874, acc = 0.8544921875\n",
      "Batch 232: loss = 0.38032203912734985, acc = 0.8671875\n",
      "Batch 233: loss = 0.47952017188072205, acc = 0.8212890625\n",
      "Batch 234: loss = 0.38197430968284607, acc = 0.87109375\n",
      "Batch 235: loss = 0.40356600284576416, acc = 0.8583984375\n",
      "Batch 236: loss = 0.44249194860458374, acc = 0.8681640625\n",
      "Batch 237: loss = 0.35153043270111084, acc = 0.8828125\n",
      "Batch 238: loss = 0.39794090390205383, acc = 0.8671875\n",
      "Batch 239: loss = 0.37267571687698364, acc = 0.8837890625\n",
      "Batch 240: loss = 0.4618443250656128, acc = 0.84765625\n",
      "Batch 241: loss = 0.408610463142395, acc = 0.861328125\n",
      "Batch 242: loss = 0.4319087862968445, acc = 0.849609375\n",
      "Batch 243: loss = 0.4296627640724182, acc = 0.853515625\n",
      "Batch 244: loss = 0.48910826444625854, acc = 0.8330078125\n",
      "Batch 245: loss = 0.3710949420928955, acc = 0.880859375\n",
      "Batch 246: loss = 0.4029209017753601, acc = 0.8623046875\n",
      "Batch 247: loss = 0.465375691652298, acc = 0.8427734375\n",
      "Batch 248: loss = 0.3648119866847992, acc = 0.8740234375\n",
      "Batch 249: loss = 0.3607436716556549, acc = 0.8798828125\n",
      "Batch 250: loss = 0.4032799005508423, acc = 0.8642578125\n",
      "Batch 251: loss = 0.33070242404937744, acc = 0.8896484375\n",
      "Batch 252: loss = 0.37830525636672974, acc = 0.8740234375\n",
      "Batch 253: loss = 0.4208603501319885, acc = 0.8505859375\n",
      "Batch 254: loss = 0.4482972025871277, acc = 0.8369140625\n",
      "Batch 255: loss = 0.4356922507286072, acc = 0.8544921875\n",
      "Batch 256: loss = 0.43748655915260315, acc = 0.845703125\n",
      "Batch 257: loss = 0.46924450993537903, acc = 0.833984375\n",
      "Batch 258: loss = 0.4329868257045746, acc = 0.8486328125\n",
      "Batch 259: loss = 0.47062721848487854, acc = 0.8447265625\n",
      "Batch 260: loss = 0.5570583343505859, acc = 0.8037109375\n",
      "Batch 261: loss = 0.47925668954849243, acc = 0.8388671875\n",
      "Batch 262: loss = 0.43178027868270874, acc = 0.84765625\n",
      "Batch 263: loss = 0.41922956705093384, acc = 0.8525390625\n",
      "Batch 264: loss = 0.43966689705848694, acc = 0.8525390625\n",
      "Batch 265: loss = 0.4010527729988098, acc = 0.8583984375\n",
      "Batch 266: loss = 0.3815625309944153, acc = 0.884765625\n",
      "Batch 267: loss = 0.3692999482154846, acc = 0.8740234375\n",
      "Batch 268: loss = 0.406465083360672, acc = 0.8642578125\n",
      "Batch 269: loss = 0.4548855423927307, acc = 0.8466796875\n",
      "Batch 270: loss = 0.4019460082054138, acc = 0.861328125\n",
      "Batch 271: loss = 0.37148988246917725, acc = 0.8662109375\n",
      "Batch 272: loss = 0.4135501980781555, acc = 0.8427734375\n",
      "Batch 273: loss = 0.4474858045578003, acc = 0.85546875\n",
      "Batch 274: loss = 0.4269413650035858, acc = 0.8642578125\n",
      "Batch 275: loss = 0.3899844288825989, acc = 0.8681640625\n",
      "Batch 276: loss = 0.4202072024345398, acc = 0.84765625\n",
      "Batch 277: loss = 0.46591517329216003, acc = 0.837890625\n",
      "Batch 278: loss = 0.4048963189125061, acc = 0.865234375\n",
      "Batch 279: loss = 0.5112534761428833, acc = 0.8251953125\n",
      "Batch 280: loss = 0.434726357460022, acc = 0.845703125\n",
      "Batch 281: loss = 0.42668870091438293, acc = 0.8544921875\n",
      "Batch 282: loss = 0.40539464354515076, acc = 0.8544921875\n",
      "Batch 283: loss = 0.45789846777915955, acc = 0.8369140625\n",
      "Batch 284: loss = 0.39108914136886597, acc = 0.8740234375\n",
      "Batch 285: loss = 0.4596374034881592, acc = 0.849609375\n",
      "Batch 286: loss = 0.48196253180503845, acc = 0.8388671875\n",
      "Batch 287: loss = 0.47751420736312866, acc = 0.8310546875\n",
      "Batch 288: loss = 0.45763546228408813, acc = 0.8349609375\n",
      "Batch 289: loss = 0.43450382351875305, acc = 0.853515625\n",
      "Batch 290: loss = 0.4762898087501526, acc = 0.828125\n",
      "Batch 291: loss = 0.44433945417404175, acc = 0.83984375\n",
      "Batch 292: loss = 0.47024980187416077, acc = 0.830078125\n",
      "Batch 293: loss = 0.41444772481918335, acc = 0.857421875\n",
      "Batch 294: loss = 0.4261665344238281, acc = 0.861328125\n",
      "Batch 295: loss = 0.4262426197528839, acc = 0.84765625\n",
      "Batch 296: loss = 0.39248621463775635, acc = 0.8642578125\n",
      "Batch 297: loss = 0.37529972195625305, acc = 0.87890625\n",
      "Batch 298: loss = 0.3736981153488159, acc = 0.8828125\n",
      "Batch 299: loss = 0.3516565263271332, acc = 0.87890625\n",
      "Batch 300: loss = 0.39689815044403076, acc = 0.8671875\n",
      "Batch 301: loss = 0.43167006969451904, acc = 0.845703125\n",
      "Batch 302: loss = 0.42828407883644104, acc = 0.859375\n",
      "Batch 303: loss = 0.43217164278030396, acc = 0.869140625\n",
      "Batch 304: loss = 0.38753944635391235, acc = 0.865234375\n",
      "Batch 305: loss = 0.36912357807159424, acc = 0.87109375\n",
      "Batch 306: loss = 0.4056912362575531, acc = 0.875\n",
      "Batch 307: loss = 0.3318917751312256, acc = 0.890625\n",
      "Batch 308: loss = 0.4239523112773895, acc = 0.861328125\n",
      "Batch 309: loss = 0.4206527769565582, acc = 0.8544921875\n",
      "Batch 310: loss = 0.44448933005332947, acc = 0.8427734375\n",
      "Batch 311: loss = 0.4199225902557373, acc = 0.8583984375\n",
      "Batch 312: loss = 0.3758765459060669, acc = 0.8740234375\n",
      "Batch 313: loss = 0.43765905499458313, acc = 0.845703125\n",
      "Batch 314: loss = 0.45295873284339905, acc = 0.84375\n",
      "Batch 315: loss = 0.4226091206073761, acc = 0.8505859375\n",
      "Batch 316: loss = 0.41858360171318054, acc = 0.85546875\n",
      "Batch 317: loss = 0.4522000253200531, acc = 0.8427734375\n",
      "Batch 318: loss = 0.4143821597099304, acc = 0.8505859375\n",
      "Batch 319: loss = 0.4204285740852356, acc = 0.869140625\n",
      "Batch 320: loss = 0.4669601023197174, acc = 0.837890625\n",
      "Batch 321: loss = 0.49335598945617676, acc = 0.849609375\n",
      "Batch 322: loss = 0.39548930525779724, acc = 0.8671875\n",
      "Batch 323: loss = 0.44220852851867676, acc = 0.8369140625\n",
      "Batch 324: loss = 0.4057497978210449, acc = 0.86328125\n",
      "Batch 325: loss = 0.461762011051178, acc = 0.8349609375\n",
      "Batch 326: loss = 0.39860039949417114, acc = 0.8681640625\n",
      "Batch 327: loss = 0.380143404006958, acc = 0.876953125\n",
      "Batch 328: loss = 0.410320907831192, acc = 0.8681640625\n",
      "Batch 329: loss = 0.49035465717315674, acc = 0.8349609375\n",
      "Batch 330: loss = 0.41196995973587036, acc = 0.8505859375\n",
      "Batch 331: loss = 0.41226980090141296, acc = 0.865234375\n",
      "Batch 332: loss = 0.4170025885105133, acc = 0.8583984375\n",
      "Batch 333: loss = 0.4519765377044678, acc = 0.845703125\n",
      "Batch 334: loss = 0.3294697403907776, acc = 0.888671875\n",
      "Batch 335: loss = 0.42194321751594543, acc = 0.857421875\n",
      "Batch 336: loss = 0.4512964189052582, acc = 0.83984375\n",
      "Batch 337: loss = 0.5188241004943848, acc = 0.826171875\n",
      "Batch 338: loss = 0.36699241399765015, acc = 0.876953125\n",
      "Batch 339: loss = 0.4102862775325775, acc = 0.8701171875\n",
      "Batch 340: loss = 0.3549342453479767, acc = 0.8828125\n",
      "Batch 341: loss = 0.4300263226032257, acc = 0.853515625\n",
      "Batch 342: loss = 0.45710334181785583, acc = 0.8525390625\n",
      "Batch 343: loss = 0.3956078886985779, acc = 0.8642578125\n",
      "Batch 344: loss = 0.3685237169265747, acc = 0.880859375\n",
      "Batch 345: loss = 0.35706108808517456, acc = 0.8779296875\n",
      "Batch 346: loss = 0.36376672983169556, acc = 0.8828125\n",
      "Batch 347: loss = 0.4356517791748047, acc = 0.8603515625\n",
      "Batch 348: loss = 0.42471227049827576, acc = 0.85546875\n",
      "Batch 349: loss = 0.3481267988681793, acc = 0.890625\n",
      "Batch 350: loss = 0.3447061777114868, acc = 0.873046875\n",
      "Batch 351: loss = 0.3625965416431427, acc = 0.869140625\n",
      "Batch 352: loss = 0.4065638780593872, acc = 0.85546875\n",
      "Batch 353: loss = 0.38219204545021057, acc = 0.8828125\n",
      "Batch 354: loss = 0.34407612681388855, acc = 0.888671875\n",
      "Batch 355: loss = 0.31209829449653625, acc = 0.8955078125\n",
      "Batch 356: loss = 0.3367379307746887, acc = 0.8837890625\n",
      "Batch 357: loss = 0.4093988537788391, acc = 0.8583984375\n",
      "Batch 358: loss = 0.3907688856124878, acc = 0.8740234375\n",
      "Batch 359: loss = 0.3760281205177307, acc = 0.8876953125\n",
      "Batch 360: loss = 0.3617689609527588, acc = 0.8876953125\n",
      "Batch 361: loss = 0.3684549331665039, acc = 0.876953125\n",
      "Batch 362: loss = 0.3350527584552765, acc = 0.8798828125\n",
      "Batch 363: loss = 0.3955667018890381, acc = 0.8623046875\n",
      "Batch 364: loss = 0.4191032350063324, acc = 0.8564453125\n",
      "Batch 365: loss = 0.38889068365097046, acc = 0.869140625\n",
      "Batch 366: loss = 0.40736156702041626, acc = 0.8623046875\n",
      "Batch 367: loss = 0.38104453682899475, acc = 0.8662109375\n",
      "Batch 368: loss = 0.42414426803588867, acc = 0.8515625\n",
      "Batch 369: loss = 0.4360906481742859, acc = 0.84765625\n",
      "Batch 370: loss = 0.37850573658943176, acc = 0.8681640625\n",
      "Batch 371: loss = 0.44080987572669983, acc = 0.841796875\n",
      "Batch 372: loss = 0.41105377674102783, acc = 0.8623046875\n",
      "Batch 373: loss = 0.4111644923686981, acc = 0.86328125\n",
      "Batch 374: loss = 0.45150527358055115, acc = 0.84765625\n",
      "Batch 375: loss = 0.4624539017677307, acc = 0.8388671875\n",
      "Batch 376: loss = 0.4470217227935791, acc = 0.861328125\n",
      "Batch 377: loss = 0.471635103225708, acc = 0.8427734375\n",
      "Batch 378: loss = 0.4468642473220825, acc = 0.84765625\n",
      "Batch 379: loss = 0.48002368211746216, acc = 0.8427734375\n",
      "Batch 380: loss = 0.3948989510536194, acc = 0.859375\n",
      "Batch 381: loss = 0.38400956988334656, acc = 0.8623046875\n",
      "Batch 382: loss = 0.41947269439697266, acc = 0.8603515625\n",
      "Batch 383: loss = 0.378164678812027, acc = 0.869140625\n",
      "Batch 384: loss = 0.45914381742477417, acc = 0.8349609375\n",
      "Batch 385: loss = 0.4254598319530487, acc = 0.8525390625\n",
      "Batch 386: loss = 0.39599183201789856, acc = 0.8642578125\n",
      "Batch 387: loss = 0.3798030614852905, acc = 0.8828125\n",
      "Batch 388: loss = 0.42764896154403687, acc = 0.8564453125\n",
      "Batch 389: loss = 0.40737518668174744, acc = 0.865234375\n",
      "Batch 390: loss = 0.45603662729263306, acc = 0.8486328125\n",
      "Batch 391: loss = 0.40915241837501526, acc = 0.865234375\n",
      "Batch 392: loss = 0.43340620398521423, acc = 0.85546875\n",
      "Batch 393: loss = 0.42378470301628113, acc = 0.8564453125\n",
      "Batch 394: loss = 0.3887024223804474, acc = 0.8779296875\n",
      "Batch 395: loss = 0.4099622666835785, acc = 0.8681640625\n",
      "Batch 396: loss = 0.4101058542728424, acc = 0.859375\n",
      "Batch 397: loss = 0.3168622851371765, acc = 0.8818359375\n",
      "Batch 398: loss = 0.3515859842300415, acc = 0.8662109375\n",
      "Batch 399: loss = 0.4360358715057373, acc = 0.8564453125\n",
      "Batch 400: loss = 0.44632214307785034, acc = 0.84765625\n",
      "Batch 401: loss = 0.42381370067596436, acc = 0.8583984375\n",
      "Batch 402: loss = 0.4698904752731323, acc = 0.8447265625\n",
      "Batch 403: loss = 0.3646872341632843, acc = 0.87890625\n",
      "Batch 404: loss = 0.47035425901412964, acc = 0.8466796875\n",
      "Batch 405: loss = 0.46840977668762207, acc = 0.8447265625\n",
      "Batch 406: loss = 0.506735622882843, acc = 0.8359375\n",
      "Batch 407: loss = 0.4827437400817871, acc = 0.8466796875\n",
      "Batch 408: loss = 0.5032025575637817, acc = 0.8310546875\n",
      "Batch 409: loss = 0.42827045917510986, acc = 0.8525390625\n",
      "Batch 410: loss = 0.45012256503105164, acc = 0.845703125\n",
      "Batch 411: loss = 0.40399396419525146, acc = 0.861328125\n",
      "Batch 412: loss = 0.40465685725212097, acc = 0.861328125\n",
      "Batch 413: loss = 0.3813788592815399, acc = 0.869140625\n",
      "Batch 414: loss = 0.4147369861602783, acc = 0.8720703125\n",
      "Batch 415: loss = 0.42652642726898193, acc = 0.837890625\n",
      "Batch 416: loss = 0.41053634881973267, acc = 0.86328125\n",
      "Batch 417: loss = 0.4105454981327057, acc = 0.8583984375\n",
      "Batch 418: loss = 0.4791327118873596, acc = 0.853515625\n",
      "Batch 419: loss = 0.4916389286518097, acc = 0.828125\n",
      "Batch 420: loss = 0.4820112884044647, acc = 0.8388671875\n",
      "Batch 421: loss = 0.43019455671310425, acc = 0.8525390625\n",
      "Batch 422: loss = 0.47152894735336304, acc = 0.8427734375\n",
      "Batch 423: loss = 0.414004921913147, acc = 0.85546875\n",
      "Batch 424: loss = 0.4511621594429016, acc = 0.8525390625\n",
      "Batch 425: loss = 0.4082162380218506, acc = 0.8720703125\n",
      "Batch 426: loss = 0.45951732993125916, acc = 0.8359375\n",
      "Batch 427: loss = 0.42220190167427063, acc = 0.8466796875\n",
      "Batch 428: loss = 0.40315234661102295, acc = 0.8603515625\n",
      "Batch 429: loss = 0.39373886585235596, acc = 0.861328125\n",
      "Batch 430: loss = 0.39595428109169006, acc = 0.861328125\n",
      "Batch 431: loss = 0.4247480034828186, acc = 0.8525390625\n",
      "Batch 432: loss = 0.41906052827835083, acc = 0.857421875\n",
      "Batch 433: loss = 0.38237816095352173, acc = 0.873046875\n",
      "Batch 434: loss = 0.3972982168197632, acc = 0.869140625\n",
      "Batch 435: loss = 0.4474641680717468, acc = 0.8427734375\n",
      "Batch 436: loss = 0.349247545003891, acc = 0.8857421875\n",
      "Batch 437: loss = 0.4334137737751007, acc = 0.857421875\n",
      "Batch 438: loss = 0.39113545417785645, acc = 0.8662109375\n",
      "Batch 439: loss = 0.38156646490097046, acc = 0.8662109375\n",
      "Batch 440: loss = 0.4004727303981781, acc = 0.8671875\n",
      "Batch 441: loss = 0.3798011541366577, acc = 0.876953125\n",
      "Saved checkpoint to weights.100.h5\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "t = time.time()\n",
    "!python train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P2lM43pIY4k0",
    "outputId": "4837c198-38fc-4813-80b5-ba1e1996e729"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "883.231115102768\n"
     ]
    }
   ],
   "source": [
    "print(time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IxWrYbv2NE_n",
    "outputId": "261b0ed7-1ab5-43f6-8c5d-a25d90b504b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: content/model/ (stored 0%)\n"
     ]
    }
   ],
   "source": [
    "!zip /content/model.zip /content/model/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "ZkhqmnFuPbLj"
   },
   "outputs": [],
   "source": [
    "!cp /content/model.zip /content/drive/MyDrive/_ML_PROJECTS/Music_generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lGXTqu3VQ4g0",
    "outputId": "ad823129-5e31-480d-a153-002d08ccbde5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-23 07:03:10.227645: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "[]\n",
      "2022-07-23 07:03:13.349585: W tensorflow/core/data/root_dataset.cc:200] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-07-23 07:03:16.355039: W tensorflow/core/data/root_dataset.cc:200] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "6T:#renman\n",
      "% Nottingham Music Database\n",
      "S:Repard Sy on Cherch, via PR\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:D\n",
      "\"D\"FA dc|\"G\"Bd BG|\"D\"AF FF|\"D\"A2 d2|\"A7\"e2 A2|Ef g/2f/2e|\n",
      "\"D\"d4-|\"D\"dA FA|\"Em\"G4|\"A7\"EF G3/2E/2|\"D\"FA d2|\"E7\"ed2B|\n",
      "\"A7\"cA GF|\"D\"D2 A2|\"D7\"de f2|\"G\"ed B2|[1\"A7\"A3\n",
      "|[4\"D\"A3\"D7\"B:|\n",
      " [2\"D\"Ad \"G7\"fg|\"D\"a3/2f/2 -aa|\"E\"gf e^f|\"E\"e4-|\\\n",
      "\"A\"ea f/2a/2g/2a/2|\n",
      "\"Em\"bb/2a/2 gf|\"A7\"eg fe|\"D\"f3f|\"A7\"e/2^d/2e/2g/2 fe|\"D\"d3F/2G/2:|\n",
      "\n",
      "\n",
      "X: 92\n",
      "T:Lumpers of Bosting\n",
      "% Nottingham Music Database\n",
      "S:Kevin Briggs\n",
      "M:4/4\n",
      "L:1/8\n",
      "R:Hornpipe\n",
      "K:A\n",
      "F/2G/2|\"A\"AEA c2B|\"E7\"d2G B2G|\"A\"ABc \"D\"dcd|\n",
      "\"E\"GEG \"A\"EFG|\"D\"AAB AGF|\"G\"GBd \"Em\"GGB|\"A\"ABc \"D\"def|\"A\"e3 \"G\"B2d|\n",
      "\"D\"AFA d2e|\"D\"f3 f2g|\"D\"afd AFA|\"Em\"e3 efg|\"D\"fed \"A7\"Adc|\n",
      "\"D\"dfd \"A\"edc|\"G\"Bcd \"D\"Adf|\"A\"edc \"D\"d2:|\n",
      "\n",
      "\n",
      "X: 128\n",
      "T:Ingargh Waltz\n",
      "% Nottingham Music Database\n",
      "S:via PR\n",
      "M:2/4\n",
      "L:1/4\n",
      "K:D\n",
      "\"D\"d/4c/4B/4A/4 \"A7\"d/4G/4F/4E/4|\"D\"D/2A/2 B/4A/4F/4A/4|\\\n",
      "\"Em\"G/4A/4B/4c/4 \"A\"d/2c/4B/4|\\\n",
      "\"D\"A/2G/2 \"G\"G/2B/2|\"D\"A/2F/2 \"A7\"E/2G/2|\"D\"F/2A/2 D:|\n",
      "\n",
      "\n",
      "X: 12\n",
      "T:Pamill's Rant\n",
      "% Nottingham Music Database\n",
      "S:FTB 1/1, via EF\n",
      "Y:AB\n",
      "M:6/8\n",
      "K:D\n",
      "P:\n"
     ]
    }
   ],
   "source": [
    "!python sample.py 100 --len 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ymJhrcUj9v3F"
   },
   "source": [
    "6T:#renman\n",
    "% Nottingham Music Database\n",
    "S:Repard Sy on Cherch, via PR\n",
    "M:4/4\n",
    "L:1/4\n",
    "K:D\n",
    "\"D\"FA dc|\"G\"Bd BG|\"D\"AF FF|\"D\"A2 d2|\"A7\"e2 A2|Ef g/2f/2e|\n",
    "\"D\"d4-|\"D\"dA FA|\"Em\"G4|\"A7\"EF G3/2E/2|\"D\"FA d2|\"E7\"ed2B|\n",
    "\"A7\"cA GF|\"D\"D2 A2|\"D7\"de f2|\"G\"ed B2|[1\"A7\"A3\n",
    "|[4\"D\"A3\"D7\"B:|\n",
    " [2\"D\"Ad \"G7\"fg|\"D\"a3/2f/2 -aa|\"E\"gf e^f|\"E\"e4-|\\\n",
    "\"A\"ea f/2a/2g/2a/2|\n",
    "\"Em\"bb/2a/2 gf|\"A7\"eg fe|\"D\"f3f|\"A7\"e/2^d/2e/2g/2 fe|\"D\"d3F/2G/2:|\n",
    "\n",
    "\n",
    "X: 92\n",
    "T:Lumpers of Bosting\n",
    "% Nottingham Music Database\n",
    "S:Kevin Briggs\n",
    "M:4/4\n",
    "L:1/8\n",
    "R:Hornpipe\n",
    "K:A\n",
    "F/2G/2|\"A\"AEA c2B|\"E7\"d2G B2G|\"A\"ABc \"D\"dcd|\n",
    "\"E\"GEG \"A\"EFG|\"D\"AAB AGF|\"G\"GBd \"Em\"GGB|\"A\"ABc \"D\"def|\"A\"e3 \"G\"B2d|\n",
    "\"D\"AFA d2e|\"D\"f3 f2g|\"D\"afd AFA|\"Em\"e3 efg|\"D\"fed \"A7\"Adc|\n",
    "\"D\"dfd \"A\"edc|\"G\"Bcd \"D\"Adf|\"A\"edc \"D\"d2:|\n",
    "\n",
    "\n",
    "X: 128\n",
    "T:Ingargh Waltz\n",
    "% Nottingham Music Database\n",
    "S:via PR\n",
    "M:2/4\n",
    "L:1/4\n",
    "K:D\n",
    "\"D\"d/4c/4B/4A/4 \"A7\"d/4G/4F/4E/4|\"D\"D/2A/2 B/4A/4F/4A/4|\\\n",
    "\"Em\"G/4A/4B/4c/4 \"A\"d/2c/4B/4|\\\n",
    "\"D\"A/2G/2 \"G\"G/2B/2|\"D\"A/2F/2 \"A7\"E/2G/2|\"D\"F/2A/2 D:|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lmNGjiAUREuZ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "music_generation_all.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
