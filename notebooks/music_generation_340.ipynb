{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K7aKe_dRMqEM"
   },
   "outputs": [],
   "source": [
    "!unzip /content/drive/MyDrive/_ML_PROJECTS/Music_generation/music_generation.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ocYSLQwwM4Pv",
    "outputId": "327db7a1-2fda-474c-e7c8-2e2622534e82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
      "Batch 4: loss = 0.39988142251968384, acc = 0.8623046875\n",
      "Batch 5: loss = 0.41681694984436035, acc = 0.86328125\n",
      "Batch 6: loss = 0.4538169801235199, acc = 0.8447265625\n",
      "Batch 7: loss = 0.35728567838668823, acc = 0.8818359375\n",
      "Batch 8: loss = 0.40395021438598633, acc = 0.8671875\n",
      "Batch 9: loss = 0.35542893409729004, acc = 0.873046875\n",
      "Batch 10: loss = 0.3372431695461273, acc = 0.8916015625\n",
      "Batch 11: loss = 0.3803956210613251, acc = 0.8857421875\n",
      "Batch 12: loss = 0.38065582513809204, acc = 0.8857421875\n",
      "Batch 13: loss = 0.3701624274253845, acc = 0.8837890625\n",
      "Batch 14: loss = 0.3515894412994385, acc = 0.8896484375\n",
      "Batch 15: loss = 0.3603408634662628, acc = 0.873046875\n",
      "Batch 16: loss = 0.3987705707550049, acc = 0.8642578125\n",
      "Batch 17: loss = 0.4038284122943878, acc = 0.8671875\n",
      "Batch 18: loss = 0.4257067143917084, acc = 0.8525390625\n",
      "Batch 19: loss = 0.40321409702301025, acc = 0.857421875\n",
      "Batch 20: loss = 0.39917635917663574, acc = 0.86328125\n",
      "Batch 21: loss = 0.3853551745414734, acc = 0.873046875\n",
      "Batch 22: loss = 0.38675278425216675, acc = 0.8740234375\n",
      "Batch 23: loss = 0.4226425886154175, acc = 0.8544921875\n",
      "Batch 24: loss = 0.3886866569519043, acc = 0.8740234375\n",
      "Batch 25: loss = 0.3793941140174866, acc = 0.8671875\n",
      "Batch 26: loss = 0.3852248787879944, acc = 0.880859375\n",
      "Batch 27: loss = 0.4738238453865051, acc = 0.8408203125\n",
      "Batch 28: loss = 0.4060096740722656, acc = 0.8623046875\n",
      "Batch 29: loss = 0.43075767159461975, acc = 0.8544921875\n",
      "Batch 30: loss = 0.3747381567955017, acc = 0.875\n",
      "Batch 31: loss = 0.4258131980895996, acc = 0.8544921875\n",
      "Batch 32: loss = 0.4559537470340729, acc = 0.83984375\n",
      "Batch 33: loss = 0.40162885189056396, acc = 0.8662109375\n",
      "Batch 34: loss = 0.4036902189254761, acc = 0.8623046875\n",
      "Batch 35: loss = 0.39463868737220764, acc = 0.8662109375\n",
      "Batch 36: loss = 0.335898220539093, acc = 0.892578125\n",
      "Batch 37: loss = 0.3430425524711609, acc = 0.884765625\n",
      "Batch 38: loss = 0.36614835262298584, acc = 0.8828125\n",
      "Batch 39: loss = 0.36053404211997986, acc = 0.8798828125\n",
      "Batch 40: loss = 0.41007474064826965, acc = 0.8623046875\n",
      "Batch 41: loss = 0.3501974940299988, acc = 0.8798828125\n",
      "Batch 42: loss = 0.3971758484840393, acc = 0.8623046875\n",
      "Batch 43: loss = 0.43665391206741333, acc = 0.8642578125\n",
      "Batch 44: loss = 0.34295451641082764, acc = 0.8759765625\n",
      "Batch 45: loss = 0.32961106300354004, acc = 0.892578125\n",
      "Batch 46: loss = 0.3652236759662628, acc = 0.8671875\n",
      "Batch 47: loss = 0.38209185004234314, acc = 0.8681640625\n",
      "Batch 48: loss = 0.3691050410270691, acc = 0.8701171875\n",
      "Batch 49: loss = 0.3499067425727844, acc = 0.8896484375\n",
      "Batch 50: loss = 0.34538158774375916, acc = 0.8857421875\n",
      "Batch 51: loss = 0.35874515771865845, acc = 0.853515625\n",
      "Batch 52: loss = 0.37285861372947693, acc = 0.880859375\n",
      "Batch 53: loss = 0.39700257778167725, acc = 0.875\n",
      "Batch 54: loss = 0.305510938167572, acc = 0.8974609375\n",
      "Batch 55: loss = 0.3396475613117218, acc = 0.8896484375\n",
      "Batch 56: loss = 0.3963302969932556, acc = 0.8603515625\n",
      "Batch 57: loss = 0.4492548704147339, acc = 0.837890625\n",
      "Batch 58: loss = 0.4113219976425171, acc = 0.8564453125\n",
      "Batch 59: loss = 0.3172747492790222, acc = 0.896484375\n",
      "Batch 60: loss = 0.37965527176856995, acc = 0.875\n",
      "Batch 61: loss = 0.3569411337375641, acc = 0.876953125\n",
      "Batch 62: loss = 0.42404064536094666, acc = 0.853515625\n",
      "Batch 63: loss = 0.37147173285484314, acc = 0.8740234375\n",
      "Batch 64: loss = 0.33096715807914734, acc = 0.8837890625\n",
      "Batch 65: loss = 0.3806031346321106, acc = 0.8779296875\n",
      "Batch 66: loss = 0.3901246190071106, acc = 0.8642578125\n",
      "Batch 67: loss = 0.3981858491897583, acc = 0.84765625\n",
      "Batch 68: loss = 0.3780383765697479, acc = 0.873046875\n",
      "Batch 69: loss = 0.33175671100616455, acc = 0.8740234375\n",
      "Batch 70: loss = 0.4264652729034424, acc = 0.8525390625\n",
      "Batch 71: loss = 0.3850107192993164, acc = 0.859375\n",
      "Batch 72: loss = 0.36531728506088257, acc = 0.8818359375\n",
      "Batch 73: loss = 0.4212626814842224, acc = 0.86328125\n",
      "Batch 74: loss = 0.41703417897224426, acc = 0.857421875\n",
      "Batch 75: loss = 0.44094181060791016, acc = 0.84765625\n",
      "Batch 76: loss = 0.43863463401794434, acc = 0.86328125\n",
      "Batch 77: loss = 0.37371182441711426, acc = 0.8740234375\n",
      "Batch 78: loss = 0.40628737211227417, acc = 0.8642578125\n",
      "Batch 79: loss = 0.3429677486419678, acc = 0.8876953125\n",
      "Batch 80: loss = 0.3852698504924774, acc = 0.8623046875\n",
      "Batch 81: loss = 0.38523396849632263, acc = 0.875\n",
      "Batch 82: loss = 0.3973982036113739, acc = 0.8603515625\n",
      "Batch 83: loss = 0.37068212032318115, acc = 0.8720703125\n",
      "Batch 84: loss = 0.38288912177085876, acc = 0.8759765625\n",
      "Batch 85: loss = 0.4341545104980469, acc = 0.8544921875\n",
      "Batch 86: loss = 0.3959086239337921, acc = 0.869140625\n",
      "Batch 87: loss = 0.3982009291648865, acc = 0.8623046875\n",
      "Batch 88: loss = 0.4432995319366455, acc = 0.845703125\n",
      "Batch 89: loss = 0.3633763790130615, acc = 0.875\n",
      "Batch 90: loss = 0.42076486349105835, acc = 0.86328125\n",
      "Batch 91: loss = 0.4165407717227936, acc = 0.859375\n",
      "Batch 92: loss = 0.38524800539016724, acc = 0.8642578125\n",
      "Batch 93: loss = 0.35460227727890015, acc = 0.8759765625\n",
      "Batch 94: loss = 0.3694826066493988, acc = 0.8828125\n",
      "Batch 95: loss = 0.37216418981552124, acc = 0.8720703125\n",
      "Batch 96: loss = 0.4399011731147766, acc = 0.857421875\n",
      "Batch 97: loss = 0.39454710483551025, acc = 0.87109375\n",
      "Batch 98: loss = 0.3957674503326416, acc = 0.865234375\n",
      "Batch 99: loss = 0.4004974663257599, acc = 0.8671875\n",
      "Batch 100: loss = 0.4304473400115967, acc = 0.8505859375\n",
      "Batch 101: loss = 0.3925275504589081, acc = 0.857421875\n",
      "Batch 102: loss = 0.40586674213409424, acc = 0.853515625\n",
      "Batch 103: loss = 0.3999912142753601, acc = 0.8583984375\n",
      "Batch 104: loss = 0.33991739153862, acc = 0.88671875\n",
      "Batch 105: loss = 0.3383263945579529, acc = 0.89453125\n",
      "Batch 106: loss = 0.39075297117233276, acc = 0.8740234375\n",
      "Batch 107: loss = 0.3623771369457245, acc = 0.8828125\n",
      "Batch 108: loss = 0.35869160294532776, acc = 0.8798828125\n",
      "Batch 109: loss = 0.3882726728916168, acc = 0.8642578125\n",
      "Batch 110: loss = 0.36195915937423706, acc = 0.88671875\n",
      "Batch 111: loss = 0.39114347100257874, acc = 0.8681640625\n",
      "Batch 112: loss = 0.38053372502326965, acc = 0.86328125\n",
      "Batch 113: loss = 0.4102001488208771, acc = 0.8544921875\n",
      "Batch 114: loss = 0.42023441195487976, acc = 0.859375\n",
      "Batch 115: loss = 0.4068230390548706, acc = 0.859375\n",
      "Batch 116: loss = 0.44873014092445374, acc = 0.8447265625\n",
      "Batch 117: loss = 0.39452195167541504, acc = 0.869140625\n",
      "Batch 118: loss = 0.3608592748641968, acc = 0.8740234375\n",
      "Batch 119: loss = 0.3697871267795563, acc = 0.888671875\n",
      "Batch 120: loss = 0.34975820779800415, acc = 0.884765625\n",
      "Batch 121: loss = 0.3635946214199066, acc = 0.8681640625\n",
      "Batch 122: loss = 0.3209896385669708, acc = 0.8896484375\n",
      "Batch 123: loss = 0.3685540556907654, acc = 0.875\n",
      "Batch 124: loss = 0.4053300619125366, acc = 0.8642578125\n",
      "Batch 125: loss = 0.4156854748725891, acc = 0.859375\n",
      "Batch 126: loss = 0.40620726346969604, acc = 0.875\n",
      "\n",
      "Epoch 63/100\n",
      "Batch 1: loss = 0.4747071862220764, acc = 0.8427734375\n",
      "Batch 2: loss = 0.4099433720111847, acc = 0.86328125\n",
      "Batch 3: loss = 0.39026814699172974, acc = 0.8720703125\n",
      "Batch 4: loss = 0.38184282183647156, acc = 0.880859375\n",
      "Batch 5: loss = 0.37503841519355774, acc = 0.890625\n",
      "Batch 6: loss = 0.41951727867126465, acc = 0.859375\n",
      "Batch 7: loss = 0.36484187841415405, acc = 0.8759765625\n",
      "Batch 8: loss = 0.40521594882011414, acc = 0.8740234375\n",
      "Batch 9: loss = 0.34657996892929077, acc = 0.88671875\n",
      "Batch 10: loss = 0.3575924038887024, acc = 0.884765625\n",
      "Batch 11: loss = 0.37563398480415344, acc = 0.8828125\n",
      "Batch 12: loss = 0.3764835000038147, acc = 0.8623046875\n",
      "Batch 13: loss = 0.3825729191303253, acc = 0.8720703125\n",
      "Batch 14: loss = 0.3407557010650635, acc = 0.8828125\n",
      "Batch 15: loss = 0.34690725803375244, acc = 0.876953125\n",
      "Batch 16: loss = 0.41215574741363525, acc = 0.8701171875\n",
      "Batch 17: loss = 0.3839609920978546, acc = 0.880859375\n",
      "Batch 18: loss = 0.45987093448638916, acc = 0.8427734375\n",
      "Batch 19: loss = 0.40207916498184204, acc = 0.861328125\n",
      "Batch 20: loss = 0.38065198063850403, acc = 0.873046875\n",
      "Batch 21: loss = 0.3960035741329193, acc = 0.8642578125\n",
      "Batch 22: loss = 0.3895767331123352, acc = 0.880859375\n",
      "Batch 23: loss = 0.39808034896850586, acc = 0.873046875\n",
      "Batch 24: loss = 0.39567309617996216, acc = 0.8662109375\n",
      "Batch 25: loss = 0.3800562620162964, acc = 0.8779296875\n",
      "Batch 26: loss = 0.3936667740345001, acc = 0.87109375\n",
      "Batch 27: loss = 0.4934421479701996, acc = 0.8349609375\n",
      "Batch 28: loss = 0.4151495099067688, acc = 0.859375\n",
      "Batch 29: loss = 0.4535003900527954, acc = 0.8447265625\n",
      "Batch 30: loss = 0.359546959400177, acc = 0.87890625\n",
      "Batch 31: loss = 0.45176249742507935, acc = 0.859375\n",
      "Batch 32: loss = 0.410703182220459, acc = 0.8662109375\n",
      "Batch 33: loss = 0.3721674680709839, acc = 0.87890625\n",
      "Batch 34: loss = 0.406123548746109, acc = 0.861328125\n",
      "Batch 35: loss = 0.391400009393692, acc = 0.8740234375\n",
      "Batch 36: loss = 0.3222667872905731, acc = 0.8837890625\n",
      "Batch 37: loss = 0.3469325304031372, acc = 0.8798828125\n",
      "Batch 38: loss = 0.3575071096420288, acc = 0.8876953125\n",
      "Batch 39: loss = 0.34660446643829346, acc = 0.8955078125\n",
      "Batch 40: loss = 0.42497187852859497, acc = 0.8515625\n",
      "Batch 41: loss = 0.3589663803577423, acc = 0.8818359375\n",
      "Batch 42: loss = 0.380362868309021, acc = 0.8681640625\n",
      "Batch 43: loss = 0.4270382821559906, acc = 0.86328125\n",
      "Batch 44: loss = 0.33751505613327026, acc = 0.8857421875\n",
      "Batch 45: loss = 0.3519112169742584, acc = 0.876953125\n",
      "Batch 46: loss = 0.36597511172294617, acc = 0.8662109375\n",
      "Batch 47: loss = 0.40104490518569946, acc = 0.8740234375\n",
      "Batch 48: loss = 0.3640805780887604, acc = 0.8818359375\n",
      "Batch 49: loss = 0.34083789587020874, acc = 0.884765625\n",
      "Batch 50: loss = 0.3549392521381378, acc = 0.888671875\n",
      "Batch 51: loss = 0.32692205905914307, acc = 0.888671875\n",
      "Batch 52: loss = 0.39928001165390015, acc = 0.869140625\n",
      "Batch 53: loss = 0.3626069128513336, acc = 0.8798828125\n",
      "Batch 54: loss = 0.3084656894207001, acc = 0.8935546875\n",
      "Batch 55: loss = 0.3394686281681061, acc = 0.888671875\n",
      "Batch 56: loss = 0.37606146931648254, acc = 0.865234375\n",
      "Batch 57: loss = 0.3829241096973419, acc = 0.865234375\n",
      "Batch 58: loss = 0.4016339182853699, acc = 0.8681640625\n",
      "Batch 59: loss = 0.3108976185321808, acc = 0.9052734375\n",
      "Batch 60: loss = 0.37729012966156006, acc = 0.8720703125\n",
      "Batch 61: loss = 0.3078714907169342, acc = 0.908203125\n",
      "Batch 62: loss = 0.4397207498550415, acc = 0.8525390625\n",
      "Batch 63: loss = 0.3419215977191925, acc = 0.884765625\n",
      "Batch 64: loss = 0.31080004572868347, acc = 0.8916015625\n",
      "Batch 65: loss = 0.3757646977901459, acc = 0.8740234375\n",
      "Batch 66: loss = 0.37584397196769714, acc = 0.869140625\n",
      "Batch 67: loss = 0.36857545375823975, acc = 0.8740234375\n",
      "Batch 68: loss = 0.36869490146636963, acc = 0.873046875\n",
      "Batch 69: loss = 0.3505724370479584, acc = 0.8828125\n",
      "Batch 70: loss = 0.38787809014320374, acc = 0.8662109375\n",
      "Batch 71: loss = 0.38749581575393677, acc = 0.8681640625\n",
      "Batch 72: loss = 0.3443412780761719, acc = 0.8876953125\n",
      "Batch 73: loss = 0.4051952362060547, acc = 0.861328125\n",
      "Batch 74: loss = 0.4085139334201813, acc = 0.8525390625\n",
      "Batch 75: loss = 0.44481360912323, acc = 0.849609375\n",
      "Batch 76: loss = 0.4184356927871704, acc = 0.84765625\n",
      "Batch 77: loss = 0.397382915019989, acc = 0.8701171875\n",
      "Batch 78: loss = 0.4159144163131714, acc = 0.853515625\n",
      "Batch 79: loss = 0.34212565422058105, acc = 0.8798828125\n",
      "Batch 80: loss = 0.33098480105400085, acc = 0.884765625\n",
      "Batch 81: loss = 0.3890780210494995, acc = 0.8583984375\n",
      "Batch 82: loss = 0.3426847457885742, acc = 0.884765625\n",
      "Batch 83: loss = 0.34885138273239136, acc = 0.8798828125\n",
      "Batch 84: loss = 0.4129043221473694, acc = 0.865234375\n",
      "Batch 85: loss = 0.42523717880249023, acc = 0.85546875\n",
      "Batch 86: loss = 0.37750738859176636, acc = 0.8671875\n",
      "Batch 87: loss = 0.3801572024822235, acc = 0.8701171875\n",
      "Batch 88: loss = 0.40828025341033936, acc = 0.869140625\n",
      "Batch 89: loss = 0.3487488031387329, acc = 0.900390625\n",
      "Batch 90: loss = 0.37912675738334656, acc = 0.8740234375\n",
      "Batch 91: loss = 0.38622087240219116, acc = 0.865234375\n",
      "Batch 92: loss = 0.38263070583343506, acc = 0.8662109375\n",
      "Batch 93: loss = 0.3423270285129547, acc = 0.8974609375\n",
      "Batch 94: loss = 0.34909477829933167, acc = 0.8779296875\n",
      "Batch 95: loss = 0.37131404876708984, acc = 0.875\n",
      "Batch 96: loss = 0.3892950117588043, acc = 0.865234375\n",
      "Batch 97: loss = 0.3926054835319519, acc = 0.8740234375\n",
      "Batch 98: loss = 0.3851354420185089, acc = 0.8662109375\n",
      "Batch 99: loss = 0.40357837080955505, acc = 0.8603515625\n",
      "Batch 100: loss = 0.4230431020259857, acc = 0.8408203125\n",
      "Batch 101: loss = 0.3652055263519287, acc = 0.8671875\n",
      "Batch 102: loss = 0.42104843258857727, acc = 0.845703125\n",
      "Batch 103: loss = 0.4143350124359131, acc = 0.8662109375\n",
      "Batch 104: loss = 0.3249117434024811, acc = 0.8876953125\n",
      "Batch 105: loss = 0.34759846329689026, acc = 0.8759765625\n",
      "Batch 106: loss = 0.3535826802253723, acc = 0.8779296875\n",
      "Batch 107: loss = 0.3421649932861328, acc = 0.8779296875\n",
      "Batch 108: loss = 0.3751860558986664, acc = 0.859375\n",
      "Batch 109: loss = 0.37951311469078064, acc = 0.8662109375\n",
      "Batch 110: loss = 0.3598724603652954, acc = 0.8828125\n",
      "Batch 111: loss = 0.3795066773891449, acc = 0.869140625\n",
      "Batch 112: loss = 0.3615442216396332, acc = 0.869140625\n",
      "Batch 113: loss = 0.39743927121162415, acc = 0.85546875\n",
      "Batch 114: loss = 0.39418449997901917, acc = 0.8759765625\n",
      "Batch 115: loss = 0.378770112991333, acc = 0.8798828125\n",
      "Batch 116: loss = 0.40344154834747314, acc = 0.8701171875\n",
      "Batch 117: loss = 0.3617071211338043, acc = 0.87890625\n",
      "Batch 118: loss = 0.36867159605026245, acc = 0.876953125\n",
      "Batch 119: loss = 0.35896193981170654, acc = 0.8857421875\n",
      "Batch 120: loss = 0.35196658968925476, acc = 0.8720703125\n",
      "Batch 121: loss = 0.39475566148757935, acc = 0.8623046875\n",
      "Batch 122: loss = 0.34509509801864624, acc = 0.8779296875\n",
      "Batch 123: loss = 0.3357452154159546, acc = 0.8935546875\n",
      "Batch 124: loss = 0.39919570088386536, acc = 0.8681640625\n",
      "Batch 125: loss = 0.3940199911594391, acc = 0.87109375\n",
      "Batch 126: loss = 0.3921361565589905, acc = 0.87109375\n",
      "\n",
      "Epoch 64/100\n",
      "Batch 1: loss = 0.4495577812194824, acc = 0.8642578125\n",
      "Batch 2: loss = 0.4186417758464813, acc = 0.853515625\n",
      "Batch 3: loss = 0.38051944971084595, acc = 0.880859375\n",
      "Batch 4: loss = 0.38125741481781006, acc = 0.8720703125\n",
      "Batch 5: loss = 0.39512014389038086, acc = 0.8740234375\n",
      "Batch 6: loss = 0.40177035331726074, acc = 0.8544921875\n",
      "Batch 7: loss = 0.3635566234588623, acc = 0.876953125\n",
      "Batch 8: loss = 0.37060800194740295, acc = 0.875\n",
      "Batch 9: loss = 0.36134958267211914, acc = 0.8798828125\n",
      "Batch 10: loss = 0.3528687655925751, acc = 0.8857421875\n",
      "Batch 11: loss = 0.384014755487442, acc = 0.8681640625\n",
      "Batch 12: loss = 0.39355215430259705, acc = 0.8603515625\n",
      "Batch 13: loss = 0.35920366644859314, acc = 0.8837890625\n",
      "Batch 14: loss = 0.34129083156585693, acc = 0.884765625\n",
      "Batch 15: loss = 0.33555349707603455, acc = 0.8818359375\n",
      "Batch 16: loss = 0.39895468950271606, acc = 0.8662109375\n",
      "Batch 17: loss = 0.3663865327835083, acc = 0.87109375\n",
      "Batch 18: loss = 0.4441834092140198, acc = 0.845703125\n",
      "Batch 19: loss = 0.36215466260910034, acc = 0.87890625\n",
      "Batch 20: loss = 0.4122384190559387, acc = 0.8623046875\n",
      "Batch 21: loss = 0.4227116107940674, acc = 0.8544921875\n",
      "Batch 22: loss = 0.39304205775260925, acc = 0.861328125\n",
      "Batch 23: loss = 0.40511801838874817, acc = 0.8525390625\n",
      "Batch 24: loss = 0.3854435980319977, acc = 0.86328125\n",
      "Batch 25: loss = 0.38892629742622375, acc = 0.859375\n",
      "Batch 26: loss = 0.3814510703086853, acc = 0.87109375\n",
      "Batch 27: loss = 0.45328640937805176, acc = 0.8388671875\n",
      "Batch 28: loss = 0.38076433539390564, acc = 0.8779296875\n",
      "Batch 29: loss = 0.429462730884552, acc = 0.8564453125\n",
      "Batch 30: loss = 0.3639720678329468, acc = 0.875\n",
      "Batch 31: loss = 0.43961527943611145, acc = 0.8525390625\n",
      "Batch 32: loss = 0.43329113721847534, acc = 0.849609375\n",
      "Batch 33: loss = 0.3500496745109558, acc = 0.8740234375\n",
      "Batch 34: loss = 0.39914670586586, acc = 0.869140625\n",
      "Batch 35: loss = 0.3788175880908966, acc = 0.869140625\n",
      "Batch 36: loss = 0.3258487582206726, acc = 0.8779296875\n",
      "Batch 37: loss = 0.335293173789978, acc = 0.8916015625\n",
      "Batch 38: loss = 0.3318287134170532, acc = 0.90625\n",
      "Batch 39: loss = 0.38161182403564453, acc = 0.8759765625\n",
      "Batch 40: loss = 0.40815478563308716, acc = 0.865234375\n",
      "Batch 41: loss = 0.3559764623641968, acc = 0.87890625\n",
      "Batch 42: loss = 0.3990822434425354, acc = 0.873046875\n",
      "Batch 43: loss = 0.425834059715271, acc = 0.8427734375\n",
      "Batch 44: loss = 0.3360145688056946, acc = 0.884765625\n",
      "Batch 45: loss = 0.3373911678791046, acc = 0.890625\n",
      "Batch 46: loss = 0.3515775203704834, acc = 0.8828125\n",
      "Batch 47: loss = 0.37350916862487793, acc = 0.87109375\n",
      "Batch 48: loss = 0.3542545437812805, acc = 0.8798828125\n",
      "Batch 49: loss = 0.3353751301765442, acc = 0.89453125\n",
      "Batch 50: loss = 0.33820632100105286, acc = 0.87890625\n",
      "Batch 51: loss = 0.33787545561790466, acc = 0.8876953125\n",
      "Batch 52: loss = 0.3734897971153259, acc = 0.8740234375\n",
      "Batch 53: loss = 0.3901073932647705, acc = 0.861328125\n",
      "Batch 54: loss = 0.30688318610191345, acc = 0.896484375\n",
      "Batch 55: loss = 0.3404066860675812, acc = 0.884765625\n",
      "Batch 56: loss = 0.3648398518562317, acc = 0.8740234375\n",
      "Batch 57: loss = 0.41737639904022217, acc = 0.857421875\n",
      "Batch 58: loss = 0.38763105869293213, acc = 0.869140625\n",
      "Batch 59: loss = 0.2884770333766937, acc = 0.904296875\n",
      "Batch 60: loss = 0.37236133217811584, acc = 0.873046875\n",
      "Batch 61: loss = 0.3314308822154999, acc = 0.8974609375\n",
      "Batch 62: loss = 0.4060303568840027, acc = 0.8671875\n",
      "Batch 63: loss = 0.36884617805480957, acc = 0.8720703125\n",
      "Batch 64: loss = 0.3195255398750305, acc = 0.8984375\n",
      "Batch 65: loss = 0.36925238370895386, acc = 0.861328125\n",
      "Batch 66: loss = 0.40500327944755554, acc = 0.8583984375\n",
      "Batch 67: loss = 0.34649401903152466, acc = 0.875\n",
      "Batch 68: loss = 0.37251269817352295, acc = 0.8701171875\n",
      "Batch 69: loss = 0.3262553811073303, acc = 0.8876953125\n",
      "Batch 70: loss = 0.37477296590805054, acc = 0.876953125\n",
      "Batch 71: loss = 0.3927440643310547, acc = 0.8583984375\n",
      "Batch 72: loss = 0.3687173128128052, acc = 0.8759765625\n",
      "Batch 73: loss = 0.39143577218055725, acc = 0.86328125\n",
      "Batch 74: loss = 0.4118301272392273, acc = 0.8623046875\n",
      "Batch 75: loss = 0.47863274812698364, acc = 0.8330078125\n",
      "Batch 76: loss = 0.3929184377193451, acc = 0.8583984375\n",
      "Batch 77: loss = 0.35724806785583496, acc = 0.8740234375\n",
      "Batch 78: loss = 0.41225147247314453, acc = 0.8603515625\n",
      "Batch 79: loss = 0.35485249757766724, acc = 0.873046875\n",
      "Batch 80: loss = 0.32001808285713196, acc = 0.8876953125\n",
      "Batch 81: loss = 0.3495911657810211, acc = 0.880859375\n",
      "Batch 82: loss = 0.3596639037132263, acc = 0.8779296875\n",
      "Batch 83: loss = 0.3508079946041107, acc = 0.8828125\n",
      "Batch 84: loss = 0.3750756084918976, acc = 0.8623046875\n",
      "Batch 85: loss = 0.4025092124938965, acc = 0.861328125\n",
      "Batch 86: loss = 0.3946170508861542, acc = 0.873046875\n",
      "Batch 87: loss = 0.38989174365997314, acc = 0.8681640625\n",
      "Batch 88: loss = 0.42883816361427307, acc = 0.8505859375\n",
      "Batch 89: loss = 0.3414185643196106, acc = 0.88671875\n",
      "Batch 90: loss = 0.38954299688339233, acc = 0.8740234375\n",
      "Batch 91: loss = 0.424846351146698, acc = 0.8544921875\n",
      "Batch 92: loss = 0.35979992151260376, acc = 0.8720703125\n",
      "Batch 93: loss = 0.3300100564956665, acc = 0.888671875\n",
      "Batch 94: loss = 0.33143287897109985, acc = 0.8876953125\n",
      "Batch 95: loss = 0.36326906085014343, acc = 0.8740234375\n",
      "Batch 96: loss = 0.4401385486125946, acc = 0.8427734375\n",
      "Batch 97: loss = 0.3724139928817749, acc = 0.8779296875\n",
      "Batch 98: loss = 0.3782464861869812, acc = 0.865234375\n",
      "Batch 99: loss = 0.41858306527137756, acc = 0.8564453125\n",
      "Batch 100: loss = 0.39830195903778076, acc = 0.861328125\n",
      "Batch 101: loss = 0.36103010177612305, acc = 0.87890625\n",
      "Batch 102: loss = 0.4063860774040222, acc = 0.8583984375\n",
      "Batch 103: loss = 0.38746777176856995, acc = 0.869140625\n",
      "Batch 104: loss = 0.3477424085140228, acc = 0.8759765625\n",
      "Batch 105: loss = 0.3401353657245636, acc = 0.8974609375\n",
      "Batch 106: loss = 0.38770854473114014, acc = 0.869140625\n",
      "Batch 107: loss = 0.3450992703437805, acc = 0.884765625\n",
      "Batch 108: loss = 0.3448459208011627, acc = 0.8837890625\n",
      "Batch 109: loss = 0.36692070960998535, acc = 0.8828125\n",
      "Batch 110: loss = 0.3264515697956085, acc = 0.8935546875\n",
      "Batch 111: loss = 0.38361284136772156, acc = 0.8759765625\n",
      "Batch 112: loss = 0.3848429322242737, acc = 0.865234375\n",
      "Batch 113: loss = 0.3556504249572754, acc = 0.8740234375\n",
      "Batch 114: loss = 0.39454787969589233, acc = 0.8720703125\n",
      "Batch 115: loss = 0.3849472403526306, acc = 0.8662109375\n",
      "Batch 116: loss = 0.41087672114372253, acc = 0.8759765625\n",
      "Batch 117: loss = 0.360106498003006, acc = 0.8857421875\n",
      "Batch 118: loss = 0.3251999318599701, acc = 0.900390625\n",
      "Batch 119: loss = 0.3561449646949768, acc = 0.8857421875\n",
      "Batch 120: loss = 0.3945755958557129, acc = 0.8515625\n",
      "Batch 121: loss = 0.34978824853897095, acc = 0.8740234375\n",
      "Batch 122: loss = 0.31608471274375916, acc = 0.90234375\n",
      "Batch 123: loss = 0.36154311895370483, acc = 0.880859375\n",
      "Batch 124: loss = 0.4258772134780884, acc = 0.861328125\n",
      "Batch 125: loss = 0.3718037009239197, acc = 0.8623046875\n",
      "Batch 126: loss = 0.40613237023353577, acc = 0.8623046875\n",
      "\n",
      "Epoch 65/100\n",
      "Batch 1: loss = 0.45499107241630554, acc = 0.85546875\n",
      "Batch 2: loss = 0.4221627414226532, acc = 0.85546875\n",
      "Batch 3: loss = 0.39918580651283264, acc = 0.8671875\n",
      "Batch 4: loss = 0.3899805545806885, acc = 0.8701171875\n",
      "Batch 5: loss = 0.3847265839576721, acc = 0.87109375\n",
      "Batch 6: loss = 0.3731512725353241, acc = 0.8720703125\n",
      "Batch 7: loss = 0.32704973220825195, acc = 0.888671875\n",
      "Batch 8: loss = 0.38838329911231995, acc = 0.8583984375\n",
      "Batch 9: loss = 0.354240357875824, acc = 0.875\n",
      "Batch 10: loss = 0.3702571392059326, acc = 0.8798828125\n",
      "Batch 11: loss = 0.37837210297584534, acc = 0.873046875\n",
      "Batch 12: loss = 0.39012694358825684, acc = 0.865234375\n",
      "Batch 13: loss = 0.34011590480804443, acc = 0.8876953125\n",
      "Batch 14: loss = 0.34371131658554077, acc = 0.8720703125\n",
      "Batch 15: loss = 0.3309025466442108, acc = 0.890625\n",
      "Batch 16: loss = 0.3947158455848694, acc = 0.8681640625\n",
      "Batch 17: loss = 0.38155701756477356, acc = 0.87890625\n",
      "Batch 18: loss = 0.3975987136363983, acc = 0.865234375\n",
      "Batch 19: loss = 0.3722204267978668, acc = 0.8798828125\n",
      "Batch 20: loss = 0.3658541738986969, acc = 0.8759765625\n",
      "Batch 21: loss = 0.3903392553329468, acc = 0.8740234375\n",
      "Batch 22: loss = 0.37161487340927124, acc = 0.8720703125\n",
      "Batch 23: loss = 0.3611851930618286, acc = 0.8798828125\n",
      "Batch 24: loss = 0.4293680191040039, acc = 0.8515625\n",
      "Batch 25: loss = 0.36416468024253845, acc = 0.8740234375\n",
      "Batch 26: loss = 0.3772864043712616, acc = 0.8603515625\n",
      "Batch 27: loss = 0.44276201725006104, acc = 0.8603515625\n",
      "Batch 28: loss = 0.3937704563140869, acc = 0.8671875\n",
      "Batch 29: loss = 0.42412400245666504, acc = 0.85546875\n",
      "Batch 30: loss = 0.3496018946170807, acc = 0.8828125\n",
      "Batch 31: loss = 0.4113684594631195, acc = 0.86328125\n",
      "Batch 32: loss = 0.4282640516757965, acc = 0.8505859375\n",
      "Batch 33: loss = 0.3718855381011963, acc = 0.8798828125\n",
      "Batch 34: loss = 0.43357792496681213, acc = 0.849609375\n",
      "Batch 35: loss = 0.3705691695213318, acc = 0.8740234375\n",
      "Batch 36: loss = 0.3326800763607025, acc = 0.888671875\n",
      "Batch 37: loss = 0.2950790822505951, acc = 0.912109375\n",
      "Batch 38: loss = 0.3608507513999939, acc = 0.876953125\n",
      "Batch 39: loss = 0.3709369897842407, acc = 0.869140625\n",
      "Batch 40: loss = 0.3963993787765503, acc = 0.861328125\n",
      "Batch 41: loss = 0.3314690887928009, acc = 0.8837890625\n",
      "Batch 42: loss = 0.3789054751396179, acc = 0.8740234375\n",
      "Batch 43: loss = 0.38534635305404663, acc = 0.8740234375\n",
      "Batch 44: loss = 0.32712653279304504, acc = 0.888671875\n",
      "Batch 45: loss = 0.3235839903354645, acc = 0.892578125\n",
      "Batch 46: loss = 0.3674325942993164, acc = 0.880859375\n",
      "Batch 47: loss = 0.39270997047424316, acc = 0.8681640625\n",
      "Batch 48: loss = 0.3395865857601166, acc = 0.8896484375\n",
      "Batch 49: loss = 0.35908934473991394, acc = 0.8828125\n",
      "Batch 50: loss = 0.33284085988998413, acc = 0.8798828125\n",
      "Batch 51: loss = 0.3443925380706787, acc = 0.888671875\n",
      "Batch 52: loss = 0.36162909865379333, acc = 0.8798828125\n",
      "Batch 53: loss = 0.3417850136756897, acc = 0.8876953125\n",
      "Batch 54: loss = 0.31645724177360535, acc = 0.89453125\n",
      "Batch 55: loss = 0.3523370623588562, acc = 0.8798828125\n",
      "Batch 56: loss = 0.3747272491455078, acc = 0.873046875\n",
      "Batch 57: loss = 0.42525607347488403, acc = 0.857421875\n",
      "Batch 58: loss = 0.3997802436351776, acc = 0.861328125\n",
      "Batch 59: loss = 0.2883358895778656, acc = 0.90234375\n",
      "Batch 60: loss = 0.3622802197933197, acc = 0.8818359375\n",
      "Batch 61: loss = 0.28796666860580444, acc = 0.9091796875\n",
      "Batch 62: loss = 0.4059322476387024, acc = 0.86328125\n",
      "Batch 63: loss = 0.3501802682876587, acc = 0.8740234375\n",
      "Batch 64: loss = 0.3317294418811798, acc = 0.8916015625\n",
      "Batch 65: loss = 0.3607286810874939, acc = 0.8818359375\n",
      "Batch 66: loss = 0.3405802249908447, acc = 0.8828125\n",
      "Batch 67: loss = 0.36240890622138977, acc = 0.87890625\n",
      "Batch 68: loss = 0.3700180947780609, acc = 0.8759765625\n",
      "Batch 69: loss = 0.3044384717941284, acc = 0.8994140625\n",
      "Batch 70: loss = 0.4037497341632843, acc = 0.86328125\n",
      "Batch 71: loss = 0.369720995426178, acc = 0.8662109375\n",
      "Batch 72: loss = 0.3477473258972168, acc = 0.888671875\n",
      "Batch 73: loss = 0.4013441503047943, acc = 0.8681640625\n",
      "Batch 74: loss = 0.3873576521873474, acc = 0.8642578125\n",
      "Batch 75: loss = 0.44830524921417236, acc = 0.8486328125\n",
      "Batch 76: loss = 0.4274938106536865, acc = 0.8486328125\n",
      "Batch 77: loss = 0.3742026090621948, acc = 0.87109375\n",
      "Batch 78: loss = 0.38240715861320496, acc = 0.87109375\n",
      "Batch 79: loss = 0.37030091881752014, acc = 0.869140625\n",
      "Batch 80: loss = 0.33069413900375366, acc = 0.884765625\n",
      "Batch 81: loss = 0.429708868265152, acc = 0.8466796875\n",
      "Batch 82: loss = 0.35818132758140564, acc = 0.884765625\n",
      "Batch 83: loss = 0.35147011280059814, acc = 0.8896484375\n",
      "Batch 84: loss = 0.37121257185935974, acc = 0.87109375\n",
      "Batch 85: loss = 0.4155603349208832, acc = 0.859375\n",
      "Batch 86: loss = 0.35350799560546875, acc = 0.8759765625\n",
      "Batch 87: loss = 0.3553665280342102, acc = 0.87890625\n",
      "Batch 88: loss = 0.4066241383552551, acc = 0.8681640625\n",
      "Batch 89: loss = 0.35039666295051575, acc = 0.88671875\n",
      "Batch 90: loss = 0.400045782327652, acc = 0.869140625\n",
      "Batch 91: loss = 0.4084581732749939, acc = 0.86328125\n",
      "Batch 92: loss = 0.377932608127594, acc = 0.8779296875\n",
      "Batch 93: loss = 0.3493146598339081, acc = 0.8896484375\n",
      "Batch 94: loss = 0.31617632508277893, acc = 0.88671875\n",
      "Batch 95: loss = 0.33897292613983154, acc = 0.8896484375\n",
      "Batch 96: loss = 0.4122213125228882, acc = 0.8447265625\n",
      "Batch 97: loss = 0.3698612451553345, acc = 0.8818359375\n",
      "Batch 98: loss = 0.3643452525138855, acc = 0.8720703125\n",
      "Batch 99: loss = 0.38092154264450073, acc = 0.8779296875\n",
      "Batch 100: loss = 0.4283254146575928, acc = 0.8564453125\n",
      "Batch 101: loss = 0.3818027377128601, acc = 0.8583984375\n",
      "Batch 102: loss = 0.42210495471954346, acc = 0.8525390625\n",
      "Batch 103: loss = 0.395285964012146, acc = 0.8681640625\n",
      "Batch 104: loss = 0.3272702395915985, acc = 0.89453125\n",
      "Batch 105: loss = 0.3155902922153473, acc = 0.8984375\n",
      "Batch 106: loss = 0.3456572890281677, acc = 0.8916015625\n",
      "Batch 107: loss = 0.3625645339488983, acc = 0.87890625\n",
      "Batch 108: loss = 0.3552660346031189, acc = 0.876953125\n",
      "Batch 109: loss = 0.37306323647499084, acc = 0.8759765625\n",
      "Batch 110: loss = 0.35240882635116577, acc = 0.875\n",
      "Batch 111: loss = 0.37532252073287964, acc = 0.87890625\n",
      "Batch 112: loss = 0.354062557220459, acc = 0.888671875\n",
      "Batch 113: loss = 0.3751394748687744, acc = 0.876953125\n",
      "Batch 114: loss = 0.3666033148765564, acc = 0.8837890625\n",
      "Batch 115: loss = 0.37199652194976807, acc = 0.876953125\n",
      "Batch 116: loss = 0.3990490138530731, acc = 0.86328125\n",
      "Batch 117: loss = 0.3636484444141388, acc = 0.888671875\n",
      "Batch 118: loss = 0.3319019675254822, acc = 0.890625\n",
      "Batch 119: loss = 0.3782705068588257, acc = 0.87109375\n",
      "Batch 120: loss = 0.32954397797584534, acc = 0.8876953125\n",
      "Batch 121: loss = 0.3590574562549591, acc = 0.876953125\n",
      "Batch 122: loss = 0.32928770780563354, acc = 0.884765625\n",
      "Batch 123: loss = 0.34170231223106384, acc = 0.8798828125\n",
      "Batch 124: loss = 0.41119518876075745, acc = 0.865234375\n",
      "Batch 125: loss = 0.37747883796691895, acc = 0.8671875\n",
      "Batch 126: loss = 0.3905841112136841, acc = 0.8720703125\n",
      "\n",
      "Epoch 66/100\n",
      "Batch 1: loss = 0.4505903422832489, acc = 0.8671875\n",
      "Batch 2: loss = 0.4291301369667053, acc = 0.861328125\n",
      "Batch 3: loss = 0.35284140706062317, acc = 0.8837890625\n",
      "Batch 4: loss = 0.3898119330406189, acc = 0.875\n",
      "Batch 5: loss = 0.3626515567302704, acc = 0.8876953125\n",
      "Batch 6: loss = 0.38122475147247314, acc = 0.8857421875\n",
      "Batch 7: loss = 0.3507096767425537, acc = 0.87890625\n",
      "Batch 8: loss = 0.3733854293823242, acc = 0.880859375\n",
      "Batch 9: loss = 0.336825966835022, acc = 0.8857421875\n",
      "Batch 10: loss = 0.32903292775154114, acc = 0.888671875\n",
      "Batch 11: loss = 0.37466663122177124, acc = 0.8623046875\n",
      "Batch 12: loss = 0.3579423129558563, acc = 0.875\n",
      "Batch 13: loss = 0.36630821228027344, acc = 0.8701171875\n",
      "Batch 14: loss = 0.3665308356285095, acc = 0.8759765625\n",
      "Batch 15: loss = 0.3384515047073364, acc = 0.888671875\n",
      "Batch 16: loss = 0.39534318447113037, acc = 0.8701171875\n",
      "Batch 17: loss = 0.376201331615448, acc = 0.884765625\n",
      "Batch 18: loss = 0.4348102807998657, acc = 0.861328125\n",
      "Batch 19: loss = 0.37109488248825073, acc = 0.8720703125\n",
      "Batch 20: loss = 0.351105660200119, acc = 0.884765625\n",
      "Batch 21: loss = 0.41899192333221436, acc = 0.8623046875\n",
      "Batch 22: loss = 0.37091556191444397, acc = 0.869140625\n",
      "Batch 23: loss = 0.3907768428325653, acc = 0.85546875\n",
      "2022-07-22 19:33:13.825535: W tensorflow/core/data/root_dataset.cc:200] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "Batch 24: loss = 0.3902682065963745, acc = 0.8701171875\n",
      "2022-07-22 19:33:13.852462: W tensorflow/core/data/root_dataset.cc:200] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "Batch 25: loss = 0.3565438389778137, acc = 0.888671875\n",
      "Batch 26: loss = 0.36170491576194763, acc = 0.8828125\n",
      "Batch 27: loss = 0.43238815665245056, acc = 0.8505859375\n",
      "2022-07-22 19:33:13.928359: W tensorflow/core/data/root_dataset.cc:200] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "Batch 28: loss = 0.3849181532859802, acc = 0.8720703125\n",
      "Batch 29: loss = 0.43810248374938965, acc = 0.837890625\n",
      "Batch 30: loss = 0.35057973861694336, acc = 0.880859375\n",
      "Batch 31: loss = 0.40280747413635254, acc = 0.8671875\n",
      "Batch 32: loss = 0.408639132976532, acc = 0.8603515625\n",
      "Batch 33: loss = 0.35284215211868286, acc = 0.8818359375\n",
      "Batch 34: loss = 0.3969195783138275, acc = 0.861328125\n",
      "2022-07-22 19:33:14.128661: W tensorflow/core/data/root_dataset.cc:200] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "Batch 35: loss = 0.3603082001209259, acc = 0.876953125\n",
      "Batch 36: loss = 0.3390713632106781, acc = 0.8798828125\n",
      "Batch 37: loss = 0.3048437535762787, acc = 0.900390625\n",
      "Batch 38: loss = 0.3328438997268677, acc = 0.89453125\n",
      "Batch 39: loss = 0.3586006164550781, acc = 0.880859375\n",
      "2022-07-22 19:33:14.267328: W tensorflow/core/data/root_dataset.cc:200] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "Batch 40: loss = 0.36901798844337463, acc = 0.8798828125\n",
      "Batch 41: loss = 0.33835798501968384, acc = 0.875\n",
      "Batch 42: loss = 0.3990345597267151, acc = 0.8583984375\n",
      "Batch 43: loss = 0.3846110701560974, acc = 0.865234375\n",
      "Batch 44: loss = 0.342852383852005, acc = 0.8818359375\n",
      "Batch 45: loss = 0.34177082777023315, acc = 0.8818359375\n",
      "Batch 46: loss = 0.31929102540016174, acc = 0.8916015625\n",
      "Batch 47: loss = 0.36033278703689575, acc = 0.8876953125\n",
      "Batch 48: loss = 0.33203575015068054, acc = 0.8876953125\n",
      "Batch 49: loss = 0.34113144874572754, acc = 0.896484375\n",
      "Batch 50: loss = 0.3499256670475006, acc = 0.8828125\n",
      "Batch 51: loss = 0.3450404107570648, acc = 0.876953125\n",
      "Batch 52: loss = 0.3985772728919983, acc = 0.8662109375\n",
      "Batch 53: loss = 0.3551689088344574, acc = 0.875\n",
      "Batch 54: loss = 0.29131627082824707, acc = 0.9013671875\n",
      "Batch 55: loss = 0.3676081597805023, acc = 0.87109375\n",
      "Batch 56: loss = 0.3636578321456909, acc = 0.8720703125\n",
      "Batch 57: loss = 0.3904746174812317, acc = 0.8671875\n",
      "Batch 58: loss = 0.39122945070266724, acc = 0.87109375\n",
      "Batch 59: loss = 0.2941517233848572, acc = 0.896484375\n",
      "Batch 60: loss = 0.35288581252098083, acc = 0.87890625\n",
      "Batch 61: loss = 0.31110256910324097, acc = 0.896484375\n",
      "Batch 62: loss = 0.40346798300743103, acc = 0.865234375\n",
      "Batch 63: loss = 0.34571000933647156, acc = 0.8740234375\n",
      "Batch 64: loss = 0.32136809825897217, acc = 0.8837890625\n",
      "Batch 65: loss = 0.3882977366447449, acc = 0.8701171875\n",
      "Batch 66: loss = 0.34310853481292725, acc = 0.8935546875\n",
      "Batch 67: loss = 0.3533174991607666, acc = 0.876953125\n",
      "Batch 68: loss = 0.3599271774291992, acc = 0.873046875\n",
      "Batch 69: loss = 0.32876360416412354, acc = 0.900390625\n",
      "Batch 70: loss = 0.3552413582801819, acc = 0.880859375\n",
      "Batch 71: loss = 0.3630458116531372, acc = 0.87109375\n",
      "Batch 72: loss = 0.34347525238990784, acc = 0.8818359375\n",
      "Batch 73: loss = 0.38065630197525024, acc = 0.8759765625\n",
      "Batch 74: loss = 0.4040793776512146, acc = 0.8583984375\n",
      "2022-07-22 19:33:15.285776: W tensorflow/core/data/root_dataset.cc:200] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "Batch 75: loss = 0.40474241971969604, acc = 0.8671875\n",
      "Batch 76: loss = 0.3483915328979492, acc = 0.87890625\n",
      "Batch 77: loss = 0.3773561120033264, acc = 0.875\n",
      "Batch 78: loss = 0.3674808740615845, acc = 0.8779296875\n",
      "Batch 79: loss = 0.33615124225616455, acc = 0.8876953125\n",
      "Batch 80: loss = 0.31134819984436035, acc = 0.8818359375\n",
      "Batch 81: loss = 0.36095818877220154, acc = 0.8662109375\n",
      "Batch 82: loss = 0.3603869676589966, acc = 0.8759765625\n",
      "Batch 83: loss = 0.3421071767807007, acc = 0.888671875\n",
      "Batch 84: loss = 0.36827704310417175, acc = 0.8681640625\n",
      "Batch 85: loss = 0.4110355079174042, acc = 0.8564453125\n",
      "Batch 86: loss = 0.33080193400382996, acc = 0.884765625\n",
      "Batch 87: loss = 0.36124753952026367, acc = 0.8837890625\n",
      "Batch 88: loss = 0.41356050968170166, acc = 0.8701171875\n",
      "Batch 89: loss = 0.3469303846359253, acc = 0.8818359375\n",
      "Batch 90: loss = 0.3422584533691406, acc = 0.8740234375\n",
      "Batch 91: loss = 0.3905857801437378, acc = 0.87109375\n",
      "Batch 92: loss = 0.3763751685619354, acc = 0.861328125\n",
      "Batch 93: loss = 0.33730456233024597, acc = 0.8876953125\n",
      "Batch 94: loss = 0.3243899643421173, acc = 0.888671875\n",
      "Batch 95: loss = 0.33043310046195984, acc = 0.900390625\n",
      "Batch 96: loss = 0.40323200821876526, acc = 0.857421875\n",
      "Batch 97: loss = 0.3642323613166809, acc = 0.8828125\n",
      "Batch 98: loss = 0.3385676443576813, acc = 0.892578125\n",
      "Batch 99: loss = 0.3979100286960602, acc = 0.8603515625\n",
      "Batch 100: loss = 0.3967292606830597, acc = 0.8544921875\n",
      "Batch 101: loss = 0.37067240476608276, acc = 0.873046875\n",
      "Batch 102: loss = 0.3774484097957611, acc = 0.87109375\n",
      "Batch 103: loss = 0.35861846804618835, acc = 0.8857421875\n",
      "Batch 104: loss = 0.3666682243347168, acc = 0.8798828125\n",
      "Batch 105: loss = 0.3452017307281494, acc = 0.884765625\n",
      "Batch 106: loss = 0.35405856370925903, acc = 0.8857421875\n",
      "Batch 107: loss = 0.30278894305229187, acc = 0.8955078125\n",
      "Batch 108: loss = 0.34763750433921814, acc = 0.8828125\n",
      "Batch 109: loss = 0.3627503514289856, acc = 0.869140625\n",
      "Batch 110: loss = 0.3182201683521271, acc = 0.8984375\n",
      "Batch 111: loss = 0.3587337136268616, acc = 0.876953125\n",
      "Batch 112: loss = 0.3591821491718292, acc = 0.87109375\n",
      "Batch 113: loss = 0.34279191493988037, acc = 0.8974609375\n",
      "Batch 114: loss = 0.35984131693840027, acc = 0.8720703125\n",
      "Batch 115: loss = 0.38442257046699524, acc = 0.857421875\n",
      "Batch 116: loss = 0.37953275442123413, acc = 0.8720703125\n",
      "Batch 117: loss = 0.3421774208545685, acc = 0.900390625\n",
      "Batch 118: loss = 0.36843141913414, acc = 0.8681640625\n",
      "Batch 119: loss = 0.34949034452438354, acc = 0.8837890625\n",
      "Batch 120: loss = 0.3232879042625427, acc = 0.8935546875\n",
      "Batch 121: loss = 0.3409600853919983, acc = 0.8818359375\n",
      "Batch 122: loss = 0.3197527229785919, acc = 0.89453125\n",
      "Batch 123: loss = 0.33356553316116333, acc = 0.88671875\n",
      "Batch 124: loss = 0.3715158700942993, acc = 0.865234375\n",
      "Batch 125: loss = 0.34622520208358765, acc = 0.8798828125\n",
      "2022-07-22 19:33:16.776269: W tensorflow/core/data/root_dataset.cc:200] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "Batch 126: loss = 0.4226102828979492, acc = 0.8623046875\n",
      "\n",
      "Epoch 67/100\n",
      "Batch 1: loss = 0.4693799614906311, acc = 0.8681640625\n",
      "2022-07-22 19:33:16.829959: W tensorflow/core/data/root_dataset.cc:200] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "Batch 2: loss = 0.37203657627105713, acc = 0.873046875\n",
      "2022-07-22 19:33:16.854978: W tensorflow/core/data/root_dataset.cc:200] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "Batch 3: loss = 0.3797057867050171, acc = 0.8798828125\n",
      "Batch 4: loss = 0.33613497018814087, acc = 0.8955078125\n",
      "Batch 5: loss = 0.34767019748687744, acc = 0.8828125\n",
      "Batch 6: loss = 0.3495948314666748, acc = 0.8828125\n",
      "Batch 7: loss = 0.32774463295936584, acc = 0.8857421875\n",
      "Batch 8: loss = 0.34598401188850403, acc = 0.8935546875\n",
      "Batch 9: loss = 0.33963778614997864, acc = 0.8759765625\n",
      "Batch 10: loss = 0.33666878938674927, acc = 0.892578125\n",
      "Batch 11: loss = 0.3918706476688385, acc = 0.8662109375\n",
      "Batch 12: loss = 0.36507558822631836, acc = 0.884765625\n",
      "Batch 13: loss = 0.3521997034549713, acc = 0.8837890625\n",
      "Batch 14: loss = 0.3420240879058838, acc = 0.884765625\n",
      "Batch 15: loss = 0.33972445130348206, acc = 0.880859375\n",
      "Batch 16: loss = 0.3420954942703247, acc = 0.888671875\n",
      "Batch 17: loss = 0.3798173666000366, acc = 0.87109375\n",
      "Batch 18: loss = 0.4106738269329071, acc = 0.8642578125\n",
      "Batch 19: loss = 0.37133485078811646, acc = 0.8720703125\n",
      "Batch 20: loss = 0.3833959102630615, acc = 0.8681640625\n",
      "Batch 21: loss = 0.3842655420303345, acc = 0.8681640625\n",
      "Batch 22: loss = 0.342550128698349, acc = 0.8896484375\n",
      "Batch 23: loss = 0.3737671971321106, acc = 0.8740234375\n",
      "Batch 24: loss = 0.37493896484375, acc = 0.884765625\n",
      "Batch 25: loss = 0.3660125136375427, acc = 0.8779296875\n",
      "Batch 26: loss = 0.36618298292160034, acc = 0.873046875\n",
      "Batch 27: loss = 0.4591931998729706, acc = 0.85546875\n",
      "Batch 28: loss = 0.3538239002227783, acc = 0.875\n",
      "Batch 29: loss = 0.3876838684082031, acc = 0.86328125\n",
      "Batch 30: loss = 0.34074491262435913, acc = 0.8837890625\n",
      "Batch 31: loss = 0.3970784544944763, acc = 0.8662109375\n",
      "Batch 32: loss = 0.3906231224536896, acc = 0.8740234375\n",
      "Batch 33: loss = 0.35845947265625, acc = 0.87890625\n",
      "Batch 34: loss = 0.3488881289958954, acc = 0.8828125\n",
      "Batch 35: loss = 0.3669193983078003, acc = 0.8671875\n",
      "Batch 36: loss = 0.3346453011035919, acc = 0.8896484375\n",
      "Batch 37: loss = 0.30828115344047546, acc = 0.8994140625\n",
      "Batch 38: loss = 0.3424437642097473, acc = 0.8828125\n",
      "Batch 39: loss = 0.3324551582336426, acc = 0.890625\n",
      "Batch 40: loss = 0.38532695174217224, acc = 0.8681640625\n",
      "Batch 41: loss = 0.32131344079971313, acc = 0.888671875\n",
      "Batch 42: loss = 0.3484477996826172, acc = 0.880859375\n",
      "Batch 43: loss = 0.38593876361846924, acc = 0.86328125\n",
      "Batch 44: loss = 0.3202759921550751, acc = 0.8974609375\n",
      "Batch 45: loss = 0.3174586892127991, acc = 0.890625\n",
      "Batch 46: loss = 0.3204430639743805, acc = 0.896484375\n",
      "Batch 47: loss = 0.3726131021976471, acc = 0.8740234375\n",
      "Batch 48: loss = 0.3406432271003723, acc = 0.8779296875\n",
      "Batch 49: loss = 0.34634727239608765, acc = 0.8837890625\n",
      "Batch 50: loss = 0.3349084258079529, acc = 0.8896484375\n",
      "Batch 51: loss = 0.33332177996635437, acc = 0.884765625\n",
      "Batch 52: loss = 0.3543790280818939, acc = 0.8818359375\n",
      "Batch 53: loss = 0.3683885335922241, acc = 0.8798828125\n",
      "Batch 54: loss = 0.27679988741874695, acc = 0.9033203125\n",
      "Batch 55: loss = 0.3227325677871704, acc = 0.9013671875\n",
      "Batch 56: loss = 0.3691084086894989, acc = 0.87890625\n",
      "Batch 57: loss = 0.40563663840293884, acc = 0.859375\n",
      "Batch 58: loss = 0.40005552768707275, acc = 0.8583984375\n",
      "Batch 59: loss = 0.2967924177646637, acc = 0.8994140625\n",
      "Batch 60: loss = 0.33945679664611816, acc = 0.873046875\n",
      "Batch 61: loss = 0.3043931722640991, acc = 0.8984375\n",
      "Batch 62: loss = 0.3833700120449066, acc = 0.8798828125\n",
      "Batch 63: loss = 0.3350079357624054, acc = 0.884765625\n",
      "Batch 64: loss = 0.3064191937446594, acc = 0.9013671875\n",
      "Batch 65: loss = 0.3613864779472351, acc = 0.87890625\n",
      "Batch 66: loss = 0.3368265926837921, acc = 0.8828125\n",
      "Batch 67: loss = 0.3566858172416687, acc = 0.8818359375\n",
      "Batch 68: loss = 0.3630460798740387, acc = 0.8759765625\n",
      "Batch 69: loss = 0.3097151815891266, acc = 0.8876953125\n",
      "Batch 70: loss = 0.3422783613204956, acc = 0.88671875\n",
      "Batch 71: loss = 0.3709053099155426, acc = 0.865234375\n",
      "Batch 72: loss = 0.3211674094200134, acc = 0.8955078125\n",
      "Batch 73: loss = 0.3504548966884613, acc = 0.8828125\n",
      "Batch 74: loss = 0.3875930905342102, acc = 0.8759765625\n",
      "Batch 75: loss = 0.42870447039604187, acc = 0.8642578125\n",
      "Batch 76: loss = 0.3787464499473572, acc = 0.869140625\n",
      "Batch 77: loss = 0.3362913131713867, acc = 0.875\n",
      "Batch 78: loss = 0.3708069622516632, acc = 0.875\n",
      "Batch 79: loss = 0.34396272897720337, acc = 0.87890625\n",
      "Batch 80: loss = 0.31336554884910583, acc = 0.904296875\n",
      "Batch 81: loss = 0.35008949041366577, acc = 0.8740234375\n",
      "Batch 82: loss = 0.35182562470436096, acc = 0.880859375\n",
      "Batch 83: loss = 0.34113621711730957, acc = 0.8857421875\n",
      "Batch 84: loss = 0.37719860672950745, acc = 0.8681640625\n",
      "Batch 85: loss = 0.3707594871520996, acc = 0.87890625\n",
      "Batch 86: loss = 0.3442068099975586, acc = 0.888671875\n",
      "Batch 87: loss = 0.3434070944786072, acc = 0.8779296875\n",
      "Batch 88: loss = 0.3890008330345154, acc = 0.865234375\n",
      "Batch 89: loss = 0.3257542848587036, acc = 0.8984375\n",
      "Batch 90: loss = 0.3510907292366028, acc = 0.8818359375\n",
      "Batch 91: loss = 0.39553067088127136, acc = 0.873046875\n",
      "Batch 92: loss = 0.37299230694770813, acc = 0.87109375\n",
      "Batch 93: loss = 0.31862127780914307, acc = 0.8896484375\n",
      "Batch 94: loss = 0.3154056966304779, acc = 0.890625\n",
      "Batch 95: loss = 0.3399319648742676, acc = 0.8896484375\n",
      "Batch 96: loss = 0.3705779016017914, acc = 0.865234375\n",
      "Batch 97: loss = 0.3737982511520386, acc = 0.880859375\n",
      "Batch 98: loss = 0.3411472737789154, acc = 0.876953125\n",
      "Batch 99: loss = 0.39207690954208374, acc = 0.8603515625\n",
      "Batch 100: loss = 0.36250269412994385, acc = 0.87890625\n",
      "Batch 101: loss = 0.3250836133956909, acc = 0.88671875\n",
      "Batch 102: loss = 0.36885586380958557, acc = 0.8662109375\n",
      "Batch 103: loss = 0.35186827182769775, acc = 0.8798828125\n",
      "Batch 104: loss = 0.30980706214904785, acc = 0.8935546875\n",
      "Batch 105: loss = 0.32436394691467285, acc = 0.88671875\n",
      "Batch 106: loss = 0.33162209391593933, acc = 0.89453125\n",
      "Batch 107: loss = 0.3238025903701782, acc = 0.8984375\n",
      "Batch 108: loss = 0.3343737721443176, acc = 0.8818359375\n",
      "Batch 109: loss = 0.36046698689460754, acc = 0.865234375\n",
      "Batch 110: loss = 0.31895166635513306, acc = 0.900390625\n",
      "Batch 111: loss = 0.35003626346588135, acc = 0.8818359375\n",
      "Batch 112: loss = 0.32073795795440674, acc = 0.8837890625\n",
      "Batch 113: loss = 0.34013038873672485, acc = 0.8876953125\n",
      "Batch 114: loss = 0.36518946290016174, acc = 0.8818359375\n",
      "Batch 115: loss = 0.3577542006969452, acc = 0.8759765625\n",
      "Batch 116: loss = 0.42380672693252563, acc = 0.859375\n",
      "Batch 117: loss = 0.3478875160217285, acc = 0.884765625\n",
      "Batch 118: loss = 0.34782975912094116, acc = 0.8798828125\n",
      "Batch 119: loss = 0.3267861008644104, acc = 0.888671875\n",
      "Batch 120: loss = 0.3202362656593323, acc = 0.8896484375\n",
      "Batch 121: loss = 0.34237223863601685, acc = 0.888671875\n",
      "Batch 122: loss = 0.3151818811893463, acc = 0.8935546875\n",
      "Batch 123: loss = 0.3268708288669586, acc = 0.896484375\n",
      "Batch 124: loss = 0.3703106939792633, acc = 0.876953125\n",
      "Batch 125: loss = 0.3738510012626648, acc = 0.87109375\n",
      "Batch 126: loss = 0.3873524069786072, acc = 0.8701171875\n",
      "\n",
      "Epoch 68/100\n",
      "Batch 1: loss = 0.49817609786987305, acc = 0.8447265625\n",
      "Batch 2: loss = 0.36028507351875305, acc = 0.880859375\n",
      "Batch 3: loss = 0.38065630197525024, acc = 0.873046875\n",
      "Batch 4: loss = 0.35346245765686035, acc = 0.8798828125\n",
      "Batch 5: loss = 0.3605637550354004, acc = 0.876953125\n",
      "Batch 6: loss = 0.41066858172416687, acc = 0.857421875\n",
      "Batch 7: loss = 0.3442172706127167, acc = 0.8828125\n",
      "Batch 8: loss = 0.39203885197639465, acc = 0.865234375\n",
      "Batch 9: loss = 0.33557936549186707, acc = 0.8818359375\n",
      "Batch 10: loss = 0.3380403220653534, acc = 0.888671875\n",
      "Batch 11: loss = 0.34630322456359863, acc = 0.8896484375\n",
      "Batch 12: loss = 0.35895663499832153, acc = 0.873046875\n",
      "Batch 13: loss = 0.3266970217227936, acc = 0.8916015625\n",
      "Batch 14: loss = 0.36582255363464355, acc = 0.884765625\n",
      "Batch 15: loss = 0.32814568281173706, acc = 0.892578125\n",
      "Batch 16: loss = 0.3516155481338501, acc = 0.876953125\n",
      "Batch 17: loss = 0.3623424768447876, acc = 0.888671875\n",
      "Batch 18: loss = 0.38645094633102417, acc = 0.87109375\n",
      "Batch 19: loss = 0.35358303785324097, acc = 0.876953125\n",
      "Batch 20: loss = 0.3649653196334839, acc = 0.8818359375\n",
      "Batch 21: loss = 0.3966383635997772, acc = 0.8642578125\n",
      "Batch 22: loss = 0.32522743940353394, acc = 0.8916015625\n",
      "Batch 23: loss = 0.361793577671051, acc = 0.865234375\n",
      "Batch 24: loss = 0.3794701397418976, acc = 0.861328125\n",
      "Batch 25: loss = 0.3256896734237671, acc = 0.8916015625\n",
      "Batch 26: loss = 0.37014663219451904, acc = 0.880859375\n",
      "Batch 27: loss = 0.42644748091697693, acc = 0.865234375\n",
      "Batch 28: loss = 0.3791976869106293, acc = 0.8662109375\n",
      "Batch 29: loss = 0.3795126676559448, acc = 0.873046875\n",
      "Batch 30: loss = 0.3630792498588562, acc = 0.8759765625\n",
      "Batch 31: loss = 0.3886900544166565, acc = 0.873046875\n",
      "Batch 32: loss = 0.37851378321647644, acc = 0.86328125\n",
      "Batch 33: loss = 0.334538996219635, acc = 0.8837890625\n",
      "Batch 34: loss = 0.37545162439346313, acc = 0.8701171875\n",
      "Batch 35: loss = 0.33886757493019104, acc = 0.896484375\n",
      "Batch 36: loss = 0.32823503017425537, acc = 0.8916015625\n",
      "Batch 37: loss = 0.3007284104824066, acc = 0.8994140625\n",
      "Batch 38: loss = 0.3297041654586792, acc = 0.8935546875\n",
      "Batch 39: loss = 0.3350057303905487, acc = 0.8837890625\n",
      "Batch 40: loss = 0.3830638527870178, acc = 0.8779296875\n",
      "Batch 41: loss = 0.3186669945716858, acc = 0.888671875\n",
      "Batch 42: loss = 0.37980177998542786, acc = 0.8740234375\n",
      "Batch 43: loss = 0.4120413362979889, acc = 0.8505859375\n",
      "Batch 44: loss = 0.30680540204048157, acc = 0.8984375\n",
      "Batch 45: loss = 0.30144479870796204, acc = 0.8994140625\n",
      "Batch 46: loss = 0.33472996950149536, acc = 0.88671875\n",
      "Batch 47: loss = 0.3521253764629364, acc = 0.8828125\n",
      "Batch 48: loss = 0.3074813485145569, acc = 0.8994140625\n",
      "Batch 49: loss = 0.310782790184021, acc = 0.8984375\n",
      "Batch 50: loss = 0.30617812275886536, acc = 0.892578125\n",
      "Batch 51: loss = 0.3008762001991272, acc = 0.8916015625\n",
      "Batch 52: loss = 0.3300642967224121, acc = 0.8896484375\n",
      "Batch 53: loss = 0.35360589623451233, acc = 0.8818359375\n",
      "Batch 54: loss = 0.2826758623123169, acc = 0.912109375\n",
      "Batch 55: loss = 0.30244311690330505, acc = 0.8955078125\n",
      "Batch 56: loss = 0.34500351548194885, acc = 0.8828125\n",
      "Batch 57: loss = 0.4222679138183594, acc = 0.857421875\n",
      "Batch 58: loss = 0.38235488533973694, acc = 0.876953125\n",
      "Batch 59: loss = 0.2895892560482025, acc = 0.90625\n",
      "Batch 60: loss = 0.3632084131240845, acc = 0.8720703125\n",
      "Batch 61: loss = 0.2893388867378235, acc = 0.90625\n",
      "Batch 62: loss = 0.3802109658718109, acc = 0.8837890625\n",
      "Batch 63: loss = 0.3346669375896454, acc = 0.8955078125\n",
      "Batch 64: loss = 0.2847629487514496, acc = 0.90625\n",
      "Batch 65: loss = 0.3194456398487091, acc = 0.88671875\n",
      "Batch 66: loss = 0.33281540870666504, acc = 0.892578125\n",
      "Batch 67: loss = 0.32946497201919556, acc = 0.88671875\n",
      "Batch 68: loss = 0.377847284078598, acc = 0.8671875\n",
      "Batch 69: loss = 0.3207900822162628, acc = 0.896484375\n",
      "Batch 70: loss = 0.36897844076156616, acc = 0.8681640625\n",
      "Batch 71: loss = 0.3435201644897461, acc = 0.8818359375\n",
      "Batch 72: loss = 0.3226139545440674, acc = 0.8955078125\n",
      "Batch 73: loss = 0.3618762493133545, acc = 0.8798828125\n",
      "Batch 74: loss = 0.4012719392776489, acc = 0.8603515625\n",
      "Batch 75: loss = 0.39512571692466736, acc = 0.8662109375\n",
      "Batch 76: loss = 0.3867165148258209, acc = 0.873046875\n",
      "Batch 77: loss = 0.369348406791687, acc = 0.8828125\n",
      "Batch 78: loss = 0.3712818920612335, acc = 0.8623046875\n",
      "Batch 79: loss = 0.369344562292099, acc = 0.8701171875\n",
      "Batch 80: loss = 0.3316880166530609, acc = 0.8828125\n",
      "Batch 81: loss = 0.3662688732147217, acc = 0.873046875\n",
      "Batch 82: loss = 0.3265315294265747, acc = 0.8857421875\n",
      "Batch 83: loss = 0.3234027624130249, acc = 0.890625\n",
      "Batch 84: loss = 0.3641091585159302, acc = 0.876953125\n",
      "Batch 85: loss = 0.35746240615844727, acc = 0.875\n",
      "Batch 86: loss = 0.3183993697166443, acc = 0.9033203125\n",
      "Batch 87: loss = 0.35883715748786926, acc = 0.8779296875\n",
      "Batch 88: loss = 0.3988956809043884, acc = 0.85546875\n",
      "Batch 89: loss = 0.31384941935539246, acc = 0.8955078125\n",
      "Batch 90: loss = 0.3345094621181488, acc = 0.888671875\n",
      "Batch 91: loss = 0.3745502829551697, acc = 0.8828125\n",
      "Batch 92: loss = 0.3537452816963196, acc = 0.8798828125\n",
      "Batch 93: loss = 0.3301960527896881, acc = 0.8818359375\n",
      "Batch 94: loss = 0.295121967792511, acc = 0.900390625\n",
      "Batch 95: loss = 0.34489351511001587, acc = 0.890625\n",
      "Batch 96: loss = 0.37052303552627563, acc = 0.87109375\n",
      "Batch 97: loss = 0.34371861815452576, acc = 0.888671875\n",
      "Batch 98: loss = 0.3285209536552429, acc = 0.880859375\n",
      "Batch 99: loss = 0.3930583596229553, acc = 0.880859375\n",
      "Batch 100: loss = 0.3831220865249634, acc = 0.8740234375\n",
      "Batch 101: loss = 0.32980218529701233, acc = 0.8828125\n",
      "Batch 102: loss = 0.3901306390762329, acc = 0.87109375\n",
      "Batch 103: loss = 0.38207393884658813, acc = 0.873046875\n",
      "Batch 104: loss = 0.3130602538585663, acc = 0.892578125\n",
      "Batch 105: loss = 0.31836599111557007, acc = 0.890625\n",
      "Batch 106: loss = 0.3233101963996887, acc = 0.884765625\n",
      "Batch 107: loss = 0.34226733446121216, acc = 0.8935546875\n",
      "Batch 108: loss = 0.35052210092544556, acc = 0.8798828125\n",
      "Batch 109: loss = 0.34722277522087097, acc = 0.8828125\n",
      "Batch 110: loss = 0.31409752368927, acc = 0.8837890625\n",
      "Batch 111: loss = 0.3689412474632263, acc = 0.876953125\n",
      "Batch 112: loss = 0.3424883782863617, acc = 0.8798828125\n",
      "Batch 113: loss = 0.3220379948616028, acc = 0.890625\n",
      "Batch 114: loss = 0.3513484597206116, acc = 0.8818359375\n",
      "Batch 115: loss = 0.3519153892993927, acc = 0.873046875\n",
      "Batch 116: loss = 0.4128692150115967, acc = 0.869140625\n",
      "Batch 117: loss = 0.3525570034980774, acc = 0.8798828125\n",
      "Batch 118: loss = 0.330597460269928, acc = 0.8916015625\n",
      "Batch 119: loss = 0.3453846871852875, acc = 0.888671875\n",
      "Batch 120: loss = 0.3506777584552765, acc = 0.875\n",
      "Batch 121: loss = 0.3051649034023285, acc = 0.89453125\n",
      "Batch 122: loss = 0.3132685720920563, acc = 0.8974609375\n",
      "Batch 123: loss = 0.3301665186882019, acc = 0.884765625\n",
      "Batch 124: loss = 0.37023261189460754, acc = 0.8955078125\n",
      "Batch 125: loss = 0.3569658100605011, acc = 0.8740234375\n",
      "Batch 126: loss = 0.36306291818618774, acc = 0.8837890625\n",
      "\n",
      "Epoch 69/100\n",
      "Batch 1: loss = 0.4246414303779602, acc = 0.875\n",
      "Batch 2: loss = 0.38803601264953613, acc = 0.869140625\n",
      "Batch 3: loss = 0.35793337225914, acc = 0.88671875\n",
      "Batch 4: loss = 0.3349183201789856, acc = 0.8955078125\n",
      "Batch 5: loss = 0.3473356366157532, acc = 0.8837890625\n",
      "Batch 6: loss = 0.36620116233825684, acc = 0.8828125\n",
      "Batch 7: loss = 0.3394474685192108, acc = 0.8916015625\n",
      "Batch 8: loss = 0.37652722001075745, acc = 0.8701171875\n",
      "Batch 9: loss = 0.35136041045188904, acc = 0.8798828125\n",
      "Batch 10: loss = 0.27897340059280396, acc = 0.91015625\n",
      "Batch 11: loss = 0.32213929295539856, acc = 0.896484375\n",
      "Batch 12: loss = 0.3790794909000397, acc = 0.8671875\n",
      "Batch 13: loss = 0.34994959831237793, acc = 0.875\n",
      "Batch 14: loss = 0.34469348192214966, acc = 0.8837890625\n",
      "Batch 15: loss = 0.32353296875953674, acc = 0.8935546875\n",
      "Batch 16: loss = 0.3630664050579071, acc = 0.880859375\n",
      "Batch 17: loss = 0.3240959048271179, acc = 0.890625\n",
      "Batch 18: loss = 0.38325145840644836, acc = 0.861328125\n",
      "Batch 19: loss = 0.3565200865268707, acc = 0.880859375\n",
      "Batch 20: loss = 0.35109519958496094, acc = 0.8740234375\n",
      "Batch 21: loss = 0.3848910927772522, acc = 0.8740234375\n",
      "Batch 22: loss = 0.3656320571899414, acc = 0.8701171875\n",
      "Batch 23: loss = 0.3627939224243164, acc = 0.86328125\n",
      "Batch 24: loss = 0.34730005264282227, acc = 0.8701171875\n",
      "Batch 25: loss = 0.31228750944137573, acc = 0.8974609375\n",
      "Batch 26: loss = 0.3548767864704132, acc = 0.8837890625\n",
      "Batch 27: loss = 0.4056479334831238, acc = 0.8515625\n",
      "Batch 28: loss = 0.3701115846633911, acc = 0.8857421875\n",
      "Batch 29: loss = 0.3841656744480133, acc = 0.8701171875\n",
      "Batch 30: loss = 0.32721206545829773, acc = 0.880859375\n",
      "Batch 31: loss = 0.3636382222175598, acc = 0.8857421875\n",
      "Batch 32: loss = 0.39593154191970825, acc = 0.861328125\n",
      "Batch 33: loss = 0.36026135087013245, acc = 0.8818359375\n",
      "Batch 34: loss = 0.3815480172634125, acc = 0.875\n",
      "Batch 35: loss = 0.3373703956604004, acc = 0.89453125\n",
      "Batch 36: loss = 0.3044898808002472, acc = 0.90234375\n",
      "Batch 37: loss = 0.31928756833076477, acc = 0.8876953125\n",
      "Batch 38: loss = 0.33418017625808716, acc = 0.888671875\n",
      "Batch 39: loss = 0.3142715096473694, acc = 0.8916015625\n",
      "Batch 40: loss = 0.3302491307258606, acc = 0.8916015625\n",
      "Batch 41: loss = 0.3176795542240143, acc = 0.890625\n",
      "Batch 42: loss = 0.372422456741333, acc = 0.8828125\n",
      "Batch 43: loss = 0.39695268869400024, acc = 0.8671875\n",
      "Batch 44: loss = 0.28285348415374756, acc = 0.91015625\n",
      "Batch 45: loss = 0.31125444173812866, acc = 0.904296875\n",
      "Batch 46: loss = 0.32959768176078796, acc = 0.888671875\n",
      "Batch 47: loss = 0.33649295568466187, acc = 0.8857421875\n",
      "Batch 48: loss = 0.32735708355903625, acc = 0.890625\n",
      "Batch 49: loss = 0.3134568929672241, acc = 0.9013671875\n",
      "Batch 50: loss = 0.3261066675186157, acc = 0.8974609375\n",
      "Batch 51: loss = 0.2925269603729248, acc = 0.8935546875\n",
      "Batch 52: loss = 0.35027235746383667, acc = 0.88671875\n",
      "Batch 53: loss = 0.32056859135627747, acc = 0.896484375\n",
      "Batch 54: loss = 0.274562269449234, acc = 0.9130859375\n",
      "Batch 55: loss = 0.3211424648761749, acc = 0.8896484375\n",
      "Batch 56: loss = 0.35822901129722595, acc = 0.8798828125\n",
      "Batch 57: loss = 0.4001525640487671, acc = 0.857421875\n",
      "Batch 58: loss = 0.3613179326057434, acc = 0.8701171875\n",
      "Batch 59: loss = 0.2582823634147644, acc = 0.9111328125\n",
      "Batch 60: loss = 0.35615116357803345, acc = 0.8798828125\n",
      "Batch 61: loss = 0.2924734055995941, acc = 0.9052734375\n",
      "Batch 62: loss = 0.36168691515922546, acc = 0.8720703125\n",
      "Batch 63: loss = 0.32440584897994995, acc = 0.888671875\n",
      "Batch 64: loss = 0.3043214678764343, acc = 0.900390625\n",
      "Batch 65: loss = 0.32380786538124084, acc = 0.888671875\n",
      "Batch 66: loss = 0.33126306533813477, acc = 0.888671875\n",
      "Batch 67: loss = 0.30334457755088806, acc = 0.90234375\n",
      "Batch 68: loss = 0.34370988607406616, acc = 0.8828125\n",
      "Batch 69: loss = 0.3175372779369354, acc = 0.896484375\n",
      "Batch 70: loss = 0.4079344868659973, acc = 0.8662109375\n",
      "Batch 71: loss = 0.3637278079986572, acc = 0.875\n",
      "Batch 72: loss = 0.3259133994579315, acc = 0.8857421875\n",
      "Batch 73: loss = 0.3736891448497772, acc = 0.8701171875\n",
      "Batch 74: loss = 0.37709346413612366, acc = 0.8701171875\n",
      "Batch 75: loss = 0.3972674012184143, acc = 0.8701171875\n",
      "Batch 76: loss = 0.35738635063171387, acc = 0.8876953125\n",
      "Batch 77: loss = 0.33860933780670166, acc = 0.8779296875\n",
      "Batch 78: loss = 0.35640856623649597, acc = 0.87890625\n",
      "Batch 79: loss = 0.3145626187324524, acc = 0.8896484375\n",
      "Batch 80: loss = 0.31949666142463684, acc = 0.8955078125\n",
      "Batch 81: loss = 0.34288185834884644, acc = 0.8857421875\n",
      "Batch 82: loss = 0.34655699133872986, acc = 0.8740234375\n",
      "Batch 83: loss = 0.3357729911804199, acc = 0.8779296875\n",
      "Batch 84: loss = 0.38279926776885986, acc = 0.8642578125\n",
      "Batch 85: loss = 0.39678457379341125, acc = 0.85546875\n",
      "Batch 86: loss = 0.33381929993629456, acc = 0.89453125\n",
      "Batch 87: loss = 0.36066657304763794, acc = 0.880859375\n",
      "Batch 88: loss = 0.3813416063785553, acc = 0.8642578125\n",
      "Batch 89: loss = 0.33535104990005493, acc = 0.896484375\n",
      "Batch 90: loss = 0.35707971453666687, acc = 0.8896484375\n",
      "Batch 91: loss = 0.358295738697052, acc = 0.8876953125\n",
      "Batch 92: loss = 0.3294188678264618, acc = 0.890625\n",
      "Batch 93: loss = 0.343281626701355, acc = 0.8896484375\n",
      "Batch 94: loss = 0.3109145760536194, acc = 0.88671875\n",
      "Batch 95: loss = 0.33667171001434326, acc = 0.8837890625\n",
      "Batch 96: loss = 0.38215622305870056, acc = 0.8740234375\n",
      "Batch 97: loss = 0.34442251920700073, acc = 0.890625\n",
      "Batch 98: loss = 0.34262770414352417, acc = 0.8740234375\n",
      "Batch 99: loss = 0.3457856774330139, acc = 0.8798828125\n",
      "Batch 100: loss = 0.3594401776790619, acc = 0.8740234375\n",
      "Batch 101: loss = 0.31546086072921753, acc = 0.8984375\n",
      "Batch 102: loss = 0.36900997161865234, acc = 0.876953125\n",
      "Batch 103: loss = 0.3657699227333069, acc = 0.884765625\n",
      "Batch 104: loss = 0.3183858394622803, acc = 0.8837890625\n",
      "Batch 105: loss = 0.2968091070652008, acc = 0.9013671875\n",
      "Batch 106: loss = 0.33215460181236267, acc = 0.888671875\n",
      "Batch 107: loss = 0.3370010256767273, acc = 0.888671875\n",
      "Batch 108: loss = 0.3313032388687134, acc = 0.888671875\n",
      "Batch 109: loss = 0.33688628673553467, acc = 0.8837890625\n",
      "Batch 110: loss = 0.3474641442298889, acc = 0.8828125\n",
      "Batch 111: loss = 0.3434688448905945, acc = 0.880859375\n",
      "Batch 112: loss = 0.32464727759361267, acc = 0.892578125\n",
      "Batch 113: loss = 0.3657349646091461, acc = 0.8681640625\n",
      "Batch 114: loss = 0.34511905908584595, acc = 0.8837890625\n",
      "Batch 115: loss = 0.3225151300430298, acc = 0.892578125\n",
      "Batch 116: loss = 0.36850473284721375, acc = 0.87890625\n",
      "Batch 117: loss = 0.3249690532684326, acc = 0.896484375\n",
      "Batch 118: loss = 0.32510557770729065, acc = 0.9013671875\n",
      "Batch 119: loss = 0.3128587603569031, acc = 0.8896484375\n",
      "Batch 120: loss = 0.3275911509990692, acc = 0.880859375\n",
      "Batch 121: loss = 0.3354540467262268, acc = 0.8876953125\n",
      "Batch 122: loss = 0.3111875653266907, acc = 0.8935546875\n",
      "Batch 123: loss = 0.32744401693344116, acc = 0.88671875\n",
      "Batch 124: loss = 0.34851977229118347, acc = 0.873046875\n",
      "Batch 125: loss = 0.38129907846450806, acc = 0.8759765625\n",
      "Batch 126: loss = 0.35892239212989807, acc = 0.8876953125\n",
      "\n",
      "Epoch 70/100\n",
      "Batch 1: loss = 0.43062064051628113, acc = 0.8642578125\n",
      "Batch 2: loss = 0.3836798071861267, acc = 0.869140625\n",
      "Batch 3: loss = 0.33138126134872437, acc = 0.884765625\n",
      "Batch 4: loss = 0.37208348512649536, acc = 0.873046875\n",
      "Batch 5: loss = 0.3668765127658844, acc = 0.888671875\n",
      "Batch 6: loss = 0.3387441635131836, acc = 0.8857421875\n",
      "Batch 7: loss = 0.33733612298965454, acc = 0.8779296875\n",
      "Batch 8: loss = 0.3752487301826477, acc = 0.8662109375\n",
      "Batch 9: loss = 0.3342989683151245, acc = 0.890625\n",
      "Batch 10: loss = 0.31975483894348145, acc = 0.8857421875\n",
      "Batch 11: loss = 0.36574068665504456, acc = 0.8662109375\n",
      "Batch 12: loss = 0.32265394926071167, acc = 0.8935546875\n",
      "Batch 13: loss = 0.3227912485599518, acc = 0.8916015625\n",
      "Batch 14: loss = 0.3188454508781433, acc = 0.8935546875\n",
      "Batch 15: loss = 0.3072706460952759, acc = 0.89453125\n",
      "Batch 16: loss = 0.36061421036720276, acc = 0.8740234375\n",
      "Batch 17: loss = 0.3408008813858032, acc = 0.8994140625\n",
      "Batch 18: loss = 0.3595942258834839, acc = 0.8828125\n",
      "Batch 19: loss = 0.33534401655197144, acc = 0.8935546875\n",
      "Batch 20: loss = 0.3488691449165344, acc = 0.880859375\n",
      "Batch 21: loss = 0.3648671507835388, acc = 0.8798828125\n",
      "Batch 22: loss = 0.3150813579559326, acc = 0.8955078125\n",
      "Batch 23: loss = 0.3403407037258148, acc = 0.87890625\n",
      "Batch 24: loss = 0.3537118434906006, acc = 0.876953125\n",
      "Batch 25: loss = 0.3395550549030304, acc = 0.8857421875\n",
      "Batch 26: loss = 0.3613968789577484, acc = 0.8857421875\n",
      "Batch 27: loss = 0.41425782442092896, acc = 0.8583984375\n",
      "Batch 28: loss = 0.3983350992202759, acc = 0.8671875\n",
      "Batch 29: loss = 0.3690531253814697, acc = 0.8828125\n",
      "Batch 30: loss = 0.3347322344779968, acc = 0.8857421875\n",
      "Batch 31: loss = 0.3579237759113312, acc = 0.88671875\n",
      "Batch 32: loss = 0.3539966642856598, acc = 0.8896484375\n",
      "Batch 33: loss = 0.32778283953666687, acc = 0.890625\n",
      "Batch 34: loss = 0.3735042214393616, acc = 0.8662109375\n",
      "Batch 35: loss = 0.33908337354660034, acc = 0.89453125\n",
      "Batch 36: loss = 0.30945268273353577, acc = 0.8828125\n",
      "Batch 37: loss = 0.29310470819473267, acc = 0.9033203125\n",
      "Batch 38: loss = 0.3399254381656647, acc = 0.88671875\n",
      "Batch 39: loss = 0.3228068947792053, acc = 0.8876953125\n",
      "Batch 40: loss = 0.34657594561576843, acc = 0.884765625\n",
      "Batch 41: loss = 0.26976388692855835, acc = 0.9072265625\n",
      "Batch 42: loss = 0.3414350152015686, acc = 0.87109375\n",
      "Batch 43: loss = 0.4057634174823761, acc = 0.85546875\n",
      "Batch 44: loss = 0.29242393374443054, acc = 0.9033203125\n",
      "Batch 45: loss = 0.308752179145813, acc = 0.890625\n",
      "Batch 46: loss = 0.32377493381500244, acc = 0.8857421875\n",
      "Batch 47: loss = 0.33410704135894775, acc = 0.8857421875\n",
      "Batch 48: loss = 0.33143627643585205, acc = 0.892578125\n",
      "Batch 49: loss = 0.32199716567993164, acc = 0.89453125\n",
      "Batch 50: loss = 0.3097854256629944, acc = 0.904296875\n",
      "Batch 51: loss = 0.2749491333961487, acc = 0.9052734375\n",
      "Batch 52: loss = 0.31956177949905396, acc = 0.896484375\n",
      "Batch 53: loss = 0.3712692856788635, acc = 0.8828125\n",
      "Batch 54: loss = 0.28761979937553406, acc = 0.900390625\n",
      "Batch 55: loss = 0.30284589529037476, acc = 0.8974609375\n",
      "Batch 56: loss = 0.32302093505859375, acc = 0.8828125\n",
      "Batch 57: loss = 0.3778170049190521, acc = 0.8681640625\n",
      "Batch 58: loss = 0.37275230884552, acc = 0.8662109375\n",
      "Batch 59: loss = 0.29900461435317993, acc = 0.904296875\n",
      "Batch 60: loss = 0.3333819508552551, acc = 0.88671875\n",
      "Batch 61: loss = 0.29741737246513367, acc = 0.8984375\n",
      "Batch 62: loss = 0.3977223038673401, acc = 0.87109375\n",
      "Batch 63: loss = 0.3198472559452057, acc = 0.900390625\n",
      "Batch 64: loss = 0.2998114824295044, acc = 0.8974609375\n",
      "Batch 65: loss = 0.3190959692001343, acc = 0.8994140625\n",
      "Batch 66: loss = 0.3193633258342743, acc = 0.8857421875\n",
      "Batch 67: loss = 0.32717153429985046, acc = 0.8837890625\n",
      "Batch 68: loss = 0.3399830460548401, acc = 0.8896484375\n",
      "Batch 69: loss = 0.2978963851928711, acc = 0.9013671875\n",
      "Batch 70: loss = 0.33137238025665283, acc = 0.884765625\n",
      "Batch 71: loss = 0.33140915632247925, acc = 0.8916015625\n",
      "Batch 72: loss = 0.2879638671875, acc = 0.8994140625\n",
      "Batch 73: loss = 0.3523690402507782, acc = 0.8759765625\n",
      "Batch 74: loss = 0.36013731360435486, acc = 0.884765625\n",
      "Batch 75: loss = 0.42474502325057983, acc = 0.8505859375\n",
      "Batch 76: loss = 0.385699599981308, acc = 0.8759765625\n",
      "Batch 77: loss = 0.3380405902862549, acc = 0.8876953125\n",
      "Batch 78: loss = 0.3517049551010132, acc = 0.8837890625\n",
      "Batch 79: loss = 0.3406403362751007, acc = 0.8876953125\n",
      "Batch 80: loss = 0.2986161410808563, acc = 0.9033203125\n",
      "Batch 81: loss = 0.3438643217086792, acc = 0.88671875\n",
      "Batch 82: loss = 0.32331228256225586, acc = 0.8916015625\n",
      "Batch 83: loss = 0.32071495056152344, acc = 0.8974609375\n",
      "Batch 84: loss = 0.33943527936935425, acc = 0.8857421875\n",
      "Batch 85: loss = 0.36406564712524414, acc = 0.8798828125\n",
      "Batch 86: loss = 0.3212970495223999, acc = 0.890625\n",
      "Batch 87: loss = 0.3395577669143677, acc = 0.8935546875\n",
      "Batch 88: loss = 0.39709776639938354, acc = 0.875\n",
      "Batch 89: loss = 0.31746989488601685, acc = 0.890625\n",
      "Batch 90: loss = 0.3229524493217468, acc = 0.8974609375\n",
      "Batch 91: loss = 0.3730986416339874, acc = 0.8720703125\n",
      "Batch 92: loss = 0.33585596084594727, acc = 0.87890625\n",
      "Batch 93: loss = 0.34095126390457153, acc = 0.884765625\n",
      "Batch 94: loss = 0.29695266485214233, acc = 0.8935546875\n",
      "Batch 95: loss = 0.32169413566589355, acc = 0.8740234375\n",
      "Batch 96: loss = 0.38186001777648926, acc = 0.880859375\n",
      "Batch 97: loss = 0.2954428493976593, acc = 0.9052734375\n",
      "Batch 98: loss = 0.32067635655403137, acc = 0.8876953125\n",
      "Batch 99: loss = 0.31080320477485657, acc = 0.896484375\n",
      "Batch 100: loss = 0.3866177201271057, acc = 0.8623046875\n",
      "Batch 101: loss = 0.3149884343147278, acc = 0.8798828125\n",
      "Batch 102: loss = 0.35937947034835815, acc = 0.880859375\n",
      "Batch 103: loss = 0.33985278010368347, acc = 0.8779296875\n",
      "Batch 104: loss = 0.28788653016090393, acc = 0.9013671875\n",
      "Batch 105: loss = 0.32809534668922424, acc = 0.89453125\n",
      "Batch 106: loss = 0.3375876843929291, acc = 0.8779296875\n",
      "Batch 107: loss = 0.3185533583164215, acc = 0.8984375\n",
      "Batch 108: loss = 0.31236982345581055, acc = 0.9013671875\n",
      "Batch 109: loss = 0.35026395320892334, acc = 0.8857421875\n",
      "Batch 110: loss = 0.31684812903404236, acc = 0.8994140625\n",
      "Batch 111: loss = 0.3413683772087097, acc = 0.8876953125\n",
      "Batch 112: loss = 0.31168171763420105, acc = 0.892578125\n",
      "Batch 113: loss = 0.32790327072143555, acc = 0.890625\n",
      "Batch 114: loss = 0.3563646078109741, acc = 0.880859375\n",
      "Batch 115: loss = 0.32203710079193115, acc = 0.8974609375\n",
      "Batch 116: loss = 0.3546329438686371, acc = 0.88671875\n",
      "Batch 117: loss = 0.32554346323013306, acc = 0.896484375\n",
      "Batch 118: loss = 0.3103277087211609, acc = 0.9013671875\n",
      "Batch 119: loss = 0.32947131991386414, acc = 0.876953125\n",
      "Batch 120: loss = 0.3301842212677002, acc = 0.8818359375\n",
      "Batch 121: loss = 0.30913540720939636, acc = 0.9013671875\n",
      "Batch 122: loss = 0.29065847396850586, acc = 0.90625\n",
      "Batch 123: loss = 0.35246655344963074, acc = 0.8779296875\n",
      "Batch 124: loss = 0.32802483439445496, acc = 0.8837890625\n",
      "Batch 125: loss = 0.34568122029304504, acc = 0.884765625\n",
      "Batch 126: loss = 0.38690781593322754, acc = 0.8779296875\n",
      "Saved checkpoint to weights.70.h5\n",
      "\n",
      "Epoch 71/100\n",
      "Batch 1: loss = 0.47467532753944397, acc = 0.853515625\n",
      "Batch 2: loss = 0.38133862614631653, acc = 0.865234375\n",
      "Batch 3: loss = 0.329465389251709, acc = 0.904296875\n",
      "Batch 4: loss = 0.32922521233558655, acc = 0.880859375\n",
      "Batch 5: loss = 0.30868953466415405, acc = 0.904296875\n",
      "Batch 6: loss = 0.3279016613960266, acc = 0.8916015625\n",
      "Batch 7: loss = 0.31109777092933655, acc = 0.8935546875\n",
      "Batch 8: loss = 0.3498084545135498, acc = 0.890625\n",
      "Batch 9: loss = 0.3199708163738251, acc = 0.89453125\n",
      "Batch 10: loss = 0.31097549200057983, acc = 0.8857421875\n",
      "Batch 11: loss = 0.3459347188472748, acc = 0.88671875\n",
      "Batch 12: loss = 0.37092459201812744, acc = 0.87109375\n",
      "Batch 13: loss = 0.3380469083786011, acc = 0.8857421875\n",
      "Batch 14: loss = 0.3138483762741089, acc = 0.8955078125\n",
      "Batch 15: loss = 0.2977776527404785, acc = 0.8955078125\n",
      "Batch 16: loss = 0.31688612699508667, acc = 0.89453125\n",
      "Batch 17: loss = 0.3182543218135834, acc = 0.8828125\n",
      "Batch 18: loss = 0.38897740840911865, acc = 0.87109375\n",
      "Batch 19: loss = 0.35094717144966125, acc = 0.8857421875\n",
      "Batch 20: loss = 0.34773382544517517, acc = 0.8779296875\n",
      "Batch 21: loss = 0.3371717631816864, acc = 0.884765625\n",
      "Batch 22: loss = 0.3298945128917694, acc = 0.892578125\n",
      "Batch 23: loss = 0.35829704999923706, acc = 0.8876953125\n",
      "Batch 24: loss = 0.39068347215652466, acc = 0.861328125\n",
      "Batch 25: loss = 0.33512288331985474, acc = 0.8857421875\n",
      "Batch 26: loss = 0.34490692615509033, acc = 0.888671875\n",
      "Batch 27: loss = 0.37827053666114807, acc = 0.87890625\n",
      "Batch 28: loss = 0.3464484214782715, acc = 0.8818359375\n",
      "Batch 29: loss = 0.38752272725105286, acc = 0.8662109375\n",
      "Batch 30: loss = 0.3558046817779541, acc = 0.880859375\n",
      "Batch 31: loss = 0.35283657908439636, acc = 0.880859375\n",
      "Batch 32: loss = 0.40783658623695374, acc = 0.8564453125\n",
      "Batch 33: loss = 0.3260965943336487, acc = 0.900390625\n",
      "Batch 34: loss = 0.35274332761764526, acc = 0.880859375\n",
      "Batch 35: loss = 0.3543839156627655, acc = 0.8798828125\n",
      "Batch 36: loss = 0.32231810688972473, acc = 0.8779296875\n",
      "Batch 37: loss = 0.2750665545463562, acc = 0.916015625\n",
      "Batch 38: loss = 0.30587929487228394, acc = 0.8994140625\n",
      "Batch 39: loss = 0.3110576272010803, acc = 0.88671875\n",
      "Batch 40: loss = 0.3508918583393097, acc = 0.8798828125\n",
      "Batch 41: loss = 0.3022070527076721, acc = 0.90234375\n",
      "Batch 42: loss = 0.34618186950683594, acc = 0.890625\n",
      "Batch 43: loss = 0.3754238188266754, acc = 0.865234375\n",
      "Batch 44: loss = 0.30242031812667847, acc = 0.8955078125\n",
      "Batch 45: loss = 0.30524349212646484, acc = 0.8994140625\n",
      "Batch 46: loss = 0.31409019231796265, acc = 0.8916015625\n",
      "Batch 47: loss = 0.34495478868484497, acc = 0.87890625\n",
      "Batch 48: loss = 0.31804102659225464, acc = 0.8916015625\n",
      "Batch 49: loss = 0.29157555103302, acc = 0.9013671875\n",
      "Batch 50: loss = 0.3059189021587372, acc = 0.8916015625\n",
      "Batch 51: loss = 0.30573195219039917, acc = 0.9013671875\n",
      "Batch 52: loss = 0.3446814715862274, acc = 0.8896484375\n",
      "Batch 53: loss = 0.3260422945022583, acc = 0.896484375\n",
      "Batch 54: loss = 0.27075397968292236, acc = 0.91015625\n",
      "Batch 55: loss = 0.3228214979171753, acc = 0.8857421875\n",
      "Batch 56: loss = 0.34879282116889954, acc = 0.875\n",
      "Batch 57: loss = 0.3823106586933136, acc = 0.8623046875\n",
      "Batch 58: loss = 0.3485809862613678, acc = 0.880859375\n",
      "Batch 59: loss = 0.294261634349823, acc = 0.89453125\n",
      "Batch 60: loss = 0.340099573135376, acc = 0.8798828125\n",
      "Batch 61: loss = 0.289150595664978, acc = 0.8974609375\n",
      "Batch 62: loss = 0.38531816005706787, acc = 0.87109375\n",
      "Batch 63: loss = 0.343118816614151, acc = 0.880859375\n",
      "Batch 64: loss = 0.2787508964538574, acc = 0.9111328125\n",
      "Batch 65: loss = 0.34583738446235657, acc = 0.8828125\n",
      "Batch 66: loss = 0.3070914149284363, acc = 0.89453125\n",
      "Batch 67: loss = 0.31392472982406616, acc = 0.890625\n",
      "Batch 68: loss = 0.3426019251346588, acc = 0.8837890625\n",
      "Batch 69: loss = 0.29801541566848755, acc = 0.912109375\n",
      "Batch 70: loss = 0.35293591022491455, acc = 0.8779296875\n",
      "Batch 71: loss = 0.3365696668624878, acc = 0.8798828125\n",
      "Batch 72: loss = 0.32508599758148193, acc = 0.8837890625\n",
      "Batch 73: loss = 0.3409939408302307, acc = 0.89453125\n",
      "Batch 74: loss = 0.37627243995666504, acc = 0.8671875\n",
      "Batch 75: loss = 0.3855053186416626, acc = 0.8720703125\n",
      "Batch 76: loss = 0.3875855803489685, acc = 0.87109375\n",
      "Batch 77: loss = 0.3323136270046234, acc = 0.87890625\n",
      "Batch 78: loss = 0.3288712501525879, acc = 0.8916015625\n",
      "Batch 79: loss = 0.2903428375720978, acc = 0.904296875\n",
      "Batch 80: loss = 0.31815648078918457, acc = 0.89453125\n",
      "Batch 81: loss = 0.3499149680137634, acc = 0.87109375\n",
      "Batch 82: loss = 0.3526151180267334, acc = 0.8857421875\n",
      "Batch 83: loss = 0.30798977613449097, acc = 0.90234375\n",
      "Batch 84: loss = 0.3398125171661377, acc = 0.8642578125\n",
      "Batch 85: loss = 0.36760440468788147, acc = 0.8671875\n",
      "Batch 86: loss = 0.32614272832870483, acc = 0.89453125\n",
      "Batch 87: loss = 0.3105311989784241, acc = 0.8955078125\n",
      "Batch 88: loss = 0.35210567712783813, acc = 0.8837890625\n",
      "Batch 89: loss = 0.32458457350730896, acc = 0.896484375\n",
      "Batch 90: loss = 0.34361183643341064, acc = 0.890625\n",
      "Batch 91: loss = 0.34137940406799316, acc = 0.8828125\n",
      "Batch 92: loss = 0.3307405412197113, acc = 0.8798828125\n",
      "Batch 93: loss = 0.326294869184494, acc = 0.8916015625\n",
      "Batch 94: loss = 0.30161163210868835, acc = 0.8896484375\n",
      "Batch 95: loss = 0.3266565501689911, acc = 0.890625\n",
      "Batch 96: loss = 0.3710969090461731, acc = 0.8759765625\n",
      "Batch 97: loss = 0.33896711468696594, acc = 0.8857421875\n",
      "Batch 98: loss = 0.32941508293151855, acc = 0.8916015625\n",
      "Batch 99: loss = 0.3559701442718506, acc = 0.87890625\n",
      "Batch 100: loss = 0.3663848042488098, acc = 0.8828125\n",
      "Batch 101: loss = 0.3096563220024109, acc = 0.8896484375\n",
      "Batch 102: loss = 0.3513241708278656, acc = 0.88671875\n",
      "Batch 103: loss = 0.36797118186950684, acc = 0.8798828125\n",
      "Batch 104: loss = 0.2943989336490631, acc = 0.9013671875\n",
      "Batch 105: loss = 0.31606578826904297, acc = 0.8994140625\n",
      "Batch 106: loss = 0.3214266300201416, acc = 0.8994140625\n",
      "Batch 107: loss = 0.31442829966545105, acc = 0.8935546875\n",
      "Batch 108: loss = 0.3258022964000702, acc = 0.88671875\n",
      "Batch 109: loss = 0.34538382291793823, acc = 0.8828125\n",
      "Batch 110: loss = 0.2932005524635315, acc = 0.908203125\n",
      "Batch 111: loss = 0.30762404203414917, acc = 0.912109375\n",
      "Batch 112: loss = 0.33216774463653564, acc = 0.884765625\n",
      "Batch 113: loss = 0.3603791892528534, acc = 0.876953125\n",
      "Batch 114: loss = 0.32400768995285034, acc = 0.8837890625\n",
      "Batch 115: loss = 0.35298851132392883, acc = 0.8837890625\n",
      "Batch 116: loss = 0.3312070965766907, acc = 0.876953125\n",
      "Batch 117: loss = 0.33949676156044006, acc = 0.87890625\n",
      "Batch 118: loss = 0.30643001198768616, acc = 0.8994140625\n",
      "Batch 119: loss = 0.35332730412483215, acc = 0.8818359375\n",
      "Batch 120: loss = 0.31004640460014343, acc = 0.8955078125\n",
      "Batch 121: loss = 0.3039644956588745, acc = 0.8935546875\n",
      "Batch 122: loss = 0.28566667437553406, acc = 0.9013671875\n",
      "Batch 123: loss = 0.324918270111084, acc = 0.8837890625\n",
      "Batch 124: loss = 0.3389400541782379, acc = 0.8779296875\n",
      "Batch 125: loss = 0.346322238445282, acc = 0.87890625\n",
      "Batch 126: loss = 0.3648536503314972, acc = 0.8837890625\n",
      "\n",
      "Epoch 72/100\n",
      "Batch 1: loss = 0.39878836274147034, acc = 0.8681640625\n",
      "Batch 2: loss = 0.3669883608818054, acc = 0.8818359375\n",
      "Batch 3: loss = 0.330011248588562, acc = 0.890625\n",
      "Batch 4: loss = 0.30505576729774475, acc = 0.9033203125\n",
      "Batch 5: loss = 0.3583795428276062, acc = 0.880859375\n",
      "Batch 6: loss = 0.35137373208999634, acc = 0.8798828125\n",
      "Batch 7: loss = 0.30325886607170105, acc = 0.896484375\n",
      "Batch 8: loss = 0.3207719027996063, acc = 0.89453125\n",
      "Batch 9: loss = 0.33239710330963135, acc = 0.892578125\n",
      "Batch 10: loss = 0.30220746994018555, acc = 0.8994140625\n",
      "Batch 11: loss = 0.3515598475933075, acc = 0.876953125\n",
      "Batch 12: loss = 0.36604583263397217, acc = 0.8740234375\n",
      "Batch 13: loss = 0.3397600054740906, acc = 0.888671875\n",
      "Batch 14: loss = 0.3003263771533966, acc = 0.8994140625\n",
      "Batch 15: loss = 0.3054289221763611, acc = 0.9072265625\n",
      "Batch 16: loss = 0.34652072191238403, acc = 0.8818359375\n",
      "Batch 17: loss = 0.3278977870941162, acc = 0.89453125\n",
      "Batch 18: loss = 0.37644022703170776, acc = 0.8583984375\n",
      "Batch 19: loss = 0.3378921151161194, acc = 0.8828125\n",
      "Batch 20: loss = 0.3216792345046997, acc = 0.89453125\n",
      "Batch 21: loss = 0.3588540256023407, acc = 0.8701171875\n",
      "Batch 22: loss = 0.30684250593185425, acc = 0.8955078125\n",
      "Batch 23: loss = 0.3030645251274109, acc = 0.8974609375\n",
      "Batch 24: loss = 0.3466392159461975, acc = 0.8818359375\n",
      "Batch 25: loss = 0.30957385897636414, acc = 0.896484375\n",
      "Batch 26: loss = 0.3375391960144043, acc = 0.888671875\n",
      "Batch 27: loss = 0.41503000259399414, acc = 0.873046875\n",
      "Batch 28: loss = 0.3518388867378235, acc = 0.8828125\n",
      "Batch 29: loss = 0.36303049325942993, acc = 0.8720703125\n",
      "Batch 30: loss = 0.31772536039352417, acc = 0.89453125\n",
      "Batch 31: loss = 0.35733866691589355, acc = 0.8701171875\n",
      "Batch 32: loss = 0.37675565481185913, acc = 0.876953125\n",
      "Batch 33: loss = 0.30592334270477295, acc = 0.8974609375\n",
      "Batch 34: loss = 0.3424249589443207, acc = 0.89453125\n",
      "Batch 35: loss = 0.30524906516075134, acc = 0.8916015625\n",
      "Batch 36: loss = 0.2784457206726074, acc = 0.908203125\n",
      "Batch 37: loss = 0.28324779868125916, acc = 0.912109375\n",
      "Batch 38: loss = 0.3274223506450653, acc = 0.890625\n",
      "Batch 39: loss = 0.31186187267303467, acc = 0.89453125\n",
      "Batch 40: loss = 0.3782428801059723, acc = 0.8681640625\n",
      "Batch 41: loss = 0.2795765995979309, acc = 0.91015625\n",
      "Batch 42: loss = 0.3347134292125702, acc = 0.88671875\n",
      "Batch 43: loss = 0.3670755624771118, acc = 0.8701171875\n",
      "Batch 44: loss = 0.2874020040035248, acc = 0.9111328125\n",
      "Batch 45: loss = 0.28871074318885803, acc = 0.916015625\n",
      "Batch 46: loss = 0.3293694853782654, acc = 0.8896484375\n",
      "Batch 47: loss = 0.318729043006897, acc = 0.9052734375\n",
      "Batch 48: loss = 0.30460110306739807, acc = 0.8994140625\n",
      "Batch 49: loss = 0.30147886276245117, acc = 0.90625\n",
      "Batch 50: loss = 0.28620558977127075, acc = 0.90234375\n",
      "Batch 51: loss = 0.29711729288101196, acc = 0.9052734375\n",
      "Batch 52: loss = 0.32531481981277466, acc = 0.888671875\n",
      "Batch 53: loss = 0.3173428773880005, acc = 0.8935546875\n",
      "Batch 54: loss = 0.2595165967941284, acc = 0.9072265625\n",
      "Batch 55: loss = 0.31090858578681946, acc = 0.8916015625\n",
      "Batch 56: loss = 0.32763412594795227, acc = 0.8876953125\n",
      "Batch 57: loss = 0.35894566774368286, acc = 0.8828125\n",
      "Batch 58: loss = 0.3430883586406708, acc = 0.87890625\n",
      "Batch 59: loss = 0.26787203550338745, acc = 0.916015625\n",
      "Batch 60: loss = 0.3202030062675476, acc = 0.88671875\n",
      "Batch 61: loss = 0.2618532180786133, acc = 0.91796875\n",
      "Batch 62: loss = 0.35269391536712646, acc = 0.8818359375\n",
      "Batch 63: loss = 0.33561792969703674, acc = 0.888671875\n",
      "Batch 64: loss = 0.28569602966308594, acc = 0.9013671875\n",
      "Batch 65: loss = 0.3316924571990967, acc = 0.8818359375\n",
      "Batch 66: loss = 0.30642205476760864, acc = 0.90234375\n",
      "Batch 67: loss = 0.31449779868125916, acc = 0.8876953125\n",
      "Batch 68: loss = 0.34055382013320923, acc = 0.88671875\n",
      "Batch 69: loss = 0.2771929204463959, acc = 0.91015625\n",
      "Batch 70: loss = 0.39958515763282776, acc = 0.869140625\n",
      "Batch 71: loss = 0.3590988516807556, acc = 0.8759765625\n",
      "Batch 72: loss = 0.30274972319602966, acc = 0.9052734375\n",
      "Batch 73: loss = 0.3088347315788269, acc = 0.892578125\n",
      "Batch 74: loss = 0.3712540864944458, acc = 0.869140625\n",
      "Batch 75: loss = 0.37547099590301514, acc = 0.8740234375\n",
      "Batch 76: loss = 0.3457537293434143, acc = 0.87890625\n",
      "Batch 77: loss = 0.30891281366348267, acc = 0.8916015625\n",
      "Batch 78: loss = 0.36104708909988403, acc = 0.900390625\n",
      "Batch 79: loss = 0.3242712616920471, acc = 0.88671875\n",
      "Batch 80: loss = 0.32695063948631287, acc = 0.8955078125\n",
      "Batch 81: loss = 0.32620471715927124, acc = 0.8896484375\n",
      "Batch 82: loss = 0.3213472068309784, acc = 0.8955078125\n",
      "Batch 83: loss = 0.3111417293548584, acc = 0.8896484375\n",
      "Batch 84: loss = 0.3437584638595581, acc = 0.8828125\n",
      "Batch 85: loss = 0.3531138598918915, acc = 0.875\n",
      "Batch 86: loss = 0.3499361574649811, acc = 0.8720703125\n",
      "Batch 87: loss = 0.33781468868255615, acc = 0.8916015625\n",
      "Batch 88: loss = 0.38403210043907166, acc = 0.8779296875\n",
      "Batch 89: loss = 0.32491639256477356, acc = 0.88671875\n",
      "Batch 90: loss = 0.3381677567958832, acc = 0.8818359375\n",
      "Batch 91: loss = 0.3159596025943756, acc = 0.8857421875\n",
      "Batch 92: loss = 0.3554183840751648, acc = 0.8779296875\n",
      "Batch 93: loss = 0.3189113140106201, acc = 0.896484375\n",
      "Batch 94: loss = 0.2943112552165985, acc = 0.896484375\n",
      "Batch 95: loss = 0.3212510049343109, acc = 0.88671875\n",
      "Batch 96: loss = 0.38360267877578735, acc = 0.853515625\n",
      "Batch 97: loss = 0.34339597821235657, acc = 0.8857421875\n",
      "Batch 98: loss = 0.31625062227249146, acc = 0.890625\n",
      "Batch 99: loss = 0.3558216094970703, acc = 0.8798828125\n",
      "Batch 100: loss = 0.35004469752311707, acc = 0.8818359375\n",
      "Batch 101: loss = 0.31086021661758423, acc = 0.8916015625\n",
      "Batch 102: loss = 0.3529700040817261, acc = 0.875\n",
      "Batch 103: loss = 0.3493950068950653, acc = 0.884765625\n",
      "Batch 104: loss = 0.2921135723590851, acc = 0.90234375\n",
      "Batch 105: loss = 0.3140997886657715, acc = 0.90625\n",
      "Batch 106: loss = 0.3266926109790802, acc = 0.8837890625\n",
      "Batch 107: loss = 0.3255844712257385, acc = 0.89453125\n",
      "Batch 108: loss = 0.3175029158592224, acc = 0.8984375\n",
      "Batch 109: loss = 0.31648361682891846, acc = 0.888671875\n",
      "Batch 110: loss = 0.2913013696670532, acc = 0.8994140625\n",
      "Batch 111: loss = 0.3368350863456726, acc = 0.8857421875\n",
      "Batch 112: loss = 0.3483671545982361, acc = 0.8798828125\n",
      "Batch 113: loss = 0.3295784294605255, acc = 0.8857421875\n",
      "Batch 114: loss = 0.35648003220558167, acc = 0.8828125\n",
      "Batch 115: loss = 0.3485969305038452, acc = 0.892578125\n",
      "Batch 116: loss = 0.3659474849700928, acc = 0.869140625\n",
      "Batch 117: loss = 0.3117823600769043, acc = 0.8935546875\n",
      "Batch 118: loss = 0.3184409439563751, acc = 0.8857421875\n",
      "Batch 119: loss = 0.35566937923431396, acc = 0.8740234375\n",
      "Batch 120: loss = 0.32199129462242126, acc = 0.8916015625\n",
      "Batch 121: loss = 0.3000774085521698, acc = 0.904296875\n",
      "Batch 122: loss = 0.29520031809806824, acc = 0.9130859375\n",
      "Batch 123: loss = 0.2915177643299103, acc = 0.8994140625\n",
      "Batch 124: loss = 0.3373926877975464, acc = 0.880859375\n",
      "Batch 125: loss = 0.34495723247528076, acc = 0.8955078125\n",
      "Batch 126: loss = 0.3447951078414917, acc = 0.8818359375\n",
      "\n",
      "Epoch 73/100\n",
      "Batch 1: loss = 0.4025235176086426, acc = 0.875\n",
      "Batch 2: loss = 0.3417063355445862, acc = 0.87890625\n",
      "Batch 3: loss = 0.31385108828544617, acc = 0.904296875\n",
      "Batch 4: loss = 0.34237268567085266, acc = 0.880859375\n",
      "Batch 5: loss = 0.30849286913871765, acc = 0.8994140625\n",
      "Batch 6: loss = 0.3374861776828766, acc = 0.892578125\n",
      "Batch 7: loss = 0.29935240745544434, acc = 0.89453125\n",
      "Batch 8: loss = 0.33253270387649536, acc = 0.888671875\n",
      "Batch 9: loss = 0.31348058581352234, acc = 0.892578125\n",
      "Batch 10: loss = 0.3073178231716156, acc = 0.90234375\n",
      "Batch 11: loss = 0.3275696933269501, acc = 0.8896484375\n",
      "Batch 12: loss = 0.32871299982070923, acc = 0.8818359375\n",
      "Batch 13: loss = 0.3424774408340454, acc = 0.8857421875\n",
      "Batch 14: loss = 0.3208385705947876, acc = 0.8955078125\n",
      "Batch 15: loss = 0.2883699834346771, acc = 0.90234375\n",
      "Batch 16: loss = 0.3348099887371063, acc = 0.8916015625\n",
      "Batch 17: loss = 0.30782872438430786, acc = 0.896484375\n",
      "Batch 18: loss = 0.34117498993873596, acc = 0.8798828125\n",
      "Batch 19: loss = 0.3022088408470154, acc = 0.88671875\n",
      "Batch 20: loss = 0.3446851372718811, acc = 0.87890625\n",
      "Batch 21: loss = 0.3466542661190033, acc = 0.876953125\n",
      "Batch 22: loss = 0.3277924060821533, acc = 0.8818359375\n",
      "Batch 23: loss = 0.34291934967041016, acc = 0.884765625\n",
      "Batch 24: loss = 0.3492332696914673, acc = 0.8779296875\n",
      "Batch 25: loss = 0.32211074233055115, acc = 0.892578125\n",
      "Batch 26: loss = 0.34620898962020874, acc = 0.876953125\n",
      "Batch 27: loss = 0.3665536046028137, acc = 0.875\n",
      "Batch 28: loss = 0.33357352018356323, acc = 0.88671875\n",
      "Batch 29: loss = 0.3609919846057892, acc = 0.87890625\n",
      "Batch 30: loss = 0.31113728880882263, acc = 0.888671875\n",
      "Batch 31: loss = 0.32475680112838745, acc = 0.8916015625\n",
      "Batch 32: loss = 0.38609325885772705, acc = 0.8583984375\n",
      "Batch 33: loss = 0.3200068473815918, acc = 0.8857421875\n",
      "Batch 34: loss = 0.33864903450012207, acc = 0.88671875\n",
      "Batch 35: loss = 0.3296498954296112, acc = 0.8828125\n",
      "Batch 36: loss = 0.28852471709251404, acc = 0.9033203125\n",
      "Batch 37: loss = 0.26932862401008606, acc = 0.9091796875\n",
      "Batch 38: loss = 0.2933674454689026, acc = 0.9013671875\n",
      "Batch 39: loss = 0.2973724901676178, acc = 0.908203125\n",
      "Batch 40: loss = 0.32916131615638733, acc = 0.892578125\n",
      "Batch 41: loss = 0.30053842067718506, acc = 0.90234375\n",
      "Batch 42: loss = 0.33727771043777466, acc = 0.8984375\n",
      "Batch 43: loss = 0.33958134055137634, acc = 0.880859375\n",
      "Batch 44: loss = 0.30714040994644165, acc = 0.9052734375\n",
      "Batch 45: loss = 0.32377585768699646, acc = 0.89453125\n",
      "Batch 46: loss = 0.3059288561344147, acc = 0.8974609375\n",
      "Batch 47: loss = 0.30916619300842285, acc = 0.89453125\n",
      "Batch 48: loss = 0.3045288920402527, acc = 0.896484375\n",
      "Batch 49: loss = 0.31200021505355835, acc = 0.9052734375\n",
      "Batch 50: loss = 0.3147842586040497, acc = 0.8974609375\n",
      "Batch 51: loss = 0.3150672912597656, acc = 0.8935546875\n",
      "Batch 52: loss = 0.35256510972976685, acc = 0.873046875\n",
      "Batch 53: loss = 0.3096100687980652, acc = 0.8974609375\n",
      "Batch 54: loss = 0.26269808411598206, acc = 0.912109375\n",
      "Batch 55: loss = 0.32462868094444275, acc = 0.8955078125\n",
      "Batch 56: loss = 0.3159277141094208, acc = 0.89453125\n",
      "Batch 57: loss = 0.3532293140888214, acc = 0.87109375\n",
      "Batch 58: loss = 0.3766111731529236, acc = 0.86328125\n",
      "Batch 59: loss = 0.2779875695705414, acc = 0.900390625\n",
      "Batch 60: loss = 0.3065267503261566, acc = 0.8984375\n",
      "Batch 61: loss = 0.28669458627700806, acc = 0.90234375\n",
      "Batch 62: loss = 0.3597094416618347, acc = 0.880859375\n",
      "Batch 63: loss = 0.311673641204834, acc = 0.892578125\n",
      "Batch 64: loss = 0.2884785532951355, acc = 0.90234375\n",
      "Batch 65: loss = 0.32754018902778625, acc = 0.8916015625\n",
      "Batch 66: loss = 0.30335357785224915, acc = 0.9033203125\n",
      "Batch 67: loss = 0.30647554993629456, acc = 0.90625\n",
      "Batch 68: loss = 0.3285696804523468, acc = 0.896484375\n",
      "Batch 69: loss = 0.27965208888053894, acc = 0.9091796875\n",
      "Batch 70: loss = 0.3239133059978485, acc = 0.8984375\n",
      "Batch 71: loss = 0.32239067554473877, acc = 0.892578125\n",
      "Batch 72: loss = 0.28330060839653015, acc = 0.908203125\n",
      "Batch 73: loss = 0.351298063993454, acc = 0.87109375\n",
      "Batch 74: loss = 0.350287526845932, acc = 0.8583984375\n",
      "Batch 75: loss = 0.35245081782341003, acc = 0.875\n",
      "Batch 76: loss = 0.35508692264556885, acc = 0.8779296875\n",
      "Batch 77: loss = 0.30771294236183167, acc = 0.8974609375\n",
      "Batch 78: loss = 0.3338387608528137, acc = 0.8935546875\n",
      "Batch 79: loss = 0.2996445298194885, acc = 0.890625\n",
      "Batch 80: loss = 0.3141213655471802, acc = 0.8837890625\n",
      "Batch 81: loss = 0.3531477451324463, acc = 0.8779296875\n",
      "Batch 82: loss = 0.344386488199234, acc = 0.888671875\n",
      "Batch 83: loss = 0.29036134481430054, acc = 0.912109375\n",
      "Batch 84: loss = 0.33234554529190063, acc = 0.888671875\n",
      "Batch 85: loss = 0.3798409402370453, acc = 0.86328125\n",
      "Batch 86: loss = 0.30912598967552185, acc = 0.896484375\n",
      "Batch 87: loss = 0.36819493770599365, acc = 0.8798828125\n",
      "Batch 88: loss = 0.35993272066116333, acc = 0.8671875\n",
      "Batch 89: loss = 0.30217215418815613, acc = 0.8955078125\n",
      "Batch 90: loss = 0.3411436080932617, acc = 0.884765625\n",
      "Batch 91: loss = 0.3285331726074219, acc = 0.88671875\n",
      "Batch 92: loss = 0.3312298059463501, acc = 0.8759765625\n",
      "Batch 93: loss = 0.32192081212997437, acc = 0.8818359375\n",
      "Batch 94: loss = 0.28370803594589233, acc = 0.8984375\n",
      "Batch 95: loss = 0.324765682220459, acc = 0.8837890625\n",
      "Batch 96: loss = 0.38541892170906067, acc = 0.8583984375\n",
      "Batch 97: loss = 0.3293837904930115, acc = 0.8935546875\n",
      "Batch 98: loss = 0.3027157187461853, acc = 0.892578125\n",
      "Batch 99: loss = 0.35063618421554565, acc = 0.8759765625\n",
      "Batch 100: loss = 0.3527523875236511, acc = 0.8671875\n",
      "Batch 101: loss = 0.3021880090236664, acc = 0.8876953125\n",
      "Batch 102: loss = 0.32388848066329956, acc = 0.89453125\n",
      "Batch 103: loss = 0.3326912522315979, acc = 0.8935546875\n",
      "Batch 104: loss = 0.29323187470436096, acc = 0.900390625\n",
      "Batch 105: loss = 0.2831474840641022, acc = 0.9111328125\n",
      "Batch 106: loss = 0.2847416400909424, acc = 0.9091796875\n",
      "Batch 107: loss = 0.3068353533744812, acc = 0.89453125\n",
      "Batch 108: loss = 0.3037959337234497, acc = 0.89453125\n",
      "Batch 109: loss = 0.3208273649215698, acc = 0.892578125\n",
      "Batch 110: loss = 0.3000805079936981, acc = 0.9013671875\n",
      "Batch 111: loss = 0.3339707851409912, acc = 0.8916015625\n",
      "Batch 112: loss = 0.3102886378765106, acc = 0.8779296875\n",
      "Batch 113: loss = 0.32935449481010437, acc = 0.8857421875\n",
      "Batch 114: loss = 0.3483545780181885, acc = 0.890625\n",
      "Batch 115: loss = 0.3403308689594269, acc = 0.880859375\n",
      "Batch 116: loss = 0.3297867476940155, acc = 0.8828125\n",
      "Batch 117: loss = 0.298443466424942, acc = 0.8974609375\n",
      "Batch 118: loss = 0.30990082025527954, acc = 0.8974609375\n",
      "Batch 119: loss = 0.33108288049697876, acc = 0.890625\n",
      "Batch 120: loss = 0.31734687089920044, acc = 0.888671875\n",
      "Batch 121: loss = 0.3217819631099701, acc = 0.88671875\n",
      "Batch 122: loss = 0.28974324464797974, acc = 0.89453125\n",
      "Batch 123: loss = 0.27299660444259644, acc = 0.9111328125\n",
      "Batch 124: loss = 0.33273249864578247, acc = 0.8935546875\n",
      "Batch 125: loss = 0.35660138726234436, acc = 0.8642578125\n",
      "Batch 126: loss = 0.33664771914482117, acc = 0.8955078125\n",
      "\n",
      "Epoch 74/100\n",
      "Batch 1: loss = 0.4171058237552643, acc = 0.875\n",
      "Batch 2: loss = 0.36823770403862, acc = 0.873046875\n",
      "Batch 3: loss = 0.3245939612388611, acc = 0.896484375\n",
      "Batch 4: loss = 0.33200427889823914, acc = 0.8916015625\n",
      "Batch 5: loss = 0.34305793046951294, acc = 0.888671875\n",
      "Batch 6: loss = 0.32369911670684814, acc = 0.8935546875\n",
      "Batch 7: loss = 0.33186089992523193, acc = 0.876953125\n",
      "Batch 8: loss = 0.33667832612991333, acc = 0.890625\n",
      "Batch 9: loss = 0.3019094467163086, acc = 0.8955078125\n",
      "Batch 10: loss = 0.3238050043582916, acc = 0.8935546875\n",
      "Batch 11: loss = 0.3408467769622803, acc = 0.8818359375\n",
      "Batch 12: loss = 0.32136034965515137, acc = 0.87109375\n",
      "Batch 13: loss = 0.3145299553871155, acc = 0.8955078125\n",
      "Batch 14: loss = 0.3241429328918457, acc = 0.8876953125\n",
      "Batch 15: loss = 0.2649391293525696, acc = 0.9140625\n",
      "Batch 16: loss = 0.33446305990219116, acc = 0.876953125\n",
      "Batch 17: loss = 0.3289218842983246, acc = 0.8837890625\n",
      "Batch 18: loss = 0.3292096257209778, acc = 0.8857421875\n",
      "Batch 19: loss = 0.3034922480583191, acc = 0.8994140625\n",
      "Batch 20: loss = 0.3307580053806305, acc = 0.88671875\n",
      "Batch 21: loss = 0.3297739028930664, acc = 0.8876953125\n",
      "Batch 22: loss = 0.3259388506412506, acc = 0.8818359375\n",
      "Batch 23: loss = 0.3403853476047516, acc = 0.89453125\n",
      "Batch 24: loss = 0.33368736505508423, acc = 0.88671875\n",
      "Batch 25: loss = 0.31518760323524475, acc = 0.8916015625\n",
      "Batch 26: loss = 0.31391382217407227, acc = 0.888671875\n",
      "Batch 27: loss = 0.4078766703605652, acc = 0.84375\n",
      "Batch 28: loss = 0.34833014011383057, acc = 0.8896484375\n",
      "Batch 29: loss = 0.3738912343978882, acc = 0.865234375\n",
      "Batch 30: loss = 0.2911280691623688, acc = 0.90625\n",
      "Batch 31: loss = 0.34275925159454346, acc = 0.87890625\n",
      "Batch 32: loss = 0.35897815227508545, acc = 0.8828125\n",
      "Batch 33: loss = 0.2980990707874298, acc = 0.896484375\n",
      "Batch 34: loss = 0.3284554183483124, acc = 0.8837890625\n",
      "Batch 35: loss = 0.3276726305484772, acc = 0.89453125\n",
      "Batch 36: loss = 0.30199146270751953, acc = 0.8916015625\n",
      "Batch 37: loss = 0.27212512493133545, acc = 0.9150390625\n",
      "Batch 38: loss = 0.3003498613834381, acc = 0.90234375\n",
      "Batch 39: loss = 0.3062441349029541, acc = 0.9052734375\n",
      "Batch 40: loss = 0.33996671438217163, acc = 0.8935546875\n",
      "Batch 41: loss = 0.28818848729133606, acc = 0.9013671875\n",
      "Batch 42: loss = 0.33137714862823486, acc = 0.8876953125\n",
      "Batch 43: loss = 0.3215654194355011, acc = 0.892578125\n",
      "Batch 44: loss = 0.280254602432251, acc = 0.9130859375\n",
      "Batch 45: loss = 0.2936607003211975, acc = 0.9013671875\n",
      "Batch 46: loss = 0.29669132828712463, acc = 0.896484375\n",
      "Batch 47: loss = 0.3142954707145691, acc = 0.8984375\n",
      "Batch 48: loss = 0.3254782557487488, acc = 0.890625\n",
      "Batch 49: loss = 0.3082641363143921, acc = 0.896484375\n",
      "Batch 50: loss = 0.2975349724292755, acc = 0.896484375\n",
      "Batch 51: loss = 0.3381642997264862, acc = 0.87890625\n",
      "Batch 52: loss = 0.31309154629707336, acc = 0.8974609375\n",
      "Batch 53: loss = 0.33338844776153564, acc = 0.8896484375\n",
      "Batch 54: loss = 0.25506827235221863, acc = 0.91015625\n",
      "Batch 55: loss = 0.3139179050922394, acc = 0.9013671875\n",
      "Batch 56: loss = 0.3129890561103821, acc = 0.892578125\n",
      "Batch 57: loss = 0.3354034721851349, acc = 0.875\n",
      "Batch 58: loss = 0.350938618183136, acc = 0.875\n",
      "Batch 59: loss = 0.27383965253829956, acc = 0.904296875\n",
      "Batch 60: loss = 0.31901872158050537, acc = 0.8837890625\n",
      "Batch 61: loss = 0.2926512360572815, acc = 0.9033203125\n",
      "Batch 62: loss = 0.3545835614204407, acc = 0.8857421875\n",
      "Batch 63: loss = 0.2834131717681885, acc = 0.89453125\n",
      "Batch 64: loss = 0.25094425678253174, acc = 0.9248046875\n",
      "Batch 65: loss = 0.3484305739402771, acc = 0.8759765625\n",
      "Batch 66: loss = 0.3193352520465851, acc = 0.8955078125\n",
      "Batch 67: loss = 0.3049357831478119, acc = 0.8916015625\n",
      "Batch 68: loss = 0.33935168385505676, acc = 0.8837890625\n",
      "Batch 69: loss = 0.28286147117614746, acc = 0.91015625\n",
      "Batch 70: loss = 0.32409554719924927, acc = 0.90234375\n",
      "Batch 71: loss = 0.31612956523895264, acc = 0.89453125\n",
      "Batch 72: loss = 0.3114340305328369, acc = 0.89453125\n",
      "Batch 73: loss = 0.3278447687625885, acc = 0.87890625\n",
      "Batch 74: loss = 0.3335370719432831, acc = 0.869140625\n",
      "Batch 75: loss = 0.3625928461551666, acc = 0.8779296875\n",
      "Batch 76: loss = 0.3661368489265442, acc = 0.8671875\n",
      "Batch 77: loss = 0.33088773488998413, acc = 0.884765625\n",
      "Batch 78: loss = 0.3457909822463989, acc = 0.8798828125\n",
      "Batch 79: loss = 0.3124176859855652, acc = 0.8955078125\n",
      "Batch 80: loss = 0.28735336661338806, acc = 0.9091796875\n",
      "Batch 81: loss = 0.3207852244377136, acc = 0.8935546875\n",
      "Batch 82: loss = 0.33051028847694397, acc = 0.88671875\n",
      "Batch 83: loss = 0.303569495677948, acc = 0.896484375\n",
      "Batch 84: loss = 0.34697872400283813, acc = 0.8818359375\n",
      "Batch 85: loss = 0.3483327031135559, acc = 0.873046875\n",
      "Batch 86: loss = 0.3150058090686798, acc = 0.892578125\n",
      "Batch 87: loss = 0.32334816455841064, acc = 0.9052734375\n",
      "Batch 88: loss = 0.35487931966781616, acc = 0.88671875\n",
      "Batch 89: loss = 0.2916434407234192, acc = 0.9130859375\n",
      "Batch 90: loss = 0.3190003037452698, acc = 0.8955078125\n",
      "Batch 91: loss = 0.3299228250980377, acc = 0.8955078125\n",
      "Batch 92: loss = 0.3389036953449249, acc = 0.88671875\n",
      "Batch 93: loss = 0.32521411776542664, acc = 0.8857421875\n",
      "Batch 94: loss = 0.26912736892700195, acc = 0.9150390625\n",
      "Batch 95: loss = 0.3027527332305908, acc = 0.900390625\n",
      "Batch 96: loss = 0.3478972017765045, acc = 0.8818359375\n",
      "Batch 97: loss = 0.33635905385017395, acc = 0.89453125\n",
      "Batch 98: loss = 0.32469549775123596, acc = 0.880859375\n",
      "Batch 99: loss = 0.3344048261642456, acc = 0.8798828125\n",
      "Batch 100: loss = 0.3205934762954712, acc = 0.8857421875\n",
      "Batch 101: loss = 0.3176196217536926, acc = 0.904296875\n",
      "Batch 102: loss = 0.3305027484893799, acc = 0.896484375\n",
      "Batch 103: loss = 0.32687100768089294, acc = 0.892578125\n",
      "Batch 104: loss = 0.2994399964809418, acc = 0.8974609375\n",
      "Batch 105: loss = 0.30565088987350464, acc = 0.8974609375\n",
      "Batch 106: loss = 0.30777156352996826, acc = 0.8994140625\n",
      "Batch 107: loss = 0.2917625308036804, acc = 0.9013671875\n",
      "Batch 108: loss = 0.3144538998603821, acc = 0.8984375\n",
      "Batch 109: loss = 0.31045058369636536, acc = 0.900390625\n",
      "Batch 110: loss = 0.2731174826622009, acc = 0.900390625\n",
      "Batch 111: loss = 0.3301886022090912, acc = 0.8955078125\n",
      "Batch 112: loss = 0.3125603199005127, acc = 0.89453125\n",
      "Batch 113: loss = 0.3474377393722534, acc = 0.880859375\n",
      "Batch 114: loss = 0.3151026666164398, acc = 0.8994140625\n",
      "Batch 115: loss = 0.3323114514350891, acc = 0.8876953125\n",
      "Batch 116: loss = 0.33451494574546814, acc = 0.890625\n",
      "Batch 117: loss = 0.3195820450782776, acc = 0.8935546875\n",
      "Batch 118: loss = 0.3168494701385498, acc = 0.8994140625\n",
      "Batch 119: loss = 0.31429988145828247, acc = 0.8916015625\n",
      "Batch 120: loss = 0.2956905961036682, acc = 0.900390625\n",
      "Batch 121: loss = 0.2824862003326416, acc = 0.892578125\n",
      "Batch 122: loss = 0.31686171889305115, acc = 0.890625\n",
      "Batch 123: loss = 0.329816997051239, acc = 0.8828125\n",
      "Batch 124: loss = 0.3327077627182007, acc = 0.890625\n",
      "Batch 125: loss = 0.3602212071418762, acc = 0.8740234375\n",
      "Batch 126: loss = 0.3436589241027832, acc = 0.8779296875\n",
      "\n",
      "Epoch 75/100\n",
      "Batch 1: loss = 0.4248766601085663, acc = 0.8603515625\n",
      "Batch 2: loss = 0.33666712045669556, acc = 0.890625\n",
      "Batch 3: loss = 0.3132169842720032, acc = 0.9013671875\n",
      "Batch 4: loss = 0.3211804926395416, acc = 0.90234375\n",
      "Batch 5: loss = 0.3733563721179962, acc = 0.87890625\n",
      "Batch 6: loss = 0.3206647038459778, acc = 0.8974609375\n",
      "Batch 7: loss = 0.28268587589263916, acc = 0.8935546875\n",
      "Batch 8: loss = 0.3348560333251953, acc = 0.8828125\n",
      "Batch 9: loss = 0.3239373564720154, acc = 0.8837890625\n",
      "Batch 10: loss = 0.29164963960647583, acc = 0.900390625\n",
      "Batch 11: loss = 0.3229888677597046, acc = 0.8759765625\n",
      "Batch 12: loss = 0.3203449547290802, acc = 0.8916015625\n",
      "Batch 13: loss = 0.3062213957309723, acc = 0.912109375\n",
      "Batch 14: loss = 0.2655704617500305, acc = 0.91015625\n",
      "Batch 15: loss = 0.26832616329193115, acc = 0.9052734375\n",
      "Batch 16: loss = 0.3357401490211487, acc = 0.8818359375\n",
      "Batch 17: loss = 0.3156285583972931, acc = 0.8984375\n",
      "Batch 18: loss = 0.3763018250465393, acc = 0.8671875\n",
      "Batch 19: loss = 0.34366723895072937, acc = 0.8857421875\n",
      "Batch 20: loss = 0.3367835283279419, acc = 0.8876953125\n",
      "Batch 21: loss = 0.3309558928012848, acc = 0.888671875\n",
      "Batch 22: loss = 0.28499269485473633, acc = 0.8984375\n",
      "Batch 23: loss = 0.3413485288619995, acc = 0.8818359375\n",
      "Batch 24: loss = 0.33640626072883606, acc = 0.8876953125\n",
      "Batch 25: loss = 0.33086875081062317, acc = 0.892578125\n",
      "Batch 26: loss = 0.31586071848869324, acc = 0.8876953125\n",
      "Batch 27: loss = 0.39666274189949036, acc = 0.87109375\n",
      "Batch 28: loss = 0.323599636554718, acc = 0.8916015625\n",
      "Batch 29: loss = 0.3983018398284912, acc = 0.8583984375\n",
      "Batch 30: loss = 0.3221049904823303, acc = 0.888671875\n",
      "Batch 31: loss = 0.3783850371837616, acc = 0.87109375\n",
      "Batch 32: loss = 0.33566221594810486, acc = 0.890625\n",
      "Batch 33: loss = 0.3349105417728424, acc = 0.8896484375\n",
      "Batch 34: loss = 0.3578149676322937, acc = 0.8779296875\n",
      "Batch 35: loss = 0.29257166385650635, acc = 0.90234375\n",
      "Batch 36: loss = 0.2779253423213959, acc = 0.91015625\n",
      "Batch 37: loss = 0.27972540259361267, acc = 0.9150390625\n",
      "Batch 38: loss = 0.2652074992656708, acc = 0.91796875\n",
      "Batch 39: loss = 0.29851579666137695, acc = 0.89453125\n",
      "Batch 40: loss = 0.31608620285987854, acc = 0.89453125\n",
      "Batch 41: loss = 0.2911127805709839, acc = 0.8994140625\n",
      "Batch 42: loss = 0.3065241277217865, acc = 0.8896484375\n",
      "Batch 43: loss = 0.3730129599571228, acc = 0.87109375\n",
      "Batch 44: loss = 0.3103983402252197, acc = 0.8935546875\n",
      "Batch 45: loss = 0.2820303440093994, acc = 0.90234375\n",
      "Batch 46: loss = 0.30329737067222595, acc = 0.904296875\n",
      "Batch 47: loss = 0.28038397431373596, acc = 0.8984375\n",
      "Batch 48: loss = 0.30715489387512207, acc = 0.9013671875\n",
      "Batch 49: loss = 0.2849003076553345, acc = 0.8994140625\n",
      "Batch 50: loss = 0.3047739267349243, acc = 0.89453125\n",
      "Batch 51: loss = 0.27985721826553345, acc = 0.9013671875\n",
      "Batch 52: loss = 0.327833890914917, acc = 0.8759765625\n",
      "Batch 53: loss = 0.32550573348999023, acc = 0.8818359375\n",
      "Batch 54: loss = 0.24717888236045837, acc = 0.919921875\n",
      "Batch 55: loss = 0.29090002179145813, acc = 0.9013671875\n",
      "Batch 56: loss = 0.3593601882457733, acc = 0.8720703125\n",
      "Batch 57: loss = 0.348632276058197, acc = 0.876953125\n",
      "Batch 58: loss = 0.3244125545024872, acc = 0.8896484375\n",
      "Batch 59: loss = 0.2543509006500244, acc = 0.916015625\n",
      "Batch 60: loss = 0.3398648202419281, acc = 0.8740234375\n",
      "Batch 61: loss = 0.27836310863494873, acc = 0.91015625\n",
      "Batch 62: loss = 0.36937281489372253, acc = 0.8759765625\n",
      "Batch 63: loss = 0.2954975366592407, acc = 0.900390625\n",
      "Batch 64: loss = 0.28211385011672974, acc = 0.900390625\n",
      "Batch 65: loss = 0.30571720004081726, acc = 0.888671875\n",
      "Batch 66: loss = 0.30911561846733093, acc = 0.8955078125\n",
      "Batch 67: loss = 0.3025725483894348, acc = 0.9033203125\n",
      "Batch 68: loss = 0.3091551661491394, acc = 0.888671875\n",
      "Batch 69: loss = 0.29954493045806885, acc = 0.9052734375\n",
      "Batch 70: loss = 0.32003307342529297, acc = 0.88671875\n",
      "Batch 71: loss = 0.31741610169410706, acc = 0.892578125\n",
      "Batch 72: loss = 0.29043030738830566, acc = 0.9052734375\n",
      "Batch 73: loss = 0.325571745634079, acc = 0.8896484375\n",
      "Batch 74: loss = 0.33001595735549927, acc = 0.896484375\n",
      "Batch 75: loss = 0.39696255326271057, acc = 0.8564453125\n",
      "Batch 76: loss = 0.3797157406806946, acc = 0.87109375\n",
      "Batch 77: loss = 0.27911219000816345, acc = 0.9150390625\n",
      "Batch 78: loss = 0.2876063287258148, acc = 0.908203125\n",
      "Batch 79: loss = 0.29878145456314087, acc = 0.9091796875\n",
      "Batch 80: loss = 0.248867928981781, acc = 0.9140625\n",
      "Batch 81: loss = 0.33568060398101807, acc = 0.8798828125\n",
      "Batch 82: loss = 0.3182833790779114, acc = 0.892578125\n",
      "Batch 83: loss = 0.29256880283355713, acc = 0.9111328125\n",
      "Batch 84: loss = 0.33246320486068726, acc = 0.8896484375\n",
      "Batch 85: loss = 0.3312511742115021, acc = 0.88671875\n",
      "Batch 86: loss = 0.2925170361995697, acc = 0.8935546875\n",
      "Batch 87: loss = 0.3121146857738495, acc = 0.8935546875\n",
      "Batch 88: loss = 0.3813838064670563, acc = 0.865234375\n",
      "Batch 89: loss = 0.3168261647224426, acc = 0.890625\n",
      "Batch 90: loss = 0.32579612731933594, acc = 0.876953125\n",
      "Batch 91: loss = 0.35216253995895386, acc = 0.88671875\n",
      "Batch 92: loss = 0.3343081474304199, acc = 0.8896484375\n",
      "Batch 93: loss = 0.31547749042510986, acc = 0.8984375\n",
      "Batch 94: loss = 0.29320430755615234, acc = 0.896484375\n",
      "Batch 95: loss = 0.29672107100486755, acc = 0.9072265625\n",
      "Batch 96: loss = 0.3507452607154846, acc = 0.8701171875\n",
      "Batch 97: loss = 0.3197444975376129, acc = 0.8994140625\n",
      "Batch 98: loss = 0.324468195438385, acc = 0.8896484375\n",
      "Batch 99: loss = 0.36026763916015625, acc = 0.88671875\n",
      "Batch 100: loss = 0.33588868379592896, acc = 0.8828125\n",
      "Batch 101: loss = 0.3013378083705902, acc = 0.890625\n",
      "Batch 102: loss = 0.3349073529243469, acc = 0.880859375\n",
      "Batch 103: loss = 0.36309412121772766, acc = 0.87109375\n",
      "Batch 104: loss = 0.267022043466568, acc = 0.90625\n",
      "Batch 105: loss = 0.29635918140411377, acc = 0.904296875\n",
      "Batch 106: loss = 0.2974052429199219, acc = 0.904296875\n",
      "Batch 107: loss = 0.31182676553726196, acc = 0.8984375\n",
      "Batch 108: loss = 0.28380969166755676, acc = 0.8974609375\n",
      "Batch 109: loss = 0.2981538772583008, acc = 0.8994140625\n",
      "Batch 110: loss = 0.32372310757637024, acc = 0.9013671875\n",
      "Batch 111: loss = 0.3204219341278076, acc = 0.8974609375\n",
      "Batch 112: loss = 0.2949347198009491, acc = 0.896484375\n",
      "Batch 113: loss = 0.33186835050582886, acc = 0.8876953125\n",
      "Batch 114: loss = 0.3290889859199524, acc = 0.88671875\n",
      "Batch 115: loss = 0.297615647315979, acc = 0.9013671875\n",
      "Batch 116: loss = 0.3116541802883148, acc = 0.904296875\n",
      "Batch 117: loss = 0.32990068197250366, acc = 0.8935546875\n",
      "Batch 118: loss = 0.28177106380462646, acc = 0.9033203125\n",
      "Batch 119: loss = 0.29994866251945496, acc = 0.900390625\n",
      "Batch 120: loss = 0.30755218863487244, acc = 0.892578125\n",
      "Batch 121: loss = 0.2850383222103119, acc = 0.9013671875\n",
      "Batch 122: loss = 0.29329827427864075, acc = 0.904296875\n",
      "Batch 123: loss = 0.29190734028816223, acc = 0.892578125\n",
      "Batch 124: loss = 0.31233730912208557, acc = 0.89453125\n",
      "Batch 125: loss = 0.3382101058959961, acc = 0.8857421875\n",
      "Batch 126: loss = 0.33827275037765503, acc = 0.88671875\n",
      "\n",
      "Epoch 76/100\n",
      "Batch 1: loss = 0.38306859135627747, acc = 0.8701171875\n",
      "Batch 2: loss = 0.3449150323867798, acc = 0.888671875\n",
      "Batch 3: loss = 0.30616673827171326, acc = 0.904296875\n",
      "Batch 4: loss = 0.3198709785938263, acc = 0.876953125\n",
      "Batch 5: loss = 0.2853885889053345, acc = 0.9091796875\n",
      "Batch 6: loss = 0.3444024622440338, acc = 0.8828125\n",
      "Batch 7: loss = 0.2978096008300781, acc = 0.8955078125\n",
      "Batch 8: loss = 0.3066154420375824, acc = 0.9013671875\n",
      "Batch 9: loss = 0.30304545164108276, acc = 0.8984375\n",
      "Batch 10: loss = 0.27869606018066406, acc = 0.9072265625\n",
      "Batch 11: loss = 0.30766865611076355, acc = 0.904296875\n",
      "Batch 12: loss = 0.31263864040374756, acc = 0.89453125\n",
      "Batch 13: loss = 0.305996835231781, acc = 0.888671875\n",
      "Batch 14: loss = 0.2702217400074005, acc = 0.9072265625\n",
      "Batch 15: loss = 0.27132144570350647, acc = 0.9140625\n",
      "Batch 16: loss = 0.2940620183944702, acc = 0.90234375\n",
      "Batch 17: loss = 0.3350059390068054, acc = 0.890625\n",
      "Batch 18: loss = 0.34284016489982605, acc = 0.87890625\n",
      "Batch 19: loss = 0.31029021739959717, acc = 0.88671875\n",
      "Batch 20: loss = 0.3030315041542053, acc = 0.8974609375\n",
      "Batch 21: loss = 0.34996163845062256, acc = 0.8798828125\n",
      "Batch 22: loss = 0.28182458877563477, acc = 0.90234375\n",
      "Batch 23: loss = 0.34268686175346375, acc = 0.8720703125\n",
      "Batch 24: loss = 0.3283099830150604, acc = 0.8828125\n",
      "Batch 25: loss = 0.30325764417648315, acc = 0.88671875\n",
      "Batch 26: loss = 0.31466078758239746, acc = 0.8935546875\n",
      "Batch 27: loss = 0.40587902069091797, acc = 0.86328125\n",
      "Batch 28: loss = 0.33634036779403687, acc = 0.8876953125\n",
      "Batch 29: loss = 0.36189866065979004, acc = 0.87890625\n",
      "Batch 30: loss = 0.3314579725265503, acc = 0.888671875\n",
      "Batch 31: loss = 0.31734779477119446, acc = 0.8896484375\n",
      "Batch 32: loss = 0.33888208866119385, acc = 0.87890625\n",
      "Batch 33: loss = 0.30641305446624756, acc = 0.904296875\n",
      "Batch 34: loss = 0.3567553758621216, acc = 0.87890625\n",
      "Batch 35: loss = 0.30700522661209106, acc = 0.888671875\n",
      "Batch 36: loss = 0.2803025245666504, acc = 0.9130859375\n",
      "Batch 37: loss = 0.25393033027648926, acc = 0.9169921875\n",
      "Batch 38: loss = 0.2983851432800293, acc = 0.900390625\n",
      "Batch 39: loss = 0.2982843518257141, acc = 0.904296875\n",
      "Batch 40: loss = 0.338291198015213, acc = 0.8837890625\n",
      "Batch 41: loss = 0.264339804649353, acc = 0.9072265625\n",
      "Batch 42: loss = 0.3661362826824188, acc = 0.880859375\n",
      "Batch 43: loss = 0.35494372248649597, acc = 0.8740234375\n",
      "Batch 44: loss = 0.2980722486972809, acc = 0.8974609375\n",
      "Batch 45: loss = 0.26278242468833923, acc = 0.90625\n",
      "Batch 46: loss = 0.32145068049430847, acc = 0.8916015625\n",
      "Batch 47: loss = 0.3153012692928314, acc = 0.8994140625\n",
      "Batch 48: loss = 0.2968319058418274, acc = 0.8984375\n",
      "Batch 49: loss = 0.2876242697238922, acc = 0.9091796875\n",
      "Batch 50: loss = 0.26770123839378357, acc = 0.9189453125\n",
      "Batch 51: loss = 0.2815113961696625, acc = 0.9013671875\n",
      "Batch 52: loss = 0.3177666962146759, acc = 0.896484375\n",
      "Batch 53: loss = 0.33192089200019836, acc = 0.8876953125\n",
      "Batch 54: loss = 0.2581483721733093, acc = 0.912109375\n",
      "Batch 55: loss = 0.2761918008327484, acc = 0.9091796875\n",
      "Batch 56: loss = 0.3119722008705139, acc = 0.8935546875\n",
      "Batch 57: loss = 0.3668692708015442, acc = 0.875\n",
      "Batch 58: loss = 0.3319096565246582, acc = 0.8935546875\n",
      "Batch 59: loss = 0.24935734272003174, acc = 0.9169921875\n",
      "Batch 60: loss = 0.3333795666694641, acc = 0.8876953125\n",
      "Batch 61: loss = 0.2647840976715088, acc = 0.908203125\n",
      "Batch 62: loss = 0.3314233124256134, acc = 0.884765625\n",
      "Batch 63: loss = 0.301645427942276, acc = 0.8955078125\n",
      "Batch 64: loss = 0.2708003520965576, acc = 0.908203125\n",
      "Batch 65: loss = 0.3192606568336487, acc = 0.8876953125\n",
      "Batch 66: loss = 0.3008897304534912, acc = 0.90625\n",
      "Batch 67: loss = 0.3021712005138397, acc = 0.890625\n",
      "Batch 68: loss = 0.3251623511314392, acc = 0.89453125\n",
      "Batch 69: loss = 0.2704755663871765, acc = 0.904296875\n",
      "Batch 70: loss = 0.30933913588523865, acc = 0.8935546875\n",
      "Batch 71: loss = 0.32091832160949707, acc = 0.8876953125\n",
      "Batch 72: loss = 0.2844688892364502, acc = 0.9013671875\n",
      "Batch 73: loss = 0.3581109046936035, acc = 0.873046875\n",
      "Batch 74: loss = 0.3518816828727722, acc = 0.8798828125\n",
      "Batch 75: loss = 0.328655868768692, acc = 0.8857421875\n",
      "Batch 76: loss = 0.3314322829246521, acc = 0.8876953125\n",
      "Batch 77: loss = 0.2921115756034851, acc = 0.9033203125\n",
      "Batch 78: loss = 0.3526352643966675, acc = 0.88671875\n",
      "Batch 79: loss = 0.2895626425743103, acc = 0.896484375\n",
      "Batch 80: loss = 0.27323681116104126, acc = 0.9033203125\n",
      "Batch 81: loss = 0.3124164342880249, acc = 0.890625\n",
      "Batch 82: loss = 0.3021554946899414, acc = 0.8974609375\n",
      "Batch 83: loss = 0.2863435745239258, acc = 0.904296875\n",
      "Batch 84: loss = 0.2841072380542755, acc = 0.900390625\n",
      "Batch 85: loss = 0.37206706404685974, acc = 0.8603515625\n",
      "Batch 86: loss = 0.31077730655670166, acc = 0.89453125\n",
      "Batch 87: loss = 0.3188287019729614, acc = 0.888671875\n",
      "Batch 88: loss = 0.3680925965309143, acc = 0.876953125\n",
      "Batch 89: loss = 0.3426347076892853, acc = 0.888671875\n",
      "Batch 90: loss = 0.31001681089401245, acc = 0.8955078125\n",
      "Batch 91: loss = 0.33688798546791077, acc = 0.888671875\n",
      "Batch 92: loss = 0.3232843279838562, acc = 0.8857421875\n",
      "Batch 93: loss = 0.29122692346572876, acc = 0.8955078125\n",
      "Batch 94: loss = 0.28223782777786255, acc = 0.9013671875\n",
      "Batch 95: loss = 0.2967090308666229, acc = 0.90625\n",
      "Batch 96: loss = 0.3349566161632538, acc = 0.888671875\n",
      "Batch 97: loss = 0.31996971368789673, acc = 0.892578125\n",
      "Batch 98: loss = 0.3018014132976532, acc = 0.8974609375\n",
      "Batch 99: loss = 0.3403679132461548, acc = 0.8896484375\n",
      "Batch 100: loss = 0.33608880639076233, acc = 0.884765625\n",
      "Batch 101: loss = 0.29818466305732727, acc = 0.89453125\n",
      "Batch 102: loss = 0.3134470283985138, acc = 0.8818359375\n",
      "Batch 103: loss = 0.3277491331100464, acc = 0.880859375\n",
      "Batch 104: loss = 0.28860682249069214, acc = 0.8984375\n",
      "Batch 105: loss = 0.27872422337532043, acc = 0.90234375\n",
      "Batch 106: loss = 0.2576736509799957, acc = 0.9208984375\n",
      "Batch 107: loss = 0.2774049937725067, acc = 0.90234375\n",
      "Batch 108: loss = 0.2978163957595825, acc = 0.8935546875\n",
      "Batch 109: loss = 0.28983867168426514, acc = 0.8994140625\n",
      "Batch 110: loss = 0.2977312207221985, acc = 0.8955078125\n",
      "Batch 111: loss = 0.32535409927368164, acc = 0.884765625\n",
      "Batch 112: loss = 0.29579371213912964, acc = 0.900390625\n",
      "Batch 113: loss = 0.3220140039920807, acc = 0.88671875\n",
      "Batch 114: loss = 0.31047382950782776, acc = 0.8974609375\n",
      "Batch 115: loss = 0.28885528445243835, acc = 0.9130859375\n",
      "Batch 116: loss = 0.3211519718170166, acc = 0.8896484375\n",
      "Batch 117: loss = 0.2854672372341156, acc = 0.9072265625\n",
      "Batch 118: loss = 0.29093417525291443, acc = 0.8974609375\n",
      "Batch 119: loss = 0.2801631689071655, acc = 0.904296875\n",
      "Batch 120: loss = 0.29558852314949036, acc = 0.896484375\n",
      "Batch 121: loss = 0.2999422252178192, acc = 0.8984375\n",
      "Batch 122: loss = 0.2808724641799927, acc = 0.904296875\n",
      "Batch 123: loss = 0.3141796588897705, acc = 0.8896484375\n",
      "Batch 124: loss = 0.3310457170009613, acc = 0.892578125\n",
      "Batch 125: loss = 0.3330461382865906, acc = 0.8828125\n",
      "Batch 126: loss = 0.32726001739501953, acc = 0.888671875\n",
      "\n",
      "Epoch 77/100\n",
      "Batch 1: loss = 0.38868647813796997, acc = 0.8779296875\n",
      "Batch 2: loss = 0.33547788858413696, acc = 0.8935546875\n",
      "Batch 3: loss = 0.3281664252281189, acc = 0.8974609375\n",
      "Batch 4: loss = 0.33023983240127563, acc = 0.87890625\n",
      "Batch 5: loss = 0.303369402885437, acc = 0.8974609375\n",
      "Batch 6: loss = 0.335506796836853, acc = 0.890625\n",
      "Batch 7: loss = 0.3133097290992737, acc = 0.8955078125\n",
      "Batch 8: loss = 0.3265841603279114, acc = 0.8876953125\n",
      "Batch 9: loss = 0.31296855211257935, acc = 0.890625\n",
      "Batch 10: loss = 0.3065199553966522, acc = 0.90234375\n",
      "Batch 11: loss = 0.29822054505348206, acc = 0.896484375\n",
      "Batch 12: loss = 0.31601107120513916, acc = 0.8935546875\n",
      "Batch 13: loss = 0.3182743489742279, acc = 0.8896484375\n",
      "Batch 14: loss = 0.2966931164264679, acc = 0.8935546875\n",
      "Batch 15: loss = 0.2841939628124237, acc = 0.904296875\n",
      "Batch 16: loss = 0.3265947103500366, acc = 0.8896484375\n",
      "Batch 17: loss = 0.32256776094436646, acc = 0.892578125\n",
      "Batch 18: loss = 0.3522339463233948, acc = 0.884765625\n",
      "Batch 19: loss = 0.28060194849967957, acc = 0.908203125\n",
      "Batch 20: loss = 0.30642613768577576, acc = 0.8935546875\n",
      "Batch 21: loss = 0.3261955976486206, acc = 0.8916015625\n",
      "Batch 22: loss = 0.3287679851055145, acc = 0.8916015625\n",
      "Batch 23: loss = 0.3072487413883209, acc = 0.9033203125\n",
      "Batch 24: loss = 0.3472842574119568, acc = 0.884765625\n",
      "Batch 25: loss = 0.3016301691532135, acc = 0.9013671875\n",
      "Batch 26: loss = 0.3073270916938782, acc = 0.890625\n",
      "Batch 27: loss = 0.35748612880706787, acc = 0.888671875\n",
      "Batch 28: loss = 0.31346017122268677, acc = 0.8935546875\n",
      "Batch 29: loss = 0.3531501889228821, acc = 0.8759765625\n",
      "Batch 30: loss = 0.34086549282073975, acc = 0.8857421875\n",
      "Batch 31: loss = 0.326587051153183, acc = 0.8916015625\n",
      "Batch 32: loss = 0.36126935482025146, acc = 0.8798828125\n",
      "Batch 33: loss = 0.3048597574234009, acc = 0.9052734375\n",
      "Batch 34: loss = 0.3395375907421112, acc = 0.88671875\n",
      "Batch 35: loss = 0.28586041927337646, acc = 0.9169921875\n",
      "Batch 36: loss = 0.2793915867805481, acc = 0.9033203125\n",
      "Batch 37: loss = 0.24192260205745697, acc = 0.923828125\n",
      "Batch 38: loss = 0.2961806654930115, acc = 0.896484375\n",
      "Batch 39: loss = 0.2857316732406616, acc = 0.9111328125\n",
      "Batch 40: loss = 0.31312069296836853, acc = 0.8984375\n",
      "Batch 41: loss = 0.29722777009010315, acc = 0.90625\n",
      "Batch 42: loss = 0.3222508728504181, acc = 0.8828125\n",
      "Batch 43: loss = 0.3219126760959625, acc = 0.884765625\n",
      "Batch 44: loss = 0.2662518620491028, acc = 0.9052734375\n",
      "Batch 45: loss = 0.25544536113739014, acc = 0.90234375\n",
      "Batch 46: loss = 0.2903805077075958, acc = 0.90625\n",
      "Batch 47: loss = 0.30212512612342834, acc = 0.9052734375\n",
      "Batch 48: loss = 0.3013550341129303, acc = 0.9052734375\n",
      "Batch 49: loss = 0.2885867953300476, acc = 0.904296875\n",
      "Batch 50: loss = 0.26941680908203125, acc = 0.919921875\n",
      "Batch 51: loss = 0.2688223719596863, acc = 0.900390625\n",
      "Batch 52: loss = 0.30104154348373413, acc = 0.8876953125\n",
      "Batch 53: loss = 0.31555819511413574, acc = 0.8876953125\n",
      "Batch 54: loss = 0.2807660698890686, acc = 0.90625\n",
      "Batch 55: loss = 0.3167627155780792, acc = 0.8876953125\n",
      "Batch 56: loss = 0.3031782805919647, acc = 0.89453125\n",
      "Batch 57: loss = 0.32501596212387085, acc = 0.8828125\n",
      "Batch 58: loss = 0.3243405818939209, acc = 0.880859375\n",
      "Batch 59: loss = 0.26169633865356445, acc = 0.912109375\n",
      "Batch 60: loss = 0.317470908164978, acc = 0.8955078125\n",
      "Batch 61: loss = 0.25521349906921387, acc = 0.9150390625\n",
      "Batch 62: loss = 0.3564756512641907, acc = 0.8740234375\n",
      "Batch 63: loss = 0.2747190594673157, acc = 0.904296875\n",
      "Batch 64: loss = 0.28751686215400696, acc = 0.89453125\n",
      "Batch 65: loss = 0.2874985337257385, acc = 0.9052734375\n",
      "Batch 66: loss = 0.27513155341148376, acc = 0.904296875\n",
      "Batch 67: loss = 0.3051716983318329, acc = 0.900390625\n",
      "Batch 68: loss = 0.31356343626976013, acc = 0.9013671875\n",
      "Batch 69: loss = 0.2972830832004547, acc = 0.9013671875\n",
      "Batch 70: loss = 0.2960990369319916, acc = 0.8984375\n",
      "Batch 71: loss = 0.3126683235168457, acc = 0.8935546875\n",
      "Batch 72: loss = 0.2918539047241211, acc = 0.9033203125\n",
      "Batch 73: loss = 0.313053697347641, acc = 0.89453125\n",
      "Batch 74: loss = 0.30109745264053345, acc = 0.89453125\n",
      "Batch 75: loss = 0.40576088428497314, acc = 0.86328125\n",
      "Batch 76: loss = 0.33470970392227173, acc = 0.880859375\n",
      "Batch 77: loss = 0.3127632737159729, acc = 0.892578125\n",
      "Batch 78: loss = 0.3187362849712372, acc = 0.8974609375\n",
      "Batch 79: loss = 0.2960069179534912, acc = 0.8984375\n",
      "Batch 80: loss = 0.2924143373966217, acc = 0.8974609375\n",
      "Batch 81: loss = 0.31441962718963623, acc = 0.89453125\n",
      "Batch 82: loss = 0.31887543201446533, acc = 0.8935546875\n",
      "Batch 83: loss = 0.32136520743370056, acc = 0.87890625\n",
      "Batch 84: loss = 0.3251781761646271, acc = 0.8876953125\n",
      "Batch 85: loss = 0.3287321627140045, acc = 0.8896484375\n",
      "Batch 86: loss = 0.2893099784851074, acc = 0.91015625\n",
      "Batch 87: loss = 0.3091092109680176, acc = 0.892578125\n",
      "Batch 88: loss = 0.35814493894577026, acc = 0.869140625\n",
      "Batch 89: loss = 0.26252782344818115, acc = 0.91015625\n",
      "Batch 90: loss = 0.3056205213069916, acc = 0.90234375\n",
      "Batch 91: loss = 0.32085517048835754, acc = 0.8935546875\n",
      "Batch 92: loss = 0.34990593791007996, acc = 0.880859375\n",
      "Batch 93: loss = 0.3131551146507263, acc = 0.900390625\n",
      "Batch 94: loss = 0.2839256823062897, acc = 0.8994140625\n",
      "Batch 95: loss = 0.30367469787597656, acc = 0.8984375\n",
      "Batch 96: loss = 0.33018243312835693, acc = 0.880859375\n",
      "Batch 97: loss = 0.32284629344940186, acc = 0.8935546875\n",
      "Batch 98: loss = 0.28409379720687866, acc = 0.91015625\n",
      "Batch 99: loss = 0.31756433844566345, acc = 0.8896484375\n",
      "Batch 100: loss = 0.323287695646286, acc = 0.8896484375\n",
      "Batch 101: loss = 0.2933504581451416, acc = 0.89453125\n",
      "Batch 102: loss = 0.3216674029827118, acc = 0.8916015625\n",
      "Batch 103: loss = 0.30691027641296387, acc = 0.8974609375\n",
      "Batch 104: loss = 0.2676905393600464, acc = 0.912109375\n",
      "Batch 105: loss = 0.2907732129096985, acc = 0.8916015625\n",
      "Batch 106: loss = 0.30684563517570496, acc = 0.896484375\n",
      "Batch 107: loss = 0.28577396273612976, acc = 0.912109375\n",
      "Batch 108: loss = 0.28779011964797974, acc = 0.900390625\n",
      "Batch 109: loss = 0.3333383798599243, acc = 0.8916015625\n",
      "Batch 110: loss = 0.27918878197669983, acc = 0.8984375\n",
      "Batch 111: loss = 0.3095695376396179, acc = 0.8974609375\n",
      "Batch 112: loss = 0.29159724712371826, acc = 0.9052734375\n",
      "Batch 113: loss = 0.31894832849502563, acc = 0.892578125\n",
      "Batch 114: loss = 0.3302004933357239, acc = 0.8896484375\n",
      "Batch 115: loss = 0.30528202652931213, acc = 0.8974609375\n",
      "Batch 116: loss = 0.3464146852493286, acc = 0.8759765625\n",
      "Batch 117: loss = 0.3127819001674652, acc = 0.8935546875\n",
      "Batch 118: loss = 0.3223680555820465, acc = 0.8935546875\n",
      "Batch 119: loss = 0.29035845398902893, acc = 0.904296875\n",
      "Batch 120: loss = 0.3043563663959503, acc = 0.8876953125\n",
      "Batch 121: loss = 0.3201894760131836, acc = 0.876953125\n",
      "Batch 122: loss = 0.2958486080169678, acc = 0.90625\n",
      "Batch 123: loss = 0.3276861310005188, acc = 0.896484375\n",
      "Batch 124: loss = 0.3449210822582245, acc = 0.8828125\n",
      "Batch 125: loss = 0.2987520694732666, acc = 0.8916015625\n",
      "Batch 126: loss = 0.31194353103637695, acc = 0.890625\n",
      "\n",
      "Epoch 78/100\n",
      "Batch 1: loss = 0.40797340869903564, acc = 0.876953125\n",
      "Batch 2: loss = 0.32032299041748047, acc = 0.9033203125\n",
      "Batch 3: loss = 0.30928096175193787, acc = 0.8974609375\n",
      "Batch 4: loss = 0.3151472210884094, acc = 0.900390625\n",
      "Batch 5: loss = 0.32773011922836304, acc = 0.88671875\n",
      "Batch 6: loss = 0.31871142983436584, acc = 0.888671875\n",
      "Batch 7: loss = 0.29759204387664795, acc = 0.8916015625\n",
      "Batch 8: loss = 0.30391234159469604, acc = 0.9033203125\n",
      "Batch 9: loss = 0.3154551386833191, acc = 0.890625\n",
      "Batch 10: loss = 0.2957215905189514, acc = 0.9013671875\n",
      "Batch 11: loss = 0.3103411793708801, acc = 0.896484375\n",
      "Batch 12: loss = 0.3001681864261627, acc = 0.896484375\n",
      "Batch 13: loss = 0.31074121594429016, acc = 0.8984375\n",
      "Batch 14: loss = 0.31148025393486023, acc = 0.8916015625\n",
      "Batch 15: loss = 0.29128146171569824, acc = 0.8994140625\n",
      "Batch 16: loss = 0.31364870071411133, acc = 0.904296875\n",
      "Batch 17: loss = 0.2986276149749756, acc = 0.8974609375\n",
      "Batch 18: loss = 0.33164793252944946, acc = 0.8876953125\n",
      "Batch 19: loss = 0.29586273431777954, acc = 0.900390625\n",
      "Batch 20: loss = 0.3123035430908203, acc = 0.8916015625\n",
      "Batch 21: loss = 0.3150808811187744, acc = 0.896484375\n",
      "Batch 22: loss = 0.28552982211112976, acc = 0.90625\n",
      "Batch 23: loss = 0.3396269381046295, acc = 0.8935546875\n",
      "Batch 24: loss = 0.29735204577445984, acc = 0.8984375\n",
      "Batch 25: loss = 0.314170241355896, acc = 0.892578125\n",
      "Batch 26: loss = 0.30344581604003906, acc = 0.8974609375\n",
      "Batch 27: loss = 0.36528635025024414, acc = 0.8779296875\n",
      "Batch 28: loss = 0.3214799165725708, acc = 0.8935546875\n",
      "Batch 29: loss = 0.33195120096206665, acc = 0.8896484375\n",
      "Batch 30: loss = 0.30203014612197876, acc = 0.89453125\n",
      "Batch 31: loss = 0.29887890815734863, acc = 0.8916015625\n",
      "Batch 32: loss = 0.30728745460510254, acc = 0.892578125\n",
      "Batch 33: loss = 0.2935379445552826, acc = 0.908203125\n",
      "Batch 34: loss = 0.3628897964954376, acc = 0.88671875\n",
      "Batch 35: loss = 0.31165191531181335, acc = 0.8916015625\n",
      "Batch 36: loss = 0.2899433374404907, acc = 0.8955078125\n",
      "Batch 37: loss = 0.2634102702140808, acc = 0.919921875\n",
      "Batch 38: loss = 0.3070860505104065, acc = 0.89453125\n",
      "Batch 39: loss = 0.28967076539993286, acc = 0.8994140625\n",
      "Batch 40: loss = 0.3359943628311157, acc = 0.8818359375\n",
      "Batch 41: loss = 0.2733563184738159, acc = 0.90625\n",
      "Batch 42: loss = 0.29225873947143555, acc = 0.904296875\n",
      "Batch 43: loss = 0.31362029910087585, acc = 0.89453125\n",
      "Batch 44: loss = 0.25060921907424927, acc = 0.9140625\n",
      "Batch 45: loss = 0.29103344678878784, acc = 0.904296875\n",
      "Batch 46: loss = 0.2749403715133667, acc = 0.904296875\n",
      "Batch 47: loss = 0.2826995253562927, acc = 0.9140625\n",
      "Batch 48: loss = 0.3135935068130493, acc = 0.884765625\n",
      "Batch 49: loss = 0.28269314765930176, acc = 0.896484375\n",
      "Batch 50: loss = 0.2806978225708008, acc = 0.9052734375\n",
      "Batch 51: loss = 0.3107813596725464, acc = 0.88671875\n",
      "Batch 52: loss = 0.3224647641181946, acc = 0.8857421875\n",
      "Batch 53: loss = 0.31282830238342285, acc = 0.8935546875\n",
      "Batch 54: loss = 0.2567177712917328, acc = 0.9111328125\n",
      "Batch 55: loss = 0.2839614152908325, acc = 0.9072265625\n",
      "Batch 56: loss = 0.2787180542945862, acc = 0.900390625\n",
      "Batch 57: loss = 0.3492712378501892, acc = 0.865234375\n",
      "Batch 58: loss = 0.3030903935432434, acc = 0.8994140625\n",
      "Batch 59: loss = 0.2350180596113205, acc = 0.931640625\n",
      "Batch 60: loss = 0.3150002360343933, acc = 0.8974609375\n",
      "Batch 61: loss = 0.26831746101379395, acc = 0.908203125\n",
      "Batch 62: loss = 0.36661532521247864, acc = 0.8662109375\n",
      "Batch 63: loss = 0.2753860056400299, acc = 0.90625\n",
      "Batch 64: loss = 0.26536887884140015, acc = 0.908203125\n",
      "Batch 65: loss = 0.29406028985977173, acc = 0.900390625\n",
      "Batch 66: loss = 0.2955561876296997, acc = 0.8935546875\n",
      "Batch 67: loss = 0.28950440883636475, acc = 0.9033203125\n",
      "Batch 68: loss = 0.30680084228515625, acc = 0.8935546875\n",
      "Batch 69: loss = 0.280762255191803, acc = 0.908203125\n",
      "Batch 70: loss = 0.33638057112693787, acc = 0.880859375\n",
      "Batch 71: loss = 0.3076784908771515, acc = 0.8955078125\n",
      "Batch 72: loss = 0.29486846923828125, acc = 0.8984375\n",
      "Batch 73: loss = 0.3508601188659668, acc = 0.888671875\n",
      "Batch 74: loss = 0.3085705041885376, acc = 0.8876953125\n",
      "Batch 75: loss = 0.3622182607650757, acc = 0.8876953125\n",
      "Batch 76: loss = 0.3490733206272125, acc = 0.8740234375\n",
      "Batch 77: loss = 0.30226749181747437, acc = 0.8994140625\n",
      "Batch 78: loss = 0.33538818359375, acc = 0.8955078125\n",
      "Batch 79: loss = 0.31200507283210754, acc = 0.8935546875\n",
      "Batch 80: loss = 0.2534010112285614, acc = 0.912109375\n",
      "Batch 81: loss = 0.33784207701683044, acc = 0.8818359375\n",
      "Batch 82: loss = 0.30274680256843567, acc = 0.900390625\n",
      "Batch 83: loss = 0.29417529702186584, acc = 0.9033203125\n",
      "Batch 84: loss = 0.31354469060897827, acc = 0.8876953125\n",
      "Batch 85: loss = 0.349243700504303, acc = 0.8876953125\n",
      "Batch 86: loss = 0.3110477030277252, acc = 0.8896484375\n",
      "Batch 87: loss = 0.2786332368850708, acc = 0.9052734375\n",
      "Batch 88: loss = 0.33548298478126526, acc = 0.8740234375\n",
      "Batch 89: loss = 0.31161966919898987, acc = 0.892578125\n",
      "Batch 90: loss = 0.33254489302635193, acc = 0.8955078125\n",
      "Batch 91: loss = 0.3030567169189453, acc = 0.8916015625\n",
      "Batch 92: loss = 0.32439106702804565, acc = 0.8779296875\n",
      "Batch 93: loss = 0.2982794940471649, acc = 0.9091796875\n",
      "Batch 94: loss = 0.2760564982891083, acc = 0.9072265625\n",
      "Batch 95: loss = 0.28920066356658936, acc = 0.904296875\n",
      "Batch 96: loss = 0.31235408782958984, acc = 0.8896484375\n",
      "Batch 97: loss = 0.3059955835342407, acc = 0.900390625\n",
      "Batch 98: loss = 0.2851560711860657, acc = 0.9013671875\n",
      "Batch 99: loss = 0.2936423718929291, acc = 0.9033203125\n",
      "Batch 100: loss = 0.3045240640640259, acc = 0.8955078125\n",
      "Batch 101: loss = 0.3100164830684662, acc = 0.884765625\n",
      "Batch 102: loss = 0.3069115877151489, acc = 0.904296875\n",
      "Batch 103: loss = 0.3349675238132477, acc = 0.88671875\n",
      "Batch 104: loss = 0.27641525864601135, acc = 0.9140625\n",
      "Batch 105: loss = 0.25975698232650757, acc = 0.916015625\n",
      "Batch 106: loss = 0.2676698863506317, acc = 0.9052734375\n",
      "Batch 107: loss = 0.32320713996887207, acc = 0.8857421875\n",
      "Batch 108: loss = 0.2996642589569092, acc = 0.8984375\n",
      "Batch 109: loss = 0.2802715301513672, acc = 0.9052734375\n",
      "Batch 110: loss = 0.26943349838256836, acc = 0.9169921875\n",
      "Batch 111: loss = 0.2748154401779175, acc = 0.912109375\n",
      "Batch 112: loss = 0.2904594838619232, acc = 0.900390625\n",
      "Batch 113: loss = 0.3112640678882599, acc = 0.9013671875\n",
      "Batch 114: loss = 0.2878853976726532, acc = 0.9052734375\n",
      "Batch 115: loss = 0.2829853892326355, acc = 0.904296875\n",
      "Batch 116: loss = 0.321042001247406, acc = 0.8857421875\n",
      "Batch 117: loss = 0.3273029625415802, acc = 0.888671875\n",
      "Batch 118: loss = 0.2919287085533142, acc = 0.8896484375\n",
      "Batch 119: loss = 0.2742499113082886, acc = 0.908203125\n",
      "Batch 120: loss = 0.2824888229370117, acc = 0.8984375\n",
      "Batch 121: loss = 0.28231149911880493, acc = 0.89453125\n",
      "Batch 122: loss = 0.2762012183666229, acc = 0.90625\n",
      "Batch 123: loss = 0.2895483672618866, acc = 0.89453125\n",
      "Batch 124: loss = 0.3224262297153473, acc = 0.89453125\n",
      "Batch 125: loss = 0.31662094593048096, acc = 0.8994140625\n",
      "Batch 126: loss = 0.3171624541282654, acc = 0.8974609375\n",
      "\n",
      "Epoch 79/100\n",
      "Batch 1: loss = 0.3515399992465973, acc = 0.8916015625\n",
      "Batch 2: loss = 0.33643603324890137, acc = 0.880859375\n",
      "Batch 3: loss = 0.30917614698410034, acc = 0.9033203125\n",
      "Batch 4: loss = 0.3299797773361206, acc = 0.8935546875\n",
      "Batch 5: loss = 0.2917434275150299, acc = 0.9033203125\n",
      "Batch 6: loss = 0.334195077419281, acc = 0.8828125\n",
      "Batch 7: loss = 0.2940209209918976, acc = 0.8974609375\n",
      "Batch 8: loss = 0.3015255928039551, acc = 0.892578125\n",
      "Batch 9: loss = 0.2903604209423065, acc = 0.9013671875\n",
      "Batch 10: loss = 0.2816612422466278, acc = 0.9033203125\n",
      "Batch 11: loss = 0.31026315689086914, acc = 0.8955078125\n",
      "Batch 12: loss = 0.31041181087493896, acc = 0.888671875\n",
      "Batch 13: loss = 0.2999986410140991, acc = 0.8984375\n",
      "Batch 14: loss = 0.284288227558136, acc = 0.9033203125\n",
      "Batch 15: loss = 0.27348828315734863, acc = 0.9111328125\n",
      "Batch 16: loss = 0.3312341570854187, acc = 0.8837890625\n",
      "Batch 17: loss = 0.3140832781791687, acc = 0.892578125\n",
      "Batch 18: loss = 0.32490330934524536, acc = 0.8916015625\n",
      "Batch 19: loss = 0.31553107500076294, acc = 0.900390625\n",
      "Batch 20: loss = 0.3251612186431885, acc = 0.884765625\n",
      "Batch 21: loss = 0.3274896740913391, acc = 0.8916015625\n",
      "Batch 22: loss = 0.3066425025463104, acc = 0.8955078125\n",
      "Batch 23: loss = 0.3180922567844391, acc = 0.888671875\n",
      "Batch 24: loss = 0.2943111062049866, acc = 0.8896484375\n",
      "Batch 25: loss = 0.2939572036266327, acc = 0.900390625\n",
      "Batch 26: loss = 0.2883185148239136, acc = 0.9052734375\n",
      "Batch 27: loss = 0.35536468029022217, acc = 0.880859375\n",
      "Batch 28: loss = 0.3395206332206726, acc = 0.876953125\n",
      "Batch 29: loss = 0.3375808000564575, acc = 0.890625\n",
      "Batch 30: loss = 0.31915852427482605, acc = 0.880859375\n",
      "Batch 31: loss = 0.3048642873764038, acc = 0.896484375\n",
      "Batch 32: loss = 0.33893513679504395, acc = 0.8837890625\n",
      "Batch 33: loss = 0.3048653304576874, acc = 0.896484375\n",
      "Batch 34: loss = 0.3346228003501892, acc = 0.8857421875\n",
      "Batch 35: loss = 0.2747708261013031, acc = 0.912109375\n",
      "Batch 36: loss = 0.25531405210494995, acc = 0.9140625\n",
      "Batch 37: loss = 0.2409275323152542, acc = 0.919921875\n",
      "Batch 38: loss = 0.29941874742507935, acc = 0.9013671875\n",
      "Batch 39: loss = 0.279357373714447, acc = 0.90234375\n",
      "Batch 40: loss = 0.31932660937309265, acc = 0.892578125\n",
      "Batch 41: loss = 0.30653855204582214, acc = 0.8935546875\n",
      "Batch 42: loss = 0.31535354256629944, acc = 0.8916015625\n",
      "Batch 43: loss = 0.31146907806396484, acc = 0.8916015625\n",
      "Batch 44: loss = 0.27062422037124634, acc = 0.9130859375\n",
      "Batch 45: loss = 0.2706602215766907, acc = 0.91015625\n",
      "Batch 46: loss = 0.29591208696365356, acc = 0.90234375\n",
      "Batch 47: loss = 0.32775238156318665, acc = 0.8896484375\n",
      "Batch 48: loss = 0.2557738721370697, acc = 0.9111328125\n",
      "Batch 49: loss = 0.2747046947479248, acc = 0.9111328125\n",
      "Batch 50: loss = 0.2797178626060486, acc = 0.9111328125\n",
      "Batch 51: loss = 0.2799258828163147, acc = 0.896484375\n",
      "Batch 52: loss = 0.3107665777206421, acc = 0.90234375\n",
      "Batch 53: loss = 0.3084644079208374, acc = 0.8955078125\n",
      "Batch 54: loss = 0.2581215798854828, acc = 0.8974609375\n",
      "Batch 55: loss = 0.28171658515930176, acc = 0.8984375\n",
      "Batch 56: loss = 0.30679675936698914, acc = 0.892578125\n",
      "Batch 57: loss = 0.34307602047920227, acc = 0.8779296875\n",
      "Batch 58: loss = 0.358917772769928, acc = 0.8720703125\n",
      "Batch 59: loss = 0.2552896738052368, acc = 0.919921875\n",
      "Batch 60: loss = 0.3105921447277069, acc = 0.8955078125\n",
      "Batch 61: loss = 0.2578014135360718, acc = 0.912109375\n",
      "Batch 62: loss = 0.3146616220474243, acc = 0.890625\n",
      "Batch 63: loss = 0.32865411043167114, acc = 0.8935546875\n",
      "Batch 64: loss = 0.28095492720603943, acc = 0.91015625\n",
      "Batch 65: loss = 0.3047739565372467, acc = 0.88671875\n",
      "Batch 66: loss = 0.27918171882629395, acc = 0.908203125\n",
      "Batch 67: loss = 0.2803490459918976, acc = 0.9140625\n",
      "Batch 68: loss = 0.2922470271587372, acc = 0.896484375\n",
      "Batch 69: loss = 0.29028046131134033, acc = 0.9072265625\n",
      "Batch 70: loss = 0.32119256258010864, acc = 0.890625\n",
      "Batch 71: loss = 0.2792399823665619, acc = 0.91796875\n",
      "Batch 72: loss = 0.26780423521995544, acc = 0.921875\n",
      "Batch 73: loss = 0.3046165704727173, acc = 0.904296875\n",
      "Batch 74: loss = 0.31823915243148804, acc = 0.8935546875\n",
      "Batch 75: loss = 0.35114678740501404, acc = 0.8857421875\n",
      "Batch 76: loss = 0.3183879554271698, acc = 0.892578125\n",
      "Batch 77: loss = 0.28880780935287476, acc = 0.896484375\n",
      "Batch 78: loss = 0.2766372859477997, acc = 0.9013671875\n",
      "Batch 79: loss = 0.2807044982910156, acc = 0.90625\n",
      "Batch 80: loss = 0.25791308283805847, acc = 0.91015625\n",
      "Batch 81: loss = 0.3118360936641693, acc = 0.87890625\n",
      "Batch 82: loss = 0.33133620023727417, acc = 0.896484375\n",
      "Batch 83: loss = 0.27923229336738586, acc = 0.908203125\n",
      "Batch 84: loss = 0.30038323998451233, acc = 0.9052734375\n",
      "Batch 85: loss = 0.3111308515071869, acc = 0.8896484375\n",
      "Batch 86: loss = 0.2799268364906311, acc = 0.900390625\n",
      "Batch 87: loss = 0.3049253225326538, acc = 0.8955078125\n",
      "Batch 88: loss = 0.3422715365886688, acc = 0.8857421875\n",
      "Batch 89: loss = 0.29786720871925354, acc = 0.9033203125\n",
      "Batch 90: loss = 0.28699254989624023, acc = 0.90625\n",
      "Batch 91: loss = 0.30722954869270325, acc = 0.89453125\n",
      "Batch 92: loss = 0.27166086435317993, acc = 0.9150390625\n",
      "Batch 93: loss = 0.27504390478134155, acc = 0.91015625\n",
      "Batch 94: loss = 0.2860102951526642, acc = 0.9091796875\n",
      "Batch 95: loss = 0.2543361783027649, acc = 0.908203125\n",
      "Batch 96: loss = 0.31913793087005615, acc = 0.8955078125\n",
      "Batch 97: loss = 0.28535354137420654, acc = 0.908203125\n",
      "Batch 98: loss = 0.2804829776287079, acc = 0.9033203125\n",
      "Batch 99: loss = 0.30608317255973816, acc = 0.9052734375\n",
      "Batch 100: loss = 0.3403521776199341, acc = 0.8720703125\n",
      "Batch 101: loss = 0.3008883595466614, acc = 0.90234375\n",
      "Batch 102: loss = 0.3014306426048279, acc = 0.8974609375\n",
      "Batch 103: loss = 0.3316214680671692, acc = 0.88671875\n",
      "Batch 104: loss = 0.2999230623245239, acc = 0.8994140625\n",
      "Batch 105: loss = 0.23742535710334778, acc = 0.9130859375\n",
      "Batch 106: loss = 0.27950775623321533, acc = 0.900390625\n",
      "Batch 107: loss = 0.28339624404907227, acc = 0.9033203125\n",
      "Batch 108: loss = 0.2860230505466461, acc = 0.8935546875\n",
      "Batch 109: loss = 0.31366193294525146, acc = 0.8876953125\n",
      "Batch 110: loss = 0.26726192235946655, acc = 0.91015625\n",
      "Batch 111: loss = 0.2979447841644287, acc = 0.904296875\n",
      "Batch 112: loss = 0.2961345314979553, acc = 0.8984375\n",
      "Batch 113: loss = 0.2650430202484131, acc = 0.9052734375\n",
      "Batch 114: loss = 0.33968478441238403, acc = 0.8916015625\n",
      "Batch 115: loss = 0.28438833355903625, acc = 0.9091796875\n",
      "Batch 116: loss = 0.3341737985610962, acc = 0.8896484375\n",
      "Batch 117: loss = 0.27242058515548706, acc = 0.912109375\n",
      "Batch 118: loss = 0.2673541307449341, acc = 0.908203125\n",
      "Batch 119: loss = 0.30217617750167847, acc = 0.8984375\n",
      "Batch 120: loss = 0.24571776390075684, acc = 0.916015625\n",
      "Batch 121: loss = 0.28474652767181396, acc = 0.8994140625\n",
      "Batch 122: loss = 0.2819380462169647, acc = 0.9052734375\n",
      "Batch 123: loss = 0.29045045375823975, acc = 0.90234375\n",
      "Batch 124: loss = 0.3072992265224457, acc = 0.9052734375\n",
      "Batch 125: loss = 0.30453726649284363, acc = 0.90234375\n",
      "Batch 126: loss = 0.34579014778137207, acc = 0.8818359375\n",
      "\n",
      "Epoch 80/100\n",
      "Batch 1: loss = 0.3579639494419098, acc = 0.89453125\n",
      "Batch 2: loss = 0.30654993653297424, acc = 0.896484375\n",
      "Batch 3: loss = 0.2878478169441223, acc = 0.90625\n",
      "Batch 4: loss = 0.30038535594940186, acc = 0.90234375\n",
      "Batch 5: loss = 0.30777308344841003, acc = 0.89453125\n",
      "Batch 6: loss = 0.2908513844013214, acc = 0.9130859375\n",
      "Batch 7: loss = 0.2825761139392853, acc = 0.8916015625\n",
      "Batch 8: loss = 0.29704374074935913, acc = 0.9091796875\n",
      "Batch 9: loss = 0.2982446551322937, acc = 0.900390625\n",
      "Batch 10: loss = 0.28654494881629944, acc = 0.9033203125\n",
      "Batch 11: loss = 0.31260916590690613, acc = 0.900390625\n",
      "Batch 12: loss = 0.310808926820755, acc = 0.8974609375\n",
      "Batch 13: loss = 0.3023330867290497, acc = 0.8974609375\n",
      "Batch 14: loss = 0.30439651012420654, acc = 0.9052734375\n",
      "Batch 15: loss = 0.2612684667110443, acc = 0.91015625\n",
      "Batch 16: loss = 0.33429062366485596, acc = 0.8955078125\n",
      "Batch 17: loss = 0.30476102232933044, acc = 0.90234375\n",
      "Batch 18: loss = 0.34373024106025696, acc = 0.8740234375\n",
      "Batch 19: loss = 0.28635749220848083, acc = 0.8955078125\n",
      "Batch 20: loss = 0.283467561006546, acc = 0.900390625\n",
      "Batch 21: loss = 0.34211233258247375, acc = 0.892578125\n",
      "Batch 22: loss = 0.3062537908554077, acc = 0.8876953125\n",
      "Batch 23: loss = 0.30842167139053345, acc = 0.896484375\n",
      "Batch 24: loss = 0.31363970041275024, acc = 0.90234375\n",
      "Batch 25: loss = 0.2747112810611725, acc = 0.8994140625\n",
      "Batch 26: loss = 0.27646875381469727, acc = 0.9130859375\n",
      "Batch 27: loss = 0.3844980001449585, acc = 0.865234375\n",
      "Batch 28: loss = 0.3321520686149597, acc = 0.8916015625\n",
      "Batch 29: loss = 0.3427962362766266, acc = 0.8818359375\n",
      "Batch 30: loss = 0.3160768747329712, acc = 0.8935546875\n",
      "Batch 31: loss = 0.31578874588012695, acc = 0.8818359375\n",
      "Batch 32: loss = 0.3557259738445282, acc = 0.8876953125\n",
      "Batch 33: loss = 0.2808842957019806, acc = 0.912109375\n",
      "Batch 34: loss = 0.32629910111427307, acc = 0.890625\n",
      "Batch 35: loss = 0.3202892243862152, acc = 0.8935546875\n",
      "Batch 36: loss = 0.27143579721450806, acc = 0.904296875\n",
      "Batch 37: loss = 0.2443934828042984, acc = 0.919921875\n",
      "Batch 38: loss = 0.2887606918811798, acc = 0.896484375\n",
      "Batch 39: loss = 0.2750064432621002, acc = 0.9140625\n",
      "Batch 40: loss = 0.32641568779945374, acc = 0.892578125\n",
      "Batch 41: loss = 0.3026006519794464, acc = 0.8896484375\n",
      "Batch 42: loss = 0.3055441379547119, acc = 0.8984375\n",
      "Batch 43: loss = 0.3163934051990509, acc = 0.8828125\n",
      "Batch 44: loss = 0.2844352722167969, acc = 0.9013671875\n",
      "Batch 45: loss = 0.28463366627693176, acc = 0.8974609375\n",
      "Batch 46: loss = 0.25490131974220276, acc = 0.9140625\n",
      "Batch 47: loss = 0.2643487751483917, acc = 0.912109375\n",
      "Batch 48: loss = 0.28651395440101624, acc = 0.90625\n",
      "Batch 49: loss = 0.30133551359176636, acc = 0.9111328125\n",
      "Batch 50: loss = 0.2707032561302185, acc = 0.9140625\n",
      "Batch 51: loss = 0.2755206823348999, acc = 0.9013671875\n",
      "Batch 52: loss = 0.30527377128601074, acc = 0.876953125\n",
      "Batch 53: loss = 0.31326451897621155, acc = 0.89453125\n",
      "Batch 54: loss = 0.22435978055000305, acc = 0.91796875\n",
      "Batch 55: loss = 0.2754342257976532, acc = 0.9052734375\n",
      "Batch 56: loss = 0.3037116825580597, acc = 0.8935546875\n",
      "Batch 57: loss = 0.3261882960796356, acc = 0.8818359375\n",
      "Batch 58: loss = 0.3212016820907593, acc = 0.8876953125\n",
      "Batch 59: loss = 0.23477821052074432, acc = 0.921875\n",
      "Batch 60: loss = 0.30531948804855347, acc = 0.896484375\n",
      "Batch 61: loss = 0.2532716691493988, acc = 0.912109375\n",
      "Batch 62: loss = 0.3467318117618561, acc = 0.873046875\n",
      "Batch 63: loss = 0.2646278142929077, acc = 0.9111328125\n",
      "Batch 64: loss = 0.25212571024894714, acc = 0.9208984375\n",
      "Batch 65: loss = 0.3146541714668274, acc = 0.8935546875\n",
      "Batch 66: loss = 0.3057807683944702, acc = 0.8955078125\n",
      "Batch 67: loss = 0.28277915716171265, acc = 0.904296875\n",
      "Batch 68: loss = 0.299072802066803, acc = 0.9072265625\n",
      "Batch 69: loss = 0.2641971707344055, acc = 0.9150390625\n",
      "Batch 70: loss = 0.3226701021194458, acc = 0.890625\n",
      "Batch 71: loss = 0.3073757588863373, acc = 0.8740234375\n",
      "Batch 72: loss = 0.2826192080974579, acc = 0.9013671875\n",
      "Batch 73: loss = 0.32452332973480225, acc = 0.892578125\n",
      "Batch 74: loss = 0.2965916395187378, acc = 0.9033203125\n",
      "Batch 75: loss = 0.3056164085865021, acc = 0.8935546875\n",
      "Batch 76: loss = 0.3619399666786194, acc = 0.8701171875\n",
      "Batch 77: loss = 0.28780826926231384, acc = 0.90234375\n",
      "Batch 78: loss = 0.3086482882499695, acc = 0.90234375\n",
      "Batch 79: loss = 0.2960680425167084, acc = 0.8896484375\n",
      "Batch 80: loss = 0.26147595047950745, acc = 0.9033203125\n",
      "Batch 81: loss = 0.294082373380661, acc = 0.9052734375\n",
      "Batch 82: loss = 0.29831409454345703, acc = 0.900390625\n",
      "Batch 83: loss = 0.29880836606025696, acc = 0.8974609375\n",
      "Batch 84: loss = 0.3122657537460327, acc = 0.8818359375\n",
      "Batch 85: loss = 0.3134533166885376, acc = 0.8984375\n",
      "Batch 86: loss = 0.2727925777435303, acc = 0.908203125\n",
      "Batch 87: loss = 0.2777564227581024, acc = 0.9091796875\n",
      "Batch 88: loss = 0.3171512484550476, acc = 0.892578125\n",
      "Batch 89: loss = 0.26437804102897644, acc = 0.904296875\n",
      "Batch 90: loss = 0.29478615522384644, acc = 0.8974609375\n",
      "Batch 91: loss = 0.2984941601753235, acc = 0.8955078125\n",
      "Batch 92: loss = 0.2997957170009613, acc = 0.8896484375\n",
      "Batch 93: loss = 0.27258363366127014, acc = 0.9072265625\n",
      "Batch 94: loss = 0.23585984110832214, acc = 0.9150390625\n",
      "Batch 95: loss = 0.2792510986328125, acc = 0.91015625\n",
      "Batch 96: loss = 0.297808974981308, acc = 0.8984375\n",
      "Batch 97: loss = 0.31416916847229004, acc = 0.890625\n",
      "Batch 98: loss = 0.26998353004455566, acc = 0.9111328125\n",
      "Batch 99: loss = 0.31180062890052795, acc = 0.8955078125\n",
      "Batch 100: loss = 0.3300471901893616, acc = 0.87890625\n",
      "Batch 101: loss = 0.2894039452075958, acc = 0.90625\n",
      "Batch 102: loss = 0.2871762216091156, acc = 0.9091796875\n",
      "Batch 103: loss = 0.3053019344806671, acc = 0.896484375\n",
      "Batch 104: loss = 0.24245426058769226, acc = 0.9189453125\n",
      "Batch 105: loss = 0.2975130081176758, acc = 0.9072265625\n",
      "Batch 106: loss = 0.2682619094848633, acc = 0.91015625\n",
      "Batch 107: loss = 0.2869138717651367, acc = 0.8994140625\n",
      "Batch 108: loss = 0.277675986289978, acc = 0.90625\n",
      "Batch 109: loss = 0.3136775493621826, acc = 0.8984375\n",
      "Batch 110: loss = 0.24668322503566742, acc = 0.9189453125\n",
      "Batch 111: loss = 0.30554425716400146, acc = 0.9013671875\n",
      "Batch 112: loss = 0.2867639660835266, acc = 0.904296875\n",
      "Batch 113: loss = 0.29917335510253906, acc = 0.90234375\n",
      "Batch 114: loss = 0.3192375898361206, acc = 0.8994140625\n",
      "Batch 115: loss = 0.30888885259628296, acc = 0.8994140625\n",
      "Batch 116: loss = 0.3082166314125061, acc = 0.8974609375\n",
      "Batch 117: loss = 0.29785555601119995, acc = 0.8984375\n",
      "Batch 118: loss = 0.3123469054698944, acc = 0.8896484375\n",
      "Batch 119: loss = 0.2953132688999176, acc = 0.8994140625\n",
      "Batch 120: loss = 0.2637341022491455, acc = 0.904296875\n",
      "Batch 121: loss = 0.29780805110931396, acc = 0.8994140625\n",
      "Batch 122: loss = 0.258202463388443, acc = 0.916015625\n",
      "Batch 123: loss = 0.28804484009742737, acc = 0.9052734375\n",
      "Batch 124: loss = 0.28541988134384155, acc = 0.9013671875\n",
      "Batch 125: loss = 0.31448566913604736, acc = 0.896484375\n",
      "Batch 126: loss = 0.30276602506637573, acc = 0.8955078125\n",
      "Saved checkpoint to weights.80.h5\n",
      "\n",
      "Epoch 81/100\n",
      "Batch 1: loss = 0.35467326641082764, acc = 0.884765625\n",
      "Batch 2: loss = 0.3092932403087616, acc = 0.8984375\n",
      "Batch 3: loss = 0.3156692087650299, acc = 0.90625\n",
      "Batch 4: loss = 0.2897486388683319, acc = 0.904296875\n",
      "Batch 5: loss = 0.2935236096382141, acc = 0.9052734375\n",
      "Batch 6: loss = 0.31176167726516724, acc = 0.8974609375\n",
      "Batch 7: loss = 0.26155945658683777, acc = 0.90234375\n",
      "Batch 8: loss = 0.3013034462928772, acc = 0.90625\n",
      "Batch 9: loss = 0.2835882306098938, acc = 0.9033203125\n",
      "Batch 10: loss = 0.30365806818008423, acc = 0.900390625\n",
      "Batch 11: loss = 0.28536418080329895, acc = 0.8974609375\n",
      "Batch 12: loss = 0.2915406823158264, acc = 0.90625\n",
      "Batch 13: loss = 0.2817244529724121, acc = 0.9150390625\n",
      "Batch 14: loss = 0.24892179667949677, acc = 0.9140625\n",
      "Batch 15: loss = 0.2613782286643982, acc = 0.916015625\n",
      "Batch 16: loss = 0.2953950762748718, acc = 0.9013671875\n",
      "Batch 17: loss = 0.31405162811279297, acc = 0.8876953125\n",
      "Batch 18: loss = 0.28358855843544006, acc = 0.91015625\n",
      "Batch 19: loss = 0.28328418731689453, acc = 0.900390625\n",
      "Batch 20: loss = 0.31309160590171814, acc = 0.89453125\n",
      "Batch 21: loss = 0.2970738410949707, acc = 0.8984375\n",
      "Batch 22: loss = 0.3294605612754822, acc = 0.892578125\n",
      "Batch 23: loss = 0.3401055335998535, acc = 0.8916015625\n",
      "Batch 24: loss = 0.27488023042678833, acc = 0.91015625\n",
      "Batch 25: loss = 0.29819759726524353, acc = 0.8994140625\n",
      "Batch 26: loss = 0.2867257595062256, acc = 0.9033203125\n",
      "Batch 27: loss = 0.38244718313217163, acc = 0.8662109375\n",
      "Batch 28: loss = 0.3129311203956604, acc = 0.9033203125\n",
      "Batch 29: loss = 0.36584150791168213, acc = 0.875\n",
      "Batch 30: loss = 0.28512436151504517, acc = 0.8974609375\n",
      "Batch 31: loss = 0.26724931597709656, acc = 0.9033203125\n",
      "Batch 32: loss = 0.33702874183654785, acc = 0.8828125\n",
      "Batch 33: loss = 0.29148629307746887, acc = 0.8984375\n",
      "Batch 34: loss = 0.301580011844635, acc = 0.9130859375\n",
      "Batch 35: loss = 0.28894755244255066, acc = 0.8994140625\n",
      "Batch 36: loss = 0.2770182490348816, acc = 0.9052734375\n",
      "Batch 37: loss = 0.2388983964920044, acc = 0.9189453125\n",
      "Batch 38: loss = 0.2640474736690521, acc = 0.9130859375\n",
      "Batch 39: loss = 0.2518887519836426, acc = 0.9248046875\n",
      "Batch 40: loss = 0.30114319920539856, acc = 0.900390625\n",
      "Batch 41: loss = 0.2760724425315857, acc = 0.904296875\n",
      "Batch 42: loss = 0.28442129492759705, acc = 0.90625\n",
      "Batch 43: loss = 0.3003731667995453, acc = 0.8974609375\n",
      "Batch 44: loss = 0.2564399242401123, acc = 0.9169921875\n",
      "Batch 45: loss = 0.24824810028076172, acc = 0.9130859375\n",
      "Batch 46: loss = 0.26275667548179626, acc = 0.91015625\n",
      "Batch 47: loss = 0.2898828983306885, acc = 0.900390625\n",
      "Batch 48: loss = 0.245896577835083, acc = 0.9228515625\n",
      "Batch 49: loss = 0.281515896320343, acc = 0.90234375\n",
      "Batch 50: loss = 0.27541911602020264, acc = 0.9169921875\n",
      "Batch 51: loss = 0.26293426752090454, acc = 0.9091796875\n",
      "Batch 52: loss = 0.297602117061615, acc = 0.904296875\n",
      "Batch 53: loss = 0.286373496055603, acc = 0.908203125\n",
      "Batch 54: loss = 0.2538382112979889, acc = 0.904296875\n",
      "Batch 55: loss = 0.2580399811267853, acc = 0.91796875\n",
      "Batch 56: loss = 0.2958579659461975, acc = 0.8916015625\n",
      "Batch 57: loss = 0.28834423422813416, acc = 0.8984375\n",
      "Batch 58: loss = 0.32430312037467957, acc = 0.8720703125\n",
      "Batch 59: loss = 0.24094359576702118, acc = 0.923828125\n",
      "Batch 60: loss = 0.2958134114742279, acc = 0.89453125\n",
      "Batch 61: loss = 0.2672690153121948, acc = 0.919921875\n",
      "Batch 62: loss = 0.3065471053123474, acc = 0.8896484375\n",
      "Batch 63: loss = 0.289142906665802, acc = 0.8994140625\n",
      "Batch 64: loss = 0.2565077245235443, acc = 0.916015625\n",
      "Batch 65: loss = 0.30648577213287354, acc = 0.8994140625\n",
      "Batch 66: loss = 0.2916177809238434, acc = 0.9091796875\n",
      "Batch 67: loss = 0.3144516944885254, acc = 0.892578125\n",
      "Batch 68: loss = 0.29928553104400635, acc = 0.8935546875\n",
      "Batch 69: loss = 0.27891409397125244, acc = 0.9052734375\n",
      "Batch 70: loss = 0.28199973702430725, acc = 0.9072265625\n",
      "Batch 71: loss = 0.2832486927509308, acc = 0.9052734375\n",
      "Batch 72: loss = 0.2753809690475464, acc = 0.9140625\n",
      "Batch 73: loss = 0.3121882379055023, acc = 0.8984375\n",
      "Batch 74: loss = 0.30972611904144287, acc = 0.8798828125\n",
      "Batch 75: loss = 0.3218069076538086, acc = 0.890625\n",
      "Batch 76: loss = 0.3110958933830261, acc = 0.8916015625\n",
      "Batch 77: loss = 0.2847461998462677, acc = 0.904296875\n",
      "Batch 78: loss = 0.3020641803741455, acc = 0.8955078125\n",
      "Batch 79: loss = 0.27905866503715515, acc = 0.90625\n",
      "Batch 80: loss = 0.2417650818824768, acc = 0.9150390625\n",
      "Batch 81: loss = 0.28579017519950867, acc = 0.90234375\n",
      "Batch 82: loss = 0.2969399094581604, acc = 0.892578125\n",
      "Batch 83: loss = 0.2816565930843353, acc = 0.8916015625\n",
      "Batch 84: loss = 0.2982002794742584, acc = 0.8974609375\n",
      "Batch 85: loss = 0.30247962474823, acc = 0.904296875\n",
      "Batch 86: loss = 0.273587167263031, acc = 0.9091796875\n",
      "Batch 87: loss = 0.29435819387435913, acc = 0.9033203125\n",
      "Batch 88: loss = 0.3398800492286682, acc = 0.8720703125\n",
      "Batch 89: loss = 0.23906055092811584, acc = 0.919921875\n",
      "Batch 90: loss = 0.2863902449607849, acc = 0.900390625\n",
      "Batch 91: loss = 0.30302345752716064, acc = 0.90234375\n",
      "Batch 92: loss = 0.3082412779331207, acc = 0.8935546875\n",
      "Batch 93: loss = 0.27225789427757263, acc = 0.919921875\n",
      "Batch 94: loss = 0.2437199056148529, acc = 0.921875\n",
      "Batch 95: loss = 0.3000277280807495, acc = 0.896484375\n",
      "Batch 96: loss = 0.3363569676876068, acc = 0.8837890625\n",
      "Batch 97: loss = 0.30342021584510803, acc = 0.888671875\n",
      "Batch 98: loss = 0.2981712222099304, acc = 0.8876953125\n",
      "Batch 99: loss = 0.30225932598114014, acc = 0.896484375\n",
      "Batch 100: loss = 0.3428072929382324, acc = 0.8759765625\n",
      "Batch 101: loss = 0.31609389185905457, acc = 0.87890625\n",
      "Batch 102: loss = 0.29984956979751587, acc = 0.892578125\n",
      "Batch 103: loss = 0.2914067506790161, acc = 0.90234375\n",
      "Batch 104: loss = 0.27343815565109253, acc = 0.91015625\n",
      "Batch 105: loss = 0.247146874666214, acc = 0.91015625\n",
      "Batch 106: loss = 0.2583897113800049, acc = 0.9150390625\n",
      "Batch 107: loss = 0.2680153548717499, acc = 0.9130859375\n",
      "Batch 108: loss = 0.276440292596817, acc = 0.90625\n",
      "Batch 109: loss = 0.2910643517971039, acc = 0.904296875\n",
      "Batch 110: loss = 0.267219603061676, acc = 0.91015625\n",
      "Batch 111: loss = 0.2981114089488983, acc = 0.89453125\n",
      "Batch 112: loss = 0.26712387800216675, acc = 0.9091796875\n",
      "Batch 113: loss = 0.3105369806289673, acc = 0.892578125\n",
      "Batch 114: loss = 0.30017906427383423, acc = 0.90234375\n",
      "Batch 115: loss = 0.2789909839630127, acc = 0.8974609375\n",
      "Batch 116: loss = 0.29463422298431396, acc = 0.90234375\n",
      "Batch 117: loss = 0.31932270526885986, acc = 0.8916015625\n",
      "Batch 118: loss = 0.2599758207798004, acc = 0.9130859375\n",
      "Batch 119: loss = 0.2722455859184265, acc = 0.900390625\n",
      "Batch 120: loss = 0.24352599680423737, acc = 0.9150390625\n",
      "Batch 121: loss = 0.29861146211624146, acc = 0.89453125\n",
      "Batch 122: loss = 0.25493720173835754, acc = 0.916015625\n",
      "Batch 123: loss = 0.28480133414268494, acc = 0.9013671875\n",
      "Batch 124: loss = 0.29871392250061035, acc = 0.896484375\n",
      "Batch 125: loss = 0.30469489097595215, acc = 0.900390625\n",
      "Batch 126: loss = 0.3366487920284271, acc = 0.8935546875\n",
      "\n",
      "Epoch 82/100\n",
      "Batch 1: loss = 0.3852236568927765, acc = 0.8828125\n",
      "Batch 2: loss = 0.3224632441997528, acc = 0.89453125\n",
      "Batch 3: loss = 0.31859347224235535, acc = 0.8955078125\n",
      "Batch 4: loss = 0.2975613474845886, acc = 0.9052734375\n",
      "Batch 5: loss = 0.27651551365852356, acc = 0.904296875\n",
      "Batch 6: loss = 0.29183143377304077, acc = 0.89453125\n",
      "Batch 7: loss = 0.2638765573501587, acc = 0.912109375\n",
      "Batch 8: loss = 0.3098406195640564, acc = 0.900390625\n",
      "Batch 9: loss = 0.30056458711624146, acc = 0.896484375\n",
      "Batch 10: loss = 0.28536456823349, acc = 0.91015625\n",
      "Batch 11: loss = 0.2900271415710449, acc = 0.9013671875\n",
      "Batch 12: loss = 0.279413640499115, acc = 0.9033203125\n",
      "Batch 13: loss = 0.28487154841423035, acc = 0.9072265625\n",
      "Batch 14: loss = 0.2646068334579468, acc = 0.904296875\n",
      "Batch 15: loss = 0.26225000619888306, acc = 0.908203125\n",
      "Batch 16: loss = 0.2806566655635834, acc = 0.908203125\n",
      "Batch 17: loss = 0.3234848380088806, acc = 0.892578125\n",
      "Batch 18: loss = 0.32063403725624084, acc = 0.8896484375\n",
      "Batch 19: loss = 0.25840961933135986, acc = 0.9111328125\n",
      "Batch 20: loss = 0.2972123622894287, acc = 0.8876953125\n",
      "Batch 21: loss = 0.2963840961456299, acc = 0.8955078125\n",
      "Batch 22: loss = 0.2926190495491028, acc = 0.9052734375\n",
      "Batch 23: loss = 0.3178423345088959, acc = 0.900390625\n",
      "Batch 24: loss = 0.31185758113861084, acc = 0.8916015625\n",
      "Batch 25: loss = 0.2856082022190094, acc = 0.9091796875\n",
      "Batch 26: loss = 0.27927643060684204, acc = 0.9150390625\n",
      "Batch 27: loss = 0.3439544141292572, acc = 0.880859375\n",
      "Batch 28: loss = 0.3058566153049469, acc = 0.900390625\n",
      "Batch 29: loss = 0.32889053225517273, acc = 0.8876953125\n",
      "Batch 30: loss = 0.2886020541191101, acc = 0.8994140625\n",
      "Batch 31: loss = 0.333597868680954, acc = 0.88671875\n",
      "Batch 32: loss = 0.3569049835205078, acc = 0.8837890625\n",
      "Batch 33: loss = 0.27955859899520874, acc = 0.91015625\n",
      "Batch 34: loss = 0.32353031635284424, acc = 0.8916015625\n",
      "Batch 35: loss = 0.2814210057258606, acc = 0.9033203125\n",
      "Batch 36: loss = 0.25064727663993835, acc = 0.9208984375\n",
      "Batch 37: loss = 0.2420526146888733, acc = 0.9248046875\n",
      "Batch 38: loss = 0.30506789684295654, acc = 0.9013671875\n",
      "Batch 39: loss = 0.28657469153404236, acc = 0.9072265625\n",
      "Batch 40: loss = 0.31913498044013977, acc = 0.888671875\n",
      "Batch 41: loss = 0.2644583582878113, acc = 0.908203125\n",
      "Batch 42: loss = 0.28572922945022583, acc = 0.90234375\n",
      "Batch 43: loss = 0.30268150568008423, acc = 0.8994140625\n",
      "Batch 44: loss = 0.2496642917394638, acc = 0.921875\n",
      "Batch 45: loss = 0.29048821330070496, acc = 0.896484375\n",
      "Batch 46: loss = 0.2689245641231537, acc = 0.904296875\n",
      "Batch 47: loss = 0.28387027978897095, acc = 0.8984375\n",
      "Batch 48: loss = 0.27150893211364746, acc = 0.900390625\n",
      "Batch 49: loss = 0.3018222451210022, acc = 0.904296875\n",
      "Batch 50: loss = 0.29693061113357544, acc = 0.900390625\n",
      "Batch 51: loss = 0.2681027054786682, acc = 0.9072265625\n",
      "Batch 52: loss = 0.31425049901008606, acc = 0.89453125\n",
      "Batch 53: loss = 0.25856539607048035, acc = 0.91796875\n",
      "Batch 54: loss = 0.2460222840309143, acc = 0.9150390625\n",
      "Batch 55: loss = 0.25492680072784424, acc = 0.9111328125\n",
      "Batch 56: loss = 0.3171624541282654, acc = 0.8916015625\n",
      "Batch 57: loss = 0.31109553575515747, acc = 0.8896484375\n",
      "Batch 58: loss = 0.32441580295562744, acc = 0.890625\n",
      "Batch 59: loss = 0.23553824424743652, acc = 0.9208984375\n",
      "Batch 60: loss = 0.29559364914894104, acc = 0.8955078125\n",
      "Batch 61: loss = 0.2656952440738678, acc = 0.919921875\n",
      "Batch 62: loss = 0.3334695100784302, acc = 0.8837890625\n",
      "Batch 63: loss = 0.2702929973602295, acc = 0.9072265625\n",
      "Batch 64: loss = 0.24378255009651184, acc = 0.9208984375\n",
      "Batch 65: loss = 0.281108558177948, acc = 0.90625\n",
      "Batch 66: loss = 0.2897454500198364, acc = 0.8994140625\n",
      "Batch 67: loss = 0.2931075096130371, acc = 0.8916015625\n",
      "Batch 68: loss = 0.322419136762619, acc = 0.8896484375\n",
      "Batch 69: loss = 0.25763949751853943, acc = 0.912109375\n",
      "Batch 70: loss = 0.3264148235321045, acc = 0.8955078125\n",
      "Batch 71: loss = 0.3017643690109253, acc = 0.8857421875\n",
      "Batch 72: loss = 0.25008904933929443, acc = 0.919921875\n",
      "Batch 73: loss = 0.2838820219039917, acc = 0.9150390625\n",
      "Batch 74: loss = 0.28569459915161133, acc = 0.900390625\n",
      "Batch 75: loss = 0.3241640031337738, acc = 0.8896484375\n",
      "Batch 76: loss = 0.3105829060077667, acc = 0.8916015625\n",
      "Batch 77: loss = 0.27713221311569214, acc = 0.9072265625\n",
      "Batch 78: loss = 0.3204334080219269, acc = 0.8896484375\n",
      "Batch 79: loss = 0.27174559235572815, acc = 0.91015625\n",
      "Batch 80: loss = 0.2902887165546417, acc = 0.896484375\n",
      "Batch 81: loss = 0.28187447786331177, acc = 0.9033203125\n",
      "Batch 82: loss = 0.2855755686759949, acc = 0.9052734375\n",
      "Batch 83: loss = 0.2405976951122284, acc = 0.921875\n",
      "Batch 84: loss = 0.26909777522087097, acc = 0.896484375\n",
      "Batch 85: loss = 0.30809852480888367, acc = 0.888671875\n",
      "Batch 86: loss = 0.28226953744888306, acc = 0.9013671875\n",
      "Batch 87: loss = 0.27845680713653564, acc = 0.9111328125\n",
      "Batch 88: loss = 0.32760128378868103, acc = 0.89453125\n",
      "Batch 89: loss = 0.2709484100341797, acc = 0.912109375\n",
      "Batch 90: loss = 0.30839061737060547, acc = 0.88671875\n",
      "Batch 91: loss = 0.3197370767593384, acc = 0.88671875\n",
      "Batch 92: loss = 0.29377326369285583, acc = 0.8984375\n",
      "Batch 93: loss = 0.29219627380371094, acc = 0.8994140625\n",
      "Batch 94: loss = 0.27927353978157043, acc = 0.900390625\n",
      "Batch 95: loss = 0.2629719376564026, acc = 0.912109375\n",
      "Batch 96: loss = 0.31511569023132324, acc = 0.880859375\n",
      "Batch 97: loss = 0.31124526262283325, acc = 0.8935546875\n",
      "Batch 98: loss = 0.3157294690608978, acc = 0.8916015625\n",
      "Batch 99: loss = 0.29578956961631775, acc = 0.8955078125\n",
      "Batch 100: loss = 0.3200289309024811, acc = 0.888671875\n",
      "Batch 101: loss = 0.3065597712993622, acc = 0.8916015625\n",
      "Batch 102: loss = 0.29159921407699585, acc = 0.8974609375\n",
      "Batch 103: loss = 0.29039350152015686, acc = 0.9111328125\n",
      "Batch 104: loss = 0.2838178277015686, acc = 0.9052734375\n",
      "Batch 105: loss = 0.2713569700717926, acc = 0.9091796875\n",
      "Batch 106: loss = 0.27607473731040955, acc = 0.9072265625\n",
      "Batch 107: loss = 0.27197402715682983, acc = 0.9091796875\n",
      "Batch 108: loss = 0.2661576271057129, acc = 0.912109375\n",
      "Batch 109: loss = 0.3247866928577423, acc = 0.884765625\n",
      "Batch 110: loss = 0.26793715357780457, acc = 0.908203125\n",
      "Batch 111: loss = 0.3209697902202606, acc = 0.9013671875\n",
      "Batch 112: loss = 0.26641303300857544, acc = 0.9150390625\n",
      "Batch 113: loss = 0.31297191977500916, acc = 0.8818359375\n",
      "Batch 114: loss = 0.3145543038845062, acc = 0.8974609375\n",
      "Batch 115: loss = 0.3082243800163269, acc = 0.896484375\n",
      "Batch 116: loss = 0.3181195557117462, acc = 0.890625\n",
      "Batch 117: loss = 0.2810881435871124, acc = 0.9150390625\n",
      "Batch 118: loss = 0.2863459885120392, acc = 0.9072265625\n",
      "Batch 119: loss = 0.2923206686973572, acc = 0.8896484375\n",
      "Batch 120: loss = 0.23510311543941498, acc = 0.921875\n",
      "Batch 121: loss = 0.27888211607933044, acc = 0.900390625\n",
      "Batch 122: loss = 0.2550159692764282, acc = 0.90625\n",
      "Batch 123: loss = 0.26359227299690247, acc = 0.9013671875\n",
      "Batch 124: loss = 0.29908427596092224, acc = 0.8955078125\n",
      "Batch 125: loss = 0.29788097739219666, acc = 0.8974609375\n",
      "Batch 126: loss = 0.3069100081920624, acc = 0.9033203125\n",
      "\n",
      "Epoch 83/100\n",
      "Batch 1: loss = 0.3719901442527771, acc = 0.8798828125\n",
      "Batch 2: loss = 0.33690351247787476, acc = 0.880859375\n",
      "Batch 3: loss = 0.3197415769100189, acc = 0.888671875\n",
      "Batch 4: loss = 0.2842581570148468, acc = 0.9072265625\n",
      "Batch 5: loss = 0.28431814908981323, acc = 0.90625\n",
      "Batch 6: loss = 0.27657514810562134, acc = 0.896484375\n",
      "Batch 7: loss = 0.31816500425338745, acc = 0.890625\n",
      "Batch 8: loss = 0.31372880935668945, acc = 0.8955078125\n",
      "Batch 9: loss = 0.2955770492553711, acc = 0.8984375\n",
      "Batch 10: loss = 0.2636096477508545, acc = 0.9013671875\n",
      "Batch 11: loss = 0.2777478098869324, acc = 0.9072265625\n",
      "Batch 12: loss = 0.3253462016582489, acc = 0.8896484375\n",
      "Batch 13: loss = 0.28293293714523315, acc = 0.912109375\n",
      "Batch 14: loss = 0.26407527923583984, acc = 0.912109375\n",
      "Batch 15: loss = 0.28100329637527466, acc = 0.9013671875\n",
      "Batch 16: loss = 0.29195481538772583, acc = 0.8916015625\n",
      "Batch 17: loss = 0.2854824960231781, acc = 0.896484375\n",
      "Batch 18: loss = 0.3298148214817047, acc = 0.8974609375\n",
      "Batch 19: loss = 0.268527090549469, acc = 0.9130859375\n",
      "Batch 20: loss = 0.2995987832546234, acc = 0.896484375\n",
      "Batch 21: loss = 0.3510620892047882, acc = 0.8916015625\n",
      "Batch 22: loss = 0.26435622572898865, acc = 0.916015625\n",
      "Batch 23: loss = 0.30941838026046753, acc = 0.89453125\n",
      "Batch 24: loss = 0.3008101284503937, acc = 0.900390625\n",
      "Batch 25: loss = 0.2719431221485138, acc = 0.90625\n",
      "Batch 26: loss = 0.29989761114120483, acc = 0.892578125\n",
      "Batch 27: loss = 0.3597441017627716, acc = 0.87109375\n",
      "Batch 28: loss = 0.317905068397522, acc = 0.8837890625\n",
      "Batch 29: loss = 0.33923590183258057, acc = 0.8828125\n",
      "Batch 30: loss = 0.32626307010650635, acc = 0.87890625\n",
      "Batch 31: loss = 0.3197709918022156, acc = 0.8896484375\n",
      "Batch 32: loss = 0.3234215974807739, acc = 0.88671875\n",
      "Batch 33: loss = 0.2770981788635254, acc = 0.904296875\n",
      "Batch 34: loss = 0.306771457195282, acc = 0.8984375\n",
      "Batch 35: loss = 0.2992422580718994, acc = 0.908203125\n",
      "Batch 36: loss = 0.25971606373786926, acc = 0.91015625\n",
      "Batch 37: loss = 0.2609604597091675, acc = 0.91015625\n",
      "Batch 38: loss = 0.28402307629585266, acc = 0.904296875\n",
      "Batch 39: loss = 0.2942126393318176, acc = 0.90625\n",
      "Batch 40: loss = 0.28571611642837524, acc = 0.9033203125\n",
      "Batch 41: loss = 0.2738085687160492, acc = 0.9072265625\n",
      "Batch 42: loss = 0.29970642924308777, acc = 0.900390625\n",
      "Batch 43: loss = 0.3060253858566284, acc = 0.89453125\n",
      "Batch 44: loss = 0.26132041215896606, acc = 0.9091796875\n",
      "Batch 45: loss = 0.2575969099998474, acc = 0.9189453125\n",
      "Batch 46: loss = 0.2663117051124573, acc = 0.900390625\n",
      "Batch 47: loss = 0.2964247465133667, acc = 0.9033203125\n",
      "Batch 48: loss = 0.2682341933250427, acc = 0.904296875\n",
      "Batch 49: loss = 0.2817886471748352, acc = 0.90234375\n",
      "Batch 50: loss = 0.2755872309207916, acc = 0.904296875\n",
      "Batch 51: loss = 0.2638736367225647, acc = 0.90234375\n",
      "Batch 52: loss = 0.29827409982681274, acc = 0.9072265625\n",
      "Batch 53: loss = 0.2936154007911682, acc = 0.8994140625\n",
      "Batch 54: loss = 0.2415381669998169, acc = 0.9189453125\n",
      "Batch 55: loss = 0.28891581296920776, acc = 0.900390625\n",
      "Batch 56: loss = 0.2932586669921875, acc = 0.90234375\n",
      "Batch 57: loss = 0.323138564825058, acc = 0.8935546875\n",
      "Batch 58: loss = 0.33895647525787354, acc = 0.8818359375\n",
      "Batch 59: loss = 0.2548756003379822, acc = 0.9150390625\n",
      "Batch 60: loss = 0.2802245020866394, acc = 0.9033203125\n",
      "Batch 61: loss = 0.23089738190174103, acc = 0.927734375\n",
      "Batch 62: loss = 0.306350439786911, acc = 0.8876953125\n",
      "Batch 63: loss = 0.2962592840194702, acc = 0.90234375\n",
      "Batch 64: loss = 0.22811239957809448, acc = 0.9248046875\n",
      "Batch 65: loss = 0.2992849051952362, acc = 0.89453125\n",
      "Batch 66: loss = 0.2635829746723175, acc = 0.9169921875\n",
      "Batch 67: loss = 0.27985242009162903, acc = 0.8955078125\n",
      "Batch 68: loss = 0.25231683254241943, acc = 0.9072265625\n",
      "Batch 69: loss = 0.2635789215564728, acc = 0.9130859375\n",
      "Batch 70: loss = 0.32350170612335205, acc = 0.8857421875\n",
      "Batch 71: loss = 0.28533416986465454, acc = 0.8955078125\n",
      "Batch 72: loss = 0.26098600029945374, acc = 0.912109375\n",
      "Batch 73: loss = 0.29584234952926636, acc = 0.9091796875\n",
      "Batch 74: loss = 0.3057222068309784, acc = 0.888671875\n",
      "Batch 75: loss = 0.30358263850212097, acc = 0.9033203125\n",
      "Batch 76: loss = 0.30164647102355957, acc = 0.8935546875\n",
      "Batch 77: loss = 0.2984961271286011, acc = 0.900390625\n",
      "Batch 78: loss = 0.30557727813720703, acc = 0.900390625\n",
      "Batch 79: loss = 0.3126540184020996, acc = 0.896484375\n",
      "Batch 80: loss = 0.25837305188179016, acc = 0.9130859375\n",
      "Batch 81: loss = 0.32042813301086426, acc = 0.8828125\n",
      "Batch 82: loss = 0.2840971052646637, acc = 0.900390625\n",
      "Batch 83: loss = 0.2764482796192169, acc = 0.9033203125\n",
      "Batch 84: loss = 0.3186892569065094, acc = 0.8916015625\n",
      "Batch 85: loss = 0.3099224865436554, acc = 0.888671875\n",
      "Batch 86: loss = 0.2750866711139679, acc = 0.8984375\n",
      "Batch 87: loss = 0.2909557819366455, acc = 0.9013671875\n",
      "Batch 88: loss = 0.3109945058822632, acc = 0.8896484375\n",
      "Batch 89: loss = 0.24818207323551178, acc = 0.9140625\n",
      "Batch 90: loss = 0.2850622534751892, acc = 0.9052734375\n",
      "Batch 91: loss = 0.26452580094337463, acc = 0.916015625\n",
      "Batch 92: loss = 0.271463543176651, acc = 0.904296875\n",
      "Batch 93: loss = 0.31214389204978943, acc = 0.8916015625\n",
      "Batch 94: loss = 0.2752448618412018, acc = 0.9013671875\n",
      "Batch 95: loss = 0.2852442264556885, acc = 0.9013671875\n",
      "Batch 96: loss = 0.3449801504611969, acc = 0.884765625\n",
      "Batch 97: loss = 0.28932076692581177, acc = 0.9091796875\n",
      "Batch 98: loss = 0.28704267740249634, acc = 0.90625\n",
      "Batch 99: loss = 0.3062272369861603, acc = 0.8916015625\n",
      "Batch 100: loss = 0.3001783490180969, acc = 0.888671875\n",
      "Batch 101: loss = 0.2819479703903198, acc = 0.8955078125\n",
      "Batch 102: loss = 0.3065411448478699, acc = 0.8974609375\n",
      "Batch 103: loss = 0.29721584916114807, acc = 0.9033203125\n",
      "Batch 104: loss = 0.25052231550216675, acc = 0.916015625\n",
      "Batch 105: loss = 0.25889843702316284, acc = 0.91015625\n",
      "Batch 106: loss = 0.25772520899772644, acc = 0.9111328125\n",
      "Batch 107: loss = 0.2743484079837799, acc = 0.908203125\n",
      "Batch 108: loss = 0.2793543338775635, acc = 0.904296875\n",
      "Batch 109: loss = 0.3004273772239685, acc = 0.8955078125\n",
      "Batch 110: loss = 0.2408221811056137, acc = 0.908203125\n",
      "Batch 111: loss = 0.2629658281803131, acc = 0.90625\n",
      "Batch 112: loss = 0.31397342681884766, acc = 0.8935546875\n",
      "Batch 113: loss = 0.28587254881858826, acc = 0.8984375\n",
      "Batch 114: loss = 0.32326191663742065, acc = 0.896484375\n",
      "Batch 115: loss = 0.2746124267578125, acc = 0.9169921875\n",
      "Batch 116: loss = 0.3239210844039917, acc = 0.89453125\n",
      "Batch 117: loss = 0.2657006084918976, acc = 0.9072265625\n",
      "Batch 118: loss = 0.2810411751270294, acc = 0.9013671875\n",
      "Batch 119: loss = 0.26389408111572266, acc = 0.9111328125\n",
      "Batch 120: loss = 0.2646397352218628, acc = 0.904296875\n",
      "Batch 121: loss = 0.2578464150428772, acc = 0.8994140625\n",
      "Batch 122: loss = 0.2564980685710907, acc = 0.919921875\n",
      "Batch 123: loss = 0.27103206515312195, acc = 0.9072265625\n",
      "Batch 124: loss = 0.2772170901298523, acc = 0.904296875\n",
      "Batch 125: loss = 0.2963063418865204, acc = 0.90234375\n",
      "Batch 126: loss = 0.3012126088142395, acc = 0.9091796875\n",
      "\n",
      "Epoch 84/100\n",
      "Batch 1: loss = 0.3320033550262451, acc = 0.8935546875\n",
      "Batch 2: loss = 0.3028895854949951, acc = 0.892578125\n",
      "Batch 3: loss = 0.2711343765258789, acc = 0.9111328125\n",
      "Batch 4: loss = 0.28538158535957336, acc = 0.90234375\n",
      "Batch 5: loss = 0.2997429072856903, acc = 0.904296875\n",
      "Batch 6: loss = 0.28029072284698486, acc = 0.919921875\n",
      "Batch 7: loss = 0.2639137804508209, acc = 0.90625\n",
      "Batch 8: loss = 0.29688942432403564, acc = 0.896484375\n",
      "Batch 9: loss = 0.2847501039505005, acc = 0.90625\n",
      "Batch 10: loss = 0.26282796263694763, acc = 0.912109375\n",
      "Batch 11: loss = 0.303044855594635, acc = 0.9091796875\n",
      "Batch 12: loss = 0.2567310333251953, acc = 0.919921875\n",
      "Batch 13: loss = 0.2807932496070862, acc = 0.90625\n",
      "Batch 14: loss = 0.26984190940856934, acc = 0.90625\n",
      "Batch 15: loss = 0.278070867061615, acc = 0.904296875\n",
      "Batch 16: loss = 0.2833184003829956, acc = 0.9033203125\n",
      "Batch 17: loss = 0.2687872052192688, acc = 0.9130859375\n",
      "Batch 18: loss = 0.34253156185150146, acc = 0.8818359375\n",
      "Batch 19: loss = 0.27996698021888733, acc = 0.91015625\n",
      "Batch 20: loss = 0.27225780487060547, acc = 0.9150390625\n",
      "Batch 21: loss = 0.3437669277191162, acc = 0.884765625\n",
      "Batch 22: loss = 0.2960011661052704, acc = 0.8974609375\n",
      "Batch 23: loss = 0.28202688694000244, acc = 0.90625\n",
      "Batch 24: loss = 0.3088948130607605, acc = 0.896484375\n",
      "Batch 25: loss = 0.27692732214927673, acc = 0.912109375\n",
      "Batch 26: loss = 0.293093740940094, acc = 0.904296875\n",
      "Batch 27: loss = 0.3282122015953064, acc = 0.8828125\n",
      "Batch 28: loss = 0.3195247948169708, acc = 0.884765625\n",
      "Batch 29: loss = 0.30750781297683716, acc = 0.8916015625\n",
      "Batch 30: loss = 0.31108060479164124, acc = 0.88671875\n",
      "Batch 31: loss = 0.3018381893634796, acc = 0.892578125\n",
      "Batch 32: loss = 0.3152337670326233, acc = 0.8876953125\n",
      "Batch 33: loss = 0.2894633114337921, acc = 0.9033203125\n",
      "Batch 34: loss = 0.2983808219432831, acc = 0.900390625\n",
      "Batch 35: loss = 0.29580599069595337, acc = 0.9013671875\n",
      "Batch 36: loss = 0.26342883706092834, acc = 0.9130859375\n",
      "Batch 37: loss = 0.24273724853992462, acc = 0.9208984375\n",
      "Batch 38: loss = 0.27221399545669556, acc = 0.9091796875\n",
      "Batch 39: loss = 0.2530345618724823, acc = 0.9189453125\n",
      "Batch 40: loss = 0.30928489565849304, acc = 0.89453125\n",
      "Batch 41: loss = 0.2713007926940918, acc = 0.8974609375\n",
      "Batch 42: loss = 0.2558435797691345, acc = 0.916015625\n",
      "Batch 43: loss = 0.3365088701248169, acc = 0.890625\n",
      "Batch 44: loss = 0.25130537152290344, acc = 0.9169921875\n",
      "Batch 45: loss = 0.25447049736976624, acc = 0.916015625\n",
      "Batch 46: loss = 0.24965618550777435, acc = 0.91015625\n",
      "Batch 47: loss = 0.27828001976013184, acc = 0.9033203125\n",
      "Batch 48: loss = 0.2706298232078552, acc = 0.908203125\n",
      "Batch 49: loss = 0.24780111014842987, acc = 0.916015625\n",
      "Batch 50: loss = 0.2483738362789154, acc = 0.9111328125\n",
      "Batch 51: loss = 0.2719711661338806, acc = 0.9111328125\n",
      "Batch 52: loss = 0.2980530560016632, acc = 0.8994140625\n",
      "Batch 53: loss = 0.28015580773353577, acc = 0.9130859375\n",
      "Batch 54: loss = 0.24800574779510498, acc = 0.91015625\n",
      "Batch 55: loss = 0.3033502399921417, acc = 0.890625\n",
      "Batch 56: loss = 0.28940314054489136, acc = 0.8974609375\n",
      "Batch 57: loss = 0.3172049820423126, acc = 0.89453125\n",
      "Batch 58: loss = 0.34777939319610596, acc = 0.89453125\n",
      "Batch 59: loss = 0.2125907838344574, acc = 0.9345703125\n",
      "Batch 60: loss = 0.2916153073310852, acc = 0.9033203125\n",
      "Batch 61: loss = 0.2580602765083313, acc = 0.904296875\n",
      "Batch 62: loss = 0.33871060609817505, acc = 0.8857421875\n",
      "Batch 63: loss = 0.27939876914024353, acc = 0.9013671875\n",
      "Batch 64: loss = 0.2445785254240036, acc = 0.919921875\n",
      "Batch 65: loss = 0.27665653824806213, acc = 0.9072265625\n",
      "Batch 66: loss = 0.2675650417804718, acc = 0.908203125\n",
      "Batch 67: loss = 0.283443421125412, acc = 0.89453125\n",
      "Batch 68: loss = 0.293762743473053, acc = 0.908203125\n",
      "Batch 69: loss = 0.24703359603881836, acc = 0.908203125\n",
      "Batch 70: loss = 0.3155117928981781, acc = 0.89453125\n",
      "Batch 71: loss = 0.28688257932662964, acc = 0.8994140625\n",
      "Batch 72: loss = 0.2886601984500885, acc = 0.9013671875\n",
      "Batch 73: loss = 0.3171514570713043, acc = 0.892578125\n",
      "Batch 74: loss = 0.313510537147522, acc = 0.8974609375\n",
      "Batch 75: loss = 0.30959704518318176, acc = 0.8935546875\n",
      "Batch 76: loss = 0.3048206865787506, acc = 0.884765625\n",
      "Batch 77: loss = 0.2781462073326111, acc = 0.9091796875\n",
      "Batch 78: loss = 0.29398390650749207, acc = 0.896484375\n",
      "Batch 79: loss = 0.25936105847358704, acc = 0.9150390625\n",
      "Batch 80: loss = 0.26216140389442444, acc = 0.9208984375\n",
      "Batch 81: loss = 0.29307717084884644, acc = 0.8896484375\n",
      "Batch 82: loss = 0.2974150478839874, acc = 0.9052734375\n",
      "Batch 83: loss = 0.29743891954421997, acc = 0.8994140625\n",
      "Batch 84: loss = 0.31698647141456604, acc = 0.8916015625\n",
      "Batch 85: loss = 0.2840759754180908, acc = 0.8994140625\n",
      "Batch 86: loss = 0.26133865118026733, acc = 0.90234375\n",
      "Batch 87: loss = 0.2912469804286957, acc = 0.900390625\n",
      "Batch 88: loss = 0.3339998126029968, acc = 0.875\n",
      "Batch 89: loss = 0.2646940350532532, acc = 0.9130859375\n",
      "Batch 90: loss = 0.25291886925697327, acc = 0.9111328125\n",
      "Batch 91: loss = 0.2812981903553009, acc = 0.90625\n",
      "Batch 92: loss = 0.3134743571281433, acc = 0.8935546875\n",
      "Batch 93: loss = 0.29437965154647827, acc = 0.900390625\n",
      "Batch 94: loss = 0.25657641887664795, acc = 0.912109375\n",
      "Batch 95: loss = 0.2776031494140625, acc = 0.9111328125\n",
      "Batch 96: loss = 0.28397613763809204, acc = 0.904296875\n",
      "Batch 97: loss = 0.28933846950531006, acc = 0.91015625\n",
      "Batch 98: loss = 0.2653880715370178, acc = 0.912109375\n",
      "Batch 99: loss = 0.3270017206668854, acc = 0.890625\n",
      "Batch 100: loss = 0.288910448551178, acc = 0.9013671875\n",
      "Batch 101: loss = 0.29135406017303467, acc = 0.8974609375\n",
      "Batch 102: loss = 0.30255845189094543, acc = 0.8916015625\n",
      "Batch 103: loss = 0.2924734652042389, acc = 0.9072265625\n",
      "Batch 104: loss = 0.2601969838142395, acc = 0.9033203125\n",
      "Batch 105: loss = 0.2714608311653137, acc = 0.90625\n",
      "Batch 106: loss = 0.26733455061912537, acc = 0.8984375\n",
      "Batch 107: loss = 0.25701841711997986, acc = 0.91796875\n",
      "Batch 108: loss = 0.289915531873703, acc = 0.90625\n",
      "Batch 109: loss = 0.27680784463882446, acc = 0.90234375\n",
      "Batch 110: loss = 0.28494712710380554, acc = 0.9052734375\n",
      "Batch 111: loss = 0.27615630626678467, acc = 0.9072265625\n",
      "Batch 112: loss = 0.27459606528282166, acc = 0.9052734375\n",
      "Batch 113: loss = 0.27790650725364685, acc = 0.90625\n",
      "Batch 114: loss = 0.31570959091186523, acc = 0.8994140625\n",
      "Batch 115: loss = 0.3185240626335144, acc = 0.884765625\n",
      "Batch 116: loss = 0.3211447298526764, acc = 0.89453125\n",
      "Batch 117: loss = 0.2848869562149048, acc = 0.9072265625\n",
      "Batch 118: loss = 0.27219724655151367, acc = 0.9013671875\n",
      "Batch 119: loss = 0.265062153339386, acc = 0.91796875\n",
      "Batch 120: loss = 0.26536160707473755, acc = 0.9033203125\n",
      "Batch 121: loss = 0.2973046898841858, acc = 0.8955078125\n",
      "Batch 122: loss = 0.25166207551956177, acc = 0.912109375\n",
      "Batch 123: loss = 0.26911723613739014, acc = 0.8994140625\n",
      "Batch 124: loss = 0.30666476488113403, acc = 0.896484375\n",
      "Batch 125: loss = 0.2813788652420044, acc = 0.9091796875\n",
      "Batch 126: loss = 0.29702329635620117, acc = 0.8984375\n",
      "\n",
      "Epoch 85/100\n",
      "Batch 1: loss = 0.3645557761192322, acc = 0.8876953125\n",
      "Batch 2: loss = 0.29784274101257324, acc = 0.8955078125\n",
      "Batch 3: loss = 0.28531578183174133, acc = 0.9111328125\n",
      "Batch 4: loss = 0.27602630853652954, acc = 0.9130859375\n",
      "Batch 5: loss = 0.26320451498031616, acc = 0.9111328125\n",
      "Batch 6: loss = 0.263401597738266, acc = 0.9091796875\n",
      "Batch 7: loss = 0.25852006673812866, acc = 0.916015625\n",
      "Batch 8: loss = 0.2979722023010254, acc = 0.8994140625\n",
      "Batch 9: loss = 0.29024311900138855, acc = 0.90625\n",
      "Batch 10: loss = 0.27398213744163513, acc = 0.908203125\n",
      "Batch 11: loss = 0.28426414728164673, acc = 0.8916015625\n",
      "Batch 12: loss = 0.2633350193500519, acc = 0.91015625\n",
      "Batch 13: loss = 0.2898027002811432, acc = 0.8974609375\n",
      "Batch 14: loss = 0.28355953097343445, acc = 0.8984375\n",
      "Batch 15: loss = 0.2565656006336212, acc = 0.908203125\n",
      "Batch 16: loss = 0.2810794711112976, acc = 0.8955078125\n",
      "Batch 17: loss = 0.27674004435539246, acc = 0.9111328125\n",
      "Batch 18: loss = 0.30923759937286377, acc = 0.88671875\n",
      "Batch 19: loss = 0.29044559597969055, acc = 0.8984375\n",
      "Batch 20: loss = 0.28304794430732727, acc = 0.9033203125\n",
      "Batch 21: loss = 0.2918599247932434, acc = 0.9072265625\n",
      "Batch 22: loss = 0.3031848967075348, acc = 0.8916015625\n",
      "Batch 23: loss = 0.30588871240615845, acc = 0.8974609375\n",
      "Batch 24: loss = 0.3043230175971985, acc = 0.896484375\n",
      "Batch 25: loss = 0.26187825202941895, acc = 0.912109375\n",
      "Batch 26: loss = 0.29750218987464905, acc = 0.90234375\n",
      "Batch 27: loss = 0.3203706443309784, acc = 0.9072265625\n",
      "Batch 28: loss = 0.3152378499507904, acc = 0.89453125\n",
      "Batch 29: loss = 0.3326939046382904, acc = 0.890625\n",
      "Batch 30: loss = 0.27041101455688477, acc = 0.904296875\n",
      "Batch 31: loss = 0.262105792760849, acc = 0.9072265625\n",
      "Batch 32: loss = 0.3209131062030792, acc = 0.8916015625\n",
      "Batch 33: loss = 0.29827234148979187, acc = 0.8994140625\n",
      "Batch 34: loss = 0.3098001778125763, acc = 0.89453125\n",
      "Batch 35: loss = 0.29689493775367737, acc = 0.8837890625\n",
      "Batch 36: loss = 0.24185281991958618, acc = 0.919921875\n",
      "Batch 37: loss = 0.22958917915821075, acc = 0.927734375\n",
      "Batch 38: loss = 0.296256422996521, acc = 0.896484375\n",
      "Batch 39: loss = 0.24173739552497864, acc = 0.916015625\n",
      "Batch 40: loss = 0.29399871826171875, acc = 0.892578125\n",
      "Batch 41: loss = 0.25877609848976135, acc = 0.91015625\n",
      "Batch 42: loss = 0.28017914295196533, acc = 0.9052734375\n",
      "Batch 43: loss = 0.26810160279273987, acc = 0.916015625\n",
      "Batch 44: loss = 0.26185065507888794, acc = 0.9111328125\n",
      "Batch 45: loss = 0.2906951606273651, acc = 0.9072265625\n",
      "Batch 46: loss = 0.27211862802505493, acc = 0.9013671875\n",
      "Batch 47: loss = 0.27881842851638794, acc = 0.90625\n",
      "Batch 48: loss = 0.2577369511127472, acc = 0.9052734375\n",
      "Batch 49: loss = 0.28976401686668396, acc = 0.9052734375\n",
      "Batch 50: loss = 0.2848770320415497, acc = 0.9130859375\n",
      "Batch 51: loss = 0.23421338200569153, acc = 0.921875\n",
      "Batch 52: loss = 0.2839357554912567, acc = 0.90625\n",
      "Batch 53: loss = 0.28565704822540283, acc = 0.904296875\n",
      "Batch 54: loss = 0.22916588187217712, acc = 0.931640625\n",
      "Batch 55: loss = 0.2969706654548645, acc = 0.8984375\n",
      "Batch 56: loss = 0.2969236671924591, acc = 0.9052734375\n",
      "Batch 57: loss = 0.2885207235813141, acc = 0.896484375\n",
      "Batch 58: loss = 0.2948093116283417, acc = 0.8984375\n",
      "Batch 59: loss = 0.2369237244129181, acc = 0.9150390625\n",
      "Batch 60: loss = 0.33442842960357666, acc = 0.880859375\n",
      "Batch 61: loss = 0.2449333369731903, acc = 0.9248046875\n",
      "Batch 62: loss = 0.3192096948623657, acc = 0.8955078125\n",
      "Batch 63: loss = 0.2527190148830414, acc = 0.9140625\n",
      "Batch 64: loss = 0.24596500396728516, acc = 0.91015625\n",
      "Batch 65: loss = 0.2602204382419586, acc = 0.9072265625\n",
      "Batch 66: loss = 0.28007930517196655, acc = 0.9052734375\n",
      "Batch 67: loss = 0.26296621561050415, acc = 0.9140625\n",
      "Batch 68: loss = 0.2559974789619446, acc = 0.9208984375\n",
      "Batch 69: loss = 0.24346664547920227, acc = 0.9150390625\n",
      "Batch 70: loss = 0.30792146921157837, acc = 0.8955078125\n",
      "Batch 71: loss = 0.27784019708633423, acc = 0.912109375\n",
      "Batch 72: loss = 0.2572852373123169, acc = 0.9130859375\n",
      "Batch 73: loss = 0.2948974668979645, acc = 0.8876953125\n",
      "Batch 74: loss = 0.2869744598865509, acc = 0.8974609375\n",
      "Batch 75: loss = 0.2870453894138336, acc = 0.9052734375\n",
      "Batch 76: loss = 0.27640995383262634, acc = 0.908203125\n",
      "Batch 77: loss = 0.2501797080039978, acc = 0.90625\n",
      "Batch 78: loss = 0.286161333322525, acc = 0.90625\n",
      "Batch 79: loss = 0.27197957038879395, acc = 0.90625\n",
      "Batch 80: loss = 0.24607963860034943, acc = 0.9130859375\n",
      "Batch 81: loss = 0.26315760612487793, acc = 0.91015625\n",
      "Batch 82: loss = 0.27009156346321106, acc = 0.904296875\n",
      "Batch 83: loss = 0.2702513039112091, acc = 0.9140625\n",
      "Batch 84: loss = 0.2708260416984558, acc = 0.9091796875\n",
      "Batch 85: loss = 0.29317787289619446, acc = 0.8974609375\n",
      "Batch 86: loss = 0.29363059997558594, acc = 0.8955078125\n",
      "Batch 87: loss = 0.29205673933029175, acc = 0.9013671875\n",
      "Batch 88: loss = 0.32855647802352905, acc = 0.892578125\n",
      "Batch 89: loss = 0.23495037853717804, acc = 0.921875\n",
      "Batch 90: loss = 0.27637141942977905, acc = 0.8994140625\n",
      "Batch 91: loss = 0.26602932810783386, acc = 0.8994140625\n",
      "Batch 92: loss = 0.31289559602737427, acc = 0.9033203125\n",
      "Batch 93: loss = 0.258428692817688, acc = 0.9091796875\n",
      "Batch 94: loss = 0.22951990365982056, acc = 0.91796875\n",
      "Batch 95: loss = 0.24741005897521973, acc = 0.9208984375\n",
      "Batch 96: loss = 0.33978310227394104, acc = 0.87890625\n",
      "Batch 97: loss = 0.25788217782974243, acc = 0.916015625\n",
      "Batch 98: loss = 0.2604788541793823, acc = 0.9248046875\n",
      "Batch 99: loss = 0.3122868835926056, acc = 0.89453125\n",
      "Batch 100: loss = 0.2824190855026245, acc = 0.908203125\n",
      "Batch 101: loss = 0.29334622621536255, acc = 0.8916015625\n",
      "Batch 102: loss = 0.3130013346672058, acc = 0.8984375\n",
      "Batch 103: loss = 0.302141010761261, acc = 0.8994140625\n",
      "Batch 104: loss = 0.2602051794528961, acc = 0.9189453125\n",
      "Batch 105: loss = 0.2198040783405304, acc = 0.9228515625\n",
      "Batch 106: loss = 0.26276272535324097, acc = 0.9111328125\n",
      "Batch 107: loss = 0.2527441382408142, acc = 0.919921875\n",
      "Batch 108: loss = 0.2910826802253723, acc = 0.89453125\n",
      "Batch 109: loss = 0.2629600763320923, acc = 0.9033203125\n",
      "Batch 110: loss = 0.27067315578460693, acc = 0.9189453125\n",
      "Batch 111: loss = 0.2775595486164093, acc = 0.9140625\n",
      "Batch 112: loss = 0.2830730974674225, acc = 0.908203125\n",
      "Batch 113: loss = 0.2790907621383667, acc = 0.90625\n",
      "Batch 114: loss = 0.2674109935760498, acc = 0.9130859375\n",
      "Batch 115: loss = 0.2849264144897461, acc = 0.8994140625\n",
      "Batch 116: loss = 0.2976003587245941, acc = 0.9013671875\n",
      "Batch 117: loss = 0.28774333000183105, acc = 0.89453125\n",
      "Batch 118: loss = 0.2517978549003601, acc = 0.8994140625\n",
      "Batch 119: loss = 0.2368786484003067, acc = 0.916015625\n",
      "Batch 120: loss = 0.2753288149833679, acc = 0.90234375\n",
      "Batch 121: loss = 0.24794785678386688, acc = 0.91796875\n",
      "Batch 122: loss = 0.24607928097248077, acc = 0.9140625\n",
      "Batch 123: loss = 0.2828347682952881, acc = 0.904296875\n",
      "Batch 124: loss = 0.2857641279697418, acc = 0.9111328125\n",
      "Batch 125: loss = 0.2719665467739105, acc = 0.912109375\n",
      "Batch 126: loss = 0.2836553156375885, acc = 0.904296875\n",
      "\n",
      "Epoch 86/100\n",
      "Batch 1: loss = 0.3292124271392822, acc = 0.90625\n",
      "Batch 2: loss = 0.25715821981430054, acc = 0.9033203125\n",
      "Batch 3: loss = 0.2706657648086548, acc = 0.9150390625\n",
      "Batch 4: loss = 0.2753658890724182, acc = 0.916015625\n",
      "Batch 5: loss = 0.26417800784111023, acc = 0.9169921875\n",
      "Batch 6: loss = 0.2854419946670532, acc = 0.900390625\n",
      "Batch 7: loss = 0.27495986223220825, acc = 0.904296875\n",
      "Batch 8: loss = 0.28072407841682434, acc = 0.916015625\n",
      "Batch 9: loss = 0.2675713896751404, acc = 0.9130859375\n",
      "Batch 10: loss = 0.2514588236808777, acc = 0.9072265625\n",
      "Batch 11: loss = 0.25727277994155884, acc = 0.923828125\n",
      "Batch 12: loss = 0.2946999967098236, acc = 0.912109375\n",
      "Batch 13: loss = 0.2561124563217163, acc = 0.9130859375\n",
      "Batch 14: loss = 0.23906844854354858, acc = 0.9111328125\n",
      "Batch 15: loss = 0.22394230961799622, acc = 0.9208984375\n",
      "Batch 16: loss = 0.27610597014427185, acc = 0.9033203125\n",
      "Batch 17: loss = 0.2878330647945404, acc = 0.904296875\n",
      "Batch 18: loss = 0.29593798518180847, acc = 0.9013671875\n",
      "Batch 19: loss = 0.2713523805141449, acc = 0.9013671875\n",
      "Batch 20: loss = 0.28597569465637207, acc = 0.892578125\n",
      "Batch 21: loss = 0.2870495021343231, acc = 0.900390625\n",
      "Batch 22: loss = 0.24845314025878906, acc = 0.91796875\n",
      "Batch 23: loss = 0.2871820032596588, acc = 0.9013671875\n",
      "Batch 24: loss = 0.3153246343135834, acc = 0.890625\n",
      "Batch 25: loss = 0.27246102690696716, acc = 0.916015625\n",
      "Batch 26: loss = 0.26279139518737793, acc = 0.9091796875\n",
      "Batch 27: loss = 0.3178694248199463, acc = 0.8896484375\n",
      "Batch 28: loss = 0.2934940457344055, acc = 0.8935546875\n",
      "Batch 29: loss = 0.29033219814300537, acc = 0.8955078125\n",
      "Batch 30: loss = 0.26254451274871826, acc = 0.9052734375\n",
      "Batch 31: loss = 0.2783950865268707, acc = 0.90234375\n",
      "Batch 32: loss = 0.3008110821247101, acc = 0.8955078125\n",
      "Batch 33: loss = 0.3122712969779968, acc = 0.8916015625\n",
      "Batch 34: loss = 0.3411751687526703, acc = 0.8828125\n",
      "Batch 35: loss = 0.2904547154903412, acc = 0.9013671875\n",
      "Batch 36: loss = 0.26409855484962463, acc = 0.91015625\n",
      "Batch 37: loss = 0.22453509271144867, acc = 0.921875\n",
      "Batch 38: loss = 0.2804058790206909, acc = 0.8994140625\n",
      "Batch 39: loss = 0.2812601923942566, acc = 0.90234375\n",
      "Batch 40: loss = 0.26756900548934937, acc = 0.908203125\n",
      "Batch 41: loss = 0.245844766497612, acc = 0.9169921875\n",
      "Batch 42: loss = 0.29876014590263367, acc = 0.896484375\n",
      "Batch 43: loss = 0.3193889558315277, acc = 0.890625\n",
      "Batch 44: loss = 0.2674208879470825, acc = 0.9111328125\n",
      "Batch 45: loss = 0.27386248111724854, acc = 0.9013671875\n",
      "Batch 46: loss = 0.2579771876335144, acc = 0.9140625\n",
      "Batch 47: loss = 0.288254052400589, acc = 0.8984375\n",
      "Batch 48: loss = 0.2795877158641815, acc = 0.9140625\n",
      "Batch 49: loss = 0.27820801734924316, acc = 0.908203125\n",
      "Batch 50: loss = 0.284902423620224, acc = 0.904296875\n",
      "Batch 51: loss = 0.2619296908378601, acc = 0.9052734375\n",
      "Batch 52: loss = 0.30721747875213623, acc = 0.90234375\n",
      "Batch 53: loss = 0.27942436933517456, acc = 0.90234375\n",
      "Batch 54: loss = 0.20847851037979126, acc = 0.9326171875\n",
      "Batch 55: loss = 0.26963359117507935, acc = 0.9169921875\n",
      "Batch 56: loss = 0.27960023283958435, acc = 0.908203125\n",
      "Batch 57: loss = 0.32074469327926636, acc = 0.8876953125\n",
      "Batch 58: loss = 0.3004229664802551, acc = 0.8974609375\n",
      "Batch 59: loss = 0.2597791254520416, acc = 0.9189453125\n",
      "Batch 60: loss = 0.28188979625701904, acc = 0.91015625\n",
      "Batch 61: loss = 0.24747785925865173, acc = 0.919921875\n",
      "Batch 62: loss = 0.298348069190979, acc = 0.896484375\n",
      "Batch 63: loss = 0.2752850353717804, acc = 0.9140625\n",
      "Batch 64: loss = 0.2785596549510956, acc = 0.90625\n",
      "Batch 65: loss = 0.2841587960720062, acc = 0.90234375\n",
      "Batch 66: loss = 0.2803642153739929, acc = 0.9169921875\n",
      "Batch 67: loss = 0.2880858778953552, acc = 0.90234375\n",
      "Batch 68: loss = 0.2719305753707886, acc = 0.8994140625\n",
      "Batch 69: loss = 0.24131515622138977, acc = 0.923828125\n",
      "Batch 70: loss = 0.2823171615600586, acc = 0.91015625\n",
      "Batch 71: loss = 0.27735447883605957, acc = 0.9111328125\n",
      "Batch 72: loss = 0.26643744111061096, acc = 0.9189453125\n",
      "Batch 73: loss = 0.27895668148994446, acc = 0.90234375\n",
      "Batch 74: loss = 0.2790371775627136, acc = 0.9013671875\n",
      "Batch 75: loss = 0.33381420373916626, acc = 0.88671875\n",
      "Batch 76: loss = 0.29484862089157104, acc = 0.8974609375\n",
      "Batch 77: loss = 0.2718013525009155, acc = 0.9150390625\n",
      "Batch 78: loss = 0.2726409435272217, acc = 0.904296875\n",
      "Batch 79: loss = 0.29003310203552246, acc = 0.896484375\n",
      "Batch 80: loss = 0.25860658288002014, acc = 0.9072265625\n",
      "Batch 81: loss = 0.2797766625881195, acc = 0.9140625\n",
      "Batch 82: loss = 0.2955431640148163, acc = 0.900390625\n",
      "Batch 83: loss = 0.2732275724411011, acc = 0.904296875\n",
      "Batch 84: loss = 0.27889782190322876, acc = 0.900390625\n",
      "Batch 85: loss = 0.29981544613838196, acc = 0.8916015625\n",
      "Batch 86: loss = 0.2727808356285095, acc = 0.908203125\n",
      "Batch 87: loss = 0.29447364807128906, acc = 0.90234375\n",
      "Batch 88: loss = 0.3298072814941406, acc = 0.8828125\n",
      "Batch 89: loss = 0.2530735433101654, acc = 0.919921875\n",
      "Batch 90: loss = 0.2804079055786133, acc = 0.912109375\n",
      "Batch 91: loss = 0.29531094431877136, acc = 0.9033203125\n",
      "Batch 92: loss = 0.26837265491485596, acc = 0.9033203125\n",
      "Batch 93: loss = 0.27371907234191895, acc = 0.908203125\n",
      "Batch 94: loss = 0.23542508482933044, acc = 0.9189453125\n",
      "Batch 95: loss = 0.26937538385391235, acc = 0.9052734375\n",
      "Batch 96: loss = 0.287837415933609, acc = 0.896484375\n",
      "Batch 97: loss = 0.2914807200431824, acc = 0.8974609375\n",
      "Batch 98: loss = 0.26875561475753784, acc = 0.908203125\n",
      "Batch 99: loss = 0.2969572842121124, acc = 0.9033203125\n",
      "Batch 100: loss = 0.27217695116996765, acc = 0.9052734375\n",
      "Batch 101: loss = 0.29307591915130615, acc = 0.900390625\n",
      "Batch 102: loss = 0.28738340735435486, acc = 0.9033203125\n",
      "Batch 103: loss = 0.29451850056648254, acc = 0.9072265625\n",
      "Batch 104: loss = 0.2412445992231369, acc = 0.9169921875\n",
      "Batch 105: loss = 0.22766174376010895, acc = 0.927734375\n",
      "Batch 106: loss = 0.2568545341491699, acc = 0.908203125\n",
      "Batch 107: loss = 0.23746682703495026, acc = 0.9189453125\n",
      "Batch 108: loss = 0.2714923322200775, acc = 0.90625\n",
      "Batch 109: loss = 0.3044702410697937, acc = 0.8984375\n",
      "Batch 110: loss = 0.27336961030960083, acc = 0.908203125\n",
      "Batch 111: loss = 0.2522847056388855, acc = 0.9130859375\n",
      "Batch 112: loss = 0.2581125795841217, acc = 0.91015625\n",
      "Batch 113: loss = 0.27127471566200256, acc = 0.9052734375\n",
      "Batch 114: loss = 0.27178841829299927, acc = 0.900390625\n",
      "Batch 115: loss = 0.2893095314502716, acc = 0.908203125\n",
      "Batch 116: loss = 0.28962305188179016, acc = 0.90234375\n",
      "Batch 117: loss = 0.2865828275680542, acc = 0.9013671875\n",
      "Batch 118: loss = 0.26496565341949463, acc = 0.9033203125\n",
      "Batch 119: loss = 0.2471107840538025, acc = 0.9130859375\n",
      "Batch 120: loss = 0.2528526782989502, acc = 0.912109375\n",
      "Batch 121: loss = 0.23587557673454285, acc = 0.916015625\n",
      "Batch 122: loss = 0.2648792564868927, acc = 0.91015625\n",
      "Batch 123: loss = 0.23644065856933594, acc = 0.9140625\n",
      "Batch 124: loss = 0.2956947088241577, acc = 0.900390625\n",
      "Batch 125: loss = 0.3149554133415222, acc = 0.8935546875\n",
      "Batch 126: loss = 0.27680283784866333, acc = 0.91015625\n",
      "\n",
      "Epoch 87/100\n",
      "Batch 1: loss = 0.3070163428783417, acc = 0.9130859375\n",
      "Batch 2: loss = 0.28998392820358276, acc = 0.8955078125\n",
      "Batch 3: loss = 0.2704913020133972, acc = 0.91015625\n",
      "Batch 4: loss = 0.2815532982349396, acc = 0.9072265625\n",
      "Batch 5: loss = 0.29354849457740784, acc = 0.90625\n",
      "Batch 6: loss = 0.3119388818740845, acc = 0.890625\n",
      "Batch 7: loss = 0.28266268968582153, acc = 0.8974609375\n",
      "Batch 8: loss = 0.2777041792869568, acc = 0.9033203125\n",
      "Batch 9: loss = 0.25676843523979187, acc = 0.9169921875\n",
      "Batch 10: loss = 0.27608686685562134, acc = 0.908203125\n",
      "Batch 11: loss = 0.2541409432888031, acc = 0.916015625\n",
      "Batch 12: loss = 0.2722865343093872, acc = 0.9111328125\n",
      "Batch 13: loss = 0.2782352566719055, acc = 0.9072265625\n",
      "Batch 14: loss = 0.28237056732177734, acc = 0.9033203125\n",
      "Batch 15: loss = 0.24727800488471985, acc = 0.9248046875\n",
      "Batch 16: loss = 0.2938079833984375, acc = 0.90625\n",
      "Batch 17: loss = 0.2625507414340973, acc = 0.916015625\n",
      "Batch 18: loss = 0.28055956959724426, acc = 0.90234375\n",
      "Batch 19: loss = 0.30818095803260803, acc = 0.904296875\n",
      "Batch 20: loss = 0.2841477692127228, acc = 0.908203125\n",
      "Batch 21: loss = 0.29769790172576904, acc = 0.90234375\n",
      "Batch 22: loss = 0.2732204496860504, acc = 0.908203125\n",
      "Batch 23: loss = 0.2860919237136841, acc = 0.896484375\n",
      "Batch 24: loss = 0.3038063049316406, acc = 0.8896484375\n",
      "Batch 25: loss = 0.2712695598602295, acc = 0.90625\n",
      "Batch 26: loss = 0.29031917452812195, acc = 0.90234375\n",
      "Batch 27: loss = 0.3282657265663147, acc = 0.8828125\n",
      "Batch 28: loss = 0.2656469941139221, acc = 0.9013671875\n",
      "Batch 29: loss = 0.31826087832450867, acc = 0.89453125\n",
      "Batch 30: loss = 0.2624346911907196, acc = 0.9091796875\n",
      "Batch 31: loss = 0.2893460988998413, acc = 0.900390625\n",
      "Batch 32: loss = 0.2923123240470886, acc = 0.900390625\n",
      "Batch 33: loss = 0.2699492275714874, acc = 0.9091796875\n",
      "Batch 34: loss = 0.29242655634880066, acc = 0.9033203125\n",
      "Batch 35: loss = 0.3098343014717102, acc = 0.8916015625\n",
      "Batch 36: loss = 0.2934839725494385, acc = 0.9013671875\n",
      "Batch 37: loss = 0.22310666739940643, acc = 0.927734375\n",
      "Batch 38: loss = 0.2378140687942505, acc = 0.927734375\n",
      "Batch 39: loss = 0.2834245562553406, acc = 0.9072265625\n",
      "Batch 40: loss = 0.2928099036216736, acc = 0.9033203125\n",
      "Batch 41: loss = 0.2583603858947754, acc = 0.921875\n",
      "Batch 42: loss = 0.29122716188430786, acc = 0.9033203125\n",
      "Batch 43: loss = 0.2921074628829956, acc = 0.8955078125\n",
      "Batch 44: loss = 0.23952671885490417, acc = 0.927734375\n",
      "Batch 45: loss = 0.27507561445236206, acc = 0.90625\n",
      "Batch 46: loss = 0.23842255771160126, acc = 0.92578125\n",
      "Batch 47: loss = 0.27436643838882446, acc = 0.90625\n",
      "Batch 48: loss = 0.25314998626708984, acc = 0.912109375\n",
      "Batch 49: loss = 0.2571297585964203, acc = 0.9111328125\n",
      "Batch 50: loss = 0.27797985076904297, acc = 0.9091796875\n",
      "Batch 51: loss = 0.27773720026016235, acc = 0.8984375\n",
      "Batch 52: loss = 0.26198717951774597, acc = 0.904296875\n",
      "Batch 53: loss = 0.28309834003448486, acc = 0.9091796875\n",
      "Batch 54: loss = 0.22088709473609924, acc = 0.92578125\n",
      "Batch 55: loss = 0.2948003113269806, acc = 0.8984375\n",
      "Batch 56: loss = 0.2794904112815857, acc = 0.9033203125\n",
      "Batch 57: loss = 0.3307340741157532, acc = 0.8759765625\n",
      "Batch 58: loss = 0.29366564750671387, acc = 0.90625\n",
      "Batch 59: loss = 0.2682162821292877, acc = 0.904296875\n",
      "Batch 60: loss = 0.29650285840034485, acc = 0.8994140625\n",
      "Batch 61: loss = 0.21706807613372803, acc = 0.93359375\n",
      "Batch 62: loss = 0.2921268045902252, acc = 0.900390625\n",
      "Batch 63: loss = 0.24061740934848785, acc = 0.9150390625\n",
      "Batch 64: loss = 0.22617939114570618, acc = 0.9248046875\n",
      "Batch 65: loss = 0.3017008602619171, acc = 0.8994140625\n",
      "Batch 66: loss = 0.24293062090873718, acc = 0.9169921875\n",
      "Batch 67: loss = 0.26618266105651855, acc = 0.90234375\n",
      "Batch 68: loss = 0.3135887384414673, acc = 0.8916015625\n",
      "Batch 69: loss = 0.25976189970970154, acc = 0.90625\n",
      "Batch 70: loss = 0.32146161794662476, acc = 0.876953125\n",
      "Batch 71: loss = 0.26331984996795654, acc = 0.912109375\n",
      "Batch 72: loss = 0.2427557110786438, acc = 0.9169921875\n",
      "Batch 73: loss = 0.27327191829681396, acc = 0.9052734375\n",
      "Batch 74: loss = 0.3019755482673645, acc = 0.892578125\n",
      "Batch 75: loss = 0.3056938052177429, acc = 0.8935546875\n",
      "Batch 76: loss = 0.30018219351768494, acc = 0.896484375\n",
      "Batch 77: loss = 0.2674434185028076, acc = 0.8935546875\n",
      "Batch 78: loss = 0.270306795835495, acc = 0.91796875\n",
      "Batch 79: loss = 0.2574302554130554, acc = 0.9140625\n",
      "Batch 80: loss = 0.26363471150398254, acc = 0.91796875\n",
      "Batch 81: loss = 0.2715890109539032, acc = 0.8994140625\n",
      "Batch 82: loss = 0.2595934569835663, acc = 0.904296875\n",
      "Batch 83: loss = 0.27488625049591064, acc = 0.904296875\n",
      "Batch 84: loss = 0.30679458379745483, acc = 0.900390625\n",
      "Batch 85: loss = 0.31247955560684204, acc = 0.8974609375\n",
      "Batch 86: loss = 0.23809710144996643, acc = 0.916015625\n",
      "Batch 87: loss = 0.29208695888519287, acc = 0.90625\n",
      "Batch 88: loss = 0.3098123073577881, acc = 0.8896484375\n",
      "Batch 89: loss = 0.248104989528656, acc = 0.919921875\n",
      "Batch 90: loss = 0.23892924189567566, acc = 0.9208984375\n",
      "Batch 91: loss = 0.22595970332622528, acc = 0.923828125\n",
      "Batch 92: loss = 0.2820592522621155, acc = 0.9013671875\n",
      "Batch 93: loss = 0.24026884138584137, acc = 0.916015625\n",
      "Batch 94: loss = 0.2297338843345642, acc = 0.9326171875\n",
      "Batch 95: loss = 0.2466917783021927, acc = 0.9150390625\n",
      "Batch 96: loss = 0.2865300178527832, acc = 0.900390625\n",
      "Batch 97: loss = 0.2997516095638275, acc = 0.8984375\n",
      "Batch 98: loss = 0.25572824478149414, acc = 0.9189453125\n",
      "Batch 99: loss = 0.26178088784217834, acc = 0.912109375\n",
      "Batch 100: loss = 0.30098068714141846, acc = 0.89453125\n",
      "Batch 101: loss = 0.2660611569881439, acc = 0.9072265625\n",
      "Batch 102: loss = 0.29518288373947144, acc = 0.888671875\n",
      "Batch 103: loss = 0.24844390153884888, acc = 0.912109375\n",
      "Batch 104: loss = 0.2583377957344055, acc = 0.9169921875\n",
      "Batch 105: loss = 0.22184564173221588, acc = 0.923828125\n",
      "Batch 106: loss = 0.2356153428554535, acc = 0.9248046875\n",
      "Batch 107: loss = 0.23741790652275085, acc = 0.9130859375\n",
      "Batch 108: loss = 0.2591554522514343, acc = 0.9140625\n",
      "Batch 109: loss = 0.28564077615737915, acc = 0.8994140625\n",
      "Batch 110: loss = 0.25419431924819946, acc = 0.916015625\n",
      "Batch 111: loss = 0.2917101979255676, acc = 0.89453125\n",
      "Batch 112: loss = 0.2415192425251007, acc = 0.9140625\n",
      "Batch 113: loss = 0.23955324292182922, acc = 0.9150390625\n",
      "Batch 114: loss = 0.26812076568603516, acc = 0.9033203125\n",
      "Batch 115: loss = 0.3139885663986206, acc = 0.8935546875\n",
      "Batch 116: loss = 0.2831035852432251, acc = 0.9033203125\n",
      "Batch 117: loss = 0.27176225185394287, acc = 0.908203125\n",
      "Batch 118: loss = 0.22356905043125153, acc = 0.9150390625\n",
      "Batch 119: loss = 0.2816055119037628, acc = 0.8935546875\n",
      "Batch 120: loss = 0.23356181383132935, acc = 0.916015625\n",
      "Batch 121: loss = 0.280140221118927, acc = 0.8984375\n",
      "Batch 122: loss = 0.24553591012954712, acc = 0.9111328125\n",
      "Batch 123: loss = 0.29303622245788574, acc = 0.8994140625\n",
      "Batch 124: loss = 0.2990001440048218, acc = 0.900390625\n",
      "Batch 125: loss = 0.3212074041366577, acc = 0.888671875\n",
      "Batch 126: loss = 0.29588863253593445, acc = 0.8984375\n",
      "\n",
      "Epoch 88/100\n",
      "Batch 1: loss = 0.35387274622917175, acc = 0.88671875\n",
      "Batch 2: loss = 0.29726871848106384, acc = 0.8974609375\n",
      "Batch 3: loss = 0.29126524925231934, acc = 0.90234375\n",
      "Batch 4: loss = 0.2781592607498169, acc = 0.9169921875\n",
      "Batch 5: loss = 0.29650574922561646, acc = 0.90625\n",
      "Batch 6: loss = 0.27266907691955566, acc = 0.9140625\n",
      "Batch 7: loss = 0.26548340916633606, acc = 0.9072265625\n",
      "Batch 8: loss = 0.318700909614563, acc = 0.890625\n",
      "Batch 9: loss = 0.2852858901023865, acc = 0.9072265625\n",
      "Batch 10: loss = 0.2501387596130371, acc = 0.9208984375\n",
      "Batch 11: loss = 0.2503623068332672, acc = 0.9169921875\n",
      "Batch 12: loss = 0.2719022333621979, acc = 0.908203125\n",
      "Batch 13: loss = 0.25470709800720215, acc = 0.904296875\n",
      "Batch 14: loss = 0.2349233478307724, acc = 0.93359375\n",
      "Batch 15: loss = 0.24944356083869934, acc = 0.9169921875\n",
      "Batch 16: loss = 0.2812640070915222, acc = 0.9052734375\n",
      "Batch 17: loss = 0.2735269069671631, acc = 0.9072265625\n",
      "Batch 18: loss = 0.29939329624176025, acc = 0.9013671875\n",
      "Batch 19: loss = 0.3212233781814575, acc = 0.8896484375\n",
      "Batch 20: loss = 0.2728489637374878, acc = 0.9130859375\n",
      "Batch 21: loss = 0.27115339040756226, acc = 0.9228515625\n",
      "Batch 22: loss = 0.2650523781776428, acc = 0.9072265625\n",
      "Batch 23: loss = 0.2975303530693054, acc = 0.89453125\n",
      "Batch 24: loss = 0.2927900552749634, acc = 0.8974609375\n",
      "Batch 25: loss = 0.2578354775905609, acc = 0.916015625\n",
      "Batch 26: loss = 0.2939968407154083, acc = 0.9033203125\n",
      "Batch 27: loss = 0.3337762951850891, acc = 0.8857421875\n",
      "Batch 28: loss = 0.31882232427597046, acc = 0.888671875\n",
      "Batch 29: loss = 0.2967298924922943, acc = 0.89453125\n",
      "Batch 30: loss = 0.27667057514190674, acc = 0.9033203125\n",
      "Batch 31: loss = 0.2765485644340515, acc = 0.9033203125\n",
      "Batch 32: loss = 0.269223690032959, acc = 0.90625\n",
      "Batch 33: loss = 0.26339632272720337, acc = 0.900390625\n",
      "Batch 34: loss = 0.30373549461364746, acc = 0.890625\n",
      "Batch 35: loss = 0.27800261974334717, acc = 0.9130859375\n",
      "Batch 36: loss = 0.2406659871339798, acc = 0.9169921875\n",
      "Batch 37: loss = 0.22855201363563538, acc = 0.919921875\n",
      "Batch 38: loss = 0.2407836616039276, acc = 0.9189453125\n",
      "Batch 39: loss = 0.26097941398620605, acc = 0.9150390625\n",
      "Batch 40: loss = 0.257104754447937, acc = 0.9091796875\n",
      "Batch 41: loss = 0.25634944438934326, acc = 0.9072265625\n",
      "Batch 42: loss = 0.29002445936203003, acc = 0.900390625\n",
      "Batch 43: loss = 0.2755585312843323, acc = 0.90625\n",
      "Batch 44: loss = 0.2592226564884186, acc = 0.9130859375\n",
      "Batch 45: loss = 0.27005526423454285, acc = 0.8984375\n",
      "Batch 46: loss = 0.2618831396102905, acc = 0.9111328125\n",
      "Batch 47: loss = 0.26733332872390747, acc = 0.9111328125\n",
      "Batch 48: loss = 0.24186603724956512, acc = 0.9228515625\n",
      "Batch 49: loss = 0.2675379514694214, acc = 0.9052734375\n",
      "Batch 50: loss = 0.2822817265987396, acc = 0.90625\n",
      "Batch 51: loss = 0.25216972827911377, acc = 0.9140625\n",
      "Batch 52: loss = 0.2787802219390869, acc = 0.9111328125\n",
      "Batch 53: loss = 0.26458749175071716, acc = 0.9052734375\n",
      "Batch 54: loss = 0.2137242555618286, acc = 0.9326171875\n",
      "Batch 55: loss = 0.263693243265152, acc = 0.912109375\n",
      "Batch 56: loss = 0.25172552466392517, acc = 0.9033203125\n",
      "Batch 57: loss = 0.33015304803848267, acc = 0.8779296875\n",
      "Batch 58: loss = 0.27972182631492615, acc = 0.9140625\n",
      "Batch 59: loss = 0.21657904982566833, acc = 0.9296875\n",
      "Batch 60: loss = 0.26550403237342834, acc = 0.90625\n",
      "Batch 61: loss = 0.21456150710582733, acc = 0.9296875\n",
      "Batch 62: loss = 0.2701491415500641, acc = 0.9013671875\n",
      "Batch 63: loss = 0.24980463087558746, acc = 0.9091796875\n",
      "Batch 64: loss = 0.25052404403686523, acc = 0.916015625\n",
      "Batch 65: loss = 0.3203205466270447, acc = 0.8896484375\n",
      "Batch 66: loss = 0.2641879916191101, acc = 0.916015625\n",
      "Batch 67: loss = 0.27266398072242737, acc = 0.90234375\n",
      "Batch 68: loss = 0.31058499217033386, acc = 0.8896484375\n",
      "Batch 69: loss = 0.23716239631175995, acc = 0.919921875\n",
      "Batch 70: loss = 0.3033105432987213, acc = 0.8994140625\n",
      "Batch 71: loss = 0.258309006690979, acc = 0.9169921875\n",
      "Batch 72: loss = 0.26640817523002625, acc = 0.91015625\n",
      "Batch 73: loss = 0.308047354221344, acc = 0.890625\n",
      "Batch 74: loss = 0.3058842718601227, acc = 0.89453125\n",
      "Batch 75: loss = 0.3055112957954407, acc = 0.8955078125\n",
      "Batch 76: loss = 0.3058461546897888, acc = 0.8935546875\n",
      "Batch 77: loss = 0.2438966929912567, acc = 0.9189453125\n",
      "Batch 78: loss = 0.2823459208011627, acc = 0.904296875\n",
      "Batch 79: loss = 0.2811823785305023, acc = 0.9013671875\n",
      "Batch 80: loss = 0.24792535603046417, acc = 0.9150390625\n",
      "Batch 81: loss = 0.2863170802593231, acc = 0.90234375\n",
      "Batch 82: loss = 0.2588203549385071, acc = 0.9130859375\n",
      "Batch 83: loss = 0.278033971786499, acc = 0.9052734375\n",
      "Batch 84: loss = 0.2871973514556885, acc = 0.896484375\n",
      "Batch 85: loss = 0.3017183840274811, acc = 0.8994140625\n",
      "Batch 86: loss = 0.29112493991851807, acc = 0.890625\n",
      "Batch 87: loss = 0.2434588074684143, acc = 0.9150390625\n",
      "Batch 88: loss = 0.32126152515411377, acc = 0.88671875\n",
      "Batch 89: loss = 0.2501845955848694, acc = 0.9228515625\n",
      "Batch 90: loss = 0.2865700125694275, acc = 0.90234375\n",
      "Batch 91: loss = 0.26112842559814453, acc = 0.9072265625\n",
      "Batch 92: loss = 0.2714768052101135, acc = 0.908203125\n",
      "Batch 93: loss = 0.2553117871284485, acc = 0.90625\n",
      "Batch 94: loss = 0.213186115026474, acc = 0.9189453125\n",
      "Batch 95: loss = 0.26508358120918274, acc = 0.919921875\n",
      "Batch 96: loss = 0.26825132966041565, acc = 0.904296875\n",
      "Batch 97: loss = 0.2499399185180664, acc = 0.91796875\n",
      "Batch 98: loss = 0.25834745168685913, acc = 0.9091796875\n",
      "Batch 99: loss = 0.2788815200328827, acc = 0.9072265625\n",
      "Batch 100: loss = 0.2833656072616577, acc = 0.904296875\n",
      "Batch 101: loss = 0.2749243974685669, acc = 0.9033203125\n",
      "Batch 102: loss = 0.25515204668045044, acc = 0.9189453125\n",
      "Batch 103: loss = 0.27476966381073, acc = 0.91015625\n",
      "Batch 104: loss = 0.23586221039295197, acc = 0.9140625\n",
      "Batch 105: loss = 0.22279062867164612, acc = 0.9287109375\n",
      "Batch 106: loss = 0.2518051266670227, acc = 0.91796875\n",
      "Batch 107: loss = 0.2448699176311493, acc = 0.9130859375\n",
      "Batch 108: loss = 0.2613447606563568, acc = 0.8974609375\n",
      "Batch 109: loss = 0.2610042989253998, acc = 0.90234375\n",
      "Batch 110: loss = 0.24608582258224487, acc = 0.9248046875\n",
      "Batch 111: loss = 0.26205310225486755, acc = 0.912109375\n",
      "Batch 112: loss = 0.25509703159332275, acc = 0.904296875\n",
      "Batch 113: loss = 0.25261878967285156, acc = 0.91796875\n",
      "Batch 114: loss = 0.2720014452934265, acc = 0.90234375\n",
      "Batch 115: loss = 0.27568864822387695, acc = 0.9072265625\n",
      "Batch 116: loss = 0.28933459520339966, acc = 0.8955078125\n",
      "Batch 117: loss = 0.2640516459941864, acc = 0.9052734375\n",
      "Batch 118: loss = 0.23592911660671234, acc = 0.9150390625\n",
      "Batch 119: loss = 0.23377713561058044, acc = 0.9248046875\n",
      "Batch 120: loss = 0.26257455348968506, acc = 0.9033203125\n",
      "Batch 121: loss = 0.2557818293571472, acc = 0.912109375\n",
      "Batch 122: loss = 0.2431156486272812, acc = 0.919921875\n",
      "Batch 123: loss = 0.2555015981197357, acc = 0.916015625\n",
      "Batch 124: loss = 0.2844933569431305, acc = 0.908203125\n",
      "Batch 125: loss = 0.27843427658081055, acc = 0.90234375\n",
      "Batch 126: loss = 0.29416680335998535, acc = 0.8935546875\n",
      "\n",
      "Epoch 89/100\n",
      "Batch 1: loss = 0.33063599467277527, acc = 0.890625\n",
      "Batch 2: loss = 0.3014414310455322, acc = 0.890625\n",
      "Batch 3: loss = 0.24772323668003082, acc = 0.916015625\n",
      "Batch 4: loss = 0.3112153708934784, acc = 0.892578125\n",
      "Batch 5: loss = 0.23734714090824127, acc = 0.9208984375\n",
      "Batch 6: loss = 0.26697877049446106, acc = 0.904296875\n",
      "Batch 7: loss = 0.28415873646736145, acc = 0.908203125\n",
      "Batch 8: loss = 0.26078182458877563, acc = 0.9111328125\n",
      "Batch 9: loss = 0.2876076102256775, acc = 0.9052734375\n",
      "Batch 10: loss = 0.24954867362976074, acc = 0.91796875\n",
      "Batch 11: loss = 0.2510682940483093, acc = 0.916015625\n",
      "Batch 12: loss = 0.27110958099365234, acc = 0.90234375\n",
      "Batch 13: loss = 0.2786596715450287, acc = 0.900390625\n",
      "Batch 14: loss = 0.24602487683296204, acc = 0.9189453125\n",
      "Batch 15: loss = 0.24795235693454742, acc = 0.9150390625\n",
      "Batch 16: loss = 0.2875548005104065, acc = 0.9052734375\n",
      "Batch 17: loss = 0.2775604724884033, acc = 0.91015625\n",
      "Batch 18: loss = 0.2947179675102234, acc = 0.9052734375\n",
      "Batch 19: loss = 0.27460193634033203, acc = 0.9052734375\n",
      "Batch 20: loss = 0.2538303732872009, acc = 0.9189453125\n",
      "Batch 21: loss = 0.31192389130592346, acc = 0.89453125\n",
      "Batch 22: loss = 0.2815769612789154, acc = 0.900390625\n",
      "Batch 23: loss = 0.2800861597061157, acc = 0.904296875\n",
      "Batch 24: loss = 0.30183184146881104, acc = 0.892578125\n",
      "Batch 25: loss = 0.25702986121177673, acc = 0.919921875\n",
      "Batch 26: loss = 0.2867606580257416, acc = 0.90625\n",
      "Batch 27: loss = 0.3352438807487488, acc = 0.8896484375\n",
      "Batch 28: loss = 0.2695384919643402, acc = 0.90625\n",
      "Batch 29: loss = 0.31103789806365967, acc = 0.8935546875\n",
      "Batch 30: loss = 0.26827526092529297, acc = 0.9130859375\n",
      "Batch 31: loss = 0.26143884658813477, acc = 0.9169921875\n",
      "Batch 32: loss = 0.27262240648269653, acc = 0.9013671875\n",
      "Batch 33: loss = 0.27159664034843445, acc = 0.91015625\n",
      "Batch 34: loss = 0.28441423177719116, acc = 0.9013671875\n",
      "Batch 35: loss = 0.25886863470077515, acc = 0.9169921875\n",
      "Batch 36: loss = 0.22944766283035278, acc = 0.92578125\n",
      "Batch 37: loss = 0.2140548974275589, acc = 0.9326171875\n",
      "Batch 38: loss = 0.288700670003891, acc = 0.90625\n",
      "Batch 39: loss = 0.23070994019508362, acc = 0.921875\n",
      "Batch 40: loss = 0.27978280186653137, acc = 0.908203125\n",
      "Batch 41: loss = 0.24857522547245026, acc = 0.9130859375\n",
      "Batch 42: loss = 0.26244834065437317, acc = 0.9091796875\n",
      "Batch 43: loss = 0.2603759765625, acc = 0.9091796875\n",
      "Batch 44: loss = 0.24333560466766357, acc = 0.919921875\n",
      "Batch 45: loss = 0.2586743235588074, acc = 0.9111328125\n",
      "Batch 46: loss = 0.253993421792984, acc = 0.9130859375\n",
      "Batch 47: loss = 0.25729528069496155, acc = 0.9208984375\n",
      "Batch 48: loss = 0.2532491981983185, acc = 0.9169921875\n",
      "Batch 49: loss = 0.25406914949417114, acc = 0.919921875\n",
      "Batch 50: loss = 0.25093334913253784, acc = 0.9140625\n",
      "Batch 51: loss = 0.22349151968955994, acc = 0.919921875\n",
      "Batch 52: loss = 0.32036644220352173, acc = 0.8916015625\n",
      "Batch 53: loss = 0.2483249455690384, acc = 0.91796875\n",
      "Batch 54: loss = 0.2255130410194397, acc = 0.9287109375\n",
      "Batch 55: loss = 0.26536092162132263, acc = 0.908203125\n",
      "Batch 56: loss = 0.269536554813385, acc = 0.91015625\n",
      "Batch 57: loss = 0.3183176517486572, acc = 0.8857421875\n",
      "Batch 58: loss = 0.32480528950691223, acc = 0.8935546875\n",
      "Batch 59: loss = 0.22194279730319977, acc = 0.923828125\n",
      "Batch 60: loss = 0.22982344031333923, acc = 0.91796875\n",
      "Batch 61: loss = 0.20855681598186493, acc = 0.93359375\n",
      "Batch 62: loss = 0.2741028964519501, acc = 0.90234375\n",
      "Batch 63: loss = 0.24142222106456757, acc = 0.91796875\n",
      "Batch 64: loss = 0.22504879534244537, acc = 0.9228515625\n",
      "Batch 65: loss = 0.2730400860309601, acc = 0.9208984375\n",
      "Batch 66: loss = 0.2620891034603119, acc = 0.9111328125\n",
      "Batch 67: loss = 0.24986892938613892, acc = 0.9111328125\n",
      "Batch 68: loss = 0.26426297426223755, acc = 0.9091796875\n",
      "Batch 69: loss = 0.2511776089668274, acc = 0.91796875\n",
      "Batch 70: loss = 0.2836846113204956, acc = 0.91015625\n",
      "Batch 71: loss = 0.27557963132858276, acc = 0.8994140625\n",
      "Batch 72: loss = 0.23511606454849243, acc = 0.919921875\n",
      "Batch 73: loss = 0.30409857630729675, acc = 0.90234375\n",
      "Batch 74: loss = 0.27700257301330566, acc = 0.904296875\n",
      "Batch 75: loss = 0.30250656604766846, acc = 0.8955078125\n",
      "Batch 76: loss = 0.2844647467136383, acc = 0.8974609375\n",
      "Batch 77: loss = 0.2691943049430847, acc = 0.90234375\n",
      "Batch 78: loss = 0.2854643166065216, acc = 0.90234375\n",
      "Batch 79: loss = 0.2536565661430359, acc = 0.9169921875\n",
      "Batch 80: loss = 0.22610744833946228, acc = 0.916015625\n",
      "Batch 81: loss = 0.27433180809020996, acc = 0.9091796875\n",
      "Batch 82: loss = 0.24836444854736328, acc = 0.9072265625\n",
      "Batch 83: loss = 0.2762179672718048, acc = 0.9072265625\n",
      "Batch 84: loss = 0.2681475579738617, acc = 0.904296875\n",
      "Batch 85: loss = 0.25487878918647766, acc = 0.904296875\n",
      "Batch 86: loss = 0.2479574829339981, acc = 0.91796875\n",
      "Batch 87: loss = 0.2708469033241272, acc = 0.912109375\n",
      "Batch 88: loss = 0.30016207695007324, acc = 0.896484375\n",
      "Batch 89: loss = 0.270473450422287, acc = 0.9052734375\n",
      "Batch 90: loss = 0.2786082625389099, acc = 0.9033203125\n",
      "Batch 91: loss = 0.25781410932540894, acc = 0.9150390625\n",
      "Batch 92: loss = 0.2633726894855499, acc = 0.9130859375\n",
      "Batch 93: loss = 0.2654590606689453, acc = 0.9072265625\n",
      "Batch 94: loss = 0.2256275713443756, acc = 0.9228515625\n",
      "Batch 95: loss = 0.24783194065093994, acc = 0.9208984375\n",
      "Batch 96: loss = 0.25440487265586853, acc = 0.9130859375\n",
      "Batch 97: loss = 0.26185160875320435, acc = 0.919921875\n",
      "Batch 98: loss = 0.27522194385528564, acc = 0.9052734375\n",
      "Batch 99: loss = 0.2901766002178192, acc = 0.892578125\n",
      "Batch 100: loss = 0.258304625749588, acc = 0.90625\n",
      "Batch 101: loss = 0.26001325249671936, acc = 0.90625\n",
      "Batch 102: loss = 0.2549172043800354, acc = 0.9052734375\n",
      "Batch 103: loss = 0.25032252073287964, acc = 0.912109375\n",
      "Batch 104: loss = 0.2827356457710266, acc = 0.9130859375\n",
      "Batch 105: loss = 0.22108089923858643, acc = 0.916015625\n",
      "Batch 106: loss = 0.25280049443244934, acc = 0.9189453125\n",
      "Batch 107: loss = 0.23845136165618896, acc = 0.912109375\n",
      "Batch 108: loss = 0.25118717551231384, acc = 0.9033203125\n",
      "Batch 109: loss = 0.2539985477924347, acc = 0.904296875\n",
      "Batch 110: loss = 0.2697485089302063, acc = 0.9150390625\n",
      "Batch 111: loss = 0.26748424768447876, acc = 0.908203125\n",
      "Batch 112: loss = 0.24777120351791382, acc = 0.90625\n",
      "Batch 113: loss = 0.2636732757091522, acc = 0.9072265625\n",
      "Batch 114: loss = 0.298371821641922, acc = 0.9013671875\n",
      "Batch 115: loss = 0.25923532247543335, acc = 0.9111328125\n",
      "Batch 116: loss = 0.30265575647354126, acc = 0.8984375\n",
      "Batch 117: loss = 0.2834101915359497, acc = 0.900390625\n",
      "Batch 118: loss = 0.24680136144161224, acc = 0.9228515625\n",
      "Batch 119: loss = 0.2395269274711609, acc = 0.9189453125\n",
      "Batch 120: loss = 0.21936345100402832, acc = 0.9208984375\n",
      "Batch 121: loss = 0.26498356461524963, acc = 0.8955078125\n",
      "Batch 122: loss = 0.2521378993988037, acc = 0.9208984375\n",
      "Batch 123: loss = 0.23573610186576843, acc = 0.9169921875\n",
      "Batch 124: loss = 0.25488537549972534, acc = 0.9140625\n",
      "Batch 125: loss = 0.2696976065635681, acc = 0.912109375\n",
      "Batch 126: loss = 0.2515101432800293, acc = 0.9072265625\n",
      "\n",
      "Epoch 90/100\n",
      "Batch 1: loss = 0.3364908695220947, acc = 0.9033203125\n",
      "Batch 2: loss = 0.2864004671573639, acc = 0.9072265625\n",
      "Batch 3: loss = 0.2841609716415405, acc = 0.9052734375\n",
      "Batch 4: loss = 0.27793553471565247, acc = 0.90234375\n",
      "Batch 5: loss = 0.27893298864364624, acc = 0.9033203125\n",
      "Batch 6: loss = 0.29164353013038635, acc = 0.9013671875\n",
      "Batch 7: loss = 0.2353478968143463, acc = 0.9208984375\n",
      "Batch 8: loss = 0.2749091386795044, acc = 0.9140625\n",
      "Batch 9: loss = 0.2930605411529541, acc = 0.908203125\n",
      "Batch 10: loss = 0.2417871057987213, acc = 0.9189453125\n",
      "Batch 11: loss = 0.2303639054298401, acc = 0.9208984375\n",
      "Batch 12: loss = 0.2841515839099884, acc = 0.904296875\n",
      "Batch 13: loss = 0.2598128318786621, acc = 0.9169921875\n",
      "Batch 14: loss = 0.28737810254096985, acc = 0.9091796875\n",
      "Batch 15: loss = 0.24519841372966766, acc = 0.9150390625\n",
      "Batch 16: loss = 0.2702256441116333, acc = 0.912109375\n",
      "Batch 17: loss = 0.2556489408016205, acc = 0.912109375\n",
      "Batch 18: loss = 0.27915051579475403, acc = 0.8994140625\n",
      "Batch 19: loss = 0.25016337633132935, acc = 0.90625\n",
      "Batch 20: loss = 0.28638947010040283, acc = 0.9033203125\n",
      "Batch 21: loss = 0.30042514204978943, acc = 0.9033203125\n",
      "Batch 22: loss = 0.2787330746650696, acc = 0.8984375\n",
      "Batch 23: loss = 0.28584814071655273, acc = 0.90234375\n",
      "Batch 24: loss = 0.27074334025382996, acc = 0.904296875\n",
      "Batch 25: loss = 0.25568389892578125, acc = 0.9130859375\n",
      "Batch 26: loss = 0.26680007576942444, acc = 0.91015625\n",
      "Batch 27: loss = 0.3176415264606476, acc = 0.8935546875\n",
      "Batch 28: loss = 0.27165988087654114, acc = 0.908203125\n",
      "Batch 29: loss = 0.28596973419189453, acc = 0.904296875\n",
      "Batch 30: loss = 0.24730056524276733, acc = 0.9208984375\n",
      "Batch 31: loss = 0.2860812842845917, acc = 0.908203125\n",
      "Batch 32: loss = 0.30738896131515503, acc = 0.9052734375\n",
      "Batch 33: loss = 0.2686803936958313, acc = 0.8974609375\n",
      "Batch 34: loss = 0.30592167377471924, acc = 0.8994140625\n",
      "Batch 35: loss = 0.2563898265361786, acc = 0.9228515625\n",
      "Batch 36: loss = 0.23720917105674744, acc = 0.92578125\n",
      "Batch 37: loss = 0.21240821480751038, acc = 0.9326171875\n",
      "Batch 38: loss = 0.27621012926101685, acc = 0.91015625\n",
      "Batch 39: loss = 0.240817129611969, acc = 0.9140625\n",
      "Batch 40: loss = 0.25912731885910034, acc = 0.9091796875\n",
      "Batch 41: loss = 0.23257572948932648, acc = 0.9248046875\n",
      "Batch 42: loss = 0.2831597924232483, acc = 0.9052734375\n",
      "Batch 43: loss = 0.28714579343795776, acc = 0.8984375\n",
      "Batch 44: loss = 0.2554803788661957, acc = 0.9140625\n",
      "Batch 45: loss = 0.25969505310058594, acc = 0.908203125\n",
      "Batch 46: loss = 0.24056418240070343, acc = 0.921875\n",
      "Batch 47: loss = 0.27618852257728577, acc = 0.9033203125\n",
      "Batch 48: loss = 0.24394121766090393, acc = 0.9287109375\n",
      "Batch 49: loss = 0.2752646803855896, acc = 0.9111328125\n",
      "Batch 50: loss = 0.25656166672706604, acc = 0.9052734375\n",
      "Batch 51: loss = 0.25306734442710876, acc = 0.9208984375\n",
      "Batch 52: loss = 0.2765384614467621, acc = 0.9072265625\n",
      "Batch 53: loss = 0.243687242269516, acc = 0.9189453125\n",
      "Batch 54: loss = 0.22908328473567963, acc = 0.9326171875\n",
      "Batch 55: loss = 0.24301990866661072, acc = 0.9248046875\n",
      "Batch 56: loss = 0.260934978723526, acc = 0.916015625\n",
      "Batch 57: loss = 0.2545289695262909, acc = 0.9091796875\n",
      "Batch 58: loss = 0.2770378589630127, acc = 0.9052734375\n",
      "Batch 59: loss = 0.20624969899654388, acc = 0.931640625\n",
      "Batch 60: loss = 0.25137951970100403, acc = 0.91796875\n",
      "Batch 61: loss = 0.24533872306346893, acc = 0.919921875\n",
      "Batch 62: loss = 0.30430567264556885, acc = 0.9033203125\n",
      "Batch 63: loss = 0.25169870257377625, acc = 0.91796875\n",
      "Batch 64: loss = 0.24509121477603912, acc = 0.9267578125\n",
      "Batch 65: loss = 0.28110939264297485, acc = 0.8974609375\n",
      "Batch 66: loss = 0.25784212350845337, acc = 0.90625\n",
      "Batch 67: loss = 0.24862873554229736, acc = 0.91796875\n",
      "Batch 68: loss = 0.2673287093639374, acc = 0.9091796875\n",
      "Batch 69: loss = 0.2661873400211334, acc = 0.9091796875\n",
      "Batch 70: loss = 0.28495797514915466, acc = 0.9111328125\n",
      "Batch 71: loss = 0.2735132873058319, acc = 0.9013671875\n",
      "Batch 72: loss = 0.26887941360473633, acc = 0.9091796875\n",
      "Batch 73: loss = 0.28620094060897827, acc = 0.89453125\n",
      "Batch 74: loss = 0.29432040452957153, acc = 0.9033203125\n",
      "Batch 75: loss = 0.325836181640625, acc = 0.8828125\n",
      "Batch 76: loss = 0.29893600940704346, acc = 0.90625\n",
      "Batch 77: loss = 0.254196435213089, acc = 0.916015625\n",
      "Batch 78: loss = 0.28135326504707336, acc = 0.9013671875\n",
      "Batch 79: loss = 0.2559615969657898, acc = 0.91015625\n",
      "Batch 80: loss = 0.26097095012664795, acc = 0.9091796875\n",
      "Batch 81: loss = 0.2622755765914917, acc = 0.9072265625\n",
      "Batch 82: loss = 0.2506868541240692, acc = 0.9208984375\n",
      "Batch 83: loss = 0.2609908878803253, acc = 0.91796875\n",
      "Batch 84: loss = 0.2638476490974426, acc = 0.9140625\n",
      "Batch 85: loss = 0.2859193682670593, acc = 0.8935546875\n",
      "Batch 86: loss = 0.27745890617370605, acc = 0.9091796875\n",
      "Batch 87: loss = 0.2846094071865082, acc = 0.8955078125\n",
      "Batch 88: loss = 0.26555967330932617, acc = 0.9072265625\n",
      "Batch 89: loss = 0.25778356194496155, acc = 0.90625\n",
      "Batch 90: loss = 0.28055617213249207, acc = 0.904296875\n",
      "Batch 91: loss = 0.2584693431854248, acc = 0.9169921875\n",
      "Batch 92: loss = 0.2570359408855438, acc = 0.904296875\n",
      "Batch 93: loss = 0.2494312822818756, acc = 0.921875\n",
      "Batch 94: loss = 0.22340312600135803, acc = 0.9228515625\n",
      "Batch 95: loss = 0.22813531756401062, acc = 0.923828125\n",
      "Batch 96: loss = 0.28474321961402893, acc = 0.90234375\n",
      "Batch 97: loss = 0.2820565700531006, acc = 0.9072265625\n",
      "Batch 98: loss = 0.2518005073070526, acc = 0.9072265625\n",
      "Batch 99: loss = 0.2921481430530548, acc = 0.896484375\n",
      "Batch 100: loss = 0.2983609139919281, acc = 0.8994140625\n",
      "Batch 101: loss = 0.26064497232437134, acc = 0.904296875\n",
      "Batch 102: loss = 0.26926955580711365, acc = 0.9091796875\n",
      "Batch 103: loss = 0.2778837978839874, acc = 0.9091796875\n",
      "Batch 104: loss = 0.24433358013629913, acc = 0.91796875\n",
      "Batch 105: loss = 0.23237904906272888, acc = 0.923828125\n",
      "Batch 106: loss = 0.22137632966041565, acc = 0.9189453125\n",
      "Batch 107: loss = 0.2400732785463333, acc = 0.9228515625\n",
      "Batch 108: loss = 0.24842213094234467, acc = 0.9208984375\n",
      "Batch 109: loss = 0.2749200463294983, acc = 0.904296875\n",
      "Batch 110: loss = 0.2837887108325958, acc = 0.90625\n",
      "Batch 111: loss = 0.27975279092788696, acc = 0.90234375\n",
      "Batch 112: loss = 0.26784390211105347, acc = 0.9072265625\n",
      "Batch 113: loss = 0.26603567600250244, acc = 0.8994140625\n",
      "Batch 114: loss = 0.28130871057510376, acc = 0.9091796875\n",
      "Batch 115: loss = 0.2586521506309509, acc = 0.908203125\n",
      "Batch 116: loss = 0.2988281846046448, acc = 0.9013671875\n",
      "Batch 117: loss = 0.260612815618515, acc = 0.9140625\n",
      "Batch 118: loss = 0.2701914310455322, acc = 0.9111328125\n",
      "Batch 119: loss = 0.230518639087677, acc = 0.9169921875\n",
      "Batch 120: loss = 0.2452867478132248, acc = 0.9013671875\n",
      "Batch 121: loss = 0.25103265047073364, acc = 0.9169921875\n",
      "Batch 122: loss = 0.24235863983631134, acc = 0.921875\n",
      "Batch 123: loss = 0.23778113722801208, acc = 0.9267578125\n",
      "Batch 124: loss = 0.2784348726272583, acc = 0.908203125\n",
      "Batch 125: loss = 0.2530915141105652, acc = 0.9130859375\n",
      "Batch 126: loss = 0.2681543827056885, acc = 0.9140625\n",
      "Saved checkpoint to weights.90.h5\n",
      "\n",
      "Epoch 91/100\n",
      "Batch 1: loss = 0.31137970089912415, acc = 0.892578125\n",
      "Batch 2: loss = 0.27586591243743896, acc = 0.9033203125\n",
      "Batch 3: loss = 0.25216302275657654, acc = 0.912109375\n",
      "Batch 4: loss = 0.259653776884079, acc = 0.908203125\n",
      "Batch 5: loss = 0.2264692187309265, acc = 0.9208984375\n",
      "Batch 6: loss = 0.25797998905181885, acc = 0.919921875\n",
      "Batch 7: loss = 0.25926700234413147, acc = 0.908203125\n",
      "Batch 8: loss = 0.2592439353466034, acc = 0.9091796875\n",
      "Batch 9: loss = 0.2562096118927002, acc = 0.919921875\n",
      "Batch 10: loss = 0.22772744297981262, acc = 0.923828125\n",
      "Batch 11: loss = 0.2733127176761627, acc = 0.9033203125\n",
      "Batch 12: loss = 0.22676879167556763, acc = 0.9296875\n",
      "Batch 13: loss = 0.2409103959798813, acc = 0.9228515625\n",
      "Batch 14: loss = 0.23519957065582275, acc = 0.921875\n",
      "Batch 15: loss = 0.2326013296842575, acc = 0.919921875\n",
      "Batch 16: loss = 0.24602147936820984, acc = 0.9091796875\n",
      "Batch 17: loss = 0.247071772813797, acc = 0.9150390625\n",
      "Batch 18: loss = 0.2960916757583618, acc = 0.904296875\n",
      "Batch 19: loss = 0.2619967460632324, acc = 0.90625\n",
      "Batch 20: loss = 0.2927730977535248, acc = 0.9072265625\n",
      "Batch 21: loss = 0.3009137809276581, acc = 0.8916015625\n",
      "Batch 22: loss = 0.280638724565506, acc = 0.9091796875\n",
      "Batch 23: loss = 0.28293749690055847, acc = 0.900390625\n",
      "Batch 24: loss = 0.2795959413051605, acc = 0.896484375\n",
      "Batch 25: loss = 0.25464335083961487, acc = 0.916015625\n",
      "Batch 26: loss = 0.2543048560619354, acc = 0.916015625\n",
      "Batch 27: loss = 0.2969675660133362, acc = 0.8984375\n",
      "Batch 28: loss = 0.27733445167541504, acc = 0.9033203125\n",
      "Batch 29: loss = 0.2859911620616913, acc = 0.9072265625\n",
      "Batch 30: loss = 0.2693417966365814, acc = 0.92578125\n",
      "Batch 31: loss = 0.28640273213386536, acc = 0.9052734375\n",
      "Batch 32: loss = 0.27025243639945984, acc = 0.9052734375\n",
      "Batch 33: loss = 0.24286003410816193, acc = 0.9150390625\n",
      "Batch 34: loss = 0.2800571322441101, acc = 0.912109375\n",
      "Batch 35: loss = 0.250013530254364, acc = 0.9189453125\n",
      "Batch 36: loss = 0.2375667542219162, acc = 0.927734375\n",
      "Batch 37: loss = 0.2227489948272705, acc = 0.9326171875\n",
      "Batch 38: loss = 0.2888023257255554, acc = 0.90625\n",
      "Batch 39: loss = 0.22628600895404816, acc = 0.9326171875\n",
      "Batch 40: loss = 0.24085429310798645, acc = 0.9111328125\n",
      "Batch 41: loss = 0.2921064794063568, acc = 0.90625\n",
      "Batch 42: loss = 0.25955402851104736, acc = 0.90625\n",
      "Batch 43: loss = 0.2773717939853668, acc = 0.9072265625\n",
      "Batch 44: loss = 0.26299217343330383, acc = 0.9169921875\n",
      "Batch 45: loss = 0.23820936679840088, acc = 0.9140625\n",
      "Batch 46: loss = 0.24263785779476166, acc = 0.9140625\n",
      "Batch 47: loss = 0.2574108839035034, acc = 0.9111328125\n",
      "Batch 48: loss = 0.2538438141345978, acc = 0.9189453125\n",
      "Batch 49: loss = 0.25078773498535156, acc = 0.9150390625\n",
      "Batch 50: loss = 0.24820560216903687, acc = 0.9189453125\n",
      "Batch 51: loss = 0.2506163418292999, acc = 0.9140625\n",
      "Batch 52: loss = 0.2833195924758911, acc = 0.8984375\n",
      "Batch 53: loss = 0.26716065406799316, acc = 0.912109375\n",
      "Batch 54: loss = 0.23944124579429626, acc = 0.9228515625\n",
      "Batch 55: loss = 0.26315930485725403, acc = 0.916015625\n",
      "Batch 56: loss = 0.24985484778881073, acc = 0.9072265625\n",
      "Batch 57: loss = 0.29173773527145386, acc = 0.888671875\n",
      "Batch 58: loss = 0.2858738303184509, acc = 0.9033203125\n",
      "Batch 59: loss = 0.21742846071720123, acc = 0.9267578125\n",
      "Batch 60: loss = 0.27532052993774414, acc = 0.8974609375\n",
      "Batch 61: loss = 0.224694162607193, acc = 0.93359375\n",
      "Batch 62: loss = 0.26788878440856934, acc = 0.904296875\n",
      "Batch 63: loss = 0.25484755635261536, acc = 0.9091796875\n",
      "Batch 64: loss = 0.24249494075775146, acc = 0.9267578125\n",
      "Batch 65: loss = 0.24478866159915924, acc = 0.919921875\n",
      "Batch 66: loss = 0.2824168801307678, acc = 0.900390625\n",
      "Batch 67: loss = 0.22436201572418213, acc = 0.923828125\n",
      "Batch 68: loss = 0.2997613549232483, acc = 0.8955078125\n",
      "Batch 69: loss = 0.2332608848810196, acc = 0.923828125\n",
      "Batch 70: loss = 0.26128312945365906, acc = 0.9140625\n",
      "Batch 71: loss = 0.2777360677719116, acc = 0.90234375\n",
      "Batch 72: loss = 0.2504172921180725, acc = 0.912109375\n",
      "Batch 73: loss = 0.2809852063655853, acc = 0.9072265625\n",
      "Batch 74: loss = 0.2844749689102173, acc = 0.89453125\n",
      "Batch 75: loss = 0.3000384569168091, acc = 0.8955078125\n",
      "Batch 76: loss = 0.2711426019668579, acc = 0.9033203125\n",
      "Batch 77: loss = 0.25478395819664, acc = 0.904296875\n",
      "Batch 78: loss = 0.28172916173934937, acc = 0.9052734375\n",
      "Batch 79: loss = 0.2592330873012543, acc = 0.908203125\n",
      "Batch 80: loss = 0.23769567906856537, acc = 0.919921875\n",
      "Batch 81: loss = 0.27849119901657104, acc = 0.90234375\n",
      "Batch 82: loss = 0.24939203262329102, acc = 0.9169921875\n",
      "Batch 83: loss = 0.23172327876091003, acc = 0.919921875\n",
      "Batch 84: loss = 0.30304470658302307, acc = 0.8837890625\n",
      "Batch 85: loss = 0.2898067235946655, acc = 0.908203125\n",
      "Batch 86: loss = 0.2494378387928009, acc = 0.91015625\n",
      "Batch 87: loss = 0.2666872441768646, acc = 0.9013671875\n",
      "Batch 88: loss = 0.32807573676109314, acc = 0.890625\n",
      "Batch 89: loss = 0.26168376207351685, acc = 0.908203125\n",
      "Batch 90: loss = 0.26200157403945923, acc = 0.9140625\n",
      "Batch 91: loss = 0.2648165225982666, acc = 0.912109375\n",
      "Batch 92: loss = 0.2580640912055969, acc = 0.91015625\n",
      "Batch 93: loss = 0.25910329818725586, acc = 0.91015625\n",
      "Batch 94: loss = 0.22011348605155945, acc = 0.9169921875\n",
      "Batch 95: loss = 0.249900221824646, acc = 0.9189453125\n",
      "Batch 96: loss = 0.30720341205596924, acc = 0.9052734375\n",
      "Batch 97: loss = 0.2590380609035492, acc = 0.9091796875\n",
      "Batch 98: loss = 0.2535417675971985, acc = 0.9169921875\n",
      "Batch 99: loss = 0.2547692656517029, acc = 0.9052734375\n",
      "Batch 100: loss = 0.28788474202156067, acc = 0.8974609375\n",
      "Batch 101: loss = 0.24131295084953308, acc = 0.916015625\n",
      "Batch 102: loss = 0.2951642572879791, acc = 0.904296875\n",
      "Batch 103: loss = 0.28607791662216187, acc = 0.9140625\n",
      "Batch 104: loss = 0.2445574402809143, acc = 0.9228515625\n",
      "Batch 105: loss = 0.2208547592163086, acc = 0.921875\n",
      "Batch 106: loss = 0.2649737298488617, acc = 0.904296875\n",
      "Batch 107: loss = 0.24378547072410583, acc = 0.91796875\n",
      "Batch 108: loss = 0.25261780619621277, acc = 0.9130859375\n",
      "Batch 109: loss = 0.2765098214149475, acc = 0.904296875\n",
      "Batch 110: loss = 0.240850567817688, acc = 0.9150390625\n",
      "Batch 111: loss = 0.24025964736938477, acc = 0.912109375\n",
      "Batch 112: loss = 0.23088869452476501, acc = 0.919921875\n",
      "Batch 113: loss = 0.2838534116744995, acc = 0.900390625\n",
      "Batch 114: loss = 0.26888975501060486, acc = 0.9150390625\n",
      "Batch 115: loss = 0.26121485233306885, acc = 0.912109375\n",
      "Batch 116: loss = 0.3028107285499573, acc = 0.8955078125\n",
      "Batch 117: loss = 0.2706114649772644, acc = 0.9189453125\n",
      "Batch 118: loss = 0.24278107285499573, acc = 0.9140625\n",
      "Batch 119: loss = 0.24910736083984375, acc = 0.91015625\n",
      "Batch 120: loss = 0.24984526634216309, acc = 0.91015625\n",
      "Batch 121: loss = 0.24130141735076904, acc = 0.9169921875\n",
      "Batch 122: loss = 0.2149331271648407, acc = 0.9326171875\n",
      "Batch 123: loss = 0.26488834619522095, acc = 0.90234375\n",
      "Batch 124: loss = 0.2717500925064087, acc = 0.9052734375\n",
      "Batch 125: loss = 0.27540457248687744, acc = 0.9052734375\n",
      "Batch 126: loss = 0.2664080262184143, acc = 0.9052734375\n",
      "\n",
      "Epoch 92/100\n",
      "Batch 1: loss = 0.31899362802505493, acc = 0.896484375\n",
      "Batch 2: loss = 0.27445051074028015, acc = 0.91015625\n",
      "Batch 3: loss = 0.29032307863235474, acc = 0.89453125\n",
      "Batch 4: loss = 0.2701008915901184, acc = 0.912109375\n",
      "Batch 5: loss = 0.2337055504322052, acc = 0.927734375\n",
      "Batch 6: loss = 0.28014302253723145, acc = 0.9091796875\n",
      "Batch 7: loss = 0.23292237520217896, acc = 0.923828125\n",
      "Batch 8: loss = 0.25699517130851746, acc = 0.921875\n",
      "Batch 9: loss = 0.24994529783725739, acc = 0.912109375\n",
      "Batch 10: loss = 0.21748864650726318, acc = 0.9189453125\n",
      "Batch 11: loss = 0.26182135939598083, acc = 0.9130859375\n",
      "Batch 12: loss = 0.23592442274093628, acc = 0.9208984375\n",
      "Batch 13: loss = 0.21600407361984253, acc = 0.92578125\n",
      "Batch 14: loss = 0.2500656247138977, acc = 0.921875\n",
      "Batch 15: loss = 0.21619930863380432, acc = 0.9248046875\n",
      "Batch 16: loss = 0.2577536106109619, acc = 0.9150390625\n",
      "Batch 17: loss = 0.25519973039627075, acc = 0.91015625\n",
      "Batch 18: loss = 0.2622629702091217, acc = 0.9033203125\n",
      "Batch 19: loss = 0.2598060369491577, acc = 0.9189453125\n",
      "Batch 20: loss = 0.26518645882606506, acc = 0.904296875\n",
      "Batch 21: loss = 0.2781386375427246, acc = 0.90625\n",
      "Batch 22: loss = 0.2502635717391968, acc = 0.9140625\n",
      "Batch 23: loss = 0.27982380986213684, acc = 0.8994140625\n",
      "Batch 24: loss = 0.25570428371429443, acc = 0.912109375\n",
      "Batch 25: loss = 0.2588551640510559, acc = 0.921875\n",
      "Batch 26: loss = 0.26993680000305176, acc = 0.9140625\n",
      "Batch 27: loss = 0.31712815165519714, acc = 0.8935546875\n",
      "Batch 28: loss = 0.2850089967250824, acc = 0.9072265625\n",
      "Batch 29: loss = 0.28356996178627014, acc = 0.9013671875\n",
      "Batch 30: loss = 0.27239546179771423, acc = 0.912109375\n",
      "Batch 31: loss = 0.25592654943466187, acc = 0.919921875\n",
      "Batch 32: loss = 0.3151858150959015, acc = 0.8974609375\n",
      "Batch 33: loss = 0.2425258904695511, acc = 0.923828125\n",
      "Batch 34: loss = 0.2733423709869385, acc = 0.9130859375\n",
      "Batch 35: loss = 0.2733519673347473, acc = 0.90625\n",
      "Batch 36: loss = 0.2597601115703583, acc = 0.9140625\n",
      "Batch 37: loss = 0.20207418501377106, acc = 0.9306640625\n",
      "Batch 38: loss = 0.22961825132369995, acc = 0.9296875\n",
      "Batch 39: loss = 0.241003155708313, acc = 0.9189453125\n",
      "Batch 40: loss = 0.24877651035785675, acc = 0.916015625\n",
      "Batch 41: loss = 0.23697338998317719, acc = 0.91796875\n",
      "Batch 42: loss = 0.24447792768478394, acc = 0.916015625\n",
      "Batch 43: loss = 0.2641744613647461, acc = 0.908203125\n",
      "Batch 44: loss = 0.2568731904029846, acc = 0.9228515625\n",
      "Batch 45: loss = 0.2402527779340744, acc = 0.9140625\n",
      "Batch 46: loss = 0.272480309009552, acc = 0.9013671875\n",
      "Batch 47: loss = 0.2698625326156616, acc = 0.8974609375\n",
      "Batch 48: loss = 0.23535844683647156, acc = 0.9296875\n",
      "Batch 49: loss = 0.26592105627059937, acc = 0.9150390625\n",
      "Batch 50: loss = 0.26198968291282654, acc = 0.9130859375\n",
      "Batch 51: loss = 0.2134503573179245, acc = 0.9228515625\n",
      "Batch 52: loss = 0.24312713742256165, acc = 0.912109375\n",
      "Batch 53: loss = 0.23192766308784485, acc = 0.92578125\n",
      "Batch 54: loss = 0.2218378186225891, acc = 0.923828125\n",
      "Batch 55: loss = 0.23849737644195557, acc = 0.9150390625\n",
      "Batch 56: loss = 0.23806248605251312, acc = 0.9169921875\n",
      "Batch 57: loss = 0.2827758491039276, acc = 0.9072265625\n",
      "Batch 58: loss = 0.28580930829048157, acc = 0.9072265625\n",
      "Batch 59: loss = 0.20292100310325623, acc = 0.9326171875\n",
      "Batch 60: loss = 0.23099669814109802, acc = 0.9189453125\n",
      "Batch 61: loss = 0.23359447717666626, acc = 0.9248046875\n",
      "Batch 62: loss = 0.28525882959365845, acc = 0.9091796875\n",
      "Batch 63: loss = 0.24808338284492493, acc = 0.9111328125\n",
      "Batch 64: loss = 0.20695477724075317, acc = 0.927734375\n",
      "Batch 65: loss = 0.26745694875717163, acc = 0.90625\n",
      "Batch 66: loss = 0.2885925769805908, acc = 0.9033203125\n",
      "Batch 67: loss = 0.25681179761886597, acc = 0.912109375\n",
      "Batch 68: loss = 0.2588108777999878, acc = 0.912109375\n",
      "Batch 69: loss = 0.23119261860847473, acc = 0.9228515625\n",
      "Batch 70: loss = 0.2758370041847229, acc = 0.9072265625\n",
      "Batch 71: loss = 0.26347941160202026, acc = 0.9150390625\n",
      "Batch 72: loss = 0.2560831606388092, acc = 0.904296875\n",
      "Batch 73: loss = 0.25735408067703247, acc = 0.9150390625\n",
      "Batch 74: loss = 0.2926543056964874, acc = 0.9052734375\n",
      "Batch 75: loss = 0.2912563979625702, acc = 0.8935546875\n",
      "Batch 76: loss = 0.2728084623813629, acc = 0.9013671875\n",
      "Batch 77: loss = 0.24209517240524292, acc = 0.916015625\n",
      "Batch 78: loss = 0.26000136137008667, acc = 0.9052734375\n",
      "Batch 79: loss = 0.2670005261898041, acc = 0.90625\n",
      "Batch 80: loss = 0.2730601131916046, acc = 0.908203125\n",
      "Batch 81: loss = 0.2670208811759949, acc = 0.908203125\n",
      "Batch 82: loss = 0.2738064229488373, acc = 0.9072265625\n",
      "Batch 83: loss = 0.27120673656463623, acc = 0.9013671875\n",
      "Batch 84: loss = 0.2783881723880768, acc = 0.90625\n",
      "Batch 85: loss = 0.25444334745407104, acc = 0.9130859375\n",
      "Batch 86: loss = 0.2567124366760254, acc = 0.91015625\n",
      "Batch 87: loss = 0.2376215159893036, acc = 0.9111328125\n",
      "Batch 88: loss = 0.2815645933151245, acc = 0.90625\n",
      "Batch 89: loss = 0.264387845993042, acc = 0.9130859375\n",
      "Batch 90: loss = 0.2701360583305359, acc = 0.9052734375\n",
      "Batch 91: loss = 0.26619407534599304, acc = 0.9072265625\n",
      "Batch 92: loss = 0.27253854274749756, acc = 0.90234375\n",
      "Batch 93: loss = 0.2636955976486206, acc = 0.9052734375\n",
      "Batch 94: loss = 0.2094138115644455, acc = 0.92578125\n",
      "Batch 95: loss = 0.26435989141464233, acc = 0.9140625\n",
      "Batch 96: loss = 0.27787676453590393, acc = 0.90234375\n",
      "Batch 97: loss = 0.2646123468875885, acc = 0.921875\n",
      "Batch 98: loss = 0.266448438167572, acc = 0.9140625\n",
      "Batch 99: loss = 0.2736967206001282, acc = 0.9013671875\n",
      "Batch 100: loss = 0.2628633677959442, acc = 0.904296875\n",
      "Batch 101: loss = 0.2824327349662781, acc = 0.90234375\n",
      "Batch 102: loss = 0.287831574678421, acc = 0.8984375\n",
      "Batch 103: loss = 0.27410373091697693, acc = 0.90625\n",
      "Batch 104: loss = 0.2221706509590149, acc = 0.9267578125\n",
      "Batch 105: loss = 0.2235282063484192, acc = 0.9326171875\n",
      "Batch 106: loss = 0.2585643529891968, acc = 0.8984375\n",
      "Batch 107: loss = 0.25770264863967896, acc = 0.9189453125\n",
      "Batch 108: loss = 0.24539583921432495, acc = 0.9140625\n",
      "Batch 109: loss = 0.254695326089859, acc = 0.9140625\n",
      "Batch 110: loss = 0.23711998760700226, acc = 0.91796875\n",
      "Batch 111: loss = 0.26038071513175964, acc = 0.9013671875\n",
      "Batch 112: loss = 0.21575438976287842, acc = 0.923828125\n",
      "Batch 113: loss = 0.26695045828819275, acc = 0.912109375\n",
      "Batch 114: loss = 0.28533121943473816, acc = 0.9052734375\n",
      "Batch 115: loss = 0.2573562562465668, acc = 0.91796875\n",
      "Batch 116: loss = 0.26709482073783875, acc = 0.904296875\n",
      "Batch 117: loss = 0.25883591175079346, acc = 0.908203125\n",
      "Batch 118: loss = 0.24261856079101562, acc = 0.9208984375\n",
      "Batch 119: loss = 0.25745177268981934, acc = 0.90625\n",
      "Batch 120: loss = 0.23990659415721893, acc = 0.916015625\n",
      "Batch 121: loss = 0.2629368305206299, acc = 0.9033203125\n",
      "Batch 122: loss = 0.21550869941711426, acc = 0.92578125\n",
      "Batch 123: loss = 0.23584307730197906, acc = 0.916015625\n",
      "Batch 124: loss = 0.2854432463645935, acc = 0.908203125\n",
      "Batch 125: loss = 0.22870337963104248, acc = 0.9189453125\n",
      "Batch 126: loss = 0.2612761855125427, acc = 0.9208984375\n",
      "\n",
      "Epoch 93/100\n",
      "Batch 1: loss = 0.3086963891983032, acc = 0.896484375\n",
      "Batch 2: loss = 0.25123798847198486, acc = 0.9111328125\n",
      "Batch 3: loss = 0.25662437081336975, acc = 0.92578125\n",
      "Batch 4: loss = 0.2926206588745117, acc = 0.9072265625\n",
      "Batch 5: loss = 0.24589863419532776, acc = 0.9248046875\n",
      "Batch 6: loss = 0.3020748496055603, acc = 0.900390625\n",
      "Batch 7: loss = 0.24166035652160645, acc = 0.9169921875\n",
      "Batch 8: loss = 0.29940900206565857, acc = 0.8935546875\n",
      "Batch 9: loss = 0.2419726550579071, acc = 0.919921875\n",
      "Batch 10: loss = 0.23426318168640137, acc = 0.9130859375\n",
      "Batch 11: loss = 0.24410778284072876, acc = 0.9150390625\n",
      "Batch 12: loss = 0.2881149649620056, acc = 0.9072265625\n",
      "Batch 13: loss = 0.2681557238101959, acc = 0.91015625\n",
      "Batch 14: loss = 0.25852516293525696, acc = 0.908203125\n",
      "Batch 15: loss = 0.23146741092205048, acc = 0.9228515625\n",
      "Batch 16: loss = 0.23913836479187012, acc = 0.921875\n",
      "Batch 17: loss = 0.27108895778656006, acc = 0.9150390625\n",
      "Batch 18: loss = 0.28036072850227356, acc = 0.9033203125\n",
      "Batch 19: loss = 0.28064122796058655, acc = 0.904296875\n",
      "Batch 20: loss = 0.277389258146286, acc = 0.9140625\n",
      "Batch 21: loss = 0.24233058094978333, acc = 0.919921875\n",
      "Batch 22: loss = 0.2407076209783554, acc = 0.916015625\n",
      "Batch 23: loss = 0.28086334466934204, acc = 0.9013671875\n",
      "Batch 24: loss = 0.25136566162109375, acc = 0.91015625\n",
      "Batch 25: loss = 0.244283065199852, acc = 0.9228515625\n",
      "Batch 26: loss = 0.26948094367980957, acc = 0.912109375\n",
      "Batch 27: loss = 0.3308212161064148, acc = 0.8916015625\n",
      "Batch 28: loss = 0.2804342210292816, acc = 0.8984375\n",
      "Batch 29: loss = 0.25251710414886475, acc = 0.9130859375\n",
      "Batch 30: loss = 0.277817964553833, acc = 0.904296875\n",
      "Batch 31: loss = 0.2558140754699707, acc = 0.9150390625\n",
      "Batch 32: loss = 0.2583984434604645, acc = 0.9111328125\n",
      "Batch 33: loss = 0.25297707319259644, acc = 0.9130859375\n",
      "Batch 34: loss = 0.3024284839630127, acc = 0.8857421875\n",
      "Batch 35: loss = 0.2700865864753723, acc = 0.91015625\n",
      "Batch 36: loss = 0.24543213844299316, acc = 0.919921875\n",
      "Batch 37: loss = 0.2411012202501297, acc = 0.923828125\n",
      "Batch 38: loss = 0.25760865211486816, acc = 0.921875\n",
      "Batch 39: loss = 0.22100821137428284, acc = 0.935546875\n",
      "Batch 40: loss = 0.2383866310119629, acc = 0.9228515625\n",
      "Batch 41: loss = 0.2266336977481842, acc = 0.92578125\n",
      "Batch 42: loss = 0.24625249207019806, acc = 0.912109375\n",
      "Batch 43: loss = 0.2707967758178711, acc = 0.90625\n",
      "Batch 44: loss = 0.22999614477157593, acc = 0.9267578125\n",
      "Batch 45: loss = 0.251969575881958, acc = 0.916015625\n",
      "Batch 46: loss = 0.25122326612472534, acc = 0.9150390625\n",
      "Batch 47: loss = 0.2999543845653534, acc = 0.9052734375\n",
      "Batch 48: loss = 0.25185441970825195, acc = 0.921875\n",
      "Batch 49: loss = 0.2624225616455078, acc = 0.91796875\n",
      "Batch 50: loss = 0.2503005266189575, acc = 0.9150390625\n",
      "Batch 51: loss = 0.2387366145849228, acc = 0.912109375\n",
      "Batch 52: loss = 0.27702152729034424, acc = 0.90625\n",
      "Batch 53: loss = 0.22108449041843414, acc = 0.931640625\n",
      "Batch 54: loss = 0.16813182830810547, acc = 0.9404296875\n",
      "Batch 55: loss = 0.28385812044143677, acc = 0.9033203125\n",
      "Batch 56: loss = 0.24879947304725647, acc = 0.9140625\n",
      "Batch 57: loss = 0.28678613901138306, acc = 0.90234375\n",
      "Batch 58: loss = 0.2721877694129944, acc = 0.9052734375\n",
      "Batch 59: loss = 0.23210665583610535, acc = 0.916015625\n",
      "Batch 60: loss = 0.2576220631599426, acc = 0.9091796875\n",
      "Batch 61: loss = 0.25637421011924744, acc = 0.908203125\n",
      "Batch 62: loss = 0.2864064574241638, acc = 0.90234375\n",
      "Batch 63: loss = 0.26416975259780884, acc = 0.9111328125\n",
      "Batch 64: loss = 0.21846376359462738, acc = 0.9208984375\n",
      "Batch 65: loss = 0.28371456265449524, acc = 0.908203125\n",
      "Batch 66: loss = 0.2701777219772339, acc = 0.9140625\n",
      "Batch 67: loss = 0.25856778025627136, acc = 0.9228515625\n",
      "Batch 68: loss = 0.2720003128051758, acc = 0.9033203125\n",
      "Batch 69: loss = 0.2324748933315277, acc = 0.919921875\n",
      "Batch 70: loss = 0.2641237676143646, acc = 0.8984375\n",
      "Batch 71: loss = 0.29351839423179626, acc = 0.892578125\n",
      "Batch 72: loss = 0.23239684104919434, acc = 0.916015625\n",
      "Batch 73: loss = 0.24282804131507874, acc = 0.921875\n",
      "Batch 74: loss = 0.27137717604637146, acc = 0.9033203125\n",
      "Batch 75: loss = 0.28774189949035645, acc = 0.908203125\n",
      "Batch 76: loss = 0.2899051308631897, acc = 0.8935546875\n",
      "Batch 77: loss = 0.2399333119392395, acc = 0.927734375\n",
      "Batch 78: loss = 0.2601321041584015, acc = 0.9111328125\n",
      "Batch 79: loss = 0.2591068744659424, acc = 0.9111328125\n",
      "Batch 80: loss = 0.2481318861246109, acc = 0.9228515625\n",
      "Batch 81: loss = 0.2777670919895172, acc = 0.90234375\n",
      "Batch 82: loss = 0.2526025176048279, acc = 0.919921875\n",
      "Batch 83: loss = 0.22725720703601837, acc = 0.9248046875\n",
      "Batch 84: loss = 0.26508936285972595, acc = 0.9130859375\n",
      "Batch 85: loss = 0.2677888870239258, acc = 0.908203125\n",
      "Batch 86: loss = 0.26086729764938354, acc = 0.9140625\n",
      "Batch 87: loss = 0.23771430552005768, acc = 0.923828125\n",
      "Batch 88: loss = 0.2722013592720032, acc = 0.9052734375\n",
      "Batch 89: loss = 0.21954819560050964, acc = 0.919921875\n",
      "Batch 90: loss = 0.24487657845020294, acc = 0.919921875\n",
      "Batch 91: loss = 0.2567008137702942, acc = 0.90625\n",
      "Batch 92: loss = 0.2605678141117096, acc = 0.9130859375\n",
      "Batch 93: loss = 0.25728657841682434, acc = 0.9130859375\n",
      "Batch 94: loss = 0.21181273460388184, acc = 0.9248046875\n",
      "Batch 95: loss = 0.23809026181697845, acc = 0.9130859375\n",
      "Batch 96: loss = 0.26222652196884155, acc = 0.9189453125\n",
      "Batch 97: loss = 0.2488318383693695, acc = 0.91015625\n",
      "Batch 98: loss = 0.23125392198562622, acc = 0.9150390625\n",
      "Batch 99: loss = 0.2836163341999054, acc = 0.9013671875\n",
      "Batch 100: loss = 0.22711771726608276, acc = 0.921875\n",
      "Batch 101: loss = 0.2577153742313385, acc = 0.9072265625\n",
      "Batch 102: loss = 0.2654322683811188, acc = 0.90234375\n",
      "Batch 103: loss = 0.2554659843444824, acc = 0.9169921875\n",
      "Batch 104: loss = 0.2253105491399765, acc = 0.9208984375\n",
      "Batch 105: loss = 0.23929323256015778, acc = 0.908203125\n",
      "Batch 106: loss = 0.23491153120994568, acc = 0.9228515625\n",
      "Batch 107: loss = 0.2179228514432907, acc = 0.9208984375\n",
      "Batch 108: loss = 0.25581881403923035, acc = 0.912109375\n",
      "Batch 109: loss = 0.2532336711883545, acc = 0.912109375\n",
      "Batch 110: loss = 0.24395650625228882, acc = 0.92578125\n",
      "Batch 111: loss = 0.22718966007232666, acc = 0.9208984375\n",
      "Batch 112: loss = 0.23775091767311096, acc = 0.9140625\n",
      "Batch 113: loss = 0.24551555514335632, acc = 0.9189453125\n",
      "Batch 114: loss = 0.26653581857681274, acc = 0.9130859375\n",
      "Batch 115: loss = 0.2534824013710022, acc = 0.9208984375\n",
      "Batch 116: loss = 0.2635333240032196, acc = 0.91015625\n",
      "Batch 117: loss = 0.25112640857696533, acc = 0.912109375\n",
      "Batch 118: loss = 0.2370050847530365, acc = 0.921875\n",
      "Batch 119: loss = 0.22498096525669098, acc = 0.9228515625\n",
      "Batch 120: loss = 0.2190706431865692, acc = 0.916015625\n",
      "Batch 121: loss = 0.25364935398101807, acc = 0.9052734375\n",
      "Batch 122: loss = 0.22479061782360077, acc = 0.927734375\n",
      "Batch 123: loss = 0.23347805440425873, acc = 0.93359375\n",
      "Batch 124: loss = 0.2804683446884155, acc = 0.90234375\n",
      "Batch 125: loss = 0.26425009965896606, acc = 0.9169921875\n",
      "Batch 126: loss = 0.25958967208862305, acc = 0.919921875\n",
      "\n",
      "Epoch 94/100\n",
      "Batch 1: loss = 0.3298574984073639, acc = 0.89453125\n",
      "Batch 2: loss = 0.24499209225177765, acc = 0.9091796875\n",
      "Batch 3: loss = 0.23942831158638, acc = 0.9189453125\n",
      "Batch 4: loss = 0.23965182900428772, acc = 0.9228515625\n",
      "Batch 5: loss = 0.23461727797985077, acc = 0.923828125\n",
      "Batch 6: loss = 0.258470356464386, acc = 0.9111328125\n",
      "Batch 7: loss = 0.2644313871860504, acc = 0.912109375\n",
      "Batch 8: loss = 0.2566167116165161, acc = 0.9111328125\n",
      "Batch 9: loss = 0.2511352002620697, acc = 0.919921875\n",
      "Batch 10: loss = 0.226993128657341, acc = 0.9306640625\n",
      "Batch 11: loss = 0.22548575699329376, acc = 0.9208984375\n",
      "Batch 12: loss = 0.27630460262298584, acc = 0.912109375\n",
      "Batch 13: loss = 0.26040905714035034, acc = 0.90625\n",
      "Batch 14: loss = 0.2353213131427765, acc = 0.9267578125\n",
      "Batch 15: loss = 0.24709531664848328, acc = 0.9287109375\n",
      "Batch 16: loss = 0.2519962787628174, acc = 0.9169921875\n",
      "Batch 17: loss = 0.2491839975118637, acc = 0.923828125\n",
      "Batch 18: loss = 0.26302623748779297, acc = 0.9130859375\n",
      "Batch 19: loss = 0.2474050521850586, acc = 0.9140625\n",
      "Batch 20: loss = 0.257992148399353, acc = 0.9208984375\n",
      "Batch 21: loss = 0.2694110572338104, acc = 0.9111328125\n",
      "Batch 22: loss = 0.24714264273643494, acc = 0.916015625\n",
      "Batch 23: loss = 0.265409380197525, acc = 0.9169921875\n",
      "Batch 24: loss = 0.23927931487560272, acc = 0.9228515625\n",
      "Batch 25: loss = 0.2576255798339844, acc = 0.91015625\n",
      "Batch 26: loss = 0.2545369863510132, acc = 0.9189453125\n",
      "Batch 27: loss = 0.2841854691505432, acc = 0.90234375\n",
      "Batch 28: loss = 0.24392184615135193, acc = 0.9150390625\n",
      "Batch 29: loss = 0.25857576727867126, acc = 0.90625\n",
      "Batch 30: loss = 0.2714604139328003, acc = 0.90234375\n",
      "Batch 31: loss = 0.25486239790916443, acc = 0.912109375\n",
      "Batch 32: loss = 0.25471949577331543, acc = 0.9150390625\n",
      "Batch 33: loss = 0.25994372367858887, acc = 0.912109375\n",
      "Batch 34: loss = 0.28857505321502686, acc = 0.900390625\n",
      "Batch 35: loss = 0.25383254885673523, acc = 0.9169921875\n",
      "Batch 36: loss = 0.20152729749679565, acc = 0.9287109375\n",
      "Batch 37: loss = 0.194495290517807, acc = 0.9345703125\n",
      "Batch 38: loss = 0.2418440878391266, acc = 0.9208984375\n",
      "Batch 39: loss = 0.2259531319141388, acc = 0.9267578125\n",
      "Batch 40: loss = 0.24377086758613586, acc = 0.91015625\n",
      "Batch 41: loss = 0.24472513794898987, acc = 0.9189453125\n",
      "Batch 42: loss = 0.2450939267873764, acc = 0.9208984375\n",
      "Batch 43: loss = 0.275511234998703, acc = 0.8994140625\n",
      "Batch 44: loss = 0.24557283520698547, acc = 0.923828125\n",
      "Batch 45: loss = 0.24978859722614288, acc = 0.9287109375\n",
      "Batch 46: loss = 0.22654175758361816, acc = 0.923828125\n",
      "Batch 47: loss = 0.25846484303474426, acc = 0.90625\n",
      "Batch 48: loss = 0.25906458497047424, acc = 0.916015625\n",
      "Batch 49: loss = 0.24487629532814026, acc = 0.9208984375\n",
      "Batch 50: loss = 0.23008131980895996, acc = 0.923828125\n",
      "Batch 51: loss = 0.23115073144435883, acc = 0.9169921875\n",
      "Batch 52: loss = 0.23860879242420197, acc = 0.9248046875\n",
      "Batch 53: loss = 0.26438838243484497, acc = 0.908203125\n",
      "Batch 54: loss = 0.17607182264328003, acc = 0.935546875\n",
      "Batch 55: loss = 0.2549966275691986, acc = 0.908203125\n",
      "Batch 56: loss = 0.2375825196504593, acc = 0.923828125\n",
      "Batch 57: loss = 0.27597469091415405, acc = 0.8974609375\n",
      "Batch 58: loss = 0.2851998209953308, acc = 0.9052734375\n",
      "Batch 59: loss = 0.20047618448734283, acc = 0.93359375\n",
      "Batch 60: loss = 0.269121915102005, acc = 0.90625\n",
      "Batch 61: loss = 0.2616029381752014, acc = 0.9130859375\n",
      "Batch 62: loss = 0.2777062654495239, acc = 0.9072265625\n",
      "Batch 63: loss = 0.24265721440315247, acc = 0.9150390625\n",
      "Batch 64: loss = 0.219233900308609, acc = 0.9296875\n",
      "Batch 65: loss = 0.25157180428504944, acc = 0.9072265625\n",
      "Batch 66: loss = 0.2604103982448578, acc = 0.9150390625\n",
      "Batch 67: loss = 0.2687585949897766, acc = 0.9091796875\n",
      "Batch 68: loss = 0.29534196853637695, acc = 0.9033203125\n",
      "Batch 69: loss = 0.23516429960727692, acc = 0.921875\n",
      "Batch 70: loss = 0.266711950302124, acc = 0.916015625\n",
      "Batch 71: loss = 0.2627066969871521, acc = 0.9072265625\n",
      "Batch 72: loss = 0.2499254196882248, acc = 0.9228515625\n",
      "Batch 73: loss = 0.2898152768611908, acc = 0.89453125\n",
      "Batch 74: loss = 0.27672022581100464, acc = 0.900390625\n",
      "Batch 75: loss = 0.2831161320209503, acc = 0.9052734375\n",
      "Batch 76: loss = 0.25711938738822937, acc = 0.912109375\n",
      "Batch 77: loss = 0.24307827651500702, acc = 0.9169921875\n",
      "Batch 78: loss = 0.24810990691184998, acc = 0.9208984375\n",
      "Batch 79: loss = 0.2429809868335724, acc = 0.90625\n",
      "Batch 80: loss = 0.2231200486421585, acc = 0.9296875\n",
      "Batch 81: loss = 0.23586997389793396, acc = 0.9228515625\n",
      "Batch 82: loss = 0.2671842575073242, acc = 0.90625\n",
      "Batch 83: loss = 0.23878565430641174, acc = 0.9150390625\n",
      "Batch 84: loss = 0.2675527036190033, acc = 0.912109375\n",
      "Batch 85: loss = 0.26493513584136963, acc = 0.908203125\n",
      "Batch 86: loss = 0.25586017966270447, acc = 0.9111328125\n",
      "Batch 87: loss = 0.25889134407043457, acc = 0.919921875\n",
      "Batch 88: loss = 0.2760942578315735, acc = 0.91015625\n",
      "Batch 89: loss = 0.24021108448505402, acc = 0.912109375\n",
      "Batch 90: loss = 0.2362050563097, acc = 0.923828125\n",
      "Batch 91: loss = 0.26696309447288513, acc = 0.908203125\n",
      "Batch 92: loss = 0.2654206156730652, acc = 0.9072265625\n",
      "Batch 93: loss = 0.23525068163871765, acc = 0.91796875\n",
      "Batch 94: loss = 0.2127520889043808, acc = 0.916015625\n",
      "Batch 95: loss = 0.222781702876091, acc = 0.92578125\n",
      "Batch 96: loss = 0.242070734500885, acc = 0.9169921875\n",
      "Batch 97: loss = 0.22902971506118774, acc = 0.9267578125\n",
      "Batch 98: loss = 0.22858630120754242, acc = 0.9248046875\n",
      "Batch 99: loss = 0.26639169454574585, acc = 0.90625\n",
      "Batch 100: loss = 0.2285001575946808, acc = 0.9228515625\n",
      "Batch 101: loss = 0.2220105677843094, acc = 0.9169921875\n",
      "Batch 102: loss = 0.26847681403160095, acc = 0.9111328125\n",
      "Batch 103: loss = 0.25778910517692566, acc = 0.9169921875\n",
      "Batch 104: loss = 0.24456359446048737, acc = 0.923828125\n",
      "Batch 105: loss = 0.2461952418088913, acc = 0.9248046875\n",
      "Batch 106: loss = 0.24812650680541992, acc = 0.9111328125\n",
      "Batch 107: loss = 0.2584046721458435, acc = 0.904296875\n",
      "Batch 108: loss = 0.23040665686130524, acc = 0.9228515625\n",
      "Batch 109: loss = 0.2502530515193939, acc = 0.91015625\n",
      "Batch 110: loss = 0.26808738708496094, acc = 0.916015625\n",
      "Batch 111: loss = 0.2535969018936157, acc = 0.9140625\n",
      "Batch 112: loss = 0.23589177429676056, acc = 0.9169921875\n",
      "Batch 113: loss = 0.24510493874549866, acc = 0.9140625\n",
      "Batch 114: loss = 0.2785288691520691, acc = 0.9072265625\n",
      "Batch 115: loss = 0.27116310596466064, acc = 0.908203125\n",
      "Batch 116: loss = 0.26035577058792114, acc = 0.908203125\n",
      "Batch 117: loss = 0.24513843655586243, acc = 0.9248046875\n",
      "Batch 118: loss = 0.2482469081878662, acc = 0.9169921875\n",
      "Batch 119: loss = 0.24615098536014557, acc = 0.9169921875\n",
      "Batch 120: loss = 0.20237506926059723, acc = 0.927734375\n",
      "Batch 121: loss = 0.23238375782966614, acc = 0.9267578125\n",
      "Batch 122: loss = 0.22263693809509277, acc = 0.9248046875\n",
      "Batch 123: loss = 0.26594576239585876, acc = 0.9130859375\n",
      "Batch 124: loss = 0.2509279251098633, acc = 0.916015625\n",
      "Batch 125: loss = 0.24918612837791443, acc = 0.916015625\n",
      "Batch 126: loss = 0.24341341853141785, acc = 0.912109375\n",
      "\n",
      "Epoch 95/100\n",
      "Batch 1: loss = 0.2897188663482666, acc = 0.9013671875\n",
      "Batch 2: loss = 0.27931421995162964, acc = 0.9091796875\n",
      "Batch 3: loss = 0.259073406457901, acc = 0.9150390625\n",
      "Batch 4: loss = 0.27553045749664307, acc = 0.9013671875\n",
      "Batch 5: loss = 0.2157914936542511, acc = 0.9296875\n",
      "Batch 6: loss = 0.2725204527378082, acc = 0.9091796875\n",
      "Batch 7: loss = 0.273272305727005, acc = 0.91015625\n",
      "Batch 8: loss = 0.2544947862625122, acc = 0.9169921875\n",
      "Batch 9: loss = 0.2698144316673279, acc = 0.90625\n",
      "Batch 10: loss = 0.25410181283950806, acc = 0.9111328125\n",
      "Batch 11: loss = 0.24160902202129364, acc = 0.91796875\n",
      "Batch 12: loss = 0.26497316360473633, acc = 0.8994140625\n",
      "Batch 13: loss = 0.25317901372909546, acc = 0.9189453125\n",
      "Batch 14: loss = 0.25055742263793945, acc = 0.919921875\n",
      "Batch 15: loss = 0.2456953227519989, acc = 0.9248046875\n",
      "Batch 16: loss = 0.26337236166000366, acc = 0.91796875\n",
      "Batch 17: loss = 0.23355454206466675, acc = 0.9111328125\n",
      "Batch 18: loss = 0.2643944025039673, acc = 0.9189453125\n",
      "Batch 19: loss = 0.26181113719940186, acc = 0.919921875\n",
      "Batch 20: loss = 0.2545742094516754, acc = 0.916015625\n",
      "Batch 21: loss = 0.25118714570999146, acc = 0.9130859375\n",
      "Batch 22: loss = 0.2600453794002533, acc = 0.904296875\n",
      "Batch 23: loss = 0.269677996635437, acc = 0.91015625\n",
      "Batch 24: loss = 0.23747003078460693, acc = 0.9248046875\n",
      "Batch 25: loss = 0.24426275491714478, acc = 0.92578125\n",
      "Batch 26: loss = 0.2554573118686676, acc = 0.9140625\n",
      "Batch 27: loss = 0.28361356258392334, acc = 0.8974609375\n",
      "Batch 28: loss = 0.27272629737854004, acc = 0.91015625\n",
      "Batch 29: loss = 0.2685040235519409, acc = 0.9140625\n",
      "Batch 30: loss = 0.22219257056713104, acc = 0.9189453125\n",
      "Batch 31: loss = 0.24589961767196655, acc = 0.9140625\n",
      "Batch 32: loss = 0.26900720596313477, acc = 0.908203125\n",
      "Batch 33: loss = 0.22618453204631805, acc = 0.9287109375\n",
      "Batch 34: loss = 0.2886921763420105, acc = 0.908203125\n",
      "Batch 35: loss = 0.2513422966003418, acc = 0.9248046875\n",
      "Batch 36: loss = 0.22702257335186005, acc = 0.9208984375\n",
      "Batch 37: loss = 0.20211553573608398, acc = 0.9326171875\n",
      "Batch 38: loss = 0.23828034102916718, acc = 0.9267578125\n",
      "Batch 39: loss = 0.24862021207809448, acc = 0.919921875\n",
      "Batch 40: loss = 0.23821020126342773, acc = 0.91796875\n",
      "Batch 41: loss = 0.23158405721187592, acc = 0.9248046875\n",
      "Batch 42: loss = 0.27778494358062744, acc = 0.8916015625\n",
      "Batch 43: loss = 0.26464593410491943, acc = 0.90625\n",
      "Batch 44: loss = 0.2596226930618286, acc = 0.9189453125\n",
      "Batch 45: loss = 0.23577995598316193, acc = 0.927734375\n",
      "Batch 46: loss = 0.2178967297077179, acc = 0.9287109375\n",
      "Batch 47: loss = 0.24246278405189514, acc = 0.921875\n",
      "Batch 48: loss = 0.21988661587238312, acc = 0.9189453125\n",
      "Batch 49: loss = 0.2457907497882843, acc = 0.9169921875\n",
      "Batch 50: loss = 0.23540657758712769, acc = 0.923828125\n",
      "Batch 51: loss = 0.2343721240758896, acc = 0.916015625\n",
      "Batch 52: loss = 0.2574605941772461, acc = 0.900390625\n",
      "Batch 53: loss = 0.23827221989631653, acc = 0.9228515625\n",
      "Batch 54: loss = 0.23898686468601227, acc = 0.912109375\n",
      "Batch 55: loss = 0.23639672994613647, acc = 0.9306640625\n",
      "Batch 56: loss = 0.26653343439102173, acc = 0.9189453125\n",
      "Batch 57: loss = 0.3305876553058624, acc = 0.8837890625\n",
      "Batch 58: loss = 0.2848854660987854, acc = 0.8955078125\n",
      "Batch 59: loss = 0.2221645712852478, acc = 0.9228515625\n",
      "Batch 60: loss = 0.2647610008716583, acc = 0.908203125\n",
      "Batch 61: loss = 0.23585014045238495, acc = 0.9208984375\n",
      "Batch 62: loss = 0.2546103298664093, acc = 0.9169921875\n",
      "Batch 63: loss = 0.2655234634876251, acc = 0.9091796875\n",
      "Batch 64: loss = 0.22059273719787598, acc = 0.927734375\n",
      "Batch 65: loss = 0.24517789483070374, acc = 0.919921875\n",
      "Batch 66: loss = 0.21652661263942719, acc = 0.927734375\n",
      "Batch 67: loss = 0.258970707654953, acc = 0.919921875\n",
      "Batch 68: loss = 0.26754283905029297, acc = 0.9072265625\n",
      "Batch 69: loss = 0.26374220848083496, acc = 0.91015625\n",
      "Batch 70: loss = 0.25759586691856384, acc = 0.919921875\n",
      "Batch 71: loss = 0.25784337520599365, acc = 0.9150390625\n",
      "Batch 72: loss = 0.25544172525405884, acc = 0.9140625\n",
      "Batch 73: loss = 0.28951215744018555, acc = 0.90234375\n",
      "Batch 74: loss = 0.2870844602584839, acc = 0.904296875\n",
      "Batch 75: loss = 0.28485673666000366, acc = 0.90625\n",
      "Batch 76: loss = 0.26117271184921265, acc = 0.9140625\n",
      "Batch 77: loss = 0.24631942808628082, acc = 0.91015625\n",
      "Batch 78: loss = 0.28486382961273193, acc = 0.8984375\n",
      "Batch 79: loss = 0.21540604531764984, acc = 0.9326171875\n",
      "Batch 80: loss = 0.20888790488243103, acc = 0.92578125\n",
      "Batch 81: loss = 0.25804412364959717, acc = 0.9072265625\n",
      "Batch 82: loss = 0.2717544436454773, acc = 0.904296875\n",
      "Batch 83: loss = 0.24824249744415283, acc = 0.9150390625\n",
      "Batch 84: loss = 0.23202069103717804, acc = 0.916015625\n",
      "Batch 85: loss = 0.24256590008735657, acc = 0.9130859375\n",
      "Batch 86: loss = 0.23712491989135742, acc = 0.9267578125\n",
      "Batch 87: loss = 0.24179714918136597, acc = 0.91796875\n",
      "Batch 88: loss = 0.2705124020576477, acc = 0.90234375\n",
      "Batch 89: loss = 0.23571494221687317, acc = 0.923828125\n",
      "Batch 90: loss = 0.25702664256095886, acc = 0.9111328125\n",
      "Batch 91: loss = 0.2432640790939331, acc = 0.9111328125\n",
      "Batch 92: loss = 0.27848532795906067, acc = 0.8984375\n",
      "Batch 93: loss = 0.2551155984401703, acc = 0.9091796875\n",
      "Batch 94: loss = 0.2115563452243805, acc = 0.9228515625\n",
      "Batch 95: loss = 0.22917108237743378, acc = 0.9228515625\n",
      "Batch 96: loss = 0.23436503112316132, acc = 0.9140625\n",
      "Batch 97: loss = 0.2700524628162384, acc = 0.9091796875\n",
      "Batch 98: loss = 0.24859508872032166, acc = 0.916015625\n",
      "Batch 99: loss = 0.24484170973300934, acc = 0.91796875\n",
      "Batch 100: loss = 0.27660179138183594, acc = 0.9111328125\n",
      "Batch 101: loss = 0.25683602690696716, acc = 0.9091796875\n",
      "Batch 102: loss = 0.26449528336524963, acc = 0.9111328125\n",
      "Batch 103: loss = 0.2560625970363617, acc = 0.9130859375\n",
      "Batch 104: loss = 0.23278886079788208, acc = 0.9287109375\n",
      "Batch 105: loss = 0.2345687299966812, acc = 0.9169921875\n",
      "Batch 106: loss = 0.2536459267139435, acc = 0.90625\n",
      "Batch 107: loss = 0.2590046525001526, acc = 0.9130859375\n",
      "Batch 108: loss = 0.22848819196224213, acc = 0.92578125\n",
      "Batch 109: loss = 0.24478335678577423, acc = 0.9130859375\n",
      "Batch 110: loss = 0.23079733550548553, acc = 0.921875\n",
      "Batch 111: loss = 0.2387717068195343, acc = 0.91796875\n",
      "Batch 112: loss = 0.2256215661764145, acc = 0.923828125\n",
      "Batch 113: loss = 0.23619170486927032, acc = 0.9228515625\n",
      "Batch 114: loss = 0.2580016255378723, acc = 0.91015625\n",
      "Batch 115: loss = 0.2620713710784912, acc = 0.9072265625\n",
      "Batch 116: loss = 0.27504122257232666, acc = 0.91015625\n",
      "Batch 117: loss = 0.23903271555900574, acc = 0.921875\n",
      "Batch 118: loss = 0.26287010312080383, acc = 0.9111328125\n",
      "Batch 119: loss = 0.2362940013408661, acc = 0.923828125\n",
      "Batch 120: loss = 0.22329728305339813, acc = 0.9208984375\n",
      "Batch 121: loss = 0.2544681131839752, acc = 0.916015625\n",
      "Batch 122: loss = 0.23857185244560242, acc = 0.9169921875\n",
      "Batch 123: loss = 0.23359733819961548, acc = 0.923828125\n",
      "Batch 124: loss = 0.29372134804725647, acc = 0.9013671875\n",
      "Batch 125: loss = 0.2637087404727936, acc = 0.916015625\n",
      "Batch 126: loss = 0.2847253978252411, acc = 0.8955078125\n",
      "\n",
      "Epoch 96/100\n",
      "Batch 1: loss = 0.31801581382751465, acc = 0.8984375\n",
      "Batch 2: loss = 0.2561367452144623, acc = 0.91796875\n",
      "Batch 3: loss = 0.2575438618659973, acc = 0.919921875\n",
      "Batch 4: loss = 0.25631600618362427, acc = 0.9169921875\n",
      "Batch 5: loss = 0.21866217255592346, acc = 0.9267578125\n",
      "Batch 6: loss = 0.2651987075805664, acc = 0.916015625\n",
      "Batch 7: loss = 0.22260822355747223, acc = 0.921875\n",
      "Batch 8: loss = 0.24875813722610474, acc = 0.916015625\n",
      "Batch 9: loss = 0.24607549607753754, acc = 0.91015625\n",
      "Batch 10: loss = 0.2191152721643448, acc = 0.9228515625\n",
      "Batch 11: loss = 0.2347618192434311, acc = 0.916015625\n",
      "Batch 12: loss = 0.25297439098358154, acc = 0.9130859375\n",
      "Batch 13: loss = 0.25812751054763794, acc = 0.9130859375\n",
      "Batch 14: loss = 0.24338290095329285, acc = 0.9306640625\n",
      "Batch 15: loss = 0.24265740811824799, acc = 0.9267578125\n",
      "Batch 16: loss = 0.2775516211986542, acc = 0.8994140625\n",
      "Batch 17: loss = 0.2634686231613159, acc = 0.9150390625\n",
      "Batch 18: loss = 0.2350679486989975, acc = 0.916015625\n",
      "Batch 19: loss = 0.2573357820510864, acc = 0.9150390625\n",
      "Batch 20: loss = 0.2743651270866394, acc = 0.912109375\n",
      "Batch 21: loss = 0.2680901288986206, acc = 0.9033203125\n",
      "Batch 22: loss = 0.22915981709957123, acc = 0.9189453125\n",
      "Batch 23: loss = 0.2594258487224579, acc = 0.9169921875\n",
      "Batch 24: loss = 0.2510286867618561, acc = 0.916015625\n",
      "Batch 25: loss = 0.24917489290237427, acc = 0.923828125\n",
      "Batch 26: loss = 0.23784923553466797, acc = 0.921875\n",
      "Batch 27: loss = 0.3028916120529175, acc = 0.90625\n",
      "Batch 28: loss = 0.25710436701774597, acc = 0.91015625\n",
      "Batch 29: loss = 0.24458496272563934, acc = 0.9111328125\n",
      "Batch 30: loss = 0.2548736035823822, acc = 0.90234375\n",
      "Batch 31: loss = 0.2372792363166809, acc = 0.919921875\n",
      "Batch 32: loss = 0.26803484559059143, acc = 0.90625\n",
      "Batch 33: loss = 0.22603318095207214, acc = 0.9208984375\n",
      "Batch 34: loss = 0.26856571435928345, acc = 0.912109375\n",
      "Batch 35: loss = 0.2540144920349121, acc = 0.9150390625\n",
      "Batch 36: loss = 0.22281774878501892, acc = 0.927734375\n",
      "Batch 37: loss = 0.1799115389585495, acc = 0.939453125\n",
      "Batch 38: loss = 0.24830162525177002, acc = 0.9140625\n",
      "Batch 39: loss = 0.2442113161087036, acc = 0.9208984375\n",
      "Batch 40: loss = 0.23397360742092133, acc = 0.9326171875\n",
      "Batch 41: loss = 0.24572746455669403, acc = 0.90625\n",
      "Batch 42: loss = 0.24023525416851044, acc = 0.9189453125\n",
      "Batch 43: loss = 0.2589821517467499, acc = 0.9189453125\n",
      "Batch 44: loss = 0.23403745889663696, acc = 0.923828125\n",
      "Batch 45: loss = 0.21648377180099487, acc = 0.92578125\n",
      "Batch 46: loss = 0.24605035781860352, acc = 0.9169921875\n",
      "Batch 47: loss = 0.2768976092338562, acc = 0.9033203125\n",
      "Batch 48: loss = 0.2325746864080429, acc = 0.916015625\n",
      "Batch 49: loss = 0.21443241834640503, acc = 0.923828125\n",
      "Batch 50: loss = 0.25221705436706543, acc = 0.9189453125\n",
      "Batch 51: loss = 0.20792117714881897, acc = 0.9296875\n",
      "Batch 52: loss = 0.2888035476207733, acc = 0.904296875\n",
      "Batch 53: loss = 0.24889972805976868, acc = 0.9130859375\n",
      "Batch 54: loss = 0.21428662538528442, acc = 0.9208984375\n",
      "Batch 55: loss = 0.2541390359401703, acc = 0.9169921875\n",
      "Batch 56: loss = 0.24847657978534698, acc = 0.9130859375\n",
      "Batch 57: loss = 0.2676611840724945, acc = 0.9140625\n",
      "Batch 58: loss = 0.2638503313064575, acc = 0.9033203125\n",
      "Batch 59: loss = 0.22587423026561737, acc = 0.927734375\n",
      "Batch 60: loss = 0.2630733847618103, acc = 0.9091796875\n",
      "Batch 61: loss = 0.23046861588954926, acc = 0.923828125\n",
      "Batch 62: loss = 0.2667158842086792, acc = 0.9111328125\n",
      "Batch 63: loss = 0.25953686237335205, acc = 0.912109375\n",
      "Batch 64: loss = 0.21878837049007416, acc = 0.931640625\n",
      "Batch 65: loss = 0.23422537744045258, acc = 0.921875\n",
      "Batch 66: loss = 0.2673220932483673, acc = 0.9140625\n",
      "Batch 67: loss = 0.24980980157852173, acc = 0.9140625\n",
      "Batch 68: loss = 0.27034756541252136, acc = 0.9091796875\n",
      "Batch 69: loss = 0.2188728302717209, acc = 0.9296875\n",
      "Batch 70: loss = 0.263616144657135, acc = 0.91015625\n",
      "Batch 71: loss = 0.26218587160110474, acc = 0.912109375\n",
      "Batch 72: loss = 0.21646687388420105, acc = 0.9267578125\n",
      "Batch 73: loss = 0.2511126399040222, acc = 0.9072265625\n",
      "Batch 74: loss = 0.29152944684028625, acc = 0.9072265625\n",
      "Batch 75: loss = 0.28913938999176025, acc = 0.8955078125\n",
      "Batch 76: loss = 0.25398823618888855, acc = 0.919921875\n",
      "Batch 77: loss = 0.24277031421661377, acc = 0.9208984375\n",
      "Batch 78: loss = 0.2597951292991638, acc = 0.9130859375\n",
      "Batch 79: loss = 0.23027774691581726, acc = 0.923828125\n",
      "Batch 80: loss = 0.2363758236169815, acc = 0.9248046875\n",
      "Batch 81: loss = 0.2643275558948517, acc = 0.904296875\n",
      "Batch 82: loss = 0.2374841272830963, acc = 0.9169921875\n",
      "Batch 83: loss = 0.21662764251232147, acc = 0.92578125\n",
      "Batch 84: loss = 0.2311602383852005, acc = 0.91796875\n",
      "Batch 85: loss = 0.26798319816589355, acc = 0.9033203125\n",
      "Batch 86: loss = 0.2564367949962616, acc = 0.9091796875\n",
      "Batch 87: loss = 0.2295604795217514, acc = 0.91796875\n",
      "Batch 88: loss = 0.23632501065731049, acc = 0.921875\n",
      "Batch 89: loss = 0.2311297059059143, acc = 0.923828125\n",
      "Batch 90: loss = 0.24910537898540497, acc = 0.9111328125\n",
      "Batch 91: loss = 0.24212157726287842, acc = 0.916015625\n",
      "Batch 92: loss = 0.2585223913192749, acc = 0.908203125\n",
      "Batch 93: loss = 0.24132035672664642, acc = 0.92578125\n",
      "Batch 94: loss = 0.20659011602401733, acc = 0.9287109375\n",
      "Batch 95: loss = 0.24410739541053772, acc = 0.919921875\n",
      "Batch 96: loss = 0.2409549057483673, acc = 0.9111328125\n",
      "Batch 97: loss = 0.2535823583602905, acc = 0.9189453125\n",
      "Batch 98: loss = 0.2630770206451416, acc = 0.9111328125\n",
      "Batch 99: loss = 0.26573869585990906, acc = 0.912109375\n",
      "Batch 100: loss = 0.27514225244522095, acc = 0.900390625\n",
      "Batch 101: loss = 0.21809802949428558, acc = 0.91796875\n",
      "Batch 102: loss = 0.2674499452114105, acc = 0.9140625\n",
      "Batch 103: loss = 0.28220537304878235, acc = 0.8994140625\n",
      "Batch 104: loss = 0.23787415027618408, acc = 0.921875\n",
      "Batch 105: loss = 0.21556660532951355, acc = 0.9228515625\n",
      "Batch 106: loss = 0.23766390979290009, acc = 0.923828125\n",
      "Batch 107: loss = 0.29387593269348145, acc = 0.9091796875\n",
      "Batch 108: loss = 0.2334531545639038, acc = 0.927734375\n",
      "Batch 109: loss = 0.2223697155714035, acc = 0.9169921875\n",
      "Batch 110: loss = 0.24284198880195618, acc = 0.9228515625\n",
      "Batch 111: loss = 0.23323586583137512, acc = 0.9150390625\n",
      "Batch 112: loss = 0.23732523620128632, acc = 0.9248046875\n",
      "Batch 113: loss = 0.24427078664302826, acc = 0.9189453125\n",
      "Batch 114: loss = 0.26781323552131653, acc = 0.9091796875\n",
      "Batch 115: loss = 0.27024954557418823, acc = 0.90625\n",
      "Batch 116: loss = 0.2672625184059143, acc = 0.90625\n",
      "Batch 117: loss = 0.24390079081058502, acc = 0.9150390625\n",
      "Batch 118: loss = 0.25609922409057617, acc = 0.9169921875\n",
      "Batch 119: loss = 0.20203793048858643, acc = 0.93359375\n",
      "Batch 120: loss = 0.21189887821674347, acc = 0.9345703125\n",
      "Batch 121: loss = 0.24175187945365906, acc = 0.9208984375\n",
      "Batch 122: loss = 0.2364821434020996, acc = 0.9140625\n",
      "Batch 123: loss = 0.22380071878433228, acc = 0.927734375\n",
      "Batch 124: loss = 0.27101343870162964, acc = 0.9150390625\n",
      "Batch 125: loss = 0.2597458064556122, acc = 0.919921875\n",
      "Batch 126: loss = 0.25739482045173645, acc = 0.9140625\n",
      "\n",
      "Epoch 97/100\n",
      "Batch 1: loss = 0.2844315469264984, acc = 0.8984375\n",
      "Batch 2: loss = 0.2405218929052353, acc = 0.9111328125\n",
      "Batch 3: loss = 0.26357442140579224, acc = 0.916015625\n",
      "Batch 4: loss = 0.264534592628479, acc = 0.9140625\n",
      "Batch 5: loss = 0.23214232921600342, acc = 0.9267578125\n",
      "Batch 6: loss = 0.28649288415908813, acc = 0.8974609375\n",
      "Batch 7: loss = 0.23381701111793518, acc = 0.916015625\n",
      "Batch 8: loss = 0.2655158042907715, acc = 0.919921875\n",
      "Batch 9: loss = 0.26307955384254456, acc = 0.9130859375\n",
      "Batch 10: loss = 0.22544245421886444, acc = 0.919921875\n",
      "Batch 11: loss = 0.21876734495162964, acc = 0.923828125\n",
      "Batch 12: loss = 0.22923597693443298, acc = 0.9228515625\n",
      "Batch 13: loss = 0.2355174571275711, acc = 0.927734375\n",
      "Batch 14: loss = 0.261029452085495, acc = 0.9140625\n",
      "Batch 15: loss = 0.20948821306228638, acc = 0.9326171875\n",
      "Batch 16: loss = 0.27054592967033386, acc = 0.908203125\n",
      "Batch 17: loss = 0.23431406915187836, acc = 0.919921875\n",
      "Batch 18: loss = 0.2683632969856262, acc = 0.9072265625\n",
      "Batch 19: loss = 0.27630099654197693, acc = 0.8984375\n",
      "Batch 20: loss = 0.23773762583732605, acc = 0.919921875\n",
      "Batch 21: loss = 0.2615087032318115, acc = 0.912109375\n",
      "Batch 22: loss = 0.2575138807296753, acc = 0.9111328125\n",
      "Batch 23: loss = 0.259284645318985, acc = 0.9111328125\n",
      "Batch 24: loss = 0.24317578971385956, acc = 0.9169921875\n",
      "Batch 25: loss = 0.2781749963760376, acc = 0.912109375\n",
      "Batch 26: loss = 0.26567089557647705, acc = 0.9091796875\n",
      "Batch 27: loss = 0.29984167218208313, acc = 0.888671875\n",
      "Batch 28: loss = 0.25569549202919006, acc = 0.916015625\n",
      "Batch 29: loss = 0.2710542380809784, acc = 0.9072265625\n",
      "Batch 30: loss = 0.2531473934650421, acc = 0.9072265625\n",
      "Batch 31: loss = 0.2692199647426605, acc = 0.9169921875\n",
      "Batch 32: loss = 0.2589792013168335, acc = 0.908203125\n",
      "Batch 33: loss = 0.23396813869476318, acc = 0.91796875\n",
      "Batch 34: loss = 0.29632458090782166, acc = 0.8984375\n",
      "Batch 35: loss = 0.22960326075553894, acc = 0.921875\n",
      "Batch 36: loss = 0.24152857065200806, acc = 0.91796875\n",
      "Batch 37: loss = 0.214251309633255, acc = 0.92578125\n",
      "Batch 38: loss = 0.21620464324951172, acc = 0.931640625\n",
      "Batch 39: loss = 0.21629753708839417, acc = 0.9345703125\n",
      "Batch 40: loss = 0.2421635389328003, acc = 0.9130859375\n",
      "Batch 41: loss = 0.22460928559303284, acc = 0.9248046875\n",
      "Batch 42: loss = 0.27362293004989624, acc = 0.9091796875\n",
      "Batch 43: loss = 0.2522006928920746, acc = 0.9091796875\n",
      "Batch 44: loss = 0.21646654605865479, acc = 0.931640625\n",
      "Batch 45: loss = 0.2408643662929535, acc = 0.9228515625\n",
      "Batch 46: loss = 0.23866941034793854, acc = 0.9189453125\n",
      "Batch 47: loss = 0.2443998008966446, acc = 0.921875\n",
      "Batch 48: loss = 0.21011477708816528, acc = 0.927734375\n",
      "Batch 49: loss = 0.2587779462337494, acc = 0.912109375\n",
      "Batch 50: loss = 0.2154179811477661, acc = 0.9228515625\n",
      "Batch 51: loss = 0.23762798309326172, acc = 0.916015625\n",
      "Batch 52: loss = 0.23050493001937866, acc = 0.9189453125\n",
      "Batch 53: loss = 0.23531389236450195, acc = 0.9189453125\n",
      "Batch 54: loss = 0.2258775532245636, acc = 0.919921875\n",
      "Batch 55: loss = 0.2568836808204651, acc = 0.91015625\n",
      "Batch 56: loss = 0.2579366862773895, acc = 0.904296875\n",
      "Batch 57: loss = 0.27268868684768677, acc = 0.908203125\n",
      "Batch 58: loss = 0.2593267560005188, acc = 0.9130859375\n",
      "Batch 59: loss = 0.20892176032066345, acc = 0.93359375\n",
      "Batch 60: loss = 0.22619524598121643, acc = 0.9150390625\n",
      "Batch 61: loss = 0.20796602964401245, acc = 0.9326171875\n",
      "Batch 62: loss = 0.2570766508579254, acc = 0.919921875\n",
      "Batch 63: loss = 0.23914486169815063, acc = 0.91796875\n",
      "Batch 64: loss = 0.19383390247821808, acc = 0.943359375\n",
      "Batch 65: loss = 0.2529199719429016, acc = 0.9189453125\n",
      "Batch 66: loss = 0.230376735329628, acc = 0.92578125\n",
      "Batch 67: loss = 0.23782360553741455, acc = 0.9130859375\n",
      "Batch 68: loss = 0.2341790348291397, acc = 0.908203125\n",
      "Batch 69: loss = 0.22899842262268066, acc = 0.92578125\n",
      "Batch 70: loss = 0.26915714144706726, acc = 0.90625\n",
      "Batch 71: loss = 0.26631349325180054, acc = 0.90625\n",
      "Batch 72: loss = 0.2548488676548004, acc = 0.912109375\n",
      "Batch 73: loss = 0.2914866805076599, acc = 0.8974609375\n",
      "Batch 74: loss = 0.2911567687988281, acc = 0.900390625\n",
      "Batch 75: loss = 0.25982964038848877, acc = 0.9169921875\n",
      "Batch 76: loss = 0.2775137424468994, acc = 0.9091796875\n",
      "Batch 77: loss = 0.23592546582221985, acc = 0.9140625\n",
      "Batch 78: loss = 0.25635677576065063, acc = 0.9111328125\n",
      "Batch 79: loss = 0.2574767768383026, acc = 0.91015625\n",
      "Batch 80: loss = 0.21398331224918365, acc = 0.9248046875\n",
      "Batch 81: loss = 0.25452953577041626, acc = 0.9140625\n",
      "Batch 82: loss = 0.2450254261493683, acc = 0.9130859375\n",
      "Batch 83: loss = 0.23775433003902435, acc = 0.916015625\n",
      "Batch 84: loss = 0.2371484488248825, acc = 0.923828125\n",
      "Batch 85: loss = 0.2435947060585022, acc = 0.9189453125\n",
      "Batch 86: loss = 0.25713595747947693, acc = 0.916015625\n",
      "Batch 87: loss = 0.2563197612762451, acc = 0.912109375\n",
      "Batch 88: loss = 0.2691051661968231, acc = 0.908203125\n",
      "Batch 89: loss = 0.22261330485343933, acc = 0.9296875\n",
      "Batch 90: loss = 0.24436789751052856, acc = 0.9150390625\n",
      "Batch 91: loss = 0.2589386999607086, acc = 0.91796875\n",
      "Batch 92: loss = 0.24502822756767273, acc = 0.9150390625\n",
      "Batch 93: loss = 0.24898642301559448, acc = 0.919921875\n",
      "Batch 94: loss = 0.22213716804981232, acc = 0.9169921875\n",
      "Batch 95: loss = 0.23636606335639954, acc = 0.92578125\n",
      "Batch 96: loss = 0.2774423658847809, acc = 0.8984375\n",
      "Batch 97: loss = 0.24230992794036865, acc = 0.9189453125\n",
      "Batch 98: loss = 0.24882113933563232, acc = 0.9169921875\n",
      "Batch 99: loss = 0.2473604679107666, acc = 0.9033203125\n",
      "Batch 100: loss = 0.2770806550979614, acc = 0.896484375\n",
      "Batch 101: loss = 0.22892910242080688, acc = 0.9267578125\n",
      "Batch 102: loss = 0.2595812976360321, acc = 0.9169921875\n",
      "Batch 103: loss = 0.24416802823543549, acc = 0.9140625\n",
      "Batch 104: loss = 0.2394188940525055, acc = 0.9189453125\n",
      "Batch 105: loss = 0.1759946346282959, acc = 0.9345703125\n",
      "Batch 106: loss = 0.23363956809043884, acc = 0.9287109375\n",
      "Batch 107: loss = 0.2320663034915924, acc = 0.9189453125\n",
      "Batch 108: loss = 0.2737167477607727, acc = 0.90234375\n",
      "Batch 109: loss = 0.25451168417930603, acc = 0.9111328125\n",
      "Batch 110: loss = 0.2632001042366028, acc = 0.916015625\n",
      "Batch 111: loss = 0.26145216822624207, acc = 0.9140625\n",
      "Batch 112: loss = 0.25153738260269165, acc = 0.9072265625\n",
      "Batch 113: loss = 0.23012658953666687, acc = 0.9150390625\n",
      "Batch 114: loss = 0.2907126247882843, acc = 0.904296875\n",
      "Batch 115: loss = 0.24967215955257416, acc = 0.916015625\n",
      "Batch 116: loss = 0.2756175696849823, acc = 0.91015625\n",
      "Batch 117: loss = 0.2638362944126129, acc = 0.916015625\n",
      "Batch 118: loss = 0.24332845211029053, acc = 0.912109375\n",
      "Batch 119: loss = 0.23485341668128967, acc = 0.9208984375\n",
      "Batch 120: loss = 0.19044673442840576, acc = 0.93359375\n",
      "Batch 121: loss = 0.24708302319049835, acc = 0.91796875\n",
      "Batch 122: loss = 0.23030370473861694, acc = 0.919921875\n",
      "Batch 123: loss = 0.22842897474765778, acc = 0.931640625\n",
      "Batch 124: loss = 0.2742759585380554, acc = 0.908203125\n",
      "Batch 125: loss = 0.2149309366941452, acc = 0.931640625\n",
      "Batch 126: loss = 0.2739875614643097, acc = 0.9130859375\n",
      "\n",
      "Epoch 98/100\n",
      "Batch 1: loss = 0.30177661776542664, acc = 0.908203125\n",
      "Batch 2: loss = 0.2572117745876312, acc = 0.9150390625\n",
      "Batch 3: loss = 0.24535533785820007, acc = 0.9140625\n",
      "Batch 4: loss = 0.23127539455890656, acc = 0.9228515625\n",
      "Batch 5: loss = 0.2090194672346115, acc = 0.935546875\n",
      "Batch 6: loss = 0.2319849580526352, acc = 0.92578125\n",
      "Batch 7: loss = 0.2296292930841446, acc = 0.9248046875\n",
      "Batch 8: loss = 0.23519405722618103, acc = 0.923828125\n",
      "Batch 9: loss = 0.25600185990333557, acc = 0.9208984375\n",
      "Batch 10: loss = 0.22798459231853485, acc = 0.9189453125\n",
      "Batch 11: loss = 0.21510010957717896, acc = 0.919921875\n",
      "Batch 12: loss = 0.2443738579750061, acc = 0.9130859375\n",
      "Batch 13: loss = 0.24622519314289093, acc = 0.91796875\n",
      "Batch 14: loss = 0.23968541622161865, acc = 0.919921875\n",
      "Batch 15: loss = 0.22176915407180786, acc = 0.9267578125\n",
      "Batch 16: loss = 0.26636290550231934, acc = 0.912109375\n",
      "Batch 17: loss = 0.23257966339588165, acc = 0.9228515625\n",
      "Batch 18: loss = 0.26722970604896545, acc = 0.91796875\n",
      "Batch 19: loss = 0.23618865013122559, acc = 0.9169921875\n",
      "Batch 20: loss = 0.2557060122489929, acc = 0.90625\n",
      "Batch 21: loss = 0.2629668712615967, acc = 0.9111328125\n",
      "Batch 22: loss = 0.2772449851036072, acc = 0.908203125\n",
      "Batch 23: loss = 0.28441935777664185, acc = 0.900390625\n",
      "Batch 24: loss = 0.26109400391578674, acc = 0.90234375\n",
      "Batch 25: loss = 0.2702476680278778, acc = 0.90625\n",
      "Batch 26: loss = 0.24851001799106598, acc = 0.927734375\n",
      "Batch 27: loss = 0.2820824384689331, acc = 0.896484375\n",
      "Batch 28: loss = 0.26159414649009705, acc = 0.904296875\n",
      "Batch 29: loss = 0.28564774990081787, acc = 0.900390625\n",
      "Batch 30: loss = 0.24818503856658936, acc = 0.90625\n",
      "Batch 31: loss = 0.25971052050590515, acc = 0.916015625\n",
      "Batch 32: loss = 0.2667519450187683, acc = 0.9130859375\n",
      "Batch 33: loss = 0.20584997534751892, acc = 0.93359375\n",
      "Batch 34: loss = 0.24316619336605072, acc = 0.9140625\n",
      "Batch 35: loss = 0.2559831142425537, acc = 0.90625\n",
      "Batch 36: loss = 0.21005597710609436, acc = 0.9248046875\n",
      "Batch 37: loss = 0.2228366732597351, acc = 0.923828125\n",
      "Batch 38: loss = 0.24802637100219727, acc = 0.9208984375\n",
      "Batch 39: loss = 0.2290663868188858, acc = 0.931640625\n",
      "Batch 40: loss = 0.22203806042671204, acc = 0.9287109375\n",
      "Batch 41: loss = 0.23169082403182983, acc = 0.919921875\n",
      "Batch 42: loss = 0.22646819055080414, acc = 0.9267578125\n",
      "Batch 43: loss = 0.2673908770084381, acc = 0.9052734375\n",
      "Batch 44: loss = 0.22103717923164368, acc = 0.9267578125\n",
      "Batch 45: loss = 0.2535053789615631, acc = 0.9267578125\n",
      "Batch 46: loss = 0.20792162418365479, acc = 0.927734375\n",
      "Batch 47: loss = 0.23468494415283203, acc = 0.9150390625\n",
      "Batch 48: loss = 0.25864672660827637, acc = 0.9140625\n",
      "Batch 49: loss = 0.21979936957359314, acc = 0.9296875\n",
      "Batch 50: loss = 0.2345920354127884, acc = 0.919921875\n",
      "Batch 51: loss = 0.2753971517086029, acc = 0.908203125\n",
      "Batch 52: loss = 0.26914647221565247, acc = 0.912109375\n",
      "Batch 53: loss = 0.22430390119552612, acc = 0.927734375\n",
      "Batch 54: loss = 0.18795417249202728, acc = 0.939453125\n",
      "Batch 55: loss = 0.2231127917766571, acc = 0.9208984375\n",
      "Batch 56: loss = 0.23076200485229492, acc = 0.9130859375\n",
      "Batch 57: loss = 0.27507126331329346, acc = 0.8994140625\n",
      "Batch 58: loss = 0.2776244580745697, acc = 0.916015625\n",
      "Batch 59: loss = 0.2119365781545639, acc = 0.9287109375\n",
      "Batch 60: loss = 0.2726435363292694, acc = 0.9072265625\n",
      "Batch 61: loss = 0.19379234313964844, acc = 0.9326171875\n",
      "Batch 62: loss = 0.2634463608264923, acc = 0.9140625\n",
      "Batch 63: loss = 0.249630868434906, acc = 0.9140625\n",
      "Batch 64: loss = 0.21967360377311707, acc = 0.9287109375\n",
      "Batch 65: loss = 0.2569274604320526, acc = 0.91796875\n",
      "Batch 66: loss = 0.2559678256511688, acc = 0.9130859375\n",
      "Batch 67: loss = 0.25172415375709534, acc = 0.9208984375\n",
      "Batch 68: loss = 0.2757863700389862, acc = 0.9150390625\n",
      "Batch 69: loss = 0.23870199918746948, acc = 0.9248046875\n",
      "Batch 70: loss = 0.2611940801143646, acc = 0.908203125\n",
      "Batch 71: loss = 0.26789355278015137, acc = 0.912109375\n",
      "Batch 72: loss = 0.23652119934558868, acc = 0.92578125\n",
      "Batch 73: loss = 0.26324933767318726, acc = 0.908203125\n",
      "Batch 74: loss = 0.2649403214454651, acc = 0.9072265625\n",
      "Batch 75: loss = 0.2907814085483551, acc = 0.8984375\n",
      "Batch 76: loss = 0.27009719610214233, acc = 0.9111328125\n",
      "Batch 77: loss = 0.232746884226799, acc = 0.9228515625\n",
      "Batch 78: loss = 0.26460564136505127, acc = 0.908203125\n",
      "Batch 79: loss = 0.23054246604442596, acc = 0.921875\n",
      "Batch 80: loss = 0.21550652384757996, acc = 0.9423828125\n",
      "Batch 81: loss = 0.24175894260406494, acc = 0.9130859375\n",
      "Batch 82: loss = 0.23556315898895264, acc = 0.9208984375\n",
      "Batch 83: loss = 0.22251276671886444, acc = 0.9248046875\n",
      "Batch 84: loss = 0.2699730098247528, acc = 0.9091796875\n",
      "Batch 85: loss = 0.26731619238853455, acc = 0.9033203125\n",
      "Batch 86: loss = 0.2241974174976349, acc = 0.9248046875\n",
      "Batch 87: loss = 0.23398812115192413, acc = 0.9267578125\n",
      "Batch 88: loss = 0.2540498971939087, acc = 0.916015625\n",
      "Batch 89: loss = 0.23531754314899445, acc = 0.923828125\n",
      "Batch 90: loss = 0.24259653687477112, acc = 0.912109375\n",
      "Batch 91: loss = 0.2290535569190979, acc = 0.9287109375\n",
      "Batch 92: loss = 0.235411137342453, acc = 0.9189453125\n",
      "Batch 93: loss = 0.2298075407743454, acc = 0.9208984375\n",
      "Batch 94: loss = 0.2297331988811493, acc = 0.9267578125\n",
      "Batch 95: loss = 0.21582606434822083, acc = 0.9248046875\n",
      "Batch 96: loss = 0.25958943367004395, acc = 0.9111328125\n",
      "Batch 97: loss = 0.2716628313064575, acc = 0.9072265625\n",
      "Batch 98: loss = 0.24957723915576935, acc = 0.916015625\n",
      "Batch 99: loss = 0.25520095229148865, acc = 0.9169921875\n",
      "Batch 100: loss = 0.23916929960250854, acc = 0.9111328125\n",
      "Batch 101: loss = 0.22427351772785187, acc = 0.9189453125\n",
      "Batch 102: loss = 0.26862838864326477, acc = 0.904296875\n",
      "Batch 103: loss = 0.26355287432670593, acc = 0.9208984375\n",
      "Batch 104: loss = 0.22527727484703064, acc = 0.9208984375\n",
      "Batch 105: loss = 0.22491231560707092, acc = 0.923828125\n",
      "Batch 106: loss = 0.23583190143108368, acc = 0.921875\n",
      "Batch 107: loss = 0.23723098635673523, acc = 0.9150390625\n",
      "Batch 108: loss = 0.23213405907154083, acc = 0.919921875\n",
      "Batch 109: loss = 0.2205916792154312, acc = 0.90625\n",
      "Batch 110: loss = 0.2225698083639145, acc = 0.921875\n",
      "Batch 111: loss = 0.2174016833305359, acc = 0.92578125\n",
      "Batch 112: loss = 0.22154808044433594, acc = 0.92578125\n",
      "Batch 113: loss = 0.25804343819618225, acc = 0.91796875\n",
      "Batch 114: loss = 0.2611885964870453, acc = 0.9228515625\n",
      "Batch 115: loss = 0.2157633900642395, acc = 0.931640625\n",
      "Batch 116: loss = 0.25243884325027466, acc = 0.9150390625\n",
      "Batch 117: loss = 0.2458019256591797, acc = 0.912109375\n",
      "Batch 118: loss = 0.23511157929897308, acc = 0.92578125\n",
      "Batch 119: loss = 0.2088187336921692, acc = 0.9306640625\n",
      "Batch 120: loss = 0.19022513926029205, acc = 0.9375\n",
      "Batch 121: loss = 0.23114371299743652, acc = 0.9208984375\n",
      "Batch 122: loss = 0.2241102159023285, acc = 0.9287109375\n",
      "Batch 123: loss = 0.2456716001033783, acc = 0.9189453125\n",
      "Batch 124: loss = 0.2348477840423584, acc = 0.9267578125\n",
      "Batch 125: loss = 0.2387271225452423, acc = 0.923828125\n",
      "Batch 126: loss = 0.22392158210277557, acc = 0.92578125\n",
      "\n",
      "Epoch 99/100\n",
      "Batch 1: loss = 0.2823183238506317, acc = 0.916015625\n",
      "Batch 2: loss = 0.2671109735965729, acc = 0.90234375\n",
      "Batch 3: loss = 0.2475854754447937, acc = 0.9111328125\n",
      "Batch 4: loss = 0.2354852855205536, acc = 0.9150390625\n",
      "Batch 5: loss = 0.23351244628429413, acc = 0.9228515625\n",
      "Batch 6: loss = 0.25263527035713196, acc = 0.91796875\n",
      "Batch 7: loss = 0.2275668829679489, acc = 0.91796875\n",
      "Batch 8: loss = 0.24581752717494965, acc = 0.9130859375\n",
      "Batch 9: loss = 0.2417672872543335, acc = 0.916015625\n",
      "Batch 10: loss = 0.21795858442783356, acc = 0.9296875\n",
      "Batch 11: loss = 0.23594579100608826, acc = 0.91796875\n",
      "Batch 12: loss = 0.24231399595737457, acc = 0.9189453125\n",
      "Batch 13: loss = 0.2551804780960083, acc = 0.9072265625\n",
      "Batch 14: loss = 0.22909024357795715, acc = 0.9228515625\n",
      "Batch 15: loss = 0.20079700648784637, acc = 0.9248046875\n",
      "Batch 16: loss = 0.24963147938251495, acc = 0.9052734375\n",
      "Batch 17: loss = 0.22887751460075378, acc = 0.923828125\n",
      "Batch 18: loss = 0.24153852462768555, acc = 0.923828125\n",
      "Batch 19: loss = 0.25023674964904785, acc = 0.9111328125\n",
      "Batch 20: loss = 0.2502635419368744, acc = 0.921875\n",
      "Batch 21: loss = 0.2651159167289734, acc = 0.919921875\n",
      "Batch 22: loss = 0.24493497610092163, acc = 0.92578125\n",
      "Batch 23: loss = 0.25868162512779236, acc = 0.9208984375\n",
      "Batch 24: loss = 0.23946037888526917, acc = 0.9169921875\n",
      "Batch 25: loss = 0.25274842977523804, acc = 0.9169921875\n",
      "Batch 26: loss = 0.2556201219558716, acc = 0.9169921875\n",
      "Batch 27: loss = 0.3006020188331604, acc = 0.8955078125\n",
      "Batch 28: loss = 0.24132394790649414, acc = 0.9208984375\n",
      "Batch 29: loss = 0.26915204524993896, acc = 0.9111328125\n",
      "Batch 30: loss = 0.24437305331230164, acc = 0.91015625\n",
      "Batch 31: loss = 0.2511638402938843, acc = 0.9248046875\n",
      "Batch 32: loss = 0.2742012143135071, acc = 0.904296875\n",
      "Batch 33: loss = 0.205524742603302, acc = 0.93359375\n",
      "Batch 34: loss = 0.25423651933670044, acc = 0.9130859375\n",
      "Batch 35: loss = 0.24696384370326996, acc = 0.9150390625\n",
      "Batch 36: loss = 0.21605774760246277, acc = 0.9208984375\n",
      "Batch 37: loss = 0.21106413006782532, acc = 0.931640625\n",
      "Batch 38: loss = 0.234023317694664, acc = 0.9306640625\n",
      "Batch 39: loss = 0.25546377897262573, acc = 0.9169921875\n",
      "Batch 40: loss = 0.23315399885177612, acc = 0.912109375\n",
      "Batch 41: loss = 0.20514726638793945, acc = 0.9345703125\n",
      "Batch 42: loss = 0.2240763157606125, acc = 0.923828125\n",
      "Batch 43: loss = 0.2455182671546936, acc = 0.9072265625\n",
      "Batch 44: loss = 0.2305864542722702, acc = 0.9287109375\n",
      "Batch 45: loss = 0.2285180687904358, acc = 0.9267578125\n",
      "Batch 46: loss = 0.22750145196914673, acc = 0.916015625\n",
      "Batch 47: loss = 0.2564500570297241, acc = 0.9111328125\n",
      "Batch 48: loss = 0.23235373198986053, acc = 0.92578125\n",
      "Batch 49: loss = 0.21127185225486755, acc = 0.93359375\n",
      "Batch 50: loss = 0.24997828900814056, acc = 0.9189453125\n",
      "Batch 51: loss = 0.23974165320396423, acc = 0.91015625\n",
      "Batch 52: loss = 0.2486945241689682, acc = 0.9130859375\n",
      "Batch 53: loss = 0.2419828623533249, acc = 0.921875\n",
      "Batch 54: loss = 0.19367697834968567, acc = 0.9365234375\n",
      "Batch 55: loss = 0.2388589084148407, acc = 0.921875\n",
      "Batch 56: loss = 0.23909956216812134, acc = 0.9150390625\n",
      "Batch 57: loss = 0.2821495831012726, acc = 0.9052734375\n",
      "Batch 58: loss = 0.28204402327537537, acc = 0.908203125\n",
      "Batch 59: loss = 0.21612109243869781, acc = 0.9296875\n",
      "Batch 60: loss = 0.24568994343280792, acc = 0.921875\n",
      "Batch 61: loss = 0.20354607701301575, acc = 0.9296875\n",
      "Batch 62: loss = 0.27508458495140076, acc = 0.91015625\n",
      "Batch 63: loss = 0.22708465158939362, acc = 0.919921875\n",
      "Batch 64: loss = 0.2165793627500534, acc = 0.9287109375\n",
      "Batch 65: loss = 0.2610918879508972, acc = 0.90625\n",
      "Batch 66: loss = 0.24656377732753754, acc = 0.9150390625\n",
      "Batch 67: loss = 0.2206386774778366, acc = 0.916015625\n",
      "Batch 68: loss = 0.259201318025589, acc = 0.9013671875\n",
      "Batch 69: loss = 0.23865506052970886, acc = 0.9208984375\n",
      "Batch 70: loss = 0.2396220564842224, acc = 0.9267578125\n",
      "Batch 71: loss = 0.2272232472896576, acc = 0.9287109375\n",
      "Batch 72: loss = 0.23266230523586273, acc = 0.919921875\n",
      "Batch 73: loss = 0.2664411962032318, acc = 0.91015625\n",
      "Batch 74: loss = 0.2349800020456314, acc = 0.921875\n",
      "Batch 75: loss = 0.2616649866104126, acc = 0.904296875\n",
      "Batch 76: loss = 0.25784173607826233, acc = 0.91796875\n",
      "Batch 77: loss = 0.2183389663696289, acc = 0.9248046875\n",
      "Batch 78: loss = 0.2584279477596283, acc = 0.919921875\n",
      "Batch 79: loss = 0.24267196655273438, acc = 0.912109375\n",
      "Batch 80: loss = 0.23590682446956635, acc = 0.9130859375\n",
      "Batch 81: loss = 0.2522764503955841, acc = 0.919921875\n",
      "Batch 82: loss = 0.22750376164913177, acc = 0.9228515625\n",
      "Batch 83: loss = 0.20257344841957092, acc = 0.93359375\n",
      "Batch 84: loss = 0.2339995950460434, acc = 0.91796875\n",
      "Batch 85: loss = 0.28663569688796997, acc = 0.8955078125\n",
      "Batch 86: loss = 0.22827327251434326, acc = 0.9189453125\n",
      "Batch 87: loss = 0.25140368938446045, acc = 0.9228515625\n",
      "Batch 88: loss = 0.25549840927124023, acc = 0.919921875\n",
      "Batch 89: loss = 0.21809493005275726, acc = 0.931640625\n",
      "Batch 90: loss = 0.24532800912857056, acc = 0.916015625\n",
      "Batch 91: loss = 0.21864378452301025, acc = 0.927734375\n",
      "Batch 92: loss = 0.2392870932817459, acc = 0.9130859375\n",
      "Batch 93: loss = 0.20873504877090454, acc = 0.9296875\n",
      "Batch 94: loss = 0.23488149046897888, acc = 0.9228515625\n",
      "Batch 95: loss = 0.22232793271541595, acc = 0.9248046875\n",
      "Batch 96: loss = 0.2936817407608032, acc = 0.9013671875\n",
      "Batch 97: loss = 0.2493773251771927, acc = 0.923828125\n",
      "Batch 98: loss = 0.23972930014133453, acc = 0.9091796875\n",
      "Batch 99: loss = 0.25914251804351807, acc = 0.9091796875\n",
      "Batch 100: loss = 0.2427273839712143, acc = 0.9150390625\n",
      "Batch 101: loss = 0.2497011423110962, acc = 0.9072265625\n",
      "Batch 102: loss = 0.2563828229904175, acc = 0.9091796875\n",
      "Batch 103: loss = 0.2525792419910431, acc = 0.912109375\n",
      "Batch 104: loss = 0.23030410706996918, acc = 0.927734375\n",
      "Batch 105: loss = 0.19917668402194977, acc = 0.9384765625\n",
      "Batch 106: loss = 0.23100769519805908, acc = 0.9248046875\n",
      "Batch 107: loss = 0.22690317034721375, acc = 0.9140625\n",
      "Batch 108: loss = 0.23385487496852875, acc = 0.9169921875\n",
      "Batch 109: loss = 0.26212480664253235, acc = 0.9072265625\n",
      "Batch 110: loss = 0.2599684000015259, acc = 0.921875\n",
      "Batch 111: loss = 0.23345020413398743, acc = 0.91796875\n",
      "Batch 112: loss = 0.23749585449695587, acc = 0.921875\n",
      "Batch 113: loss = 0.23852717876434326, acc = 0.9208984375\n",
      "Batch 114: loss = 0.2337019443511963, acc = 0.9189453125\n",
      "Batch 115: loss = 0.24253696203231812, acc = 0.9189453125\n",
      "Batch 116: loss = 0.25938722491264343, acc = 0.912109375\n",
      "Batch 117: loss = 0.25549307465553284, acc = 0.9130859375\n",
      "Batch 118: loss = 0.21178443729877472, acc = 0.9287109375\n",
      "Batch 119: loss = 0.20794890820980072, acc = 0.9296875\n",
      "Batch 120: loss = 0.23683446645736694, acc = 0.912109375\n",
      "Batch 121: loss = 0.21245254576206207, acc = 0.927734375\n",
      "Batch 122: loss = 0.21994951367378235, acc = 0.931640625\n",
      "Batch 123: loss = 0.2260027825832367, acc = 0.9326171875\n",
      "Batch 124: loss = 0.20492814481258392, acc = 0.93359375\n",
      "Batch 125: loss = 0.26866817474365234, acc = 0.91796875\n",
      "Batch 126: loss = 0.25143665075302124, acc = 0.9189453125\n",
      "\n",
      "Epoch 100/100\n",
      "Batch 1: loss = 0.32177290320396423, acc = 0.900390625\n",
      "Batch 2: loss = 0.25811055302619934, acc = 0.91015625\n",
      "Batch 3: loss = 0.2500820457935333, acc = 0.9130859375\n",
      "Batch 4: loss = 0.2544202208518982, acc = 0.9150390625\n",
      "Batch 5: loss = 0.2229447215795517, acc = 0.9228515625\n",
      "Batch 6: loss = 0.24572022259235382, acc = 0.9228515625\n",
      "Batch 7: loss = 0.2229623645544052, acc = 0.9208984375\n",
      "Batch 8: loss = 0.2252534180879593, acc = 0.9228515625\n",
      "Batch 9: loss = 0.23816576600074768, acc = 0.9267578125\n",
      "Batch 10: loss = 0.21378213167190552, acc = 0.927734375\n",
      "Batch 11: loss = 0.25367501378059387, acc = 0.91796875\n",
      "Batch 12: loss = 0.2421744167804718, acc = 0.9189453125\n",
      "Batch 13: loss = 0.23565061390399933, acc = 0.916015625\n",
      "Batch 14: loss = 0.2348567694425583, acc = 0.9189453125\n",
      "Batch 15: loss = 0.21695110201835632, acc = 0.927734375\n",
      "Batch 16: loss = 0.26579055190086365, acc = 0.9091796875\n",
      "Batch 17: loss = 0.23276866972446442, acc = 0.9189453125\n",
      "Batch 18: loss = 0.26934200525283813, acc = 0.9130859375\n",
      "Batch 19: loss = 0.24639466404914856, acc = 0.92578125\n",
      "Batch 20: loss = 0.2515720725059509, acc = 0.9189453125\n",
      "Batch 21: loss = 0.2475937306880951, acc = 0.919921875\n",
      "Batch 22: loss = 0.25121626257896423, acc = 0.9267578125\n",
      "Batch 23: loss = 0.267225056886673, acc = 0.90234375\n",
      "Batch 24: loss = 0.2676166892051697, acc = 0.9091796875\n",
      "Batch 25: loss = 0.24532262980937958, acc = 0.9208984375\n",
      "Batch 26: loss = 0.25195786356925964, acc = 0.9140625\n",
      "Batch 27: loss = 0.3242250680923462, acc = 0.8779296875\n",
      "Batch 28: loss = 0.2740418016910553, acc = 0.9091796875\n",
      "Batch 29: loss = 0.2675834596157074, acc = 0.91796875\n",
      "Batch 30: loss = 0.2683883309364319, acc = 0.900390625\n",
      "Batch 31: loss = 0.22266033291816711, acc = 0.9296875\n",
      "Batch 32: loss = 0.2863202393054962, acc = 0.9033203125\n",
      "Batch 33: loss = 0.23509225249290466, acc = 0.9208984375\n",
      "Batch 34: loss = 0.2563974857330322, acc = 0.90625\n",
      "Batch 35: loss = 0.2715214490890503, acc = 0.9091796875\n",
      "Batch 36: loss = 0.22354042530059814, acc = 0.923828125\n",
      "Batch 37: loss = 0.21545255184173584, acc = 0.9267578125\n",
      "Batch 38: loss = 0.22397305071353912, acc = 0.9267578125\n",
      "Batch 39: loss = 0.19738325476646423, acc = 0.94140625\n",
      "Batch 40: loss = 0.24623872339725494, acc = 0.9130859375\n",
      "Batch 41: loss = 0.2318817526102066, acc = 0.921875\n",
      "Batch 42: loss = 0.2462083101272583, acc = 0.91796875\n",
      "Batch 43: loss = 0.2495010495185852, acc = 0.9130859375\n",
      "Batch 44: loss = 0.21577639877796173, acc = 0.921875\n",
      "Batch 45: loss = 0.21313269436359406, acc = 0.9169921875\n",
      "Batch 46: loss = 0.228282168507576, acc = 0.919921875\n",
      "Batch 47: loss = 0.22907161712646484, acc = 0.923828125\n",
      "Batch 48: loss = 0.235181987285614, acc = 0.91796875\n",
      "Batch 49: loss = 0.25669625401496887, acc = 0.9189453125\n",
      "Batch 50: loss = 0.21528784930706024, acc = 0.9287109375\n",
      "Batch 51: loss = 0.198475182056427, acc = 0.9296875\n",
      "Batch 52: loss = 0.240138977766037, acc = 0.9140625\n",
      "Batch 53: loss = 0.22881412506103516, acc = 0.9169921875\n",
      "Batch 54: loss = 0.211422398686409, acc = 0.9228515625\n",
      "Batch 55: loss = 0.23873187601566315, acc = 0.921875\n",
      "Batch 56: loss = 0.23828747868537903, acc = 0.9140625\n",
      "Batch 57: loss = 0.27716904878616333, acc = 0.896484375\n",
      "Batch 58: loss = 0.28686457872390747, acc = 0.888671875\n",
      "Batch 59: loss = 0.23421208560466766, acc = 0.9208984375\n",
      "Batch 60: loss = 0.23642949759960175, acc = 0.92578125\n",
      "Batch 61: loss = 0.22122615575790405, acc = 0.9306640625\n",
      "Batch 62: loss = 0.2732544541358948, acc = 0.90234375\n",
      "Batch 63: loss = 0.23159471154212952, acc = 0.919921875\n",
      "Batch 64: loss = 0.22992858290672302, acc = 0.9169921875\n",
      "Batch 65: loss = 0.21894849836826324, acc = 0.923828125\n",
      "Batch 66: loss = 0.22335612773895264, acc = 0.92578125\n",
      "Batch 67: loss = 0.24235375225543976, acc = 0.916015625\n",
      "Batch 68: loss = 0.2646477520465851, acc = 0.91015625\n",
      "Batch 69: loss = 0.22392624616622925, acc = 0.931640625\n",
      "Batch 70: loss = 0.24928829073905945, acc = 0.9052734375\n",
      "Batch 71: loss = 0.24110069870948792, acc = 0.9130859375\n",
      "Batch 72: loss = 0.2359115481376648, acc = 0.9248046875\n",
      "Batch 73: loss = 0.2556270658969879, acc = 0.912109375\n",
      "Batch 74: loss = 0.29585349559783936, acc = 0.9111328125\n",
      "Batch 75: loss = 0.27065369486808777, acc = 0.9130859375\n",
      "Batch 76: loss = 0.23673567175865173, acc = 0.9052734375\n",
      "Batch 77: loss = 0.23500843346118927, acc = 0.919921875\n",
      "Batch 78: loss = 0.257146954536438, acc = 0.9208984375\n",
      "Batch 79: loss = 0.24112291634082794, acc = 0.91796875\n",
      "Batch 80: loss = 0.19283203780651093, acc = 0.9375\n",
      "Batch 81: loss = 0.2323106825351715, acc = 0.9228515625\n",
      "Batch 82: loss = 0.25814032554626465, acc = 0.91796875\n",
      "Batch 83: loss = 0.2135712206363678, acc = 0.9267578125\n",
      "Batch 84: loss = 0.2600093185901642, acc = 0.9150390625\n",
      "Batch 85: loss = 0.2491246610879898, acc = 0.912109375\n",
      "Batch 86: loss = 0.22284597158432007, acc = 0.9248046875\n",
      "Batch 87: loss = 0.24245411157608032, acc = 0.921875\n",
      "Batch 88: loss = 0.24143251776695251, acc = 0.916015625\n",
      "Batch 89: loss = 0.20531421899795532, acc = 0.9345703125\n",
      "Batch 90: loss = 0.2391659915447235, acc = 0.9208984375\n",
      "Batch 91: loss = 0.2266758233308792, acc = 0.923828125\n",
      "Batch 92: loss = 0.24648602306842804, acc = 0.9091796875\n",
      "Batch 93: loss = 0.252313494682312, acc = 0.91015625\n",
      "Batch 94: loss = 0.19723020493984222, acc = 0.93359375\n",
      "Batch 95: loss = 0.2098972201347351, acc = 0.927734375\n",
      "Batch 96: loss = 0.2418525516986847, acc = 0.9189453125\n",
      "Batch 97: loss = 0.2325294464826584, acc = 0.91796875\n",
      "Batch 98: loss = 0.23436690866947174, acc = 0.9208984375\n",
      "Batch 99: loss = 0.23436138033866882, acc = 0.919921875\n",
      "Batch 100: loss = 0.229293555021286, acc = 0.916015625\n",
      "Batch 101: loss = 0.258045494556427, acc = 0.908203125\n",
      "Batch 102: loss = 0.22735746204853058, acc = 0.9208984375\n",
      "Batch 103: loss = 0.2013595551252365, acc = 0.935546875\n",
      "Batch 104: loss = 0.20715244114398956, acc = 0.9384765625\n",
      "Batch 105: loss = 0.19030143320560455, acc = 0.93359375\n",
      "Batch 106: loss = 0.22702711820602417, acc = 0.921875\n",
      "Batch 107: loss = 0.24029475450515747, acc = 0.9208984375\n",
      "Batch 108: loss = 0.23277361690998077, acc = 0.916015625\n",
      "Batch 109: loss = 0.23563499748706818, acc = 0.927734375\n",
      "Batch 110: loss = 0.21293853223323822, acc = 0.9306640625\n",
      "Batch 111: loss = 0.24718070030212402, acc = 0.9091796875\n",
      "Batch 112: loss = 0.23278385400772095, acc = 0.9189453125\n",
      "Batch 113: loss = 0.20977383852005005, acc = 0.927734375\n",
      "Batch 114: loss = 0.23712976276874542, acc = 0.9296875\n",
      "Batch 115: loss = 0.2429610788822174, acc = 0.91796875\n",
      "Batch 116: loss = 0.26384440064430237, acc = 0.904296875\n",
      "Batch 117: loss = 0.24039369821548462, acc = 0.91015625\n",
      "Batch 118: loss = 0.22693845629692078, acc = 0.923828125\n",
      "Batch 119: loss = 0.23379351198673248, acc = 0.91796875\n",
      "Batch 120: loss = 0.18455079197883606, acc = 0.935546875\n",
      "Batch 121: loss = 0.2230185717344284, acc = 0.9189453125\n",
      "Batch 122: loss = 0.23839440941810608, acc = 0.9130859375\n",
      "Batch 123: loss = 0.20958702266216278, acc = 0.92578125\n",
      "Batch 124: loss = 0.22540521621704102, acc = 0.9248046875\n",
      "Batch 125: loss = 0.25657621026039124, acc = 0.9091796875\n",
      "Batch 126: loss = 0.2396107316017151, acc = 0.9208984375\n",
      "Saved checkpoint to weights.100.h5\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "t = time.time()\n",
    "!python train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P2lM43pIY4k0",
    "outputId": "023665a3-932a-4212-dee2-eec211afbd78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "252.86412739753723\n"
     ]
    }
   ],
   "source": [
    "print(time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IxWrYbv2NE_n",
    "outputId": "ba682a72-d644-4f72-a5d8-eb4d67be7681"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: content/model/ (stored 0%)\n"
     ]
    }
   ],
   "source": [
    "!zip /content/model.zip /content/model/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZkhqmnFuPbLj"
   },
   "outputs": [],
   "source": [
    "!cp /content/model.zip /content/drive/MyDrive/_ML_PROJECTS/Music_generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lGXTqu3VQ4g0",
    "outputId": "73787b96-f95d-402d-ce53-750eecbb6534"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-22 19:29:36.515304: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "2022-07-22 19:29:41.375019: W tensorflow/core/data/root_dataset.cc:200] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-07-22 19:29:42.285023: W tensorflow/core/data/root_dataset.cc:200] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-07-22 19:29:42.522555: W tensorflow/core/data/root_dataset.cc:200] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-07-22 19:29:43.301025: W tensorflow/core/data/root_dataset.cc:200] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "g#####Qc#m#b\"b3 a2||\n",
      "f2g |\"Bm\"d2B B2F|\"Bm\"d2d \"E7\"e3|\"Am\"e2A ABc|\"Dm\"d3 -d2d|\n",
      "\"C\"e2d cBA|\"G\"B2c d3|\"C\"e2d c2B|\"F\"A3 -\"F7\"cde|\n",
      "\"Bb\"d2B \"F7\"c2A|\"Gm\n",
      "\"G2B \"D7\"AcA|\"Gm\"G3 -G2G|\"G7\"d2d \"C\"e3|\"C7\"g3 _e3|\"F\"A3 ||\n",
      "\n",
      "\n",
      "X: 171\n",
      "T:Logbenitar's\n",
      "% Nottingham Music Database\n",
      "Y:AABB\n",
      "S:Kevin Briggs, via EF\n",
      "M:4/4\n",
      "K:G\n",
      "M:6/8\n",
      "P:A\n",
      "d/2c/2|\"G\"B2B Bgf|\"C\"e2e efg|\"G\"ded Bdg|\"G\"fgf \"C\"e3|\"G/b\"d2d \"C\"efg|\"G\"dBG g2f|\n",
      "\"A7\"ecA Ace|\"D\"fgf f3|\"C\"ecg ece|\"G\"dBg gfg|\n",
      "\"Am\"ABA fed|\"Am\"eAA edc|\"D\"dfg agf|\"Em\"e3 -e2f|\n",
      "\"Em\"g2g b2a|g2f efg|\"Em\"e2e efg|\"A7\"a2A ABc|\"D\"d3 ||\n",
      "\n",
      "\n",
      "X: 69\n",
      "T:Davie's Brae\n",
      "% Nottingham Music Database\n",
      "S:Trad, arr Phil Rowe\n",
      "M:6/8\n",
      "K:G\n",
      "d|\"G\"Bdd gdd|\"D7\"def \"G\"g2d|\"C\"ede \"D7\"d2c|\"G\"BGG G2:|\n",
      "P:B\n",
      "d/2g/2|\"G\"b2a g2f|\"C\"e3 \"G/b\"d2d|\"Am\"cdc \"D7\"BcA|\"G\"G3 -G2:|\n",
      "\n",
      "\n",
      "X: 182\n",
      "T:The Lassie's Fancy\n",
      "% Nottingham Music Database\n",
      "S:Trad, arr Phil Rowe\n",
      "M:6/8\n",
      "K:D\n",
      "F|:\"D\"F3 \"A7/c+\"A2G|\"Bm\"FGF \"A7\"E3|\"D\"FEF AFD|\"G\"B=cd BAB|\n",
      "\"D\"Add \"A\"cBA|\"G\"BGB \"D\"AFD|\"Em\"E3 -E2c|\"E7\"B^de dcB|\"A\"A3 -A2||\n",
      "\n",
      "\n",
      "X: 334\n",
      "T:The Widow Magee\n",
      "% Nottingham Music Database\n",
      "S:Kevin Briggs, vi\n"
     ]
    }
   ],
   "source": [
    "!python sample.py 100 --len 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lmNGjiAUREuZ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "music_generation_340.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
